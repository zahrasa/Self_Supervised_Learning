{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Assignment09_partA&B.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jb7-Dp0xyFht",
        "jL14tdbrwt81"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uribtHOxyBVQ",
        "cellView": "form"
      },
      "source": [
        "#@title Load Libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb7-Dp0xyFht"
      },
      "source": [
        "# prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STjYIZjAyFxr"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_8WqL5TyMQD"
      },
      "source": [
        "unlabeld_index = np.ones(y_train.shape, np.bool)\n",
        "\n",
        "N = 20\n",
        "for i in range(10):\n",
        "  idx = np.where(y_train == i)[0][:N]\n",
        "  unlabeld_index[idx] = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xfGX-QKyNaQ"
      },
      "source": [
        "x_unlabeld = x_train[np.where(unlabeld_index)[0], ...]\n",
        "\n",
        "x_train = x_train[np.where(~unlabeld_index)[0], ...]\n",
        "y_train = y_train[np.where(~unlabeld_index)[0], ...]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrATJytqyR4a",
        "outputId": "8dbfa8f1-61c4-4b43-c23b-827f4d59a892"
      },
      "source": [
        "print(len(x_unlabeld))\n",
        "print(x_unlabeld.shape)\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "\n",
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49800\n",
            "(49800, 32, 32, 3)\n",
            "200\n",
            "200\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMJ_WEHjyTMk",
        "outputId": "9410f85a-46f7-4f79-eece-0e0f8f2f2900"
      },
      "source": [
        "# examples of categorical crossentropy\n",
        "cce = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# a labeled data from the second class\n",
        "y_true = [[0, 1, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# an ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# another ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.1, 0.4, 0.3, 0.2]]\n",
        "print(cce(y_true, y_pred).numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.051293306\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgQy-pPFM1I"
      },
      "source": [
        "# normalize\n",
        "x_train = x_train.astype(float) / 255\n",
        "x_test = x_test.astype(float) / 255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7QCVICLFfeR",
        "outputId": "ea4f4fdd-10f1-44b1-d2f4-0b786874b968"
      },
      "source": [
        "# convert label to one hot\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL14tdbrwt81"
      },
      "source": [
        "# First model\n",
        "training with 200 labeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ogB5LzXrv_",
        "outputId": "b0485d7d-c7c7-4136-a227-aa6e542bce47"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# define regularization norm 2\n",
        "reg = tf.keras.regularizers.l2(0.001)\n",
        "\n",
        "# input layer\n",
        "# model.add(tf.keras.Input(X_train[0].shape))  # 32x32 RGB images\n",
        "model.add(tf.keras.layers.Input((32,32,3)))\n",
        "\n",
        "# create the base model\n",
        "# First convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_1'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_1'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_1'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_1'))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_2'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_2'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_2'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_2'))\n",
        "\n",
        "# Third convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_3'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_3'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_3'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_3'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_3'))\n",
        "\n",
        "# add a Flatten layer\n",
        "model.add(tf.keras.layers.Flatten(name='Flatten'))\n",
        "\n",
        "# let's add fully-connected layers\n",
        "model.add(tf.keras.layers.Dense(1024, kernel_regularizer=reg, name='Dense_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_4'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_4'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_4'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, kernel_regularizer=reg, name='Dense_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_5'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_5'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_5'))\n",
        "\n",
        "\n",
        "# and a logistic layer -- let's say we have 10 classes\n",
        "model.add(tf.keras.layers.Dense(10, kernel_regularizer=reg, name='Dense_3'))\n",
        "model.add(tf.keras.layers.Activation('softmax', name='Act_6'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "BatchN_1 (BatchNormalization (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_1 (Activation)           (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_1 (MaxPooling2D)        (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "Drop_1 (Dropout)             (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 13, 13, 128)       147584    \n",
            "_________________________________________________________________\n",
            "BatchN_2 (BatchNormalization (None, 13, 13, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_2 (Activation)           (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_2 (MaxPooling2D)        (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_2 (Dropout)             (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "BatchN_3 (BatchNormalization (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "Act_3 (Activation)           (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "pool_3 (MaxPooling2D)        (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_3 (Dropout)             (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "Act_4 (Activation)           (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "BatchN_4 (BatchNormalization (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "Drop_4 (Dropout)             (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "Act_5 (Activation)           (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "BatchN_5 (BatchNormalization (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "Drop_5 (Dropout)             (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "Dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "Act_6 (Activation)           (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 962,698\n",
            "Trainable params: 959,626\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI6jdtfclNbh",
        "outputId": "f702f059-1ab5-4694-972b-65f031c5ab71"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=600)\n",
        "\n",
        "# train the model on the 200 labeld data for some epochs\n",
        "# test the model on the 10000 labeld data\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=6000,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1527/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3140 - accuracy: 0.9950 - val_loss: 3.7588 - val_accuracy: 0.3286\n",
            "Epoch 1528/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3180 - accuracy: 0.9900 - val_loss: 3.7726 - val_accuracy: 0.3291\n",
            "Epoch 1529/6000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 3.7641 - val_accuracy: 0.3277\n",
            "Epoch 1530/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.3090 - accuracy: 0.9950 - val_loss: 3.9046 - val_accuracy: 0.3231\n",
            "Epoch 1531/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 3.8812 - val_accuracy: 0.3229\n",
            "Epoch 1532/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.3071 - accuracy: 0.9900 - val_loss: 4.1506 - val_accuracy: 0.3045\n",
            "Epoch 1533/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3268 - accuracy: 0.9950 - val_loss: 3.8498 - val_accuracy: 0.3240\n",
            "Epoch 1534/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3041 - accuracy: 1.0000 - val_loss: 3.8514 - val_accuracy: 0.3288\n",
            "Epoch 1535/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2965 - accuracy: 1.0000 - val_loss: 3.9179 - val_accuracy: 0.3218\n",
            "Epoch 1536/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 3.8753 - val_accuracy: 0.3319\n",
            "Epoch 1537/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 3.8888 - val_accuracy: 0.3342\n",
            "Epoch 1538/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3133 - accuracy: 0.9900 - val_loss: 3.7733 - val_accuracy: 0.3538\n",
            "Epoch 1539/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3044 - accuracy: 0.9900 - val_loss: 3.8198 - val_accuracy: 0.3502\n",
            "Epoch 1540/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3198 - accuracy: 0.9900 - val_loss: 3.7873 - val_accuracy: 0.3500\n",
            "Epoch 1541/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3226 - accuracy: 0.9850 - val_loss: 3.8826 - val_accuracy: 0.3434\n",
            "Epoch 1542/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2943 - accuracy: 1.0000 - val_loss: 3.8589 - val_accuracy: 0.3449\n",
            "Epoch 1543/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3153 - accuracy: 0.9900 - val_loss: 3.8328 - val_accuracy: 0.3484\n",
            "Epoch 1544/6000\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.3288 - accuracy: 0.9900 - val_loss: 3.7768 - val_accuracy: 0.3546\n",
            "Epoch 1545/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3277 - accuracy: 0.9900 - val_loss: 3.8488 - val_accuracy: 0.3530\n",
            "Epoch 1546/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2989 - accuracy: 0.9950 - val_loss: 3.9408 - val_accuracy: 0.3528\n",
            "Epoch 1547/6000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.3124 - accuracy: 0.9950 - val_loss: 3.9621 - val_accuracy: 0.3498\n",
            "Epoch 1548/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 3.9268 - val_accuracy: 0.3535\n",
            "Epoch 1549/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3337 - accuracy: 0.9900 - val_loss: 3.9779 - val_accuracy: 0.3411\n",
            "Epoch 1550/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3010 - accuracy: 0.9950 - val_loss: 3.9050 - val_accuracy: 0.3572\n",
            "Epoch 1551/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3058 - accuracy: 0.9900 - val_loss: 3.7806 - val_accuracy: 0.3600\n",
            "Epoch 1552/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.3207 - accuracy: 0.9900 - val_loss: 3.8833 - val_accuracy: 0.3451\n",
            "Epoch 1553/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.3120 - accuracy: 0.9950 - val_loss: 3.8208 - val_accuracy: 0.3498\n",
            "Epoch 1554/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3065 - accuracy: 0.9950 - val_loss: 3.8306 - val_accuracy: 0.3501\n",
            "Epoch 1555/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.3618 - accuracy: 0.9850 - val_loss: 4.0084 - val_accuracy: 0.3418\n",
            "Epoch 1556/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 3.9004 - val_accuracy: 0.3491\n",
            "Epoch 1557/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 3.9259 - val_accuracy: 0.3507\n",
            "Epoch 1558/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2973 - accuracy: 0.9950 - val_loss: 4.0280 - val_accuracy: 0.3453\n",
            "Epoch 1559/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3013 - accuracy: 0.9950 - val_loss: 3.8667 - val_accuracy: 0.3579\n",
            "Epoch 1560/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2894 - accuracy: 1.0000 - val_loss: 3.7903 - val_accuracy: 0.3601\n",
            "Epoch 1561/6000\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.3001 - accuracy: 0.9950 - val_loss: 3.7777 - val_accuracy: 0.3582\n",
            "Epoch 1562/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3156 - accuracy: 0.9900 - val_loss: 3.7569 - val_accuracy: 0.3522\n",
            "Epoch 1563/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2941 - accuracy: 0.9950 - val_loss: 3.7456 - val_accuracy: 0.3482\n",
            "Epoch 1564/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3366 - accuracy: 0.9800 - val_loss: 4.1336 - val_accuracy: 0.3118\n",
            "Epoch 1565/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3028 - accuracy: 0.9950 - val_loss: 3.9156 - val_accuracy: 0.3167\n",
            "Epoch 1566/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2937 - accuracy: 1.0000 - val_loss: 3.8652 - val_accuracy: 0.3215\n",
            "Epoch 1567/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2936 - accuracy: 1.0000 - val_loss: 3.7894 - val_accuracy: 0.3313\n",
            "Epoch 1568/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2996 - accuracy: 0.9950 - val_loss: 3.6459 - val_accuracy: 0.3471\n",
            "Epoch 1569/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2934 - accuracy: 1.0000 - val_loss: 3.6314 - val_accuracy: 0.3465\n",
            "Epoch 1570/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 3.6408 - val_accuracy: 0.3445\n",
            "Epoch 1571/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3119 - accuracy: 0.9900 - val_loss: 3.5758 - val_accuracy: 0.3482\n",
            "Epoch 1572/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2906 - accuracy: 0.9950 - val_loss: 3.6397 - val_accuracy: 0.3508\n",
            "Epoch 1573/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.3131 - accuracy: 0.9850 - val_loss: 3.8660 - val_accuracy: 0.3364\n",
            "Epoch 1574/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2921 - accuracy: 1.0000 - val_loss: 3.8065 - val_accuracy: 0.3367\n",
            "Epoch 1575/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3124 - accuracy: 0.9900 - val_loss: 3.7020 - val_accuracy: 0.3435\n",
            "Epoch 1576/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2957 - accuracy: 0.9950 - val_loss: 3.8013 - val_accuracy: 0.3356\n",
            "Epoch 1577/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3144 - accuracy: 0.9850 - val_loss: 3.8928 - val_accuracy: 0.3196\n",
            "Epoch 1578/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3215 - accuracy: 0.9800 - val_loss: 4.2203 - val_accuracy: 0.3023\n",
            "Epoch 1579/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2915 - accuracy: 0.9950 - val_loss: 4.1315 - val_accuracy: 0.3096\n",
            "Epoch 1580/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3202 - accuracy: 0.9900 - val_loss: 3.7981 - val_accuracy: 0.3472\n",
            "Epoch 1581/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2960 - accuracy: 1.0000 - val_loss: 3.9385 - val_accuracy: 0.3350\n",
            "Epoch 1582/6000\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.3243 - accuracy: 0.9950 - val_loss: 4.0011 - val_accuracy: 0.3257\n",
            "Epoch 1583/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3125 - accuracy: 0.9900 - val_loss: 4.5345 - val_accuracy: 0.2755\n",
            "Epoch 1584/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3217 - accuracy: 0.9900 - val_loss: 4.8725 - val_accuracy: 0.2490\n",
            "Epoch 1585/6000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3039 - accuracy: 0.9900 - val_loss: 4.2497 - val_accuracy: 0.2912\n",
            "Epoch 1586/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.3048 - accuracy: 0.9900 - val_loss: 4.6667 - val_accuracy: 0.2494\n",
            "Epoch 1587/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2945 - accuracy: 1.0000 - val_loss: 4.1745 - val_accuracy: 0.2783\n",
            "Epoch 1588/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3094 - accuracy: 0.9900 - val_loss: 4.1141 - val_accuracy: 0.2931\n",
            "Epoch 1589/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2955 - accuracy: 0.9950 - val_loss: 4.1497 - val_accuracy: 0.2798\n",
            "Epoch 1590/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.3081 - accuracy: 0.9900 - val_loss: 3.8419 - val_accuracy: 0.3067\n",
            "Epoch 1591/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2991 - accuracy: 0.9950 - val_loss: 4.0094 - val_accuracy: 0.2939\n",
            "Epoch 1592/6000\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2934 - accuracy: 0.9950 - val_loss: 4.0315 - val_accuracy: 0.2953\n",
            "Epoch 1593/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3445 - accuracy: 0.9750 - val_loss: 3.9465 - val_accuracy: 0.3137\n",
            "Epoch 1594/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2956 - accuracy: 0.9950 - val_loss: 4.0072 - val_accuracy: 0.3036\n",
            "Epoch 1595/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.3289 - accuracy: 0.9800 - val_loss: 3.9654 - val_accuracy: 0.3078\n",
            "Epoch 1596/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2994 - accuracy: 0.9950 - val_loss: 4.0342 - val_accuracy: 0.3123\n",
            "Epoch 1597/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2987 - accuracy: 0.9950 - val_loss: 4.0427 - val_accuracy: 0.3088\n",
            "Epoch 1598/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3043 - accuracy: 0.9950 - val_loss: 4.0891 - val_accuracy: 0.3137\n",
            "Epoch 1599/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2919 - accuracy: 1.0000 - val_loss: 4.0260 - val_accuracy: 0.3188\n",
            "Epoch 1600/6000\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.3043 - accuracy: 0.9900 - val_loss: 3.9445 - val_accuracy: 0.3200\n",
            "Epoch 1601/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.3079 - accuracy: 0.9850 - val_loss: 3.8811 - val_accuracy: 0.3273\n",
            "Epoch 1602/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 3.8899 - val_accuracy: 0.3268\n",
            "Epoch 1603/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3112 - accuracy: 0.9850 - val_loss: 4.0370 - val_accuracy: 0.2999\n",
            "Epoch 1604/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3076 - accuracy: 0.9950 - val_loss: 4.0990 - val_accuracy: 0.2886\n",
            "Epoch 1605/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3169 - accuracy: 0.9900 - val_loss: 3.9603 - val_accuracy: 0.3043\n",
            "Epoch 1606/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 3.9593 - val_accuracy: 0.3040\n",
            "Epoch 1607/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2982 - accuracy: 1.0000 - val_loss: 3.8509 - val_accuracy: 0.3228\n",
            "Epoch 1608/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3004 - accuracy: 0.9900 - val_loss: 3.7786 - val_accuracy: 0.3399\n",
            "Epoch 1609/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2960 - accuracy: 0.9900 - val_loss: 3.7174 - val_accuracy: 0.3492\n",
            "Epoch 1610/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2840 - accuracy: 1.0000 - val_loss: 3.7339 - val_accuracy: 0.3466\n",
            "Epoch 1611/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2910 - accuracy: 0.9950 - val_loss: 3.6897 - val_accuracy: 0.3544\n",
            "Epoch 1612/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2893 - accuracy: 1.0000 - val_loss: 3.7728 - val_accuracy: 0.3440\n",
            "Epoch 1613/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2942 - accuracy: 0.9950 - val_loss: 3.7105 - val_accuracy: 0.3507\n",
            "Epoch 1614/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3189 - accuracy: 0.9900 - val_loss: 3.8767 - val_accuracy: 0.3391\n",
            "Epoch 1615/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2883 - accuracy: 1.0000 - val_loss: 3.9719 - val_accuracy: 0.3300\n",
            "Epoch 1616/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 3.8986 - val_accuracy: 0.3304\n",
            "Epoch 1617/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2936 - accuracy: 0.9950 - val_loss: 3.9025 - val_accuracy: 0.3315\n",
            "Epoch 1618/6000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 3.8698 - val_accuracy: 0.3316\n",
            "Epoch 1619/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 3.8871 - val_accuracy: 0.3303\n",
            "Epoch 1620/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2995 - accuracy: 0.9950 - val_loss: 3.7637 - val_accuracy: 0.3330\n",
            "Epoch 1621/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2905 - accuracy: 0.9950 - val_loss: 3.7043 - val_accuracy: 0.3426\n",
            "Epoch 1622/6000\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 3.6937 - val_accuracy: 0.3443\n",
            "Epoch 1623/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 3.7236 - val_accuracy: 0.3387\n",
            "Epoch 1624/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2797 - accuracy: 0.9950 - val_loss: 3.8365 - val_accuracy: 0.3281\n",
            "Epoch 1625/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2909 - accuracy: 0.9950 - val_loss: 3.8306 - val_accuracy: 0.3243\n",
            "Epoch 1626/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2954 - accuracy: 0.9900 - val_loss: 3.7161 - val_accuracy: 0.3453\n",
            "Epoch 1627/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 3.7340 - val_accuracy: 0.3451\n",
            "Epoch 1628/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2836 - accuracy: 0.9950 - val_loss: 3.7736 - val_accuracy: 0.3414\n",
            "Epoch 1629/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2930 - accuracy: 0.9850 - val_loss: 3.6557 - val_accuracy: 0.3455\n",
            "Epoch 1630/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2957 - accuracy: 0.9950 - val_loss: 3.7753 - val_accuracy: 0.3516\n",
            "Epoch 1631/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2872 - accuracy: 0.9950 - val_loss: 3.6658 - val_accuracy: 0.3570\n",
            "Epoch 1632/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3297 - accuracy: 0.9800 - val_loss: 3.9109 - val_accuracy: 0.3307\n",
            "Epoch 1633/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2802 - accuracy: 1.0000 - val_loss: 3.9895 - val_accuracy: 0.3117\n",
            "Epoch 1634/6000\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.2810 - accuracy: 1.0000 - val_loss: 3.9932 - val_accuracy: 0.3124\n",
            "Epoch 1635/6000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.2903 - accuracy: 0.9950 - val_loss: 4.1944 - val_accuracy: 0.3052\n",
            "Epoch 1636/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2778 - accuracy: 0.9950 - val_loss: 4.1724 - val_accuracy: 0.3027\n",
            "Epoch 1637/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2787 - accuracy: 0.9950 - val_loss: 3.9564 - val_accuracy: 0.3115\n",
            "Epoch 1638/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 3.9436 - val_accuracy: 0.3117\n",
            "Epoch 1639/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2751 - accuracy: 1.0000 - val_loss: 3.9360 - val_accuracy: 0.3106\n",
            "Epoch 1640/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2829 - accuracy: 0.9950 - val_loss: 3.8913 - val_accuracy: 0.3164\n",
            "Epoch 1641/6000\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2847 - accuracy: 0.9950 - val_loss: 3.9241 - val_accuracy: 0.3193\n",
            "Epoch 1642/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.3016 - accuracy: 0.9900 - val_loss: 4.0274 - val_accuracy: 0.3090\n",
            "Epoch 1643/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3002 - accuracy: 0.9950 - val_loss: 5.0054 - val_accuracy: 0.2594\n",
            "Epoch 1644/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3047 - accuracy: 0.9800 - val_loss: 4.2426 - val_accuracy: 0.2774\n",
            "Epoch 1645/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2918 - accuracy: 0.9900 - val_loss: 4.2967 - val_accuracy: 0.2820\n",
            "Epoch 1646/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2832 - accuracy: 1.0000 - val_loss: 4.2238 - val_accuracy: 0.2943\n",
            "Epoch 1647/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2843 - accuracy: 1.0000 - val_loss: 3.9678 - val_accuracy: 0.3135\n",
            "Epoch 1648/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2837 - accuracy: 0.9950 - val_loss: 3.8998 - val_accuracy: 0.3260\n",
            "Epoch 1649/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2725 - accuracy: 1.0000 - val_loss: 3.8894 - val_accuracy: 0.3230\n",
            "Epoch 1650/6000\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2830 - accuracy: 0.9900 - val_loss: 3.9738 - val_accuracy: 0.3231\n",
            "Epoch 1651/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2806 - accuracy: 1.0000 - val_loss: 3.8308 - val_accuracy: 0.3414\n",
            "Epoch 1652/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2873 - accuracy: 0.9900 - val_loss: 3.8981 - val_accuracy: 0.3288\n",
            "Epoch 1653/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3041 - accuracy: 0.9900 - val_loss: 3.8718 - val_accuracy: 0.3371\n",
            "Epoch 1654/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2793 - accuracy: 0.9950 - val_loss: 3.8224 - val_accuracy: 0.3396\n",
            "Epoch 1655/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2915 - accuracy: 0.9900 - val_loss: 3.8323 - val_accuracy: 0.3330\n",
            "Epoch 1656/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3065 - accuracy: 0.9850 - val_loss: 4.0929 - val_accuracy: 0.3070\n",
            "Epoch 1657/6000\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2817 - accuracy: 1.0000 - val_loss: 4.0106 - val_accuracy: 0.3115\n",
            "Epoch 1658/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2802 - accuracy: 0.9950 - val_loss: 3.8104 - val_accuracy: 0.3307\n",
            "Epoch 1659/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2737 - accuracy: 1.0000 - val_loss: 3.7459 - val_accuracy: 0.3388\n",
            "Epoch 1660/6000\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2767 - accuracy: 0.9950 - val_loss: 3.8311 - val_accuracy: 0.3341\n",
            "Epoch 1661/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2847 - accuracy: 0.9950 - val_loss: 3.7795 - val_accuracy: 0.3466\n",
            "Epoch 1662/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2733 - accuracy: 0.9950 - val_loss: 3.8707 - val_accuracy: 0.3425\n",
            "Epoch 1663/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2822 - accuracy: 0.9900 - val_loss: 3.9656 - val_accuracy: 0.3292\n",
            "Epoch 1664/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2702 - accuracy: 1.0000 - val_loss: 3.8516 - val_accuracy: 0.3399\n",
            "Epoch 1665/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2767 - accuracy: 0.9950 - val_loss: 3.8193 - val_accuracy: 0.3449\n",
            "Epoch 1666/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2935 - accuracy: 0.9950 - val_loss: 3.9455 - val_accuracy: 0.3308\n",
            "Epoch 1667/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 3.8763 - val_accuracy: 0.3361\n",
            "Epoch 1668/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 3.7166 - val_accuracy: 0.3493\n",
            "Epoch 1669/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2934 - accuracy: 0.9800 - val_loss: 3.9416 - val_accuracy: 0.3197\n",
            "Epoch 1670/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2769 - accuracy: 0.9950 - val_loss: 3.9887 - val_accuracy: 0.3180\n",
            "Epoch 1671/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2745 - accuracy: 1.0000 - val_loss: 3.7723 - val_accuracy: 0.3409\n",
            "Epoch 1672/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2749 - accuracy: 1.0000 - val_loss: 3.9514 - val_accuracy: 0.3222\n",
            "Epoch 1673/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2854 - accuracy: 0.9850 - val_loss: 4.2737 - val_accuracy: 0.2882\n",
            "Epoch 1674/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2860 - accuracy: 0.9950 - val_loss: 3.9430 - val_accuracy: 0.3195\n",
            "Epoch 1675/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2799 - accuracy: 0.9950 - val_loss: 3.9631 - val_accuracy: 0.3183\n",
            "Epoch 1676/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2721 - accuracy: 0.9950 - val_loss: 4.0732 - val_accuracy: 0.3061\n",
            "Epoch 1677/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 3.8849 - val_accuracy: 0.3308\n",
            "Epoch 1678/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2859 - accuracy: 0.9900 - val_loss: 3.7891 - val_accuracy: 0.3419\n",
            "Epoch 1679/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2746 - accuracy: 0.9950 - val_loss: 3.7997 - val_accuracy: 0.3454\n",
            "Epoch 1680/6000\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.2853 - accuracy: 0.9800 - val_loss: 3.9169 - val_accuracy: 0.3358\n",
            "Epoch 1681/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2740 - accuracy: 0.9900 - val_loss: 3.7843 - val_accuracy: 0.3491\n",
            "Epoch 1682/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2682 - accuracy: 1.0000 - val_loss: 3.6842 - val_accuracy: 0.3632\n",
            "Epoch 1683/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2699 - accuracy: 1.0000 - val_loss: 3.6713 - val_accuracy: 0.3650\n",
            "Epoch 1684/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2914 - accuracy: 0.9850 - val_loss: 3.7634 - val_accuracy: 0.3589\n",
            "Epoch 1685/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2727 - accuracy: 0.9950 - val_loss: 3.8554 - val_accuracy: 0.3455\n",
            "Epoch 1686/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2834 - accuracy: 0.9850 - val_loss: 3.8400 - val_accuracy: 0.3450\n",
            "Epoch 1687/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 3.9054 - val_accuracy: 0.3375\n",
            "Epoch 1688/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2785 - accuracy: 0.9850 - val_loss: 4.0415 - val_accuracy: 0.3284\n",
            "Epoch 1689/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3000 - accuracy: 0.9800 - val_loss: 3.6828 - val_accuracy: 0.3579\n",
            "Epoch 1690/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2632 - accuracy: 1.0000 - val_loss: 3.6973 - val_accuracy: 0.3555\n",
            "Epoch 1691/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2801 - accuracy: 0.9950 - val_loss: 3.7717 - val_accuracy: 0.3560\n",
            "Epoch 1692/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 3.8483 - val_accuracy: 0.3427\n",
            "Epoch 1693/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 3.7180 - val_accuracy: 0.3543\n",
            "Epoch 1694/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2628 - accuracy: 1.0000 - val_loss: 3.7498 - val_accuracy: 0.3510\n",
            "Epoch 1695/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2724 - accuracy: 0.9950 - val_loss: 3.7411 - val_accuracy: 0.3521\n",
            "Epoch 1696/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2702 - accuracy: 0.9950 - val_loss: 3.7966 - val_accuracy: 0.3414\n",
            "Epoch 1697/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2757 - accuracy: 0.9900 - val_loss: 3.8124 - val_accuracy: 0.3527\n",
            "Epoch 1698/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2997 - accuracy: 0.9850 - val_loss: 3.8061 - val_accuracy: 0.3440\n",
            "Epoch 1699/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2862 - accuracy: 0.9900 - val_loss: 3.6692 - val_accuracy: 0.3562\n",
            "Epoch 1700/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2633 - accuracy: 1.0000 - val_loss: 3.6439 - val_accuracy: 0.3616\n",
            "Epoch 1701/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2924 - accuracy: 0.9850 - val_loss: 3.5582 - val_accuracy: 0.3736\n",
            "Epoch 1702/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2628 - accuracy: 1.0000 - val_loss: 3.5589 - val_accuracy: 0.3736\n",
            "Epoch 1703/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2705 - accuracy: 0.9950 - val_loss: 3.5421 - val_accuracy: 0.3746\n",
            "Epoch 1704/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2755 - accuracy: 0.9950 - val_loss: 3.5460 - val_accuracy: 0.3788\n",
            "Epoch 1705/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2701 - accuracy: 0.9950 - val_loss: 3.5247 - val_accuracy: 0.3776\n",
            "Epoch 1706/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 3.5765 - val_accuracy: 0.3749\n",
            "Epoch 1707/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 3.7230 - val_accuracy: 0.3606\n",
            "Epoch 1708/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3116 - accuracy: 0.9850 - val_loss: 3.4831 - val_accuracy: 0.3788\n",
            "Epoch 1709/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2684 - accuracy: 0.9950 - val_loss: 3.5349 - val_accuracy: 0.3743\n",
            "Epoch 1710/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2818 - accuracy: 0.9900 - val_loss: 3.6552 - val_accuracy: 0.3703\n",
            "Epoch 1711/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2652 - accuracy: 1.0000 - val_loss: 3.5749 - val_accuracy: 0.3706\n",
            "Epoch 1712/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 3.5865 - val_accuracy: 0.3689\n",
            "Epoch 1713/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2810 - accuracy: 0.9850 - val_loss: 3.8918 - val_accuracy: 0.3327\n",
            "Epoch 1714/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 3.8819 - val_accuracy: 0.3360\n",
            "Epoch 1715/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2744 - accuracy: 0.9950 - val_loss: 3.8363 - val_accuracy: 0.3428\n",
            "Epoch 1716/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2954 - accuracy: 0.9850 - val_loss: 3.9219 - val_accuracy: 0.3315\n",
            "Epoch 1717/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 4.0546 - val_accuracy: 0.3276\n",
            "Epoch 1718/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2747 - accuracy: 0.9900 - val_loss: 3.9195 - val_accuracy: 0.3313\n",
            "Epoch 1719/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 3.9907 - val_accuracy: 0.3165\n",
            "Epoch 1720/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2663 - accuracy: 0.9950 - val_loss: 4.0796 - val_accuracy: 0.3220\n",
            "Epoch 1721/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2757 - accuracy: 0.9950 - val_loss: 3.8894 - val_accuracy: 0.3358\n",
            "Epoch 1722/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2640 - accuracy: 0.9950 - val_loss: 3.9072 - val_accuracy: 0.3330\n",
            "Epoch 1723/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2575 - accuracy: 1.0000 - val_loss: 3.8895 - val_accuracy: 0.3328\n",
            "Epoch 1724/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2617 - accuracy: 1.0000 - val_loss: 3.8423 - val_accuracy: 0.3350\n",
            "Epoch 1725/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2921 - accuracy: 0.9950 - val_loss: 3.8499 - val_accuracy: 0.3316\n",
            "Epoch 1726/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2840 - accuracy: 0.9900 - val_loss: 3.9877 - val_accuracy: 0.3126\n",
            "Epoch 1727/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2686 - accuracy: 0.9950 - val_loss: 3.8956 - val_accuracy: 0.3192\n",
            "Epoch 1728/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 3.8822 - val_accuracy: 0.3206\n",
            "Epoch 1729/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3032 - accuracy: 0.9850 - val_loss: 3.8237 - val_accuracy: 0.3408\n",
            "Epoch 1730/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2700 - accuracy: 0.9900 - val_loss: 3.7927 - val_accuracy: 0.3338\n",
            "Epoch 1731/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 3.7188 - val_accuracy: 0.3412\n",
            "Epoch 1732/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2663 - accuracy: 0.9950 - val_loss: 3.7961 - val_accuracy: 0.3360\n",
            "Epoch 1733/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2635 - accuracy: 1.0000 - val_loss: 3.7510 - val_accuracy: 0.3437\n",
            "Epoch 1734/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2668 - accuracy: 0.9900 - val_loss: 3.5833 - val_accuracy: 0.3513\n",
            "Epoch 1735/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2814 - accuracy: 0.9900 - val_loss: 3.6841 - val_accuracy: 0.3525\n",
            "Epoch 1736/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 3.7114 - val_accuracy: 0.3449\n",
            "Epoch 1737/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2548 - accuracy: 1.0000 - val_loss: 3.7679 - val_accuracy: 0.3397\n",
            "Epoch 1738/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2813 - accuracy: 0.9850 - val_loss: 3.9423 - val_accuracy: 0.3312\n",
            "Epoch 1739/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2842 - accuracy: 0.9900 - val_loss: 3.9611 - val_accuracy: 0.3321\n",
            "Epoch 1740/6000\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.2587 - accuracy: 1.0000 - val_loss: 3.9154 - val_accuracy: 0.3381\n",
            "Epoch 1741/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2905 - accuracy: 0.9800 - val_loss: 3.5858 - val_accuracy: 0.3690\n",
            "Epoch 1742/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2652 - accuracy: 0.9950 - val_loss: 3.6186 - val_accuracy: 0.3625\n",
            "Epoch 1743/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 3.5220 - val_accuracy: 0.3771\n",
            "Epoch 1744/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2630 - accuracy: 0.9950 - val_loss: 3.5910 - val_accuracy: 0.3656\n",
            "Epoch 1745/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 3.6783 - val_accuracy: 0.3567\n",
            "Epoch 1746/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 3.5884 - val_accuracy: 0.3633\n",
            "Epoch 1747/6000\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2717 - accuracy: 0.9950 - val_loss: 3.6227 - val_accuracy: 0.3609\n",
            "Epoch 1748/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2768 - accuracy: 0.9850 - val_loss: 3.7103 - val_accuracy: 0.3509\n",
            "Epoch 1749/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 3.7418 - val_accuracy: 0.3460\n",
            "Epoch 1750/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2620 - accuracy: 0.9950 - val_loss: 3.6459 - val_accuracy: 0.3562\n",
            "Epoch 1751/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2537 - accuracy: 1.0000 - val_loss: 3.6156 - val_accuracy: 0.3631\n",
            "Epoch 1752/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2606 - accuracy: 0.9950 - val_loss: 3.6150 - val_accuracy: 0.3652\n",
            "Epoch 1753/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2646 - accuracy: 0.9950 - val_loss: 3.7459 - val_accuracy: 0.3471\n",
            "Epoch 1754/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2734 - accuracy: 0.9900 - val_loss: 3.5681 - val_accuracy: 0.3670\n",
            "Epoch 1755/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2882 - accuracy: 0.9900 - val_loss: 3.5325 - val_accuracy: 0.3608\n",
            "Epoch 1756/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2648 - accuracy: 0.9900 - val_loss: 3.6020 - val_accuracy: 0.3446\n",
            "Epoch 1757/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2479 - accuracy: 1.0000 - val_loss: 3.6197 - val_accuracy: 0.3429\n",
            "Epoch 1758/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2901 - accuracy: 0.9900 - val_loss: 3.6843 - val_accuracy: 0.3361\n",
            "Epoch 1759/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2656 - accuracy: 0.9950 - val_loss: 3.6454 - val_accuracy: 0.3386\n",
            "Epoch 1760/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2841 - accuracy: 0.9800 - val_loss: 4.3026 - val_accuracy: 0.2934\n",
            "Epoch 1761/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 4.0368 - val_accuracy: 0.3109\n",
            "Epoch 1762/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2665 - accuracy: 0.9950 - val_loss: 3.6284 - val_accuracy: 0.3411\n",
            "Epoch 1763/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2829 - accuracy: 0.9900 - val_loss: 4.1441 - val_accuracy: 0.2920\n",
            "Epoch 1764/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3159 - accuracy: 0.9700 - val_loss: 3.6101 - val_accuracy: 0.3426\n",
            "Epoch 1765/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2893 - accuracy: 0.9850 - val_loss: 3.7284 - val_accuracy: 0.3289\n",
            "Epoch 1766/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2843 - accuracy: 0.9800 - val_loss: 3.6864 - val_accuracy: 0.3381\n",
            "Epoch 1767/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2715 - accuracy: 0.9900 - val_loss: 3.6414 - val_accuracy: 0.3471\n",
            "Epoch 1768/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2653 - accuracy: 0.9950 - val_loss: 3.6599 - val_accuracy: 0.3487\n",
            "Epoch 1769/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2565 - accuracy: 1.0000 - val_loss: 3.7090 - val_accuracy: 0.3429\n",
            "Epoch 1770/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2572 - accuracy: 1.0000 - val_loss: 3.7098 - val_accuracy: 0.3455\n",
            "Epoch 1771/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2746 - accuracy: 0.9950 - val_loss: 3.7592 - val_accuracy: 0.3400\n",
            "Epoch 1772/6000\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.2594 - accuracy: 1.0000 - val_loss: 3.8133 - val_accuracy: 0.3365\n",
            "Epoch 1773/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2895 - accuracy: 0.9800 - val_loss: 3.6912 - val_accuracy: 0.3457\n",
            "Epoch 1774/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2674 - accuracy: 0.9950 - val_loss: 3.7769 - val_accuracy: 0.3386\n",
            "Epoch 1775/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2528 - accuracy: 1.0000 - val_loss: 3.8318 - val_accuracy: 0.3357\n",
            "Epoch 1776/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 3.8563 - val_accuracy: 0.3304\n",
            "Epoch 1777/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2685 - accuracy: 0.9900 - val_loss: 3.7814 - val_accuracy: 0.3424\n",
            "Epoch 1778/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2883 - accuracy: 0.9850 - val_loss: 3.7489 - val_accuracy: 0.3435\n",
            "Epoch 1779/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2652 - accuracy: 0.9900 - val_loss: 3.7137 - val_accuracy: 0.3424\n",
            "Epoch 1780/6000\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2649 - accuracy: 0.9950 - val_loss: 3.7462 - val_accuracy: 0.3414\n",
            "Epoch 1781/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2611 - accuracy: 0.9900 - val_loss: 3.9402 - val_accuracy: 0.3193\n",
            "Epoch 1782/6000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2643 - accuracy: 0.9950 - val_loss: 3.9192 - val_accuracy: 0.3214\n",
            "Epoch 1783/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2864 - accuracy: 0.9900 - val_loss: 3.8942 - val_accuracy: 0.3313\n",
            "Epoch 1784/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2641 - accuracy: 0.9950 - val_loss: 4.1021 - val_accuracy: 0.3164\n",
            "Epoch 1785/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2667 - accuracy: 0.9950 - val_loss: 4.0744 - val_accuracy: 0.3179\n",
            "Epoch 1786/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2598 - accuracy: 0.9950 - val_loss: 3.8988 - val_accuracy: 0.3358\n",
            "Epoch 1787/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2732 - accuracy: 0.9900 - val_loss: 4.2202 - val_accuracy: 0.3006\n",
            "Epoch 1788/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2832 - accuracy: 0.9850 - val_loss: 4.1558 - val_accuracy: 0.3147\n",
            "Epoch 1789/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2617 - accuracy: 0.9950 - val_loss: 3.9346 - val_accuracy: 0.3261\n",
            "Epoch 1790/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3064 - accuracy: 0.9800 - val_loss: 4.0264 - val_accuracy: 0.3246\n",
            "Epoch 1791/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2608 - accuracy: 0.9950 - val_loss: 3.9050 - val_accuracy: 0.3395\n",
            "Epoch 1792/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2860 - accuracy: 0.9800 - val_loss: 3.6771 - val_accuracy: 0.3452\n",
            "Epoch 1793/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2701 - accuracy: 0.9900 - val_loss: 3.6951 - val_accuracy: 0.3475\n",
            "Epoch 1794/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2657 - accuracy: 0.9950 - val_loss: 3.7020 - val_accuracy: 0.3442\n",
            "Epoch 1795/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2692 - accuracy: 0.9950 - val_loss: 3.7450 - val_accuracy: 0.3398\n",
            "Epoch 1796/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2715 - accuracy: 0.9900 - val_loss: 3.6669 - val_accuracy: 0.3577\n",
            "Epoch 1797/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2822 - accuracy: 0.9850 - val_loss: 3.5955 - val_accuracy: 0.3627\n",
            "Epoch 1798/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2672 - accuracy: 0.9950 - val_loss: 3.5820 - val_accuracy: 0.3582\n",
            "Epoch 1799/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2671 - accuracy: 0.9950 - val_loss: 3.7058 - val_accuracy: 0.3556\n",
            "Epoch 1800/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2808 - accuracy: 0.9800 - val_loss: 4.0941 - val_accuracy: 0.3195\n",
            "Epoch 1801/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2877 - accuracy: 0.9900 - val_loss: 4.0633 - val_accuracy: 0.3352\n",
            "Epoch 1802/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3028 - accuracy: 0.9800 - val_loss: 3.7808 - val_accuracy: 0.3565\n",
            "Epoch 1803/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2892 - accuracy: 0.9900 - val_loss: 3.7997 - val_accuracy: 0.3545\n",
            "Epoch 1804/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3068 - accuracy: 0.9700 - val_loss: 3.7337 - val_accuracy: 0.3473\n",
            "Epoch 1805/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2940 - accuracy: 0.9900 - val_loss: 3.8205 - val_accuracy: 0.3489\n",
            "Epoch 1806/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2572 - accuracy: 1.0000 - val_loss: 3.8555 - val_accuracy: 0.3491\n",
            "Epoch 1807/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2965 - accuracy: 0.9750 - val_loss: 3.7185 - val_accuracy: 0.3511\n",
            "Epoch 1808/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2771 - accuracy: 0.9900 - val_loss: 3.5749 - val_accuracy: 0.3687\n",
            "Epoch 1809/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.3227 - accuracy: 0.9800 - val_loss: 3.7081 - val_accuracy: 0.3463\n",
            "Epoch 1810/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2815 - accuracy: 0.9900 - val_loss: 3.9060 - val_accuracy: 0.3343\n",
            "Epoch 1811/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.3103 - accuracy: 0.9850 - val_loss: 3.7377 - val_accuracy: 0.3624\n",
            "Epoch 1812/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2772 - accuracy: 0.9850 - val_loss: 3.6021 - val_accuracy: 0.3624\n",
            "Epoch 1813/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2619 - accuracy: 1.0000 - val_loss: 3.5966 - val_accuracy: 0.3616\n",
            "Epoch 1814/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2741 - accuracy: 0.9900 - val_loss: 3.6618 - val_accuracy: 0.3573\n",
            "Epoch 1815/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2672 - accuracy: 0.9950 - val_loss: 3.7511 - val_accuracy: 0.3504\n",
            "Epoch 1816/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2806 - accuracy: 0.9950 - val_loss: 4.0963 - val_accuracy: 0.3213\n",
            "Epoch 1817/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2632 - accuracy: 1.0000 - val_loss: 3.9731 - val_accuracy: 0.3291\n",
            "Epoch 1818/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 4.1632 - val_accuracy: 0.3179\n",
            "Epoch 1819/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2876 - accuracy: 0.9850 - val_loss: 4.2193 - val_accuracy: 0.3152\n",
            "Epoch 1820/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 4.1062 - val_accuracy: 0.3259\n",
            "Epoch 1821/6000\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2706 - accuracy: 0.9850 - val_loss: 4.7606 - val_accuracy: 0.2705\n",
            "Epoch 1822/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2992 - accuracy: 0.9900 - val_loss: 3.7988 - val_accuracy: 0.3399\n",
            "Epoch 1823/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2794 - accuracy: 0.9900 - val_loss: 3.8713 - val_accuracy: 0.3328\n",
            "Epoch 1824/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 4.0442 - val_accuracy: 0.3179\n",
            "Epoch 1825/6000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2757 - accuracy: 0.9900 - val_loss: 4.3820 - val_accuracy: 0.3008\n",
            "Epoch 1826/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2764 - accuracy: 0.9850 - val_loss: 4.2468 - val_accuracy: 0.3089\n",
            "Epoch 1827/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2765 - accuracy: 0.9900 - val_loss: 4.2888 - val_accuracy: 0.2964\n",
            "Epoch 1828/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2705 - accuracy: 0.9900 - val_loss: 4.0900 - val_accuracy: 0.3008\n",
            "Epoch 1829/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 4.1145 - val_accuracy: 0.2983\n",
            "Epoch 1830/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2849 - accuracy: 0.9900 - val_loss: 4.1980 - val_accuracy: 0.2959\n",
            "Epoch 1831/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 4.0025 - val_accuracy: 0.3144\n",
            "Epoch 1832/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2686 - accuracy: 0.9950 - val_loss: 4.3197 - val_accuracy: 0.2892\n",
            "Epoch 1833/6000\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2754 - accuracy: 0.9950 - val_loss: 4.0501 - val_accuracy: 0.3157\n",
            "Epoch 1834/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2795 - accuracy: 0.9900 - val_loss: 5.4927 - val_accuracy: 0.2288\n",
            "Epoch 1835/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2973 - accuracy: 0.9850 - val_loss: 4.3030 - val_accuracy: 0.2803\n",
            "Epoch 1836/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2901 - accuracy: 0.9900 - val_loss: 4.5329 - val_accuracy: 0.2718\n",
            "Epoch 1837/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2850 - accuracy: 0.9850 - val_loss: 4.3508 - val_accuracy: 0.2840\n",
            "Epoch 1838/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2716 - accuracy: 0.9950 - val_loss: 4.3669 - val_accuracy: 0.2854\n",
            "Epoch 1839/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 4.3763 - val_accuracy: 0.2891\n",
            "Epoch 1840/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 4.1873 - val_accuracy: 0.3056\n",
            "Epoch 1841/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2936 - accuracy: 0.9900 - val_loss: 4.2538 - val_accuracy: 0.2915\n",
            "Epoch 1842/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2559 - accuracy: 1.0000 - val_loss: 4.1639 - val_accuracy: 0.3031\n",
            "Epoch 1843/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2673 - accuracy: 0.9950 - val_loss: 4.1567 - val_accuracy: 0.3043\n",
            "Epoch 1844/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2763 - accuracy: 0.9950 - val_loss: 4.3790 - val_accuracy: 0.2919\n",
            "Epoch 1845/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2698 - accuracy: 0.9950 - val_loss: 4.3103 - val_accuracy: 0.2923\n",
            "Epoch 1846/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2714 - accuracy: 0.9900 - val_loss: 4.1836 - val_accuracy: 0.3060\n",
            "Epoch 1847/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2667 - accuracy: 1.0000 - val_loss: 3.8934 - val_accuracy: 0.3310\n",
            "Epoch 1848/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2959 - accuracy: 0.9850 - val_loss: 4.0849 - val_accuracy: 0.3118\n",
            "Epoch 1849/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2749 - accuracy: 0.9900 - val_loss: 4.0608 - val_accuracy: 0.3097\n",
            "Epoch 1850/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2677 - accuracy: 0.9950 - val_loss: 4.1103 - val_accuracy: 0.3013\n",
            "Epoch 1851/6000\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2698 - accuracy: 0.9950 - val_loss: 4.0219 - val_accuracy: 0.3176\n",
            "Epoch 1852/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2629 - accuracy: 0.9950 - val_loss: 3.8844 - val_accuracy: 0.3300\n",
            "Epoch 1853/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2836 - accuracy: 0.9900 - val_loss: 4.3274 - val_accuracy: 0.3247\n",
            "Epoch 1854/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2802 - accuracy: 0.9800 - val_loss: 4.4227 - val_accuracy: 0.3042\n",
            "Epoch 1855/6000\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2927 - accuracy: 0.9850 - val_loss: 4.3455 - val_accuracy: 0.2915\n",
            "Epoch 1856/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2954 - accuracy: 0.9850 - val_loss: 4.0478 - val_accuracy: 0.3260\n",
            "Epoch 1857/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2850 - accuracy: 0.9900 - val_loss: 4.2029 - val_accuracy: 0.3311\n",
            "Epoch 1858/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.3152 - accuracy: 0.9750 - val_loss: 3.8000 - val_accuracy: 0.3461\n",
            "Epoch 1859/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2646 - accuracy: 1.0000 - val_loss: 3.7415 - val_accuracy: 0.3474\n",
            "Epoch 1860/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2902 - accuracy: 0.9900 - val_loss: 3.6840 - val_accuracy: 0.3641\n",
            "Epoch 1861/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2684 - accuracy: 1.0000 - val_loss: 3.5991 - val_accuracy: 0.3672\n",
            "Epoch 1862/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2818 - accuracy: 0.9900 - val_loss: 3.5937 - val_accuracy: 0.3678\n",
            "Epoch 1863/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3147 - accuracy: 0.9700 - val_loss: 3.6839 - val_accuracy: 0.3519\n",
            "Epoch 1864/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2678 - accuracy: 0.9950 - val_loss: 3.6731 - val_accuracy: 0.3555\n",
            "Epoch 1865/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2688 - accuracy: 0.9900 - val_loss: 3.7980 - val_accuracy: 0.3446\n",
            "Epoch 1866/6000\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2650 - accuracy: 0.9950 - val_loss: 3.7435 - val_accuracy: 0.3522\n",
            "Epoch 1867/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2620 - accuracy: 1.0000 - val_loss: 3.6933 - val_accuracy: 0.3576\n",
            "Epoch 1868/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2638 - accuracy: 0.9950 - val_loss: 3.8354 - val_accuracy: 0.3412\n",
            "Epoch 1869/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2736 - accuracy: 0.9900 - val_loss: 3.8664 - val_accuracy: 0.3466\n",
            "Epoch 1870/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2770 - accuracy: 0.9900 - val_loss: 3.8687 - val_accuracy: 0.3448\n",
            "Epoch 1871/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2802 - accuracy: 0.9900 - val_loss: 3.9574 - val_accuracy: 0.3396\n",
            "Epoch 1872/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3022 - accuracy: 0.9800 - val_loss: 3.7663 - val_accuracy: 0.3561\n",
            "Epoch 1873/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2642 - accuracy: 0.9950 - val_loss: 3.9007 - val_accuracy: 0.3486\n",
            "Epoch 1874/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 3.8047 - val_accuracy: 0.3526\n",
            "Epoch 1875/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3151 - accuracy: 0.9900 - val_loss: 4.0341 - val_accuracy: 0.3389\n",
            "Epoch 1876/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2963 - accuracy: 0.9800 - val_loss: 3.6737 - val_accuracy: 0.3724\n",
            "Epoch 1877/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2686 - accuracy: 0.9950 - val_loss: 3.6597 - val_accuracy: 0.3700\n",
            "Epoch 1878/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2661 - accuracy: 0.9950 - val_loss: 3.6307 - val_accuracy: 0.3765\n",
            "Epoch 1879/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2726 - accuracy: 0.9950 - val_loss: 3.6101 - val_accuracy: 0.3753\n",
            "Epoch 1880/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2706 - accuracy: 0.9950 - val_loss: 3.5613 - val_accuracy: 0.3813\n",
            "Epoch 1881/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3026 - accuracy: 0.9750 - val_loss: 3.7458 - val_accuracy: 0.3550\n",
            "Epoch 1882/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2610 - accuracy: 1.0000 - val_loss: 3.6680 - val_accuracy: 0.3642\n",
            "Epoch 1883/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 3.7393 - val_accuracy: 0.3576\n",
            "Epoch 1884/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2782 - accuracy: 0.9950 - val_loss: 3.7339 - val_accuracy: 0.3564\n",
            "Epoch 1885/6000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.2872 - accuracy: 0.9850 - val_loss: 3.6899 - val_accuracy: 0.3570\n",
            "Epoch 1886/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2854 - accuracy: 0.9900 - val_loss: 3.5650 - val_accuracy: 0.3685\n",
            "Epoch 1887/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 3.5684 - val_accuracy: 0.3693\n",
            "Epoch 1888/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.3029 - accuracy: 0.9800 - val_loss: 3.6228 - val_accuracy: 0.3762\n",
            "Epoch 1889/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2807 - accuracy: 0.9900 - val_loss: 3.7044 - val_accuracy: 0.3725\n",
            "Epoch 1890/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2596 - accuracy: 1.0000 - val_loss: 3.6663 - val_accuracy: 0.3760\n",
            "Epoch 1891/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2936 - accuracy: 0.9850 - val_loss: 3.8722 - val_accuracy: 0.3537\n",
            "Epoch 1892/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2896 - accuracy: 0.9800 - val_loss: 3.7774 - val_accuracy: 0.3633\n",
            "Epoch 1893/6000\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2559 - accuracy: 1.0000 - val_loss: 3.7828 - val_accuracy: 0.3645\n",
            "Epoch 1894/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2842 - accuracy: 0.9800 - val_loss: 4.0211 - val_accuracy: 0.3440\n",
            "Epoch 1895/6000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 4.1088 - val_accuracy: 0.3400\n",
            "Epoch 1896/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2799 - accuracy: 0.9800 - val_loss: 4.0973 - val_accuracy: 0.3443\n",
            "Epoch 1897/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2753 - accuracy: 0.9950 - val_loss: 4.1029 - val_accuracy: 0.3278\n",
            "Epoch 1898/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2670 - accuracy: 0.9950 - val_loss: 4.0495 - val_accuracy: 0.3351\n",
            "Epoch 1899/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2796 - accuracy: 0.9850 - val_loss: 4.1166 - val_accuracy: 0.3461\n",
            "Epoch 1900/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2678 - accuracy: 0.9950 - val_loss: 4.2954 - val_accuracy: 0.3323\n",
            "Epoch 1901/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2755 - accuracy: 0.9900 - val_loss: 4.1043 - val_accuracy: 0.3526\n",
            "Epoch 1902/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2937 - accuracy: 0.9850 - val_loss: 3.9050 - val_accuracy: 0.3628\n",
            "Epoch 1903/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2740 - accuracy: 0.9950 - val_loss: 4.0275 - val_accuracy: 0.3365\n",
            "Epoch 1904/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2628 - accuracy: 0.9950 - val_loss: 4.1790 - val_accuracy: 0.3205\n",
            "Epoch 1905/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2681 - accuracy: 0.9900 - val_loss: 4.0294 - val_accuracy: 0.3293\n",
            "Epoch 1906/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2841 - accuracy: 0.9950 - val_loss: 4.0505 - val_accuracy: 0.3260\n",
            "Epoch 1907/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2858 - accuracy: 0.9900 - val_loss: 4.0646 - val_accuracy: 0.3472\n",
            "Epoch 1908/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2786 - accuracy: 0.9900 - val_loss: 4.2713 - val_accuracy: 0.3383\n",
            "Epoch 1909/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.3211 - accuracy: 0.9700 - val_loss: 3.8965 - val_accuracy: 0.3556\n",
            "Epoch 1910/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2875 - accuracy: 0.9900 - val_loss: 4.0808 - val_accuracy: 0.3304\n",
            "Epoch 1911/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2812 - accuracy: 0.9950 - val_loss: 3.9260 - val_accuracy: 0.3415\n",
            "Epoch 1912/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2969 - accuracy: 0.9850 - val_loss: 4.0733 - val_accuracy: 0.3354\n",
            "Epoch 1913/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2699 - accuracy: 0.9950 - val_loss: 3.9626 - val_accuracy: 0.3406\n",
            "Epoch 1914/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2706 - accuracy: 0.9900 - val_loss: 3.9363 - val_accuracy: 0.3381\n",
            "Epoch 1915/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2664 - accuracy: 0.9900 - val_loss: 3.9115 - val_accuracy: 0.3517\n",
            "Epoch 1916/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2880 - accuracy: 0.9800 - val_loss: 4.1445 - val_accuracy: 0.3387\n",
            "Epoch 1917/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.3154 - accuracy: 0.9800 - val_loss: 4.0585 - val_accuracy: 0.3320\n",
            "Epoch 1918/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2801 - accuracy: 0.9900 - val_loss: 4.0475 - val_accuracy: 0.3470\n",
            "Epoch 1919/6000\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2719 - accuracy: 0.9950 - val_loss: 4.2475 - val_accuracy: 0.3315\n",
            "Epoch 1920/6000\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2902 - accuracy: 0.9850 - val_loss: 3.9591 - val_accuracy: 0.3599\n",
            "Epoch 1921/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2867 - accuracy: 0.9900 - val_loss: 3.9271 - val_accuracy: 0.3551\n",
            "Epoch 1922/6000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2758 - accuracy: 0.9850 - val_loss: 4.0376 - val_accuracy: 0.3449\n",
            "Epoch 1923/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2760 - accuracy: 0.9950 - val_loss: 4.0342 - val_accuracy: 0.3398\n",
            "Epoch 1924/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2806 - accuracy: 0.9900 - val_loss: 4.0810 - val_accuracy: 0.3370\n",
            "Epoch 1925/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2886 - accuracy: 0.9850 - val_loss: 4.5044 - val_accuracy: 0.3001\n",
            "Epoch 1926/6000\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2816 - accuracy: 0.9900 - val_loss: 4.1868 - val_accuracy: 0.3214\n",
            "Epoch 1927/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2760 - accuracy: 0.9950 - val_loss: 3.8127 - val_accuracy: 0.3528\n",
            "Epoch 1928/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2824 - accuracy: 0.9900 - val_loss: 3.6750 - val_accuracy: 0.3641\n",
            "Epoch 1929/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2861 - accuracy: 0.9900 - val_loss: 3.7334 - val_accuracy: 0.3601\n",
            "Epoch 1930/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2939 - accuracy: 0.9900 - val_loss: 3.7258 - val_accuracy: 0.3628\n",
            "Epoch 1931/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2865 - accuracy: 0.9850 - val_loss: 3.7536 - val_accuracy: 0.3629\n",
            "Epoch 1932/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2854 - accuracy: 0.9900 - val_loss: 3.6846 - val_accuracy: 0.3709\n",
            "Epoch 1933/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2947 - accuracy: 0.9900 - val_loss: 3.7326 - val_accuracy: 0.3701\n",
            "Epoch 1934/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2773 - accuracy: 0.9900 - val_loss: 3.6771 - val_accuracy: 0.3739\n",
            "Epoch 1935/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2828 - accuracy: 0.9900 - val_loss: 3.6074 - val_accuracy: 0.3753\n",
            "Epoch 1936/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2661 - accuracy: 0.9950 - val_loss: 3.6576 - val_accuracy: 0.3741\n",
            "Epoch 1937/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2793 - accuracy: 0.9900 - val_loss: 3.8086 - val_accuracy: 0.3563\n",
            "Epoch 1938/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3247 - accuracy: 0.9850 - val_loss: 3.6744 - val_accuracy: 0.3680\n",
            "Epoch 1939/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2738 - accuracy: 0.9950 - val_loss: 3.7077 - val_accuracy: 0.3606\n",
            "Epoch 1940/6000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.2828 - accuracy: 0.9900 - val_loss: 3.7305 - val_accuracy: 0.3590\n",
            "Epoch 1941/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2661 - accuracy: 1.0000 - val_loss: 3.6748 - val_accuracy: 0.3642\n",
            "Epoch 1942/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2926 - accuracy: 0.9950 - val_loss: 3.5633 - val_accuracy: 0.3746\n",
            "Epoch 1943/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2758 - accuracy: 0.9900 - val_loss: 3.5940 - val_accuracy: 0.3688\n",
            "Epoch 1944/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2765 - accuracy: 0.9950 - val_loss: 3.6689 - val_accuracy: 0.3667\n",
            "Epoch 1945/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 3.6438 - val_accuracy: 0.3722\n",
            "Epoch 1946/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2685 - accuracy: 1.0000 - val_loss: 3.6847 - val_accuracy: 0.3669\n",
            "Epoch 1947/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3232 - accuracy: 0.9750 - val_loss: 3.6039 - val_accuracy: 0.3684\n",
            "Epoch 1948/6000\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 3.5880 - val_accuracy: 0.3656\n",
            "Epoch 1949/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2769 - accuracy: 0.9950 - val_loss: 3.5712 - val_accuracy: 0.3678\n",
            "Epoch 1950/6000\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.2666 - accuracy: 1.0000 - val_loss: 3.6264 - val_accuracy: 0.3667\n",
            "Epoch 1951/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2927 - accuracy: 0.9850 - val_loss: 3.7282 - val_accuracy: 0.3573\n",
            "Epoch 1952/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2612 - accuracy: 1.0000 - val_loss: 3.6715 - val_accuracy: 0.3640\n",
            "Epoch 1953/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2702 - accuracy: 0.9950 - val_loss: 3.6690 - val_accuracy: 0.3655\n",
            "Epoch 1954/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3032 - accuracy: 0.9900 - val_loss: 3.9189 - val_accuracy: 0.3368\n",
            "Epoch 1955/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 4.0320 - val_accuracy: 0.3269\n",
            "Epoch 1956/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2783 - accuracy: 0.9950 - val_loss: 4.0477 - val_accuracy: 0.3308\n",
            "Epoch 1957/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2679 - accuracy: 0.9900 - val_loss: 4.0777 - val_accuracy: 0.3271\n",
            "Epoch 1958/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2646 - accuracy: 1.0000 - val_loss: 3.9719 - val_accuracy: 0.3319\n",
            "Epoch 1959/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2798 - accuracy: 0.9900 - val_loss: 3.9289 - val_accuracy: 0.3303\n",
            "Epoch 1960/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2587 - accuracy: 1.0000 - val_loss: 3.9600 - val_accuracy: 0.3263\n",
            "Epoch 1961/6000\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2813 - accuracy: 0.9900 - val_loss: 3.9763 - val_accuracy: 0.3202\n",
            "Epoch 1962/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 3.7755 - val_accuracy: 0.3422\n",
            "Epoch 1963/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2771 - accuracy: 0.9900 - val_loss: 3.6170 - val_accuracy: 0.3559\n",
            "Epoch 1964/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3030 - accuracy: 0.9900 - val_loss: 3.8106 - val_accuracy: 0.3367\n",
            "Epoch 1965/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2897 - accuracy: 0.9900 - val_loss: 4.4434 - val_accuracy: 0.2782\n",
            "Epoch 1966/6000\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2682 - accuracy: 1.0000 - val_loss: 4.1537 - val_accuracy: 0.2960\n",
            "Epoch 1967/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2762 - accuracy: 0.9950 - val_loss: 3.9762 - val_accuracy: 0.3123\n",
            "Epoch 1968/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2902 - accuracy: 0.9900 - val_loss: 4.5290 - val_accuracy: 0.2821\n",
            "Epoch 1969/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2901 - accuracy: 0.9900 - val_loss: 4.1538 - val_accuracy: 0.2992\n",
            "Epoch 1970/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2828 - accuracy: 0.9900 - val_loss: 3.6884 - val_accuracy: 0.3466\n",
            "Epoch 1971/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 3.6358 - val_accuracy: 0.3569\n",
            "Epoch 1972/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2820 - accuracy: 0.9950 - val_loss: 3.6087 - val_accuracy: 0.3655\n",
            "Epoch 1973/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2777 - accuracy: 0.9950 - val_loss: 3.6109 - val_accuracy: 0.3644\n",
            "Epoch 1974/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3099 - accuracy: 0.9750 - val_loss: 3.6778 - val_accuracy: 0.3619\n",
            "Epoch 1975/6000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3271 - accuracy: 0.9850 - val_loss: 3.6798 - val_accuracy: 0.3653\n",
            "Epoch 1976/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2908 - accuracy: 0.9900 - val_loss: 3.8898 - val_accuracy: 0.3505\n",
            "Epoch 1977/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3099 - accuracy: 0.9900 - val_loss: 3.6438 - val_accuracy: 0.3682\n",
            "Epoch 1978/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2947 - accuracy: 0.9850 - val_loss: 3.8195 - val_accuracy: 0.3567\n",
            "Epoch 1979/6000\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.2767 - accuracy: 0.9950 - val_loss: 3.8050 - val_accuracy: 0.3576\n",
            "Epoch 1980/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3034 - accuracy: 0.9850 - val_loss: 3.9155 - val_accuracy: 0.3390\n",
            "Epoch 1981/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2664 - accuracy: 1.0000 - val_loss: 3.9119 - val_accuracy: 0.3356\n",
            "Epoch 1982/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2894 - accuracy: 0.9900 - val_loss: 3.9309 - val_accuracy: 0.3327\n",
            "Epoch 1983/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 3.7370 - val_accuracy: 0.3517\n",
            "Epoch 1984/6000\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 3.7174 - val_accuracy: 0.3542\n",
            "Epoch 1985/6000\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3119 - accuracy: 0.9900 - val_loss: 3.6880 - val_accuracy: 0.3547\n",
            "Epoch 1986/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 3.6748 - val_accuracy: 0.3615\n",
            "Epoch 1987/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2780 - accuracy: 0.9950 - val_loss: 3.7002 - val_accuracy: 0.3620\n",
            "Epoch 1988/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 3.6372 - val_accuracy: 0.3648\n",
            "Epoch 1989/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2672 - accuracy: 0.9950 - val_loss: 3.6161 - val_accuracy: 0.3563\n",
            "Epoch 1990/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2801 - accuracy: 0.9850 - val_loss: 3.6000 - val_accuracy: 0.3661\n",
            "Epoch 1991/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2932 - accuracy: 0.9900 - val_loss: 3.8123 - val_accuracy: 0.3609\n",
            "Epoch 1992/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2873 - accuracy: 0.9850 - val_loss: 4.1841 - val_accuracy: 0.3388\n",
            "Epoch 1993/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2655 - accuracy: 0.9950 - val_loss: 4.2604 - val_accuracy: 0.3349\n",
            "Epoch 1994/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3098 - accuracy: 0.9900 - val_loss: 5.2539 - val_accuracy: 0.2579\n",
            "Epoch 1995/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2892 - accuracy: 0.9950 - val_loss: 3.8786 - val_accuracy: 0.3435\n",
            "Epoch 1996/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2678 - accuracy: 1.0000 - val_loss: 3.8116 - val_accuracy: 0.3483\n",
            "Epoch 1997/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2951 - accuracy: 0.9900 - val_loss: 3.8909 - val_accuracy: 0.3486\n",
            "Epoch 1998/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3121 - accuracy: 0.9800 - val_loss: 4.1256 - val_accuracy: 0.3257\n",
            "Epoch 1999/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2821 - accuracy: 0.9850 - val_loss: 3.8887 - val_accuracy: 0.3534\n",
            "Epoch 2000/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2740 - accuracy: 0.9950 - val_loss: 4.1000 - val_accuracy: 0.3431\n",
            "Epoch 2001/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3043 - accuracy: 0.9800 - val_loss: 3.7706 - val_accuracy: 0.3588\n",
            "Epoch 2002/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3120 - accuracy: 0.9900 - val_loss: 4.0104 - val_accuracy: 0.3336\n",
            "Epoch 2003/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2849 - accuracy: 0.9950 - val_loss: 3.9043 - val_accuracy: 0.3466\n",
            "Epoch 2004/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2658 - accuracy: 0.9950 - val_loss: 3.8964 - val_accuracy: 0.3494\n",
            "Epoch 2005/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2873 - accuracy: 0.9850 - val_loss: 4.0179 - val_accuracy: 0.3492\n",
            "Epoch 2006/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2826 - accuracy: 0.9950 - val_loss: 3.9180 - val_accuracy: 0.3578\n",
            "Epoch 2007/6000\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2635 - accuracy: 0.9950 - val_loss: 3.9620 - val_accuracy: 0.3480\n",
            "Epoch 2008/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2626 - accuracy: 1.0000 - val_loss: 3.9729 - val_accuracy: 0.3475\n",
            "Epoch 2009/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2791 - accuracy: 0.9850 - val_loss: 4.1724 - val_accuracy: 0.3428\n",
            "Epoch 2010/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2984 - accuracy: 0.9900 - val_loss: 5.5708 - val_accuracy: 0.2649\n",
            "Epoch 2011/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3021 - accuracy: 0.9850 - val_loss: 4.7849 - val_accuracy: 0.3049\n",
            "Epoch 2012/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.3011 - accuracy: 0.9900 - val_loss: 3.6886 - val_accuracy: 0.3727\n",
            "Epoch 2013/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2718 - accuracy: 1.0000 - val_loss: 3.6683 - val_accuracy: 0.3723\n",
            "Epoch 2014/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2901 - accuracy: 0.9850 - val_loss: 3.7352 - val_accuracy: 0.3676\n",
            "Epoch 2015/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2802 - accuracy: 0.9950 - val_loss: 3.6364 - val_accuracy: 0.3726\n",
            "Epoch 2016/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2892 - accuracy: 0.9800 - val_loss: 3.8368 - val_accuracy: 0.3552\n",
            "Epoch 2017/6000\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2732 - accuracy: 0.9950 - val_loss: 3.7276 - val_accuracy: 0.3663\n",
            "Epoch 2018/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 3.9698 - val_accuracy: 0.3526\n",
            "Epoch 2019/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 3.9288 - val_accuracy: 0.3547\n",
            "Epoch 2020/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2884 - accuracy: 0.9900 - val_loss: 3.9631 - val_accuracy: 0.3597\n",
            "Epoch 2021/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2746 - accuracy: 0.9950 - val_loss: 4.0290 - val_accuracy: 0.3531\n",
            "Epoch 2022/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2866 - accuracy: 0.9850 - val_loss: 3.7016 - val_accuracy: 0.3756\n",
            "Epoch 2023/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3104 - accuracy: 0.9900 - val_loss: 4.3928 - val_accuracy: 0.3070\n",
            "Epoch 2024/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.3096 - accuracy: 0.9850 - val_loss: 4.2433 - val_accuracy: 0.3181\n",
            "Epoch 2025/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2801 - accuracy: 0.9850 - val_loss: 4.2883 - val_accuracy: 0.3049\n",
            "Epoch 2026/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2776 - accuracy: 0.9950 - val_loss: 4.1811 - val_accuracy: 0.3141\n",
            "Epoch 2027/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3247 - accuracy: 0.9850 - val_loss: 4.2693 - val_accuracy: 0.3073\n",
            "Epoch 2028/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.3068 - accuracy: 0.9800 - val_loss: 3.9751 - val_accuracy: 0.3313\n",
            "Epoch 2029/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3167 - accuracy: 0.9850 - val_loss: 3.8126 - val_accuracy: 0.3542\n",
            "Epoch 2030/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2814 - accuracy: 0.9850 - val_loss: 3.7843 - val_accuracy: 0.3569\n",
            "Epoch 2031/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2777 - accuracy: 0.9950 - val_loss: 3.7235 - val_accuracy: 0.3593\n",
            "Epoch 2032/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2637 - accuracy: 1.0000 - val_loss: 3.7012 - val_accuracy: 0.3626\n",
            "Epoch 2033/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2970 - accuracy: 0.9950 - val_loss: 3.9900 - val_accuracy: 0.3380\n",
            "Epoch 2034/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2949 - accuracy: 0.9900 - val_loss: 3.8549 - val_accuracy: 0.3570\n",
            "Epoch 2035/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2722 - accuracy: 0.9950 - val_loss: 3.9133 - val_accuracy: 0.3529\n",
            "Epoch 2036/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2778 - accuracy: 0.9900 - val_loss: 4.4581 - val_accuracy: 0.3181\n",
            "Epoch 2037/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2755 - accuracy: 0.9950 - val_loss: 4.3683 - val_accuracy: 0.3243\n",
            "Epoch 2038/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2667 - accuracy: 1.0000 - val_loss: 4.3558 - val_accuracy: 0.3269\n",
            "Epoch 2039/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2834 - accuracy: 0.9900 - val_loss: 4.0270 - val_accuracy: 0.3428\n",
            "Epoch 2040/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3324 - accuracy: 0.9850 - val_loss: 4.0754 - val_accuracy: 0.3476\n",
            "Epoch 2041/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 4.0503 - val_accuracy: 0.3500\n",
            "Epoch 2042/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2681 - accuracy: 1.0000 - val_loss: 4.2562 - val_accuracy: 0.3369\n",
            "Epoch 2043/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2865 - accuracy: 0.9900 - val_loss: 4.5745 - val_accuracy: 0.3225\n",
            "Epoch 2044/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2793 - accuracy: 0.9900 - val_loss: 4.7470 - val_accuracy: 0.3084\n",
            "Epoch 2045/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2965 - accuracy: 0.9850 - val_loss: 4.6908 - val_accuracy: 0.3057\n",
            "Epoch 2046/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2802 - accuracy: 0.9850 - val_loss: 4.4312 - val_accuracy: 0.3280\n",
            "Epoch 2047/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2779 - accuracy: 0.9950 - val_loss: 4.5747 - val_accuracy: 0.3150\n",
            "Epoch 2048/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2754 - accuracy: 0.9950 - val_loss: 4.4719 - val_accuracy: 0.3293\n",
            "Epoch 2049/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2843 - accuracy: 0.9900 - val_loss: 4.3395 - val_accuracy: 0.3387\n",
            "Epoch 2050/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2892 - accuracy: 0.9850 - val_loss: 4.5014 - val_accuracy: 0.3285\n",
            "Epoch 2051/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2846 - accuracy: 0.9950 - val_loss: 4.1346 - val_accuracy: 0.3556\n",
            "Epoch 2052/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 4.1044 - val_accuracy: 0.3574\n",
            "Epoch 2053/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3177 - accuracy: 0.9800 - val_loss: 3.9755 - val_accuracy: 0.3601\n",
            "Epoch 2054/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2706 - accuracy: 0.9950 - val_loss: 4.0142 - val_accuracy: 0.3606\n",
            "Epoch 2055/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2686 - accuracy: 0.9950 - val_loss: 4.0074 - val_accuracy: 0.3590\n",
            "Epoch 2056/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2678 - accuracy: 0.9950 - val_loss: 4.0072 - val_accuracy: 0.3581\n",
            "Epoch 2057/6000\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.2789 - accuracy: 0.9950 - val_loss: 4.1218 - val_accuracy: 0.3575\n",
            "Epoch 2058/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2707 - accuracy: 0.9950 - val_loss: 4.1646 - val_accuracy: 0.3570\n",
            "Epoch 2059/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2720 - accuracy: 0.9950 - val_loss: 3.9309 - val_accuracy: 0.3662\n",
            "Epoch 2060/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2998 - accuracy: 0.9900 - val_loss: 4.0605 - val_accuracy: 0.3592\n",
            "Epoch 2061/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3016 - accuracy: 0.9900 - val_loss: 3.8806 - val_accuracy: 0.3647\n",
            "Epoch 2062/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2886 - accuracy: 0.9850 - val_loss: 4.2015 - val_accuracy: 0.3423\n",
            "Epoch 2063/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2664 - accuracy: 0.9950 - val_loss: 4.1335 - val_accuracy: 0.3472\n",
            "Epoch 2064/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 3.9845 - val_accuracy: 0.3558\n",
            "Epoch 2065/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2751 - accuracy: 0.9950 - val_loss: 4.0221 - val_accuracy: 0.3541\n",
            "Epoch 2066/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 3.8497 - val_accuracy: 0.3620\n",
            "Epoch 2067/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.3008 - accuracy: 0.9900 - val_loss: 3.8684 - val_accuracy: 0.3635\n",
            "Epoch 2068/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2640 - accuracy: 0.9950 - val_loss: 3.8367 - val_accuracy: 0.3665\n",
            "Epoch 2069/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2892 - accuracy: 0.9850 - val_loss: 3.9121 - val_accuracy: 0.3552\n",
            "Epoch 2070/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2935 - accuracy: 0.9850 - val_loss: 3.7688 - val_accuracy: 0.3622\n",
            "Epoch 2071/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2770 - accuracy: 0.9950 - val_loss: 3.7953 - val_accuracy: 0.3645\n",
            "Epoch 2072/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2572 - accuracy: 1.0000 - val_loss: 3.8233 - val_accuracy: 0.3601\n",
            "Epoch 2073/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2951 - accuracy: 0.9900 - val_loss: 3.7460 - val_accuracy: 0.3630\n",
            "Epoch 2074/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2680 - accuracy: 0.9950 - val_loss: 3.8735 - val_accuracy: 0.3504\n",
            "Epoch 2075/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2705 - accuracy: 0.9900 - val_loss: 3.9992 - val_accuracy: 0.3400\n",
            "Epoch 2076/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2874 - accuracy: 0.9900 - val_loss: 3.8072 - val_accuracy: 0.3530\n",
            "Epoch 2077/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2787 - accuracy: 0.9900 - val_loss: 3.7255 - val_accuracy: 0.3619\n",
            "Epoch 2078/6000\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 3.7325 - val_accuracy: 0.3628\n",
            "Epoch 2079/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2791 - accuracy: 0.9950 - val_loss: 3.7371 - val_accuracy: 0.3632\n",
            "Epoch 2080/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2889 - accuracy: 0.9850 - val_loss: 3.8573 - val_accuracy: 0.3628\n",
            "Epoch 2081/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2745 - accuracy: 0.9900 - val_loss: 3.6931 - val_accuracy: 0.3697\n",
            "Epoch 2082/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.3108 - accuracy: 0.9850 - val_loss: 3.5389 - val_accuracy: 0.3809\n",
            "Epoch 2083/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2792 - accuracy: 0.9900 - val_loss: 3.5671 - val_accuracy: 0.3777\n",
            "Epoch 2084/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2834 - accuracy: 0.9850 - val_loss: 3.5338 - val_accuracy: 0.3818\n",
            "Epoch 2085/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2604 - accuracy: 1.0000 - val_loss: 3.5402 - val_accuracy: 0.3809\n",
            "Epoch 2086/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2623 - accuracy: 1.0000 - val_loss: 3.6289 - val_accuracy: 0.3670\n",
            "Epoch 2087/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2676 - accuracy: 1.0000 - val_loss: 3.7031 - val_accuracy: 0.3668\n",
            "Epoch 2088/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2897 - accuracy: 0.9850 - val_loss: 3.6072 - val_accuracy: 0.3703\n",
            "Epoch 2089/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2793 - accuracy: 0.9950 - val_loss: 3.6015 - val_accuracy: 0.3782\n",
            "Epoch 2090/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2781 - accuracy: 0.9850 - val_loss: 3.9305 - val_accuracy: 0.3447\n",
            "Epoch 2091/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2649 - accuracy: 0.9950 - val_loss: 3.8675 - val_accuracy: 0.3529\n",
            "Epoch 2092/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2891 - accuracy: 0.9900 - val_loss: 4.0911 - val_accuracy: 0.3446\n",
            "Epoch 2093/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2824 - accuracy: 0.9900 - val_loss: 3.8755 - val_accuracy: 0.3492\n",
            "Epoch 2094/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.3129 - accuracy: 0.9800 - val_loss: 4.1560 - val_accuracy: 0.3363\n",
            "Epoch 2095/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3278 - accuracy: 0.9800 - val_loss: 3.6541 - val_accuracy: 0.3597\n",
            "Epoch 2096/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2753 - accuracy: 0.9950 - val_loss: 3.6084 - val_accuracy: 0.3747\n",
            "Epoch 2097/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2736 - accuracy: 0.9950 - val_loss: 3.6682 - val_accuracy: 0.3725\n",
            "Epoch 2098/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2746 - accuracy: 0.9950 - val_loss: 3.6456 - val_accuracy: 0.3744\n",
            "Epoch 2099/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 3.7013 - val_accuracy: 0.3729\n",
            "Epoch 2100/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2817 - accuracy: 0.9900 - val_loss: 3.6144 - val_accuracy: 0.3722\n",
            "Epoch 2101/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2776 - accuracy: 0.9950 - val_loss: 3.6856 - val_accuracy: 0.3668\n",
            "Epoch 2102/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2707 - accuracy: 0.9950 - val_loss: 3.7154 - val_accuracy: 0.3683\n",
            "Epoch 2103/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2738 - accuracy: 0.9950 - val_loss: 3.7552 - val_accuracy: 0.3696\n",
            "Epoch 2104/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2948 - accuracy: 0.9800 - val_loss: 3.9438 - val_accuracy: 0.3503\n",
            "Epoch 2105/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3031 - accuracy: 0.9850 - val_loss: 3.7088 - val_accuracy: 0.3660\n",
            "Epoch 2106/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2763 - accuracy: 0.9900 - val_loss: 3.7772 - val_accuracy: 0.3701\n",
            "Epoch 2107/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3010 - accuracy: 0.9700 - val_loss: 3.8100 - val_accuracy: 0.3710\n",
            "Epoch 2108/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2685 - accuracy: 0.9950 - val_loss: 3.9103 - val_accuracy: 0.3644\n",
            "Epoch 2109/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2980 - accuracy: 0.9800 - val_loss: 4.6132 - val_accuracy: 0.3296\n",
            "Epoch 2110/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2699 - accuracy: 0.9950 - val_loss: 4.7520 - val_accuracy: 0.3163\n",
            "Epoch 2111/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2717 - accuracy: 0.9950 - val_loss: 4.5969 - val_accuracy: 0.3226\n",
            "Epoch 2112/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2682 - accuracy: 0.9900 - val_loss: 5.0135 - val_accuracy: 0.2936\n",
            "Epoch 2113/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2682 - accuracy: 0.9950 - val_loss: 4.8798 - val_accuracy: 0.2980\n",
            "Epoch 2114/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 4.6013 - val_accuracy: 0.3144\n",
            "Epoch 2115/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2824 - accuracy: 0.9850 - val_loss: 4.0763 - val_accuracy: 0.3441\n",
            "Epoch 2116/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2620 - accuracy: 1.0000 - val_loss: 4.1927 - val_accuracy: 0.3391\n",
            "Epoch 2117/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2929 - accuracy: 0.9850 - val_loss: 4.1448 - val_accuracy: 0.3423\n",
            "Epoch 2118/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2728 - accuracy: 0.9950 - val_loss: 4.1421 - val_accuracy: 0.3452\n",
            "Epoch 2119/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2886 - accuracy: 0.9900 - val_loss: 4.3009 - val_accuracy: 0.3398\n",
            "Epoch 2120/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2690 - accuracy: 1.0000 - val_loss: 4.1011 - val_accuracy: 0.3592\n",
            "Epoch 2121/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2692 - accuracy: 0.9950 - val_loss: 4.2835 - val_accuracy: 0.3517\n",
            "Epoch 2122/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2648 - accuracy: 0.9950 - val_loss: 3.9988 - val_accuracy: 0.3660\n",
            "Epoch 2123/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2605 - accuracy: 1.0000 - val_loss: 4.0015 - val_accuracy: 0.3652\n",
            "Epoch 2124/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2748 - accuracy: 0.9950 - val_loss: 3.9185 - val_accuracy: 0.3663\n",
            "Epoch 2125/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3215 - accuracy: 0.9650 - val_loss: 4.8176 - val_accuracy: 0.3183\n",
            "Epoch 2126/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 4.8295 - val_accuracy: 0.3157\n",
            "Epoch 2127/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2827 - accuracy: 0.9800 - val_loss: 8.0558 - val_accuracy: 0.1707\n",
            "Epoch 2128/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2669 - accuracy: 0.9950 - val_loss: 6.5063 - val_accuracy: 0.2079\n",
            "Epoch 2129/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.3009 - accuracy: 0.9800 - val_loss: 5.6915 - val_accuracy: 0.2323\n",
            "Epoch 2130/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2694 - accuracy: 0.9900 - val_loss: 4.5473 - val_accuracy: 0.2954\n",
            "Epoch 2131/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 4.5387 - val_accuracy: 0.2914\n",
            "Epoch 2132/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2877 - accuracy: 0.9900 - val_loss: 4.0999 - val_accuracy: 0.3165\n",
            "Epoch 2133/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 4.2501 - val_accuracy: 0.3066\n",
            "Epoch 2134/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2623 - accuracy: 1.0000 - val_loss: 4.3971 - val_accuracy: 0.2959\n",
            "Epoch 2135/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2688 - accuracy: 0.9950 - val_loss: 4.4836 - val_accuracy: 0.2958\n",
            "Epoch 2136/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2931 - accuracy: 0.9850 - val_loss: 4.2936 - val_accuracy: 0.3010\n",
            "Epoch 2137/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3118 - accuracy: 0.9800 - val_loss: 5.3369 - val_accuracy: 0.2417\n",
            "Epoch 2138/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2752 - accuracy: 0.9900 - val_loss: 5.3909 - val_accuracy: 0.2465\n",
            "Epoch 2139/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2832 - accuracy: 0.9950 - val_loss: 4.5987 - val_accuracy: 0.2975\n",
            "Epoch 2140/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3091 - accuracy: 0.9800 - val_loss: 4.0971 - val_accuracy: 0.3008\n",
            "Epoch 2141/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2958 - accuracy: 0.9900 - val_loss: 4.0950 - val_accuracy: 0.3089\n",
            "Epoch 2142/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2935 - accuracy: 0.9850 - val_loss: 4.5185 - val_accuracy: 0.2964\n",
            "Epoch 2143/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2803 - accuracy: 0.9950 - val_loss: 4.1308 - val_accuracy: 0.3261\n",
            "Epoch 2144/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2731 - accuracy: 0.9950 - val_loss: 3.8681 - val_accuracy: 0.3331\n",
            "Epoch 2145/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2731 - accuracy: 0.9950 - val_loss: 3.8633 - val_accuracy: 0.3441\n",
            "Epoch 2146/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2794 - accuracy: 0.9900 - val_loss: 3.6497 - val_accuracy: 0.3634\n",
            "Epoch 2147/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2731 - accuracy: 0.9950 - val_loss: 3.6667 - val_accuracy: 0.3561\n",
            "Epoch 2148/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2905 - accuracy: 0.9900 - val_loss: 3.5632 - val_accuracy: 0.3649\n",
            "Epoch 2149/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2857 - accuracy: 0.9850 - val_loss: 3.4890 - val_accuracy: 0.3715\n",
            "Epoch 2150/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 3.4759 - val_accuracy: 0.3725\n",
            "Epoch 2151/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2788 - accuracy: 0.9900 - val_loss: 3.4352 - val_accuracy: 0.3792\n",
            "Epoch 2152/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2837 - accuracy: 0.9850 - val_loss: 3.5029 - val_accuracy: 0.3724\n",
            "Epoch 2153/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2729 - accuracy: 1.0000 - val_loss: 3.5304 - val_accuracy: 0.3716\n",
            "Epoch 2154/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2889 - accuracy: 0.9900 - val_loss: 3.6260 - val_accuracy: 0.3619\n",
            "Epoch 2155/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2661 - accuracy: 1.0000 - val_loss: 3.5584 - val_accuracy: 0.3656\n",
            "Epoch 2156/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2682 - accuracy: 0.9950 - val_loss: 3.4454 - val_accuracy: 0.3782\n",
            "Epoch 2157/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2742 - accuracy: 0.9900 - val_loss: 3.5223 - val_accuracy: 0.3743\n",
            "Epoch 2158/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2804 - accuracy: 0.9950 - val_loss: 3.7091 - val_accuracy: 0.3676\n",
            "Epoch 2159/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2861 - accuracy: 0.9900 - val_loss: 3.6063 - val_accuracy: 0.3782\n",
            "Epoch 2160/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2704 - accuracy: 0.9950 - val_loss: 3.6097 - val_accuracy: 0.3791\n",
            "Epoch 2161/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2635 - accuracy: 1.0000 - val_loss: 3.6655 - val_accuracy: 0.3754\n",
            "Epoch 2162/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2730 - accuracy: 0.9900 - val_loss: 3.7719 - val_accuracy: 0.3693\n",
            "Epoch 2163/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2784 - accuracy: 0.9900 - val_loss: 3.6380 - val_accuracy: 0.3685\n",
            "Epoch 2164/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2953 - accuracy: 0.9850 - val_loss: 3.5298 - val_accuracy: 0.3802\n",
            "Epoch 2165/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 3.5024 - val_accuracy: 0.3834\n",
            "Epoch 2166/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2799 - accuracy: 0.9950 - val_loss: 3.5616 - val_accuracy: 0.3800\n",
            "Epoch 2167/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2640 - accuracy: 0.9950 - val_loss: 3.5662 - val_accuracy: 0.3755\n",
            "Epoch 2168/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2930 - accuracy: 0.9800 - val_loss: 3.6114 - val_accuracy: 0.3786\n",
            "Epoch 2169/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2852 - accuracy: 0.9950 - val_loss: 3.6884 - val_accuracy: 0.3744\n",
            "Epoch 2170/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2999 - accuracy: 0.9800 - val_loss: 3.5757 - val_accuracy: 0.3772\n",
            "Epoch 2171/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2697 - accuracy: 0.9950 - val_loss: 3.6589 - val_accuracy: 0.3661\n",
            "Epoch 2172/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2712 - accuracy: 0.9950 - val_loss: 3.6334 - val_accuracy: 0.3711\n",
            "Epoch 2173/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2774 - accuracy: 0.9900 - val_loss: 3.6765 - val_accuracy: 0.3710\n",
            "Epoch 2174/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2629 - accuracy: 1.0000 - val_loss: 3.6333 - val_accuracy: 0.3736\n",
            "Epoch 2175/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 3.6586 - val_accuracy: 0.3624\n",
            "Epoch 2176/6000\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 3.6329 - val_accuracy: 0.3639\n",
            "Epoch 2177/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2687 - accuracy: 0.9950 - val_loss: 3.6271 - val_accuracy: 0.3660\n",
            "Epoch 2178/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2582 - accuracy: 1.0000 - val_loss: 3.6360 - val_accuracy: 0.3642\n",
            "Epoch 2179/6000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2612 - accuracy: 1.0000 - val_loss: 3.6197 - val_accuracy: 0.3654\n",
            "Epoch 2180/6000\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2726 - accuracy: 0.9950 - val_loss: 3.7647 - val_accuracy: 0.3496\n",
            "Epoch 2181/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2683 - accuracy: 0.9950 - val_loss: 4.0348 - val_accuracy: 0.3228\n",
            "Epoch 2182/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 4.0855 - val_accuracy: 0.3187\n",
            "Epoch 2183/6000\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 4.0285 - val_accuracy: 0.3228\n",
            "Epoch 2184/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2648 - accuracy: 0.9950 - val_loss: 3.8179 - val_accuracy: 0.3441\n",
            "Epoch 2185/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3045 - accuracy: 0.9900 - val_loss: 3.9835 - val_accuracy: 0.3272\n",
            "Epoch 2186/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2818 - accuracy: 0.9850 - val_loss: 3.8906 - val_accuracy: 0.3352\n",
            "Epoch 2187/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2712 - accuracy: 0.9950 - val_loss: 4.0658 - val_accuracy: 0.3164\n",
            "Epoch 2188/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2733 - accuracy: 0.9900 - val_loss: 4.2413 - val_accuracy: 0.3059\n",
            "Epoch 2189/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2784 - accuracy: 0.9950 - val_loss: 3.9086 - val_accuracy: 0.3432\n",
            "Epoch 2190/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2818 - accuracy: 0.9950 - val_loss: 3.8615 - val_accuracy: 0.3458\n",
            "Epoch 2191/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 3.8060 - val_accuracy: 0.3438\n",
            "Epoch 2192/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2757 - accuracy: 0.9950 - val_loss: 4.0573 - val_accuracy: 0.3211\n",
            "Epoch 2193/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 4.0524 - val_accuracy: 0.3209\n",
            "Epoch 2194/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2814 - accuracy: 0.9900 - val_loss: 3.9837 - val_accuracy: 0.3189\n",
            "Epoch 2195/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 3.9100 - val_accuracy: 0.3296\n",
            "Epoch 2196/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 3.8455 - val_accuracy: 0.3392\n",
            "Epoch 2197/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2840 - accuracy: 0.9850 - val_loss: 3.8906 - val_accuracy: 0.3380\n",
            "Epoch 2198/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2700 - accuracy: 0.9950 - val_loss: 3.7455 - val_accuracy: 0.3586\n",
            "Epoch 2199/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.3223 - accuracy: 0.9850 - val_loss: 3.8826 - val_accuracy: 0.3496\n",
            "Epoch 2200/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 4.1198 - val_accuracy: 0.3330\n",
            "Epoch 2201/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2619 - accuracy: 1.0000 - val_loss: 4.0842 - val_accuracy: 0.3289\n",
            "Epoch 2202/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2633 - accuracy: 0.9950 - val_loss: 4.1148 - val_accuracy: 0.3213\n",
            "Epoch 2203/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2712 - accuracy: 0.9950 - val_loss: 3.8673 - val_accuracy: 0.3463\n",
            "Epoch 2204/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2826 - accuracy: 0.9900 - val_loss: 3.9083 - val_accuracy: 0.3365\n",
            "Epoch 2205/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2649 - accuracy: 0.9950 - val_loss: 3.9046 - val_accuracy: 0.3374\n",
            "Epoch 2206/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 3.9054 - val_accuracy: 0.3376\n",
            "Epoch 2207/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2793 - accuracy: 0.9950 - val_loss: 3.8633 - val_accuracy: 0.3445\n",
            "Epoch 2208/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2703 - accuracy: 0.9900 - val_loss: 3.8161 - val_accuracy: 0.3488\n",
            "Epoch 2209/6000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2660 - accuracy: 0.9950 - val_loss: 3.8140 - val_accuracy: 0.3496\n",
            "Epoch 2210/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2791 - accuracy: 0.9900 - val_loss: 3.8146 - val_accuracy: 0.3546\n",
            "Epoch 2211/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2585 - accuracy: 0.9950 - val_loss: 3.8711 - val_accuracy: 0.3476\n",
            "Epoch 2212/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2649 - accuracy: 0.9950 - val_loss: 3.7693 - val_accuracy: 0.3589\n",
            "Epoch 2213/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2755 - accuracy: 0.9950 - val_loss: 3.8184 - val_accuracy: 0.3459\n",
            "Epoch 2214/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2768 - accuracy: 0.9950 - val_loss: 3.7999 - val_accuracy: 0.3446\n",
            "Epoch 2215/6000\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 3.7818 - val_accuracy: 0.3479\n",
            "Epoch 2216/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3005 - accuracy: 0.9800 - val_loss: 4.0347 - val_accuracy: 0.3152\n",
            "Epoch 2217/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2681 - accuracy: 0.9900 - val_loss: 4.0687 - val_accuracy: 0.3080\n",
            "Epoch 2218/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3119 - accuracy: 0.9850 - val_loss: 3.9560 - val_accuracy: 0.3221\n",
            "Epoch 2219/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2716 - accuracy: 0.9950 - val_loss: 3.9929 - val_accuracy: 0.3119\n",
            "Epoch 2220/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2604 - accuracy: 0.9950 - val_loss: 3.8668 - val_accuracy: 0.3221\n",
            "Epoch 2221/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2725 - accuracy: 0.9950 - val_loss: 3.8640 - val_accuracy: 0.3280\n",
            "Epoch 2222/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2749 - accuracy: 0.9950 - val_loss: 3.9138 - val_accuracy: 0.3320\n",
            "Epoch 2223/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2556 - accuracy: 1.0000 - val_loss: 3.9876 - val_accuracy: 0.3239\n",
            "Epoch 2224/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2656 - accuracy: 0.9950 - val_loss: 3.8709 - val_accuracy: 0.3342\n",
            "Epoch 2225/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2616 - accuracy: 0.9950 - val_loss: 3.9533 - val_accuracy: 0.3304\n",
            "Epoch 2226/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2514 - accuracy: 1.0000 - val_loss: 3.8917 - val_accuracy: 0.3312\n",
            "Epoch 2227/6000\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.3009 - accuracy: 0.9850 - val_loss: 4.0404 - val_accuracy: 0.3345\n",
            "Epoch 2228/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2940 - accuracy: 0.9850 - val_loss: 4.5807 - val_accuracy: 0.3096\n",
            "Epoch 2229/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2637 - accuracy: 0.9950 - val_loss: 4.4068 - val_accuracy: 0.3261\n",
            "Epoch 2230/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2633 - accuracy: 0.9950 - val_loss: 4.2725 - val_accuracy: 0.3202\n",
            "Epoch 2231/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2576 - accuracy: 0.9950 - val_loss: 3.8257 - val_accuracy: 0.3582\n",
            "Epoch 2232/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2653 - accuracy: 1.0000 - val_loss: 3.8779 - val_accuracy: 0.3534\n",
            "Epoch 2233/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2752 - accuracy: 0.9950 - val_loss: 3.8678 - val_accuracy: 0.3497\n",
            "Epoch 2234/6000\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2550 - accuracy: 1.0000 - val_loss: 3.9036 - val_accuracy: 0.3493\n",
            "Epoch 2235/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 3.9315 - val_accuracy: 0.3477\n",
            "Epoch 2236/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2753 - accuracy: 0.9950 - val_loss: 4.1247 - val_accuracy: 0.3311\n",
            "Epoch 2237/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2660 - accuracy: 0.9900 - val_loss: 3.7972 - val_accuracy: 0.3468\n",
            "Epoch 2238/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2664 - accuracy: 0.9900 - val_loss: 3.8102 - val_accuracy: 0.3366\n",
            "Epoch 2239/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2699 - accuracy: 0.9900 - val_loss: 3.9640 - val_accuracy: 0.3222\n",
            "Epoch 2240/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2789 - accuracy: 0.9900 - val_loss: 3.8243 - val_accuracy: 0.3386\n",
            "Epoch 2241/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2558 - accuracy: 1.0000 - val_loss: 4.0009 - val_accuracy: 0.3350\n",
            "Epoch 2242/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2744 - accuracy: 0.9900 - val_loss: 3.8718 - val_accuracy: 0.3467\n",
            "Epoch 2243/6000\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.2569 - accuracy: 0.9950 - val_loss: 3.8553 - val_accuracy: 0.3483\n",
            "Epoch 2244/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2758 - accuracy: 0.9900 - val_loss: 3.7529 - val_accuracy: 0.3392\n",
            "Epoch 2245/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2524 - accuracy: 1.0000 - val_loss: 3.7578 - val_accuracy: 0.3393\n",
            "Epoch 2246/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2576 - accuracy: 1.0000 - val_loss: 3.7414 - val_accuracy: 0.3366\n",
            "Epoch 2247/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2655 - accuracy: 0.9950 - val_loss: 3.7972 - val_accuracy: 0.3364\n",
            "Epoch 2248/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2628 - accuracy: 0.9950 - val_loss: 3.8041 - val_accuracy: 0.3352\n",
            "Epoch 2249/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2592 - accuracy: 1.0000 - val_loss: 3.8114 - val_accuracy: 0.3321\n",
            "Epoch 2250/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2642 - accuracy: 0.9950 - val_loss: 3.8088 - val_accuracy: 0.3331\n",
            "Epoch 2251/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2760 - accuracy: 0.9950 - val_loss: 3.7398 - val_accuracy: 0.3497\n",
            "Epoch 2252/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2565 - accuracy: 0.9950 - val_loss: 3.7109 - val_accuracy: 0.3535\n",
            "Epoch 2253/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2623 - accuracy: 0.9950 - val_loss: 3.7577 - val_accuracy: 0.3465\n",
            "Epoch 2254/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2839 - accuracy: 0.9850 - val_loss: 3.7261 - val_accuracy: 0.3546\n",
            "Epoch 2255/6000\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2510 - accuracy: 1.0000 - val_loss: 3.7310 - val_accuracy: 0.3531\n",
            "Epoch 2256/6000\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2523 - accuracy: 0.9950 - val_loss: 3.6929 - val_accuracy: 0.3534\n",
            "Epoch 2257/6000\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2639 - accuracy: 0.9900 - val_loss: 3.6748 - val_accuracy: 0.3551\n",
            "Epoch 2258/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2570 - accuracy: 0.9950 - val_loss: 3.6790 - val_accuracy: 0.3527\n",
            "Epoch 2259/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2621 - accuracy: 0.9950 - val_loss: 3.5946 - val_accuracy: 0.3608\n",
            "Epoch 2260/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 3.5980 - val_accuracy: 0.3649\n",
            "Epoch 2261/6000\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2504 - accuracy: 1.0000 - val_loss: 3.5985 - val_accuracy: 0.3660\n",
            "Epoch 2262/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2593 - accuracy: 0.9900 - val_loss: 3.5961 - val_accuracy: 0.3609\n",
            "Epoch 2263/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2707 - accuracy: 0.9900 - val_loss: 3.6554 - val_accuracy: 0.3546\n",
            "Epoch 2264/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2533 - accuracy: 0.9950 - val_loss: 3.6918 - val_accuracy: 0.3514\n",
            "Epoch 2265/6000\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2569 - accuracy: 0.9950 - val_loss: 3.6374 - val_accuracy: 0.3544\n",
            "Epoch 2266/6000\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 3.6237 - val_accuracy: 0.3537\n",
            "Epoch 2267/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2555 - accuracy: 0.9950 - val_loss: 3.7621 - val_accuracy: 0.3397\n",
            "Epoch 2268/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2554 - accuracy: 0.9950 - val_loss: 3.7910 - val_accuracy: 0.3372\n",
            "Epoch 2269/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2537 - accuracy: 0.9950 - val_loss: 3.8527 - val_accuracy: 0.3292\n",
            "Epoch 2270/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2611 - accuracy: 0.9900 - val_loss: 3.9502 - val_accuracy: 0.3144\n",
            "Epoch 2271/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 3.9069 - val_accuracy: 0.3213\n",
            "Epoch 2272/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2632 - accuracy: 0.9950 - val_loss: 3.6487 - val_accuracy: 0.3473\n",
            "Epoch 2273/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2532 - accuracy: 0.9950 - val_loss: 3.6541 - val_accuracy: 0.3479\n",
            "Epoch 2274/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2480 - accuracy: 1.0000 - val_loss: 3.6179 - val_accuracy: 0.3499\n",
            "Epoch 2275/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2563 - accuracy: 0.9950 - val_loss: 3.5437 - val_accuracy: 0.3631\n",
            "Epoch 2276/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2548 - accuracy: 0.9950 - val_loss: 3.5041 - val_accuracy: 0.3650\n",
            "Epoch 2277/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2652 - accuracy: 0.9900 - val_loss: 3.4877 - val_accuracy: 0.3781\n",
            "Epoch 2278/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 3.6305 - val_accuracy: 0.3737\n",
            "Epoch 2279/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2635 - accuracy: 0.9950 - val_loss: 3.4452 - val_accuracy: 0.3814\n",
            "Epoch 2280/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2401 - accuracy: 1.0000 - val_loss: 3.4288 - val_accuracy: 0.3842\n",
            "Epoch 2281/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 3.3998 - val_accuracy: 0.3828\n",
            "Epoch 2282/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 3.4094 - val_accuracy: 0.3780\n",
            "Epoch 2283/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2491 - accuracy: 1.0000 - val_loss: 3.4534 - val_accuracy: 0.3712\n",
            "Epoch 2284/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2830 - accuracy: 0.9900 - val_loss: 3.6564 - val_accuracy: 0.3545\n",
            "Epoch 2285/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 3.8321 - val_accuracy: 0.3389\n",
            "Epoch 2286/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 3.9275 - val_accuracy: 0.3293\n",
            "Epoch 2287/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 3.8738 - val_accuracy: 0.3353\n",
            "Epoch 2288/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2643 - accuracy: 0.9900 - val_loss: 3.8796 - val_accuracy: 0.3295\n",
            "Epoch 2289/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2635 - accuracy: 0.9900 - val_loss: 4.1940 - val_accuracy: 0.3106\n",
            "Epoch 2290/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2499 - accuracy: 0.9950 - val_loss: 3.7558 - val_accuracy: 0.3357\n",
            "Epoch 2291/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2392 - accuracy: 1.0000 - val_loss: 3.7941 - val_accuracy: 0.3307\n",
            "Epoch 2292/6000\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 3.7983 - val_accuracy: 0.3286\n",
            "Epoch 2293/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.8454 - val_accuracy: 0.3251\n",
            "Epoch 2294/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 4.1293 - val_accuracy: 0.3090\n",
            "Epoch 2295/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2524 - accuracy: 0.9900 - val_loss: 4.2719 - val_accuracy: 0.3028\n",
            "Epoch 2296/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2439 - accuracy: 0.9950 - val_loss: 4.1879 - val_accuracy: 0.3056\n",
            "Epoch 2297/6000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 3.9813 - val_accuracy: 0.3162\n",
            "Epoch 2298/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2535 - accuracy: 0.9900 - val_loss: 3.7484 - val_accuracy: 0.3305\n",
            "Epoch 2299/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2506 - accuracy: 0.9950 - val_loss: 3.8653 - val_accuracy: 0.3321\n",
            "Epoch 2300/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 3.7936 - val_accuracy: 0.3384\n",
            "Epoch 2301/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 3.7718 - val_accuracy: 0.3379\n",
            "Epoch 2302/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2581 - accuracy: 0.9900 - val_loss: 3.6391 - val_accuracy: 0.3402\n",
            "Epoch 2303/6000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 3.6571 - val_accuracy: 0.3386\n",
            "Epoch 2304/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2921 - accuracy: 0.9900 - val_loss: 3.8951 - val_accuracy: 0.3229\n",
            "Epoch 2305/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2689 - accuracy: 0.9850 - val_loss: 3.7256 - val_accuracy: 0.3188\n",
            "Epoch 2306/6000\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2837 - accuracy: 0.9900 - val_loss: 3.7140 - val_accuracy: 0.3154\n",
            "Epoch 2307/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2396 - accuracy: 1.0000 - val_loss: 3.6742 - val_accuracy: 0.3240\n",
            "Epoch 2308/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2419 - accuracy: 0.9950 - val_loss: 3.6630 - val_accuracy: 0.3267\n",
            "Epoch 2309/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2500 - accuracy: 0.9950 - val_loss: 3.6491 - val_accuracy: 0.3296\n",
            "Epoch 2310/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.6516 - val_accuracy: 0.3279\n",
            "Epoch 2311/6000\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.2724 - accuracy: 0.9850 - val_loss: 3.7517 - val_accuracy: 0.3330\n",
            "Epoch 2312/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 3.8242 - val_accuracy: 0.3242\n",
            "Epoch 2313/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 3.7202 - val_accuracy: 0.3310\n",
            "Epoch 2314/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2352 - accuracy: 1.0000 - val_loss: 3.6763 - val_accuracy: 0.3356\n",
            "Epoch 2315/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2533 - accuracy: 0.9850 - val_loss: 3.4476 - val_accuracy: 0.3602\n",
            "Epoch 2316/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2581 - accuracy: 0.9850 - val_loss: 3.5350 - val_accuracy: 0.3594\n",
            "Epoch 2317/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2404 - accuracy: 0.9950 - val_loss: 3.4613 - val_accuracy: 0.3620\n",
            "Epoch 2318/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2457 - accuracy: 0.9950 - val_loss: 3.4200 - val_accuracy: 0.3660\n",
            "Epoch 2319/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2589 - accuracy: 0.9950 - val_loss: 3.3667 - val_accuracy: 0.3734\n",
            "Epoch 2320/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2526 - accuracy: 0.9900 - val_loss: 3.3885 - val_accuracy: 0.3668\n",
            "Epoch 2321/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2371 - accuracy: 0.9950 - val_loss: 3.4165 - val_accuracy: 0.3634\n",
            "Epoch 2322/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2672 - accuracy: 0.9850 - val_loss: 3.6073 - val_accuracy: 0.3382\n",
            "Epoch 2323/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2492 - accuracy: 0.9950 - val_loss: 3.6573 - val_accuracy: 0.3417\n",
            "Epoch 2324/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 3.5648 - val_accuracy: 0.3490\n",
            "Epoch 2325/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2602 - accuracy: 0.9850 - val_loss: 3.4415 - val_accuracy: 0.3732\n",
            "Epoch 2326/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 3.5139 - val_accuracy: 0.3620\n",
            "Epoch 2327/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3063 - accuracy: 0.9750 - val_loss: 3.7995 - val_accuracy: 0.3422\n",
            "Epoch 2328/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2445 - accuracy: 1.0000 - val_loss: 3.8374 - val_accuracy: 0.3333\n",
            "Epoch 2329/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2564 - accuracy: 0.9950 - val_loss: 3.9551 - val_accuracy: 0.3160\n",
            "Epoch 2330/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2727 - accuracy: 0.9900 - val_loss: 3.9369 - val_accuracy: 0.3093\n",
            "Epoch 2331/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2466 - accuracy: 0.9950 - val_loss: 3.8235 - val_accuracy: 0.3211\n",
            "Epoch 2332/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 3.9121 - val_accuracy: 0.3092\n",
            "Epoch 2333/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2749 - accuracy: 0.9900 - val_loss: 3.6458 - val_accuracy: 0.3420\n",
            "Epoch 2334/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.5890 - val_accuracy: 0.3440\n",
            "Epoch 2335/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.5339 - val_accuracy: 0.3504\n",
            "Epoch 2336/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2782 - accuracy: 0.9950 - val_loss: 3.5740 - val_accuracy: 0.3420\n",
            "Epoch 2337/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 3.5385 - val_accuracy: 0.3466\n",
            "Epoch 2338/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2647 - accuracy: 0.9850 - val_loss: 3.5299 - val_accuracy: 0.3408\n",
            "Epoch 2339/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2448 - accuracy: 0.9950 - val_loss: 3.4899 - val_accuracy: 0.3408\n",
            "Epoch 2340/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2382 - accuracy: 1.0000 - val_loss: 3.5062 - val_accuracy: 0.3389\n",
            "Epoch 2341/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2755 - accuracy: 0.9900 - val_loss: 3.2910 - val_accuracy: 0.3725\n",
            "Epoch 2342/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2458 - accuracy: 0.9950 - val_loss: 3.3530 - val_accuracy: 0.3684\n",
            "Epoch 2343/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2555 - accuracy: 0.9850 - val_loss: 3.2550 - val_accuracy: 0.3755\n",
            "Epoch 2344/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2535 - accuracy: 0.9950 - val_loss: 3.3525 - val_accuracy: 0.3604\n",
            "Epoch 2345/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2778 - accuracy: 0.9850 - val_loss: 3.3960 - val_accuracy: 0.3542\n",
            "Epoch 2346/6000\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 3.3586 - val_accuracy: 0.3586\n",
            "Epoch 2347/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2466 - accuracy: 0.9950 - val_loss: 3.3826 - val_accuracy: 0.3562\n",
            "Epoch 2348/6000\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 3.3278 - val_accuracy: 0.3607\n",
            "Epoch 2349/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2521 - accuracy: 0.9950 - val_loss: 3.3777 - val_accuracy: 0.3603\n",
            "Epoch 2350/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.4046 - val_accuracy: 0.3594\n",
            "Epoch 2351/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2726 - accuracy: 0.9900 - val_loss: 3.5103 - val_accuracy: 0.3387\n",
            "Epoch 2352/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.3744 - val_accuracy: 0.3518\n",
            "Epoch 2353/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2433 - accuracy: 0.9950 - val_loss: 3.3894 - val_accuracy: 0.3571\n",
            "Epoch 2354/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2700 - accuracy: 0.9800 - val_loss: 3.4687 - val_accuracy: 0.3493\n",
            "Epoch 2355/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2461 - accuracy: 0.9950 - val_loss: 3.3544 - val_accuracy: 0.3643\n",
            "Epoch 2356/6000\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.2485 - accuracy: 0.9950 - val_loss: 3.3785 - val_accuracy: 0.3598\n",
            "Epoch 2357/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2458 - accuracy: 0.9950 - val_loss: 3.4362 - val_accuracy: 0.3611\n",
            "Epoch 2358/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2635 - accuracy: 0.9850 - val_loss: 3.5041 - val_accuracy: 0.3567\n",
            "Epoch 2359/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2356 - accuracy: 1.0000 - val_loss: 3.5026 - val_accuracy: 0.3580\n",
            "Epoch 2360/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2526 - accuracy: 0.9900 - val_loss: 3.4924 - val_accuracy: 0.3570\n",
            "Epoch 2361/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2723 - accuracy: 0.9850 - val_loss: 3.6865 - val_accuracy: 0.3425\n",
            "Epoch 2362/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2595 - accuracy: 0.9900 - val_loss: 3.6292 - val_accuracy: 0.3491\n",
            "Epoch 2363/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2341 - accuracy: 1.0000 - val_loss: 3.6537 - val_accuracy: 0.3454\n",
            "Epoch 2364/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2524 - accuracy: 0.9900 - val_loss: 3.9227 - val_accuracy: 0.3268\n",
            "Epoch 2365/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 3.9144 - val_accuracy: 0.3188\n",
            "Epoch 2366/6000\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.2607 - accuracy: 0.9900 - val_loss: 4.3677 - val_accuracy: 0.2921\n",
            "Epoch 2367/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 4.2144 - val_accuracy: 0.2967\n",
            "Epoch 2368/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 4.3217 - val_accuracy: 0.2928\n",
            "Epoch 2369/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2755 - accuracy: 0.9950 - val_loss: 4.6255 - val_accuracy: 0.2917\n",
            "Epoch 2370/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2536 - accuracy: 0.9950 - val_loss: 4.2344 - val_accuracy: 0.3105\n",
            "Epoch 2371/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2509 - accuracy: 0.9900 - val_loss: 3.9049 - val_accuracy: 0.3294\n",
            "Epoch 2372/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2804 - accuracy: 0.9900 - val_loss: 3.9714 - val_accuracy: 0.3274\n",
            "Epoch 2373/6000\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.2781 - accuracy: 0.9850 - val_loss: 4.1486 - val_accuracy: 0.3221\n",
            "Epoch 2374/6000\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2509 - accuracy: 0.9950 - val_loss: 3.5149 - val_accuracy: 0.3594\n",
            "Epoch 2375/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2582 - accuracy: 0.9950 - val_loss: 3.5817 - val_accuracy: 0.3569\n",
            "Epoch 2376/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2599 - accuracy: 0.9850 - val_loss: 3.5741 - val_accuracy: 0.3589\n",
            "Epoch 2377/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2639 - accuracy: 0.9900 - val_loss: 3.6633 - val_accuracy: 0.3555\n",
            "Epoch 2378/6000\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.2526 - accuracy: 0.9950 - val_loss: 3.5442 - val_accuracy: 0.3615\n",
            "Epoch 2379/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2442 - accuracy: 0.9950 - val_loss: 3.5279 - val_accuracy: 0.3681\n",
            "Epoch 2380/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 3.5306 - val_accuracy: 0.3649\n",
            "Epoch 2381/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2695 - accuracy: 0.9850 - val_loss: 3.4869 - val_accuracy: 0.3696\n",
            "Epoch 2382/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2472 - accuracy: 0.9950 - val_loss: 3.6459 - val_accuracy: 0.3497\n",
            "Epoch 2383/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2580 - accuracy: 0.9900 - val_loss: 3.5473 - val_accuracy: 0.3612\n",
            "Epoch 2384/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2538 - accuracy: 0.9850 - val_loss: 3.6682 - val_accuracy: 0.3378\n",
            "Epoch 2385/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2422 - accuracy: 1.0000 - val_loss: 3.6432 - val_accuracy: 0.3444\n",
            "Epoch 2386/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2435 - accuracy: 1.0000 - val_loss: 3.5944 - val_accuracy: 0.3484\n",
            "Epoch 2387/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2499 - accuracy: 0.9950 - val_loss: 3.5712 - val_accuracy: 0.3558\n",
            "Epoch 2388/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2907 - accuracy: 0.9750 - val_loss: 3.4948 - val_accuracy: 0.3638\n",
            "Epoch 2389/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 3.4778 - val_accuracy: 0.3661\n",
            "Epoch 2390/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2558 - accuracy: 0.9900 - val_loss: 3.8757 - val_accuracy: 0.3420\n",
            "Epoch 2391/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2549 - accuracy: 0.9950 - val_loss: 3.5336 - val_accuracy: 0.3611\n",
            "Epoch 2392/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2422 - accuracy: 0.9950 - val_loss: 3.6971 - val_accuracy: 0.3459\n",
            "Epoch 2393/6000\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 3.6247 - val_accuracy: 0.3573\n",
            "Epoch 2394/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2502 - accuracy: 0.9900 - val_loss: 3.8271 - val_accuracy: 0.3413\n",
            "Epoch 2395/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2383 - accuracy: 1.0000 - val_loss: 3.8298 - val_accuracy: 0.3402\n",
            "Epoch 2396/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2699 - accuracy: 0.9900 - val_loss: 3.8240 - val_accuracy: 0.3394\n",
            "Epoch 2397/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2527 - accuracy: 0.9900 - val_loss: 3.8583 - val_accuracy: 0.3415\n",
            "Epoch 2398/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2646 - accuracy: 0.9950 - val_loss: 4.1623 - val_accuracy: 0.2993\n",
            "Epoch 2399/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2514 - accuracy: 0.9950 - val_loss: 3.7238 - val_accuracy: 0.3384\n",
            "Epoch 2400/6000\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2586 - accuracy: 0.9950 - val_loss: 3.7589 - val_accuracy: 0.3329\n",
            "Epoch 2401/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2685 - accuracy: 0.9900 - val_loss: 3.8247 - val_accuracy: 0.3319\n",
            "Epoch 2402/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2596 - accuracy: 0.9900 - val_loss: 4.7130 - val_accuracy: 0.2929\n",
            "Epoch 2403/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2712 - accuracy: 0.9900 - val_loss: 4.4368 - val_accuracy: 0.3039\n",
            "Epoch 2404/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 4.0664 - val_accuracy: 0.3222\n",
            "Epoch 2405/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2527 - accuracy: 0.9900 - val_loss: 3.8418 - val_accuracy: 0.3337\n",
            "Epoch 2406/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2477 - accuracy: 1.0000 - val_loss: 3.9403 - val_accuracy: 0.3346\n",
            "Epoch 2407/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2506 - accuracy: 1.0000 - val_loss: 3.7095 - val_accuracy: 0.3477\n",
            "Epoch 2408/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2699 - accuracy: 0.9800 - val_loss: 3.6649 - val_accuracy: 0.3467\n",
            "Epoch 2409/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2707 - accuracy: 0.9850 - val_loss: 3.6075 - val_accuracy: 0.3543\n",
            "Epoch 2410/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2463 - accuracy: 0.9950 - val_loss: 3.6749 - val_accuracy: 0.3540\n",
            "Epoch 2411/6000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2568 - accuracy: 0.9900 - val_loss: 3.7893 - val_accuracy: 0.3510\n",
            "Epoch 2412/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2854 - accuracy: 0.9850 - val_loss: 3.6800 - val_accuracy: 0.3519\n",
            "Epoch 2413/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2640 - accuracy: 0.9950 - val_loss: 3.7419 - val_accuracy: 0.3532\n",
            "Epoch 2414/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2684 - accuracy: 0.9850 - val_loss: 3.9734 - val_accuracy: 0.3526\n",
            "Epoch 2415/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2665 - accuracy: 0.9850 - val_loss: 4.5069 - val_accuracy: 0.3221\n",
            "Epoch 2416/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2844 - accuracy: 0.9800 - val_loss: 3.9223 - val_accuracy: 0.3391\n",
            "Epoch 2417/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3054 - accuracy: 0.9750 - val_loss: 3.9272 - val_accuracy: 0.3459\n",
            "Epoch 2418/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2586 - accuracy: 1.0000 - val_loss: 3.9014 - val_accuracy: 0.3489\n",
            "Epoch 2419/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 3.8768 - val_accuracy: 0.3507\n",
            "Epoch 2420/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2747 - accuracy: 0.9850 - val_loss: 3.7493 - val_accuracy: 0.3595\n",
            "Epoch 2421/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2533 - accuracy: 0.9950 - val_loss: 3.7611 - val_accuracy: 0.3625\n",
            "Epoch 2422/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2512 - accuracy: 1.0000 - val_loss: 3.7636 - val_accuracy: 0.3603\n",
            "Epoch 2423/6000\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2877 - accuracy: 0.9800 - val_loss: 3.5950 - val_accuracy: 0.3724\n",
            "Epoch 2424/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2815 - accuracy: 0.9850 - val_loss: 3.5108 - val_accuracy: 0.3737\n",
            "Epoch 2425/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2828 - accuracy: 0.9800 - val_loss: 3.5591 - val_accuracy: 0.3616\n",
            "Epoch 2426/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2546 - accuracy: 0.9950 - val_loss: 3.4839 - val_accuracy: 0.3646\n",
            "Epoch 2427/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2649 - accuracy: 0.9850 - val_loss: 3.6439 - val_accuracy: 0.3563\n",
            "Epoch 2428/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2687 - accuracy: 0.9950 - val_loss: 3.6981 - val_accuracy: 0.3560\n",
            "Epoch 2429/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2614 - accuracy: 0.9950 - val_loss: 3.6374 - val_accuracy: 0.3627\n",
            "Epoch 2430/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2694 - accuracy: 0.9850 - val_loss: 3.6159 - val_accuracy: 0.3635\n",
            "Epoch 2431/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2925 - accuracy: 0.9900 - val_loss: 3.7730 - val_accuracy: 0.3431\n",
            "Epoch 2432/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2869 - accuracy: 0.9800 - val_loss: 3.6194 - val_accuracy: 0.3604\n",
            "Epoch 2433/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2708 - accuracy: 0.9900 - val_loss: 3.9253 - val_accuracy: 0.3350\n",
            "Epoch 2434/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2794 - accuracy: 0.9850 - val_loss: 3.6372 - val_accuracy: 0.3550\n",
            "Epoch 2435/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2612 - accuracy: 0.9950 - val_loss: 3.7348 - val_accuracy: 0.3481\n",
            "Epoch 2436/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2684 - accuracy: 0.9950 - val_loss: 3.7139 - val_accuracy: 0.3470\n",
            "Epoch 2437/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2852 - accuracy: 0.9800 - val_loss: 3.6045 - val_accuracy: 0.3635\n",
            "Epoch 2438/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2595 - accuracy: 0.9900 - val_loss: 3.6415 - val_accuracy: 0.3637\n",
            "Epoch 2439/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2514 - accuracy: 1.0000 - val_loss: 3.6502 - val_accuracy: 0.3654\n",
            "Epoch 2440/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.3178 - accuracy: 0.9850 - val_loss: 4.1430 - val_accuracy: 0.3038\n",
            "Epoch 2441/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2563 - accuracy: 0.9950 - val_loss: 3.8793 - val_accuracy: 0.3319\n",
            "Epoch 2442/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2607 - accuracy: 0.9950 - val_loss: 3.7319 - val_accuracy: 0.3467\n",
            "Epoch 2443/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2881 - accuracy: 0.9850 - val_loss: 3.6665 - val_accuracy: 0.3516\n",
            "Epoch 2444/6000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 3.6370 - val_accuracy: 0.3544\n",
            "Epoch 2445/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2584 - accuracy: 0.9950 - val_loss: 3.6331 - val_accuracy: 0.3567\n",
            "Epoch 2446/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2560 - accuracy: 0.9950 - val_loss: 3.6186 - val_accuracy: 0.3549\n",
            "Epoch 2447/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2584 - accuracy: 0.9950 - val_loss: 3.6796 - val_accuracy: 0.3538\n",
            "Epoch 2448/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2684 - accuracy: 0.9900 - val_loss: 3.6690 - val_accuracy: 0.3526\n",
            "Epoch 2449/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2881 - accuracy: 0.9900 - val_loss: 3.8122 - val_accuracy: 0.3495\n",
            "Epoch 2450/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2627 - accuracy: 0.9900 - val_loss: 3.7329 - val_accuracy: 0.3571\n",
            "Epoch 2451/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2761 - accuracy: 0.9900 - val_loss: 3.7878 - val_accuracy: 0.3567\n",
            "Epoch 2452/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2591 - accuracy: 1.0000 - val_loss: 3.7731 - val_accuracy: 0.3568\n",
            "Epoch 2453/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 3.7790 - val_accuracy: 0.3583\n",
            "Epoch 2454/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 3.7871 - val_accuracy: 0.3593\n",
            "Epoch 2455/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2885 - accuracy: 0.9800 - val_loss: 4.0378 - val_accuracy: 0.3504\n",
            "Epoch 2456/6000\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2728 - accuracy: 0.9900 - val_loss: 4.0674 - val_accuracy: 0.3478\n",
            "Epoch 2457/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2807 - accuracy: 0.9850 - val_loss: 4.2104 - val_accuracy: 0.3426\n",
            "Epoch 2458/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2773 - accuracy: 0.9900 - val_loss: 4.1335 - val_accuracy: 0.3523\n",
            "Epoch 2459/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2632 - accuracy: 0.9900 - val_loss: 4.2376 - val_accuracy: 0.3321\n",
            "Epoch 2460/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2863 - accuracy: 0.9800 - val_loss: 4.1666 - val_accuracy: 0.3362\n",
            "Epoch 2461/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2733 - accuracy: 0.9850 - val_loss: 4.3697 - val_accuracy: 0.3264\n",
            "Epoch 2462/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.3095 - accuracy: 0.9750 - val_loss: 4.0723 - val_accuracy: 0.3534\n",
            "Epoch 2463/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2634 - accuracy: 0.9950 - val_loss: 4.0636 - val_accuracy: 0.3545\n",
            "Epoch 2464/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2613 - accuracy: 0.9950 - val_loss: 4.0854 - val_accuracy: 0.3521\n",
            "Epoch 2465/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.3062 - accuracy: 0.9800 - val_loss: 4.2661 - val_accuracy: 0.3416\n",
            "Epoch 2466/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3335 - accuracy: 0.9750 - val_loss: 4.0330 - val_accuracy: 0.3600\n",
            "Epoch 2467/6000\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2786 - accuracy: 0.9950 - val_loss: 3.7689 - val_accuracy: 0.3789\n",
            "Epoch 2468/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2728 - accuracy: 0.9950 - val_loss: 3.7076 - val_accuracy: 0.3788\n",
            "Epoch 2469/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2682 - accuracy: 0.9900 - val_loss: 3.7463 - val_accuracy: 0.3722\n",
            "Epoch 2470/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2697 - accuracy: 0.9900 - val_loss: 3.6249 - val_accuracy: 0.3714\n",
            "Epoch 2471/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2762 - accuracy: 0.9900 - val_loss: 3.5930 - val_accuracy: 0.3714\n",
            "Epoch 2472/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.3118 - accuracy: 0.9750 - val_loss: 3.8237 - val_accuracy: 0.3607\n",
            "Epoch 2473/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2669 - accuracy: 0.9950 - val_loss: 3.7511 - val_accuracy: 0.3607\n",
            "Epoch 2474/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2813 - accuracy: 0.9850 - val_loss: 3.6097 - val_accuracy: 0.3673\n",
            "Epoch 2475/6000\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2701 - accuracy: 0.9900 - val_loss: 3.6269 - val_accuracy: 0.3638\n",
            "Epoch 2476/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2867 - accuracy: 0.9850 - val_loss: 3.7031 - val_accuracy: 0.3639\n",
            "Epoch 2477/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2900 - accuracy: 0.9800 - val_loss: 3.6723 - val_accuracy: 0.3788\n",
            "Epoch 2478/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2996 - accuracy: 0.9900 - val_loss: 3.6662 - val_accuracy: 0.3679\n",
            "Epoch 2479/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2662 - accuracy: 0.9950 - val_loss: 3.6711 - val_accuracy: 0.3648\n",
            "Epoch 2480/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2951 - accuracy: 0.9850 - val_loss: 3.7156 - val_accuracy: 0.3589\n",
            "Epoch 2481/6000\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2779 - accuracy: 0.9900 - val_loss: 3.6733 - val_accuracy: 0.3565\n",
            "Epoch 2482/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 3.6664 - val_accuracy: 0.3571\n",
            "Epoch 2483/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3148 - accuracy: 0.9850 - val_loss: 4.1110 - val_accuracy: 0.3143\n",
            "Epoch 2484/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3114 - accuracy: 0.9700 - val_loss: 3.5249 - val_accuracy: 0.3806\n",
            "Epoch 2485/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2832 - accuracy: 0.9900 - val_loss: 3.6132 - val_accuracy: 0.3702\n",
            "Epoch 2486/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2556 - accuracy: 1.0000 - val_loss: 3.6099 - val_accuracy: 0.3714\n",
            "Epoch 2487/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 3.6072 - val_accuracy: 0.3689\n",
            "Epoch 2488/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2688 - accuracy: 0.9900 - val_loss: 3.6129 - val_accuracy: 0.3706\n",
            "Epoch 2489/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2644 - accuracy: 0.9950 - val_loss: 3.6594 - val_accuracy: 0.3706\n",
            "Epoch 2490/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2816 - accuracy: 0.9900 - val_loss: 3.5381 - val_accuracy: 0.3812\n",
            "Epoch 2491/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2768 - accuracy: 0.9850 - val_loss: 3.5319 - val_accuracy: 0.3788\n",
            "Epoch 2492/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 3.5309 - val_accuracy: 0.3800\n",
            "Epoch 2493/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2800 - accuracy: 0.9950 - val_loss: 3.5084 - val_accuracy: 0.3802\n",
            "Epoch 2494/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 3.5047 - val_accuracy: 0.3818\n",
            "Epoch 2495/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2793 - accuracy: 0.9900 - val_loss: 3.5849 - val_accuracy: 0.3700\n",
            "Epoch 2496/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 3.6135 - val_accuracy: 0.3674\n",
            "Epoch 2497/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2599 - accuracy: 1.0000 - val_loss: 3.5755 - val_accuracy: 0.3690\n",
            "Epoch 2498/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2669 - accuracy: 0.9950 - val_loss: 3.5839 - val_accuracy: 0.3689\n",
            "Epoch 2499/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 3.5958 - val_accuracy: 0.3688\n",
            "Epoch 2500/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2718 - accuracy: 0.9900 - val_loss: 3.6928 - val_accuracy: 0.3645\n",
            "Epoch 2501/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2620 - accuracy: 1.0000 - val_loss: 3.7385 - val_accuracy: 0.3623\n",
            "Epoch 2502/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2550 - accuracy: 1.0000 - val_loss: 3.7945 - val_accuracy: 0.3616\n",
            "Epoch 2503/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2724 - accuracy: 1.0000 - val_loss: 3.7120 - val_accuracy: 0.3675\n",
            "Epoch 2504/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2698 - accuracy: 0.9900 - val_loss: 3.6430 - val_accuracy: 0.3770\n",
            "Epoch 2505/6000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2629 - accuracy: 0.9950 - val_loss: 3.6248 - val_accuracy: 0.3817\n",
            "Epoch 2506/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2603 - accuracy: 0.9950 - val_loss: 3.6533 - val_accuracy: 0.3787\n",
            "Epoch 2507/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2683 - accuracy: 0.9950 - val_loss: 3.7339 - val_accuracy: 0.3773\n",
            "Epoch 2508/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2644 - accuracy: 0.9950 - val_loss: 3.7361 - val_accuracy: 0.3774\n",
            "Epoch 2509/6000\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 3.7333 - val_accuracy: 0.3783\n",
            "Epoch 2510/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2627 - accuracy: 0.9950 - val_loss: 3.6284 - val_accuracy: 0.3846\n",
            "Epoch 2511/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2623 - accuracy: 0.9950 - val_loss: 3.6984 - val_accuracy: 0.3828\n",
            "Epoch 2512/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 3.6443 - val_accuracy: 0.3810\n",
            "Epoch 2513/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2569 - accuracy: 1.0000 - val_loss: 3.5947 - val_accuracy: 0.3814\n",
            "Epoch 2514/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 3.6373 - val_accuracy: 0.3754\n",
            "Epoch 2515/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2708 - accuracy: 0.9950 - val_loss: 3.6579 - val_accuracy: 0.3762\n",
            "Epoch 2516/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2559 - accuracy: 0.9950 - val_loss: 3.7779 - val_accuracy: 0.3643\n",
            "Epoch 2517/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2491 - accuracy: 1.0000 - val_loss: 3.7932 - val_accuracy: 0.3620\n",
            "Epoch 2518/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2598 - accuracy: 0.9950 - val_loss: 3.7577 - val_accuracy: 0.3637\n",
            "Epoch 2519/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2726 - accuracy: 0.9900 - val_loss: 3.9754 - val_accuracy: 0.3468\n",
            "Epoch 2520/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 3.9143 - val_accuracy: 0.3551\n",
            "Epoch 2521/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2527 - accuracy: 1.0000 - val_loss: 3.9141 - val_accuracy: 0.3544\n",
            "Epoch 2522/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2458 - accuracy: 1.0000 - val_loss: 3.9230 - val_accuracy: 0.3533\n",
            "Epoch 2523/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2602 - accuracy: 0.9950 - val_loss: 3.8463 - val_accuracy: 0.3578\n",
            "Epoch 2524/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2533 - accuracy: 1.0000 - val_loss: 3.8202 - val_accuracy: 0.3630\n",
            "Epoch 2525/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2577 - accuracy: 1.0000 - val_loss: 3.8157 - val_accuracy: 0.3647\n",
            "Epoch 2526/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2501 - accuracy: 1.0000 - val_loss: 3.7945 - val_accuracy: 0.3653\n",
            "Epoch 2527/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 3.8110 - val_accuracy: 0.3645\n",
            "Epoch 2528/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2817 - accuracy: 0.9850 - val_loss: 3.8318 - val_accuracy: 0.3497\n",
            "Epoch 2529/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2538 - accuracy: 0.9950 - val_loss: 3.7385 - val_accuracy: 0.3571\n",
            "Epoch 2530/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2665 - accuracy: 0.9950 - val_loss: 3.5876 - val_accuracy: 0.3682\n",
            "Epoch 2531/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2616 - accuracy: 0.9950 - val_loss: 3.5879 - val_accuracy: 0.3663\n",
            "Epoch 2532/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2749 - accuracy: 0.9850 - val_loss: 3.6382 - val_accuracy: 0.3685\n",
            "Epoch 2533/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2530 - accuracy: 0.9950 - val_loss: 3.6490 - val_accuracy: 0.3659\n",
            "Epoch 2534/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2586 - accuracy: 0.9950 - val_loss: 3.6208 - val_accuracy: 0.3755\n",
            "Epoch 2535/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2458 - accuracy: 1.0000 - val_loss: 3.6301 - val_accuracy: 0.3736\n",
            "Epoch 2536/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2528 - accuracy: 0.9950 - val_loss: 3.6169 - val_accuracy: 0.3713\n",
            "Epoch 2537/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 3.6133 - val_accuracy: 0.3715\n",
            "Epoch 2538/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2655 - accuracy: 0.9950 - val_loss: 3.6731 - val_accuracy: 0.3635\n",
            "Epoch 2539/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2693 - accuracy: 0.9900 - val_loss: 3.7952 - val_accuracy: 0.3509\n",
            "Epoch 2540/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 3.8647 - val_accuracy: 0.3491\n",
            "Epoch 2541/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2460 - accuracy: 1.0000 - val_loss: 3.9629 - val_accuracy: 0.3372\n",
            "Epoch 2542/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2589 - accuracy: 0.9950 - val_loss: 4.4115 - val_accuracy: 0.3025\n",
            "Epoch 2543/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2515 - accuracy: 0.9950 - val_loss: 4.5127 - val_accuracy: 0.2931\n",
            "Epoch 2544/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2599 - accuracy: 0.9950 - val_loss: 4.5346 - val_accuracy: 0.2976\n",
            "Epoch 2545/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2486 - accuracy: 1.0000 - val_loss: 4.3707 - val_accuracy: 0.3073\n",
            "Epoch 2546/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2506 - accuracy: 1.0000 - val_loss: 4.0687 - val_accuracy: 0.3280\n",
            "Epoch 2547/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2409 - accuracy: 1.0000 - val_loss: 4.0239 - val_accuracy: 0.3324\n",
            "Epoch 2548/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2743 - accuracy: 0.9850 - val_loss: 3.7767 - val_accuracy: 0.3575\n",
            "Epoch 2549/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2532 - accuracy: 0.9950 - val_loss: 3.7564 - val_accuracy: 0.3551\n",
            "Epoch 2550/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2506 - accuracy: 0.9950 - val_loss: 3.6913 - val_accuracy: 0.3617\n",
            "Epoch 2551/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 3.7205 - val_accuracy: 0.3614\n",
            "Epoch 2552/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 3.7461 - val_accuracy: 0.3596\n",
            "Epoch 2553/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2510 - accuracy: 0.9950 - val_loss: 3.7624 - val_accuracy: 0.3584\n",
            "Epoch 2554/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2456 - accuracy: 1.0000 - val_loss: 3.7541 - val_accuracy: 0.3611\n",
            "Epoch 2555/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 3.7367 - val_accuracy: 0.3612\n",
            "Epoch 2556/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 3.7301 - val_accuracy: 0.3601\n",
            "Epoch 2557/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2745 - accuracy: 0.9900 - val_loss: 3.7955 - val_accuracy: 0.3579\n",
            "Epoch 2558/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2439 - accuracy: 1.0000 - val_loss: 3.7821 - val_accuracy: 0.3613\n",
            "Epoch 2559/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2427 - accuracy: 1.0000 - val_loss: 3.7772 - val_accuracy: 0.3544\n",
            "Epoch 2560/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 3.8177 - val_accuracy: 0.3522\n",
            "Epoch 2561/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2749 - accuracy: 0.9900 - val_loss: 3.8865 - val_accuracy: 0.3454\n",
            "Epoch 2562/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2525 - accuracy: 0.9950 - val_loss: 3.8099 - val_accuracy: 0.3539\n",
            "Epoch 2563/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 3.8138 - val_accuracy: 0.3512\n",
            "Epoch 2564/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2464 - accuracy: 0.9950 - val_loss: 3.8597 - val_accuracy: 0.3551\n",
            "Epoch 2565/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2431 - accuracy: 0.9950 - val_loss: 3.8872 - val_accuracy: 0.3590\n",
            "Epoch 2566/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2627 - accuracy: 0.9850 - val_loss: 3.8629 - val_accuracy: 0.3556\n",
            "Epoch 2567/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2598 - accuracy: 0.9900 - val_loss: 3.8835 - val_accuracy: 0.3481\n",
            "Epoch 2568/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2677 - accuracy: 0.9950 - val_loss: 3.9876 - val_accuracy: 0.3427\n",
            "Epoch 2569/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 3.7442 - val_accuracy: 0.3532\n",
            "Epoch 2570/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2535 - accuracy: 0.9950 - val_loss: 3.7203 - val_accuracy: 0.3572\n",
            "Epoch 2571/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2573 - accuracy: 0.9950 - val_loss: 3.5812 - val_accuracy: 0.3663\n",
            "Epoch 2572/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2418 - accuracy: 0.9950 - val_loss: 3.5659 - val_accuracy: 0.3655\n",
            "Epoch 2573/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2456 - accuracy: 0.9950 - val_loss: 3.5534 - val_accuracy: 0.3662\n",
            "Epoch 2574/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2421 - accuracy: 0.9950 - val_loss: 3.6232 - val_accuracy: 0.3588\n",
            "Epoch 2575/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2415 - accuracy: 0.9950 - val_loss: 3.6468 - val_accuracy: 0.3558\n",
            "Epoch 2576/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2500 - accuracy: 0.9900 - val_loss: 3.9402 - val_accuracy: 0.3240\n",
            "Epoch 2577/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2353 - accuracy: 1.0000 - val_loss: 3.9026 - val_accuracy: 0.3304\n",
            "Epoch 2578/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 3.9212 - val_accuracy: 0.3279\n",
            "Epoch 2579/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2688 - accuracy: 0.9850 - val_loss: 3.7270 - val_accuracy: 0.3502\n",
            "Epoch 2580/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2545 - accuracy: 0.9900 - val_loss: 4.0661 - val_accuracy: 0.3281\n",
            "Epoch 2581/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2471 - accuracy: 0.9950 - val_loss: 3.9147 - val_accuracy: 0.3363\n",
            "Epoch 2582/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.9639 - val_accuracy: 0.3278\n",
            "Epoch 2583/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 3.8567 - val_accuracy: 0.3296\n",
            "Epoch 2584/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2347 - accuracy: 1.0000 - val_loss: 4.0082 - val_accuracy: 0.3128\n",
            "Epoch 2585/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.9825 - val_accuracy: 0.3220\n",
            "Epoch 2586/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2754 - accuracy: 0.9850 - val_loss: 3.7794 - val_accuracy: 0.3519\n",
            "Epoch 2587/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 3.6888 - val_accuracy: 0.3530\n",
            "Epoch 2588/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2462 - accuracy: 0.9950 - val_loss: 3.9956 - val_accuracy: 0.3366\n",
            "Epoch 2589/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2513 - accuracy: 0.9900 - val_loss: 4.5181 - val_accuracy: 0.3026\n",
            "Epoch 2590/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2454 - accuracy: 0.9950 - val_loss: 3.9230 - val_accuracy: 0.3352\n",
            "Epoch 2591/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2523 - accuracy: 0.9900 - val_loss: 3.8349 - val_accuracy: 0.3412\n",
            "Epoch 2592/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2415 - accuracy: 0.9950 - val_loss: 3.8358 - val_accuracy: 0.3382\n",
            "Epoch 2593/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2373 - accuracy: 1.0000 - val_loss: 3.8092 - val_accuracy: 0.3425\n",
            "Epoch 2594/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2674 - accuracy: 0.9900 - val_loss: 3.8543 - val_accuracy: 0.3555\n",
            "Epoch 2595/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2591 - accuracy: 0.9900 - val_loss: 3.7896 - val_accuracy: 0.3545\n",
            "Epoch 2596/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2437 - accuracy: 0.9950 - val_loss: 3.6531 - val_accuracy: 0.3629\n",
            "Epoch 2597/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2333 - accuracy: 1.0000 - val_loss: 3.6325 - val_accuracy: 0.3643\n",
            "Epoch 2598/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 3.6330 - val_accuracy: 0.3642\n",
            "Epoch 2599/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2493 - accuracy: 0.9900 - val_loss: 4.0259 - val_accuracy: 0.3417\n",
            "Epoch 2600/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2488 - accuracy: 0.9950 - val_loss: 3.6729 - val_accuracy: 0.3586\n",
            "Epoch 2601/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2347 - accuracy: 1.0000 - val_loss: 3.6555 - val_accuracy: 0.3603\n",
            "Epoch 2602/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2350 - accuracy: 1.0000 - val_loss: 3.6752 - val_accuracy: 0.3607\n",
            "Epoch 2603/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 3.6529 - val_accuracy: 0.3591\n",
            "Epoch 2604/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2741 - accuracy: 0.9800 - val_loss: 4.3428 - val_accuracy: 0.2931\n",
            "Epoch 2605/6000\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2419 - accuracy: 0.9950 - val_loss: 4.1451 - val_accuracy: 0.3076\n",
            "Epoch 2606/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3074 - accuracy: 0.9800 - val_loss: 3.6967 - val_accuracy: 0.3506\n",
            "Epoch 2607/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2749 - accuracy: 0.9850 - val_loss: 3.8496 - val_accuracy: 0.3416\n",
            "Epoch 2608/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2676 - accuracy: 0.9800 - val_loss: 3.8312 - val_accuracy: 0.3384\n",
            "Epoch 2609/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2470 - accuracy: 0.9950 - val_loss: 3.8956 - val_accuracy: 0.3323\n",
            "Epoch 2610/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2610 - accuracy: 0.9950 - val_loss: 4.6927 - val_accuracy: 0.2743\n",
            "Epoch 2611/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2761 - accuracy: 0.9800 - val_loss: 5.2547 - val_accuracy: 0.2737\n",
            "Epoch 2612/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2420 - accuracy: 0.9950 - val_loss: 5.0300 - val_accuracy: 0.2914\n",
            "Epoch 2613/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3292 - accuracy: 0.9650 - val_loss: 4.2426 - val_accuracy: 0.3274\n",
            "Epoch 2614/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2436 - accuracy: 0.9950 - val_loss: 4.2271 - val_accuracy: 0.3307\n",
            "Epoch 2615/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2540 - accuracy: 0.9950 - val_loss: 4.6607 - val_accuracy: 0.3006\n",
            "Epoch 2616/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2568 - accuracy: 0.9950 - val_loss: 3.9777 - val_accuracy: 0.3300\n",
            "Epoch 2617/6000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2526 - accuracy: 0.9950 - val_loss: 3.7392 - val_accuracy: 0.3378\n",
            "Epoch 2618/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2374 - accuracy: 1.0000 - val_loss: 3.6331 - val_accuracy: 0.3447\n",
            "Epoch 2619/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 3.6576 - val_accuracy: 0.3429\n",
            "Epoch 2620/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2605 - accuracy: 0.9950 - val_loss: 3.7746 - val_accuracy: 0.3351\n",
            "Epoch 2621/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2698 - accuracy: 0.9900 - val_loss: 3.7707 - val_accuracy: 0.3288\n",
            "Epoch 2622/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2525 - accuracy: 0.9900 - val_loss: 4.1979 - val_accuracy: 0.3166\n",
            "Epoch 2623/6000\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.2675 - accuracy: 0.9850 - val_loss: 4.1179 - val_accuracy: 0.3170\n",
            "Epoch 2624/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2508 - accuracy: 0.9900 - val_loss: 4.0569 - val_accuracy: 0.3183\n",
            "Epoch 2625/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2578 - accuracy: 0.9900 - val_loss: 3.9382 - val_accuracy: 0.3305\n",
            "Epoch 2626/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2399 - accuracy: 0.9950 - val_loss: 4.0313 - val_accuracy: 0.3214\n",
            "Epoch 2627/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2583 - accuracy: 0.9900 - val_loss: 4.1371 - val_accuracy: 0.3194\n",
            "Epoch 2628/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2720 - accuracy: 0.9800 - val_loss: 5.1077 - val_accuracy: 0.2661\n",
            "Epoch 2629/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2816 - accuracy: 0.9800 - val_loss: 3.7962 - val_accuracy: 0.3317\n",
            "Epoch 2630/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2548 - accuracy: 0.9950 - val_loss: 3.8971 - val_accuracy: 0.3244\n",
            "Epoch 2631/6000\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2461 - accuracy: 1.0000 - val_loss: 3.8806 - val_accuracy: 0.3272\n",
            "Epoch 2632/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2737 - accuracy: 0.9900 - val_loss: 3.6680 - val_accuracy: 0.3452\n",
            "Epoch 2633/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2593 - accuracy: 0.9950 - val_loss: 3.6919 - val_accuracy: 0.3446\n",
            "Epoch 2634/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2633 - accuracy: 0.9900 - val_loss: 3.7593 - val_accuracy: 0.3444\n",
            "Epoch 2635/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 3.9056 - val_accuracy: 0.3394\n",
            "Epoch 2636/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2822 - accuracy: 0.9850 - val_loss: 3.9132 - val_accuracy: 0.3427\n",
            "Epoch 2637/6000\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.2544 - accuracy: 0.9900 - val_loss: 3.9795 - val_accuracy: 0.3429\n",
            "Epoch 2638/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2455 - accuracy: 0.9950 - val_loss: 3.9693 - val_accuracy: 0.3427\n",
            "Epoch 2639/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2599 - accuracy: 0.9950 - val_loss: 4.0782 - val_accuracy: 0.3351\n",
            "Epoch 2640/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2419 - accuracy: 1.0000 - val_loss: 4.1387 - val_accuracy: 0.3355\n",
            "Epoch 2641/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2547 - accuracy: 0.9950 - val_loss: 3.8812 - val_accuracy: 0.3405\n",
            "Epoch 2642/6000\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2680 - accuracy: 0.9900 - val_loss: 3.7122 - val_accuracy: 0.3445\n",
            "Epoch 2643/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2659 - accuracy: 0.9850 - val_loss: 3.7679 - val_accuracy: 0.3495\n",
            "Epoch 2644/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2525 - accuracy: 0.9950 - val_loss: 3.7894 - val_accuracy: 0.3464\n",
            "Epoch 2645/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2754 - accuracy: 0.9850 - val_loss: 3.7366 - val_accuracy: 0.3516\n",
            "Epoch 2646/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2664 - accuracy: 0.9900 - val_loss: 3.9234 - val_accuracy: 0.3412\n",
            "Epoch 2647/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2468 - accuracy: 0.9950 - val_loss: 3.9821 - val_accuracy: 0.3370\n",
            "Epoch 2648/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2752 - accuracy: 0.9850 - val_loss: 3.8068 - val_accuracy: 0.3430\n",
            "Epoch 2649/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2647 - accuracy: 0.9850 - val_loss: 3.8431 - val_accuracy: 0.3464\n",
            "Epoch 2650/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2584 - accuracy: 0.9900 - val_loss: 4.0453 - val_accuracy: 0.3369\n",
            "Epoch 2651/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2668 - accuracy: 0.9850 - val_loss: 3.7848 - val_accuracy: 0.3572\n",
            "Epoch 2652/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 3.7774 - val_accuracy: 0.3566\n",
            "Epoch 2653/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2731 - accuracy: 0.9800 - val_loss: 3.6912 - val_accuracy: 0.3611\n",
            "Epoch 2654/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2456 - accuracy: 1.0000 - val_loss: 3.6905 - val_accuracy: 0.3631\n",
            "Epoch 2655/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2449 - accuracy: 1.0000 - val_loss: 3.7126 - val_accuracy: 0.3600\n",
            "Epoch 2656/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2536 - accuracy: 0.9900 - val_loss: 3.6543 - val_accuracy: 0.3657\n",
            "Epoch 2657/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 3.6698 - val_accuracy: 0.3657\n",
            "Epoch 2658/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2605 - accuracy: 0.9950 - val_loss: 3.5882 - val_accuracy: 0.3703\n",
            "Epoch 2659/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2568 - accuracy: 0.9950 - val_loss: 3.5931 - val_accuracy: 0.3685\n",
            "Epoch 2660/6000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2608 - accuracy: 0.9950 - val_loss: 3.6174 - val_accuracy: 0.3622\n",
            "Epoch 2661/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2578 - accuracy: 0.9900 - val_loss: 4.0085 - val_accuracy: 0.3431\n",
            "Epoch 2662/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2653 - accuracy: 0.9950 - val_loss: 4.0130 - val_accuracy: 0.3372\n",
            "Epoch 2663/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 4.0311 - val_accuracy: 0.3361\n",
            "Epoch 2664/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 3.9658 - val_accuracy: 0.3432\n",
            "Epoch 2665/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2564 - accuracy: 0.9850 - val_loss: 4.0525 - val_accuracy: 0.3344\n",
            "Epoch 2666/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2545 - accuracy: 0.9900 - val_loss: 4.1578 - val_accuracy: 0.3259\n",
            "Epoch 2667/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2706 - accuracy: 0.9900 - val_loss: 4.1543 - val_accuracy: 0.3310\n",
            "Epoch 2668/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2634 - accuracy: 0.9950 - val_loss: 4.1113 - val_accuracy: 0.3240\n",
            "Epoch 2669/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 4.0399 - val_accuracy: 0.3246\n",
            "Epoch 2670/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2921 - accuracy: 0.9800 - val_loss: 3.6217 - val_accuracy: 0.3534\n",
            "Epoch 2671/6000\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.2648 - accuracy: 0.9850 - val_loss: 3.6614 - val_accuracy: 0.3473\n",
            "Epoch 2672/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2543 - accuracy: 0.9950 - val_loss: 3.7117 - val_accuracy: 0.3502\n",
            "Epoch 2673/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2844 - accuracy: 0.9900 - val_loss: 3.7553 - val_accuracy: 0.3502\n",
            "Epoch 2674/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2653 - accuracy: 0.9900 - val_loss: 3.6860 - val_accuracy: 0.3523\n",
            "Epoch 2675/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2536 - accuracy: 0.9950 - val_loss: 3.5793 - val_accuracy: 0.3561\n",
            "Epoch 2676/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 3.5329 - val_accuracy: 0.3553\n",
            "Epoch 2677/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2631 - accuracy: 0.9950 - val_loss: 3.4801 - val_accuracy: 0.3612\n",
            "Epoch 2678/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2433 - accuracy: 0.9950 - val_loss: 3.4824 - val_accuracy: 0.3617\n",
            "Epoch 2679/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2965 - accuracy: 0.9900 - val_loss: 3.3782 - val_accuracy: 0.3650\n",
            "Epoch 2680/6000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2513 - accuracy: 0.9950 - val_loss: 3.3136 - val_accuracy: 0.3683\n",
            "Epoch 2681/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2731 - accuracy: 0.9850 - val_loss: 3.3333 - val_accuracy: 0.3700\n",
            "Epoch 2682/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2907 - accuracy: 0.9850 - val_loss: 3.3176 - val_accuracy: 0.3692\n",
            "Epoch 2683/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2503 - accuracy: 0.9950 - val_loss: 3.3459 - val_accuracy: 0.3675\n",
            "Epoch 2684/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2662 - accuracy: 0.9850 - val_loss: 3.4811 - val_accuracy: 0.3614\n",
            "Epoch 2685/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2609 - accuracy: 0.9900 - val_loss: 3.5253 - val_accuracy: 0.3568\n",
            "Epoch 2686/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 3.3592 - val_accuracy: 0.3701\n",
            "Epoch 2687/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2597 - accuracy: 0.9900 - val_loss: 3.3263 - val_accuracy: 0.3719\n",
            "Epoch 2688/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2996 - accuracy: 0.9850 - val_loss: 3.2055 - val_accuracy: 0.3682\n",
            "Epoch 2689/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2615 - accuracy: 0.9900 - val_loss: 3.2961 - val_accuracy: 0.3590\n",
            "Epoch 2690/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2546 - accuracy: 0.9950 - val_loss: 3.4699 - val_accuracy: 0.3393\n",
            "Epoch 2691/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2619 - accuracy: 0.9900 - val_loss: 3.5159 - val_accuracy: 0.3427\n",
            "Epoch 2692/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2483 - accuracy: 1.0000 - val_loss: 3.4813 - val_accuracy: 0.3536\n",
            "Epoch 2693/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2756 - accuracy: 0.9850 - val_loss: 3.5634 - val_accuracy: 0.3471\n",
            "Epoch 2694/6000\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.2514 - accuracy: 1.0000 - val_loss: 3.6871 - val_accuracy: 0.3356\n",
            "Epoch 2695/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2600 - accuracy: 0.9950 - val_loss: 3.6841 - val_accuracy: 0.3345\n",
            "Epoch 2696/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 3.6271 - val_accuracy: 0.3415\n",
            "Epoch 2697/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 3.5360 - val_accuracy: 0.3553\n",
            "Epoch 2698/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2604 - accuracy: 0.9950 - val_loss: 3.6701 - val_accuracy: 0.3467\n",
            "Epoch 2699/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2822 - accuracy: 0.9800 - val_loss: 3.4857 - val_accuracy: 0.3657\n",
            "Epoch 2700/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2449 - accuracy: 0.9950 - val_loss: 3.4525 - val_accuracy: 0.3677\n",
            "Epoch 2701/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.5051 - val_accuracy: 0.3658\n",
            "Epoch 2702/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2466 - accuracy: 1.0000 - val_loss: 3.5287 - val_accuracy: 0.3663\n",
            "Epoch 2703/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2506 - accuracy: 0.9950 - val_loss: 3.6906 - val_accuracy: 0.3530\n",
            "Epoch 2704/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2514 - accuracy: 1.0000 - val_loss: 3.5489 - val_accuracy: 0.3678\n",
            "Epoch 2705/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2467 - accuracy: 1.0000 - val_loss: 3.5023 - val_accuracy: 0.3706\n",
            "Epoch 2706/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2463 - accuracy: 0.9950 - val_loss: 3.4371 - val_accuracy: 0.3698\n",
            "Epoch 2707/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2641 - accuracy: 0.9900 - val_loss: 3.3980 - val_accuracy: 0.3706\n",
            "Epoch 2708/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2460 - accuracy: 1.0000 - val_loss: 3.3791 - val_accuracy: 0.3708\n",
            "Epoch 2709/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.3657 - val_accuracy: 0.3691\n",
            "Epoch 2710/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2532 - accuracy: 0.9950 - val_loss: 3.4105 - val_accuracy: 0.3705\n",
            "Epoch 2711/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2578 - accuracy: 0.9950 - val_loss: 3.4023 - val_accuracy: 0.3710\n",
            "Epoch 2712/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2496 - accuracy: 1.0000 - val_loss: 3.3717 - val_accuracy: 0.3726\n",
            "Epoch 2713/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 3.4259 - val_accuracy: 0.3751\n",
            "Epoch 2714/6000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2584 - accuracy: 0.9950 - val_loss: 3.4366 - val_accuracy: 0.3729\n",
            "Epoch 2715/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 3.4349 - val_accuracy: 0.3760\n",
            "Epoch 2716/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 3.5292 - val_accuracy: 0.3700\n",
            "Epoch 2717/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2833 - accuracy: 0.9900 - val_loss: 3.7353 - val_accuracy: 0.3660\n",
            "Epoch 2718/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2447 - accuracy: 1.0000 - val_loss: 3.7407 - val_accuracy: 0.3702\n",
            "Epoch 2719/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2567 - accuracy: 0.9900 - val_loss: 3.6897 - val_accuracy: 0.3624\n",
            "Epoch 2720/6000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2548 - accuracy: 0.9900 - val_loss: 3.7390 - val_accuracy: 0.3548\n",
            "Epoch 2721/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2534 - accuracy: 0.9950 - val_loss: 3.9166 - val_accuracy: 0.3410\n",
            "Epoch 2722/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2557 - accuracy: 0.9950 - val_loss: 3.9362 - val_accuracy: 0.3384\n",
            "Epoch 2723/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2600 - accuracy: 0.9950 - val_loss: 3.8695 - val_accuracy: 0.3466\n",
            "Epoch 2724/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2520 - accuracy: 0.9850 - val_loss: 3.9500 - val_accuracy: 0.3377\n",
            "Epoch 2725/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 3.9588 - val_accuracy: 0.3372\n",
            "Epoch 2726/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2679 - accuracy: 0.9950 - val_loss: 3.9259 - val_accuracy: 0.3349\n",
            "Epoch 2727/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2790 - accuracy: 0.9900 - val_loss: 3.9170 - val_accuracy: 0.3314\n",
            "Epoch 2728/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 3.9073 - val_accuracy: 0.3338\n",
            "Epoch 2729/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2708 - accuracy: 0.9900 - val_loss: 3.8394 - val_accuracy: 0.3524\n",
            "Epoch 2730/6000\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 3.7775 - val_accuracy: 0.3588\n",
            "Epoch 2731/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 3.7403 - val_accuracy: 0.3630\n",
            "Epoch 2732/6000\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2506 - accuracy: 0.9950 - val_loss: 3.7234 - val_accuracy: 0.3659\n",
            "Epoch 2733/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2706 - accuracy: 0.9900 - val_loss: 3.8231 - val_accuracy: 0.3555\n",
            "Epoch 2734/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2798 - accuracy: 0.9800 - val_loss: 3.6728 - val_accuracy: 0.3636\n",
            "Epoch 2735/6000\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 3.6588 - val_accuracy: 0.3615\n",
            "Epoch 2736/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2587 - accuracy: 0.9900 - val_loss: 3.6704 - val_accuracy: 0.3613\n",
            "Epoch 2737/6000\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 3.6098 - val_accuracy: 0.3656\n",
            "Epoch 2738/6000\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.2848 - accuracy: 0.9950 - val_loss: 3.6388 - val_accuracy: 0.3603\n",
            "Epoch 2739/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2579 - accuracy: 0.9900 - val_loss: 3.6965 - val_accuracy: 0.3551\n",
            "Epoch 2740/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2573 - accuracy: 0.9900 - val_loss: 3.6938 - val_accuracy: 0.3626\n",
            "Epoch 2741/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2504 - accuracy: 0.9950 - val_loss: 3.7494 - val_accuracy: 0.3611\n",
            "Epoch 2742/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2432 - accuracy: 0.9950 - val_loss: 3.7791 - val_accuracy: 0.3584\n",
            "Epoch 2743/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2417 - accuracy: 1.0000 - val_loss: 3.8533 - val_accuracy: 0.3550\n",
            "Epoch 2744/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2548 - accuracy: 0.9950 - val_loss: 3.7985 - val_accuracy: 0.3569\n",
            "Epoch 2745/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 3.7556 - val_accuracy: 0.3595\n",
            "Epoch 2746/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2501 - accuracy: 0.9950 - val_loss: 3.8189 - val_accuracy: 0.3418\n",
            "Epoch 2747/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2558 - accuracy: 0.9850 - val_loss: 3.7928 - val_accuracy: 0.3439\n",
            "Epoch 2748/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 3.7879 - val_accuracy: 0.3412\n",
            "Epoch 2749/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2541 - accuracy: 0.9900 - val_loss: 3.6606 - val_accuracy: 0.3576\n",
            "Epoch 2750/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2563 - accuracy: 0.9850 - val_loss: 3.5715 - val_accuracy: 0.3689\n",
            "Epoch 2751/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2436 - accuracy: 0.9950 - val_loss: 3.5314 - val_accuracy: 0.3683\n",
            "Epoch 2752/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2663 - accuracy: 0.9950 - val_loss: 3.5318 - val_accuracy: 0.3658\n",
            "Epoch 2753/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2501 - accuracy: 0.9950 - val_loss: 3.5832 - val_accuracy: 0.3616\n",
            "Epoch 2754/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2427 - accuracy: 1.0000 - val_loss: 3.5594 - val_accuracy: 0.3658\n",
            "Epoch 2755/6000\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2808 - accuracy: 0.9800 - val_loss: 3.4442 - val_accuracy: 0.3651\n",
            "Epoch 2756/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2457 - accuracy: 0.9950 - val_loss: 3.5127 - val_accuracy: 0.3649\n",
            "Epoch 2757/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2654 - accuracy: 0.9900 - val_loss: 3.4565 - val_accuracy: 0.3768\n",
            "Epoch 2758/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2384 - accuracy: 1.0000 - val_loss: 3.4599 - val_accuracy: 0.3766\n",
            "Epoch 2759/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2711 - accuracy: 0.9900 - val_loss: 3.5602 - val_accuracy: 0.3668\n",
            "Epoch 2760/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 3.6763 - val_accuracy: 0.3644\n",
            "Epoch 2761/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2452 - accuracy: 0.9950 - val_loss: 3.5994 - val_accuracy: 0.3652\n",
            "Epoch 2762/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2420 - accuracy: 1.0000 - val_loss: 3.5739 - val_accuracy: 0.3690\n",
            "Epoch 2763/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2641 - accuracy: 0.9900 - val_loss: 3.5051 - val_accuracy: 0.3644\n",
            "Epoch 2764/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2405 - accuracy: 0.9950 - val_loss: 3.5191 - val_accuracy: 0.3619\n",
            "Epoch 2765/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2533 - accuracy: 0.9900 - val_loss: 3.4587 - val_accuracy: 0.3776\n",
            "Epoch 2766/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2610 - accuracy: 0.9950 - val_loss: 3.5703 - val_accuracy: 0.3619\n",
            "Epoch 2767/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2930 - accuracy: 0.9750 - val_loss: 3.5268 - val_accuracy: 0.3545\n",
            "Epoch 2768/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 3.5382 - val_accuracy: 0.3524\n",
            "Epoch 2769/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 3.5853 - val_accuracy: 0.3420\n",
            "Epoch 2770/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2351 - accuracy: 1.0000 - val_loss: 3.6076 - val_accuracy: 0.3354\n",
            "Epoch 2771/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2455 - accuracy: 0.9950 - val_loss: 3.4066 - val_accuracy: 0.3566\n",
            "Epoch 2772/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2762 - accuracy: 0.9850 - val_loss: 3.6010 - val_accuracy: 0.3308\n",
            "Epoch 2773/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2687 - accuracy: 0.9900 - val_loss: 3.5028 - val_accuracy: 0.3396\n",
            "Epoch 2774/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 3.4659 - val_accuracy: 0.3361\n",
            "Epoch 2775/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2664 - accuracy: 0.9900 - val_loss: 3.4575 - val_accuracy: 0.3429\n",
            "Epoch 2776/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2560 - accuracy: 0.9900 - val_loss: 3.4021 - val_accuracy: 0.3520\n",
            "Epoch 2777/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2423 - accuracy: 0.9950 - val_loss: 3.5607 - val_accuracy: 0.3341\n",
            "Epoch 2778/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2855 - accuracy: 0.9800 - val_loss: 3.5465 - val_accuracy: 0.3224\n",
            "Epoch 2779/6000\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2697 - accuracy: 0.9950 - val_loss: 3.3606 - val_accuracy: 0.3433\n",
            "Epoch 2780/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3165 - accuracy: 0.9750 - val_loss: 3.9727 - val_accuracy: 0.3099\n",
            "Epoch 2781/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 4.2019 - val_accuracy: 0.3032\n",
            "Epoch 2782/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2658 - accuracy: 0.9950 - val_loss: 3.9752 - val_accuracy: 0.3220\n",
            "Epoch 2783/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2393 - accuracy: 1.0000 - val_loss: 3.9940 - val_accuracy: 0.3206\n",
            "Epoch 2784/6000\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2539 - accuracy: 0.9900 - val_loss: 3.8997 - val_accuracy: 0.3324\n",
            "Epoch 2785/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2479 - accuracy: 0.9950 - val_loss: 4.2259 - val_accuracy: 0.2997\n",
            "Epoch 2786/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2597 - accuracy: 0.9950 - val_loss: 4.0651 - val_accuracy: 0.3050\n",
            "Epoch 2787/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2588 - accuracy: 0.9950 - val_loss: 3.9753 - val_accuracy: 0.3204\n",
            "Epoch 2788/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2563 - accuracy: 0.9950 - val_loss: 3.9843 - val_accuracy: 0.3210\n",
            "Epoch 2789/6000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2636 - accuracy: 0.9900 - val_loss: 3.8776 - val_accuracy: 0.3324\n",
            "Epoch 2790/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2665 - accuracy: 0.9900 - val_loss: 3.7406 - val_accuracy: 0.3450\n",
            "Epoch 2791/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2666 - accuracy: 0.9900 - val_loss: 3.7207 - val_accuracy: 0.3446\n",
            "Epoch 2792/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.6389 - val_accuracy: 0.3537\n",
            "Epoch 2793/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2686 - accuracy: 0.9950 - val_loss: 3.5105 - val_accuracy: 0.3658\n",
            "Epoch 2794/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2583 - accuracy: 0.9850 - val_loss: 3.5694 - val_accuracy: 0.3675\n",
            "Epoch 2795/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2449 - accuracy: 1.0000 - val_loss: 3.7225 - val_accuracy: 0.3602\n",
            "Epoch 2796/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.7229 - val_accuracy: 0.3576\n",
            "Epoch 2797/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2742 - accuracy: 0.9850 - val_loss: 4.0856 - val_accuracy: 0.3087\n",
            "Epoch 2798/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 4.0832 - val_accuracy: 0.3092\n",
            "Epoch 2799/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2538 - accuracy: 0.9950 - val_loss: 3.8199 - val_accuracy: 0.3351\n",
            "Epoch 2800/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2517 - accuracy: 0.9950 - val_loss: 3.7853 - val_accuracy: 0.3373\n",
            "Epoch 2801/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2810 - accuracy: 0.9800 - val_loss: 3.7788 - val_accuracy: 0.3241\n",
            "Epoch 2802/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2687 - accuracy: 0.9850 - val_loss: 3.7890 - val_accuracy: 0.3280\n",
            "Epoch 2803/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2812 - accuracy: 0.9900 - val_loss: 3.6808 - val_accuracy: 0.3363\n",
            "Epoch 2804/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2846 - accuracy: 0.9750 - val_loss: 3.6190 - val_accuracy: 0.3598\n",
            "Epoch 2805/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2653 - accuracy: 0.9900 - val_loss: 4.2822 - val_accuracy: 0.3031\n",
            "Epoch 2806/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2499 - accuracy: 0.9950 - val_loss: 4.2073 - val_accuracy: 0.3187\n",
            "Epoch 2807/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2665 - accuracy: 0.9900 - val_loss: 4.5488 - val_accuracy: 0.2929\n",
            "Epoch 2808/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 4.5300 - val_accuracy: 0.2965\n",
            "Epoch 2809/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 4.4831 - val_accuracy: 0.2989\n",
            "Epoch 2810/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2837 - accuracy: 0.9750 - val_loss: 3.6477 - val_accuracy: 0.3530\n",
            "Epoch 2811/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2488 - accuracy: 0.9950 - val_loss: 3.6005 - val_accuracy: 0.3579\n",
            "Epoch 2812/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2535 - accuracy: 0.9950 - val_loss: 3.4979 - val_accuracy: 0.3758\n",
            "Epoch 2813/6000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2593 - accuracy: 0.9950 - val_loss: 3.5511 - val_accuracy: 0.3734\n",
            "Epoch 2814/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2776 - accuracy: 0.9900 - val_loss: 3.6678 - val_accuracy: 0.3694\n",
            "Epoch 2815/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2953 - accuracy: 0.9850 - val_loss: 3.5049 - val_accuracy: 0.3760\n",
            "Epoch 2816/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2452 - accuracy: 1.0000 - val_loss: 3.5415 - val_accuracy: 0.3752\n",
            "Epoch 2817/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2544 - accuracy: 1.0000 - val_loss: 3.5604 - val_accuracy: 0.3723\n",
            "Epoch 2818/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 3.7170 - val_accuracy: 0.3687\n",
            "Epoch 2819/6000\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.2500 - accuracy: 0.9950 - val_loss: 3.7349 - val_accuracy: 0.3672\n",
            "Epoch 2820/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2532 - accuracy: 0.9950 - val_loss: 3.6286 - val_accuracy: 0.3737\n",
            "Epoch 2821/6000\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2554 - accuracy: 0.9950 - val_loss: 3.6935 - val_accuracy: 0.3708\n",
            "Epoch 2822/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2772 - accuracy: 0.9900 - val_loss: 3.5440 - val_accuracy: 0.3624\n",
            "Epoch 2823/6000\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.3104 - accuracy: 0.9800 - val_loss: 3.4820 - val_accuracy: 0.3753\n",
            "Epoch 2824/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2651 - accuracy: 0.9950 - val_loss: 3.4724 - val_accuracy: 0.3667\n",
            "Epoch 2825/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2479 - accuracy: 0.9950 - val_loss: 3.4023 - val_accuracy: 0.3758\n",
            "Epoch 2826/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2725 - accuracy: 0.9850 - val_loss: 3.4205 - val_accuracy: 0.3773\n",
            "Epoch 2827/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2794 - accuracy: 0.9900 - val_loss: 3.4184 - val_accuracy: 0.3774\n",
            "Epoch 2828/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2852 - accuracy: 0.9850 - val_loss: 3.5310 - val_accuracy: 0.3733\n",
            "Epoch 2829/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2509 - accuracy: 0.9950 - val_loss: 3.5067 - val_accuracy: 0.3770\n",
            "Epoch 2830/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2738 - accuracy: 0.9850 - val_loss: 3.5297 - val_accuracy: 0.3793\n",
            "Epoch 2831/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2506 - accuracy: 0.9950 - val_loss: 3.5003 - val_accuracy: 0.3816\n",
            "Epoch 2832/6000\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 3.5037 - val_accuracy: 0.3839\n",
            "Epoch 2833/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2757 - accuracy: 0.9900 - val_loss: 3.5010 - val_accuracy: 0.3829\n",
            "Epoch 2834/6000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2568 - accuracy: 0.9900 - val_loss: 3.4960 - val_accuracy: 0.3843\n",
            "Epoch 2835/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2837 - accuracy: 0.9850 - val_loss: 3.5029 - val_accuracy: 0.3830\n",
            "Epoch 2836/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2629 - accuracy: 0.9900 - val_loss: 3.4690 - val_accuracy: 0.3762\n",
            "Epoch 2837/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2698 - accuracy: 0.9850 - val_loss: 3.4833 - val_accuracy: 0.3702\n",
            "Epoch 2838/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2481 - accuracy: 0.9950 - val_loss: 3.5010 - val_accuracy: 0.3708\n",
            "Epoch 2839/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2653 - accuracy: 0.9900 - val_loss: 3.4558 - val_accuracy: 0.3783\n",
            "Epoch 2840/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2632 - accuracy: 0.9850 - val_loss: 3.4964 - val_accuracy: 0.3721\n",
            "Epoch 2841/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2584 - accuracy: 0.9900 - val_loss: 3.6401 - val_accuracy: 0.3616\n",
            "Epoch 2842/6000\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 3.6094 - val_accuracy: 0.3632\n",
            "Epoch 2843/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2468 - accuracy: 1.0000 - val_loss: 3.6478 - val_accuracy: 0.3599\n",
            "Epoch 2844/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2613 - accuracy: 0.9950 - val_loss: 3.6436 - val_accuracy: 0.3580\n",
            "Epoch 2845/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2582 - accuracy: 0.9950 - val_loss: 3.6699 - val_accuracy: 0.3580\n",
            "Epoch 2846/6000\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2454 - accuracy: 0.9950 - val_loss: 3.6805 - val_accuracy: 0.3548\n",
            "Epoch 2847/6000\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 3.6924 - val_accuracy: 0.3567\n",
            "Epoch 2848/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2541 - accuracy: 0.9900 - val_loss: 3.7173 - val_accuracy: 0.3482\n",
            "Epoch 2849/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2488 - accuracy: 0.9950 - val_loss: 3.7389 - val_accuracy: 0.3458\n",
            "Epoch 2850/6000\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 3.9295 - val_accuracy: 0.3319\n",
            "Epoch 2851/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2499 - accuracy: 0.9950 - val_loss: 4.1383 - val_accuracy: 0.3239\n",
            "Epoch 2852/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2578 - accuracy: 0.9900 - val_loss: 4.0772 - val_accuracy: 0.3193\n",
            "Epoch 2853/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2504 - accuracy: 0.9950 - val_loss: 3.8116 - val_accuracy: 0.3414\n",
            "Epoch 2854/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2932 - accuracy: 0.9800 - val_loss: 3.7010 - val_accuracy: 0.3504\n",
            "Epoch 2855/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2658 - accuracy: 0.9950 - val_loss: 4.0138 - val_accuracy: 0.3295\n",
            "Epoch 2856/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2573 - accuracy: 0.9900 - val_loss: 4.1501 - val_accuracy: 0.3209\n",
            "Epoch 2857/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2543 - accuracy: 0.9950 - val_loss: 3.7395 - val_accuracy: 0.3563\n",
            "Epoch 2858/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2581 - accuracy: 0.9950 - val_loss: 3.7128 - val_accuracy: 0.3505\n",
            "Epoch 2859/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2473 - accuracy: 1.0000 - val_loss: 3.6211 - val_accuracy: 0.3495\n",
            "Epoch 2860/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2676 - accuracy: 0.9850 - val_loss: 3.6357 - val_accuracy: 0.3455\n",
            "Epoch 2861/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2866 - accuracy: 0.9800 - val_loss: 3.6920 - val_accuracy: 0.3506\n",
            "Epoch 2862/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2874 - accuracy: 0.9850 - val_loss: 3.6129 - val_accuracy: 0.3579\n",
            "Epoch 2863/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 3.5947 - val_accuracy: 0.3623\n",
            "Epoch 2864/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2906 - accuracy: 0.9900 - val_loss: 3.5859 - val_accuracy: 0.3660\n",
            "Epoch 2865/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2519 - accuracy: 0.9950 - val_loss: 3.4675 - val_accuracy: 0.3805\n",
            "Epoch 2866/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2540 - accuracy: 0.9950 - val_loss: 3.4379 - val_accuracy: 0.3809\n",
            "Epoch 2867/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2390 - accuracy: 1.0000 - val_loss: 3.4513 - val_accuracy: 0.3771\n",
            "Epoch 2868/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 3.4450 - val_accuracy: 0.3764\n",
            "Epoch 2869/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2639 - accuracy: 0.9900 - val_loss: 3.5085 - val_accuracy: 0.3806\n",
            "Epoch 2870/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2456 - accuracy: 0.9950 - val_loss: 3.5027 - val_accuracy: 0.3837\n",
            "Epoch 2871/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2760 - accuracy: 0.9900 - val_loss: 3.5614 - val_accuracy: 0.3751\n",
            "Epoch 2872/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2482 - accuracy: 0.9950 - val_loss: 3.5835 - val_accuracy: 0.3718\n",
            "Epoch 2873/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2650 - accuracy: 0.9950 - val_loss: 3.7143 - val_accuracy: 0.3603\n",
            "Epoch 2874/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 3.7548 - val_accuracy: 0.3577\n",
            "Epoch 2875/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 3.7067 - val_accuracy: 0.3667\n",
            "Epoch 2876/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2483 - accuracy: 1.0000 - val_loss: 3.5861 - val_accuracy: 0.3789\n",
            "Epoch 2877/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2472 - accuracy: 0.9950 - val_loss: 3.6454 - val_accuracy: 0.3748\n",
            "Epoch 2878/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 3.6267 - val_accuracy: 0.3765\n",
            "Epoch 2879/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2859 - accuracy: 0.9850 - val_loss: 3.5035 - val_accuracy: 0.3769\n",
            "Epoch 2880/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2568 - accuracy: 0.9900 - val_loss: 3.5236 - val_accuracy: 0.3676\n",
            "Epoch 2881/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 3.4806 - val_accuracy: 0.3676\n",
            "Epoch 2882/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 3.5651 - val_accuracy: 0.3578\n",
            "Epoch 2883/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2816 - accuracy: 0.9950 - val_loss: 3.6176 - val_accuracy: 0.3582\n",
            "Epoch 2884/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2594 - accuracy: 0.9900 - val_loss: 3.5334 - val_accuracy: 0.3593\n",
            "Epoch 2885/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2434 - accuracy: 1.0000 - val_loss: 3.5129 - val_accuracy: 0.3616\n",
            "Epoch 2886/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 3.4940 - val_accuracy: 0.3603\n",
            "Epoch 2887/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2640 - accuracy: 0.9900 - val_loss: 3.4343 - val_accuracy: 0.3678\n",
            "Epoch 2888/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2473 - accuracy: 0.9950 - val_loss: 3.3792 - val_accuracy: 0.3784\n",
            "Epoch 2889/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2629 - accuracy: 0.9950 - val_loss: 3.4156 - val_accuracy: 0.3725\n",
            "Epoch 2890/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2443 - accuracy: 1.0000 - val_loss: 3.4876 - val_accuracy: 0.3644\n",
            "Epoch 2891/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2626 - accuracy: 0.9950 - val_loss: 3.4592 - val_accuracy: 0.3698\n",
            "Epoch 2892/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2605 - accuracy: 0.9950 - val_loss: 3.5998 - val_accuracy: 0.3581\n",
            "Epoch 2893/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2403 - accuracy: 1.0000 - val_loss: 3.5374 - val_accuracy: 0.3661\n",
            "Epoch 2894/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2485 - accuracy: 0.9950 - val_loss: 3.5318 - val_accuracy: 0.3698\n",
            "Epoch 2895/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 3.4305 - val_accuracy: 0.3749\n",
            "Epoch 2896/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2476 - accuracy: 0.9950 - val_loss: 3.3982 - val_accuracy: 0.3780\n",
            "Epoch 2897/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2486 - accuracy: 0.9950 - val_loss: 3.4302 - val_accuracy: 0.3792\n",
            "Epoch 2898/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2514 - accuracy: 0.9950 - val_loss: 3.2658 - val_accuracy: 0.3889\n",
            "Epoch 2899/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2602 - accuracy: 0.9850 - val_loss: 3.2632 - val_accuracy: 0.3858\n",
            "Epoch 2900/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2488 - accuracy: 0.9950 - val_loss: 3.3908 - val_accuracy: 0.3806\n",
            "Epoch 2901/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2350 - accuracy: 1.0000 - val_loss: 3.3904 - val_accuracy: 0.3797\n",
            "Epoch 2902/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2360 - accuracy: 1.0000 - val_loss: 3.4033 - val_accuracy: 0.3780\n",
            "Epoch 2903/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2710 - accuracy: 0.9850 - val_loss: 3.4703 - val_accuracy: 0.3709\n",
            "Epoch 2904/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2671 - accuracy: 0.9950 - val_loss: 3.5472 - val_accuracy: 0.3600\n",
            "Epoch 2905/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 3.4885 - val_accuracy: 0.3649\n",
            "Epoch 2906/6000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2628 - accuracy: 0.9950 - val_loss: 3.6300 - val_accuracy: 0.3568\n",
            "Epoch 2907/6000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.2439 - accuracy: 0.9950 - val_loss: 3.5077 - val_accuracy: 0.3631\n",
            "Epoch 2908/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2620 - accuracy: 0.9900 - val_loss: 3.4507 - val_accuracy: 0.3768\n",
            "Epoch 2909/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2741 - accuracy: 0.9800 - val_loss: 3.4579 - val_accuracy: 0.3758\n",
            "Epoch 2910/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2542 - accuracy: 0.9900 - val_loss: 3.3880 - val_accuracy: 0.3743\n",
            "Epoch 2911/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2463 - accuracy: 0.9950 - val_loss: 3.5219 - val_accuracy: 0.3558\n",
            "Epoch 2912/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2444 - accuracy: 0.9950 - val_loss: 3.5497 - val_accuracy: 0.3495\n",
            "Epoch 2913/6000\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.2521 - accuracy: 0.9950 - val_loss: 3.4077 - val_accuracy: 0.3695\n",
            "Epoch 2914/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2526 - accuracy: 0.9950 - val_loss: 3.4161 - val_accuracy: 0.3730\n",
            "Epoch 2915/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2644 - accuracy: 0.9950 - val_loss: 3.3766 - val_accuracy: 0.3784\n",
            "Epoch 2916/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2490 - accuracy: 0.9900 - val_loss: 3.4703 - val_accuracy: 0.3725\n",
            "Epoch 2917/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2406 - accuracy: 0.9950 - val_loss: 3.5088 - val_accuracy: 0.3704\n",
            "Epoch 2918/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 3.5783 - val_accuracy: 0.3636\n",
            "Epoch 2919/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2528 - accuracy: 0.9900 - val_loss: 3.6076 - val_accuracy: 0.3593\n",
            "Epoch 2920/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2625 - accuracy: 0.9900 - val_loss: 3.5686 - val_accuracy: 0.3664\n",
            "Epoch 2921/6000\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.2473 - accuracy: 0.9900 - val_loss: 3.5914 - val_accuracy: 0.3689\n",
            "Epoch 2922/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2467 - accuracy: 0.9950 - val_loss: 3.8674 - val_accuracy: 0.3444\n",
            "Epoch 2923/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 3.6979 - val_accuracy: 0.3614\n",
            "Epoch 2924/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2706 - accuracy: 0.9900 - val_loss: 3.6825 - val_accuracy: 0.3635\n",
            "Epoch 2925/6000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.2504 - accuracy: 1.0000 - val_loss: 3.6797 - val_accuracy: 0.3703\n",
            "Epoch 2926/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 3.7072 - val_accuracy: 0.3719\n",
            "Epoch 2927/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 3.6769 - val_accuracy: 0.3683\n",
            "Epoch 2928/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2489 - accuracy: 0.9950 - val_loss: 3.6669 - val_accuracy: 0.3690\n",
            "Epoch 2929/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 3.7696 - val_accuracy: 0.3571\n",
            "Epoch 2930/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2688 - accuracy: 0.9950 - val_loss: 3.7043 - val_accuracy: 0.3624\n",
            "Epoch 2931/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2965 - accuracy: 0.9850 - val_loss: 4.0041 - val_accuracy: 0.3255\n",
            "Epoch 2932/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2394 - accuracy: 0.9950 - val_loss: 4.1860 - val_accuracy: 0.3109\n",
            "Epoch 2933/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2465 - accuracy: 0.9950 - val_loss: 4.0818 - val_accuracy: 0.3200\n",
            "Epoch 2934/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2400 - accuracy: 1.0000 - val_loss: 4.1189 - val_accuracy: 0.3238\n",
            "Epoch 2935/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2674 - accuracy: 0.9850 - val_loss: 3.6023 - val_accuracy: 0.3612\n",
            "Epoch 2936/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2927 - accuracy: 0.9950 - val_loss: 3.8429 - val_accuracy: 0.3274\n",
            "Epoch 2937/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2677 - accuracy: 0.9900 - val_loss: 4.5013 - val_accuracy: 0.3050\n",
            "Epoch 2938/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2441 - accuracy: 0.9950 - val_loss: 4.5065 - val_accuracy: 0.3074\n",
            "Epoch 2939/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2457 - accuracy: 0.9950 - val_loss: 4.1491 - val_accuracy: 0.3315\n",
            "Epoch 2940/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2376 - accuracy: 0.9950 - val_loss: 4.1642 - val_accuracy: 0.3249\n",
            "Epoch 2941/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.9644 - val_accuracy: 0.3326\n",
            "Epoch 2942/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 3.9261 - val_accuracy: 0.3369\n",
            "Epoch 2943/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2441 - accuracy: 0.9950 - val_loss: 3.6713 - val_accuracy: 0.3524\n",
            "Epoch 2944/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2418 - accuracy: 0.9950 - val_loss: 3.6295 - val_accuracy: 0.3537\n",
            "Epoch 2945/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.6132 - val_accuracy: 0.3518\n",
            "Epoch 2946/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2438 - accuracy: 0.9950 - val_loss: 3.6035 - val_accuracy: 0.3530\n",
            "Epoch 2947/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2471 - accuracy: 0.9950 - val_loss: 3.6942 - val_accuracy: 0.3430\n",
            "Epoch 2948/6000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 3.8468 - val_accuracy: 0.3289\n",
            "Epoch 2949/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2366 - accuracy: 0.9950 - val_loss: 3.9363 - val_accuracy: 0.3224\n",
            "Epoch 2950/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2418 - accuracy: 0.9950 - val_loss: 3.9273 - val_accuracy: 0.3231\n",
            "Epoch 2951/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2314 - accuracy: 1.0000 - val_loss: 3.9852 - val_accuracy: 0.3202\n",
            "Epoch 2952/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2558 - accuracy: 0.9850 - val_loss: 4.0010 - val_accuracy: 0.3252\n",
            "Epoch 2953/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2353 - accuracy: 1.0000 - val_loss: 3.9029 - val_accuracy: 0.3305\n",
            "Epoch 2954/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2565 - accuracy: 0.9900 - val_loss: 3.7799 - val_accuracy: 0.3382\n",
            "Epoch 2955/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2375 - accuracy: 0.9950 - val_loss: 3.8712 - val_accuracy: 0.3293\n",
            "Epoch 2956/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 3.6575 - val_accuracy: 0.3398\n",
            "Epoch 2957/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 3.5882 - val_accuracy: 0.3441\n",
            "Epoch 2958/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2380 - accuracy: 0.9950 - val_loss: 3.5373 - val_accuracy: 0.3493\n",
            "Epoch 2959/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2737 - accuracy: 0.9850 - val_loss: 3.5421 - val_accuracy: 0.3466\n",
            "Epoch 2960/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2349 - accuracy: 0.9950 - val_loss: 3.6591 - val_accuracy: 0.3367\n",
            "Epoch 2961/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 3.6224 - val_accuracy: 0.3380\n",
            "Epoch 2962/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2341 - accuracy: 1.0000 - val_loss: 3.6411 - val_accuracy: 0.3342\n",
            "Epoch 2963/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2446 - accuracy: 0.9900 - val_loss: 3.6561 - val_accuracy: 0.3330\n",
            "Epoch 2964/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 3.5968 - val_accuracy: 0.3357\n",
            "Epoch 2965/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 3.6012 - val_accuracy: 0.3353\n",
            "Epoch 2966/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2291 - accuracy: 1.0000 - val_loss: 3.5771 - val_accuracy: 0.3394\n",
            "Epoch 2967/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2539 - accuracy: 0.9900 - val_loss: 3.5261 - val_accuracy: 0.3356\n",
            "Epoch 2968/6000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2534 - accuracy: 0.9850 - val_loss: 3.5015 - val_accuracy: 0.3394\n",
            "Epoch 2969/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2411 - accuracy: 0.9950 - val_loss: 3.4778 - val_accuracy: 0.3418\n",
            "Epoch 2970/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 3.5482 - val_accuracy: 0.3323\n",
            "Epoch 2971/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2336 - accuracy: 1.0000 - val_loss: 3.6673 - val_accuracy: 0.3165\n",
            "Epoch 2972/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2312 - accuracy: 0.9950 - val_loss: 3.7978 - val_accuracy: 0.2976\n",
            "Epoch 2973/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2379 - accuracy: 0.9900 - val_loss: 3.6599 - val_accuracy: 0.3146\n",
            "Epoch 2974/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2420 - accuracy: 0.9950 - val_loss: 3.7400 - val_accuracy: 0.3068\n",
            "Epoch 2975/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 3.7873 - val_accuracy: 0.3093\n",
            "Epoch 2976/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2438 - accuracy: 0.9950 - val_loss: 3.4692 - val_accuracy: 0.3414\n",
            "Epoch 2977/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 3.4133 - val_accuracy: 0.3465\n",
            "Epoch 2978/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2437 - accuracy: 0.9900 - val_loss: 3.4467 - val_accuracy: 0.3392\n",
            "Epoch 2979/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2461 - accuracy: 0.9900 - val_loss: 3.4876 - val_accuracy: 0.3437\n",
            "Epoch 2980/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2308 - accuracy: 1.0000 - val_loss: 3.5486 - val_accuracy: 0.3402\n",
            "Epoch 2981/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2373 - accuracy: 0.9950 - val_loss: 3.6349 - val_accuracy: 0.3308\n",
            "Epoch 2982/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2330 - accuracy: 0.9950 - val_loss: 3.8001 - val_accuracy: 0.3278\n",
            "Epoch 2983/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2348 - accuracy: 0.9950 - val_loss: 3.9090 - val_accuracy: 0.3209\n",
            "Epoch 2984/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2273 - accuracy: 1.0000 - val_loss: 3.9275 - val_accuracy: 0.3207\n",
            "Epoch 2985/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2383 - accuracy: 0.9950 - val_loss: 4.2695 - val_accuracy: 0.2830\n",
            "Epoch 2986/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2335 - accuracy: 1.0000 - val_loss: 4.0310 - val_accuracy: 0.2976\n",
            "Epoch 2987/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 4.0898 - val_accuracy: 0.2943\n",
            "Epoch 2988/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2406 - accuracy: 0.9950 - val_loss: 4.1989 - val_accuracy: 0.2827\n",
            "Epoch 2989/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2348 - accuracy: 0.9950 - val_loss: 4.1335 - val_accuracy: 0.2847\n",
            "Epoch 2990/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2340 - accuracy: 0.9950 - val_loss: 4.0076 - val_accuracy: 0.2912\n",
            "Epoch 2991/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2392 - accuracy: 0.9950 - val_loss: 3.9575 - val_accuracy: 0.2998\n",
            "Epoch 2992/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2339 - accuracy: 0.9900 - val_loss: 4.0687 - val_accuracy: 0.2849\n",
            "Epoch 2993/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2358 - accuracy: 0.9950 - val_loss: 4.3219 - val_accuracy: 0.2633\n",
            "Epoch 2994/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2507 - accuracy: 0.9950 - val_loss: 4.0274 - val_accuracy: 0.3125\n",
            "Epoch 2995/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2224 - accuracy: 1.0000 - val_loss: 4.0100 - val_accuracy: 0.3156\n",
            "Epoch 2996/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2450 - accuracy: 0.9900 - val_loss: 4.1587 - val_accuracy: 0.3099\n",
            "Epoch 2997/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2400 - accuracy: 0.9950 - val_loss: 4.0084 - val_accuracy: 0.3222\n",
            "Epoch 2998/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 3.8310 - val_accuracy: 0.3357\n",
            "Epoch 2999/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2458 - accuracy: 0.9900 - val_loss: 3.7664 - val_accuracy: 0.3382\n",
            "Epoch 3000/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 3.7199 - val_accuracy: 0.3472\n",
            "Epoch 3001/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 3.8348 - val_accuracy: 0.3424\n",
            "Epoch 3002/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2237 - accuracy: 1.0000 - val_loss: 3.8049 - val_accuracy: 0.3449\n",
            "Epoch 3003/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2325 - accuracy: 0.9950 - val_loss: 3.8131 - val_accuracy: 0.3359\n",
            "Epoch 3004/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2336 - accuracy: 1.0000 - val_loss: 3.7621 - val_accuracy: 0.3354\n",
            "Epoch 3005/6000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.2233 - accuracy: 1.0000 - val_loss: 3.7554 - val_accuracy: 0.3372\n",
            "Epoch 3006/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2570 - accuracy: 0.9900 - val_loss: 3.8337 - val_accuracy: 0.3335\n",
            "Epoch 3007/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2348 - accuracy: 0.9950 - val_loss: 3.7913 - val_accuracy: 0.3382\n",
            "Epoch 3008/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2307 - accuracy: 1.0000 - val_loss: 3.8372 - val_accuracy: 0.3427\n",
            "Epoch 3009/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2439 - accuracy: 0.9900 - val_loss: 3.7189 - val_accuracy: 0.3521\n",
            "Epoch 3010/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 3.7117 - val_accuracy: 0.3509\n",
            "Epoch 3011/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 3.6147 - val_accuracy: 0.3610\n",
            "Epoch 3012/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2235 - accuracy: 1.0000 - val_loss: 3.5202 - val_accuracy: 0.3688\n",
            "Epoch 3013/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2216 - accuracy: 1.0000 - val_loss: 3.5077 - val_accuracy: 0.3692\n",
            "Epoch 3014/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2635 - accuracy: 0.9850 - val_loss: 3.4648 - val_accuracy: 0.3728\n",
            "Epoch 3015/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2315 - accuracy: 0.9950 - val_loss: 3.6192 - val_accuracy: 0.3592\n",
            "Epoch 3016/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2257 - accuracy: 1.0000 - val_loss: 3.6082 - val_accuracy: 0.3605\n",
            "Epoch 3017/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2236 - accuracy: 1.0000 - val_loss: 3.7157 - val_accuracy: 0.3509\n",
            "Epoch 3018/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 3.7360 - val_accuracy: 0.3490\n",
            "Epoch 3019/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2290 - accuracy: 0.9950 - val_loss: 3.8357 - val_accuracy: 0.3364\n",
            "Epoch 3020/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2444 - accuracy: 0.9900 - val_loss: 3.6914 - val_accuracy: 0.3520\n",
            "Epoch 3021/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2241 - accuracy: 0.9950 - val_loss: 3.7173 - val_accuracy: 0.3485\n",
            "Epoch 3022/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2279 - accuracy: 1.0000 - val_loss: 3.6571 - val_accuracy: 0.3528\n",
            "Epoch 3023/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2581 - accuracy: 0.9900 - val_loss: 3.6443 - val_accuracy: 0.3573\n",
            "Epoch 3024/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2193 - accuracy: 1.0000 - val_loss: 3.6521 - val_accuracy: 0.3520\n",
            "Epoch 3025/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2369 - accuracy: 0.9900 - val_loss: 3.5271 - val_accuracy: 0.3570\n",
            "Epoch 3026/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2333 - accuracy: 0.9950 - val_loss: 3.5289 - val_accuracy: 0.3641\n",
            "Epoch 3027/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2321 - accuracy: 0.9950 - val_loss: 3.6729 - val_accuracy: 0.3358\n",
            "Epoch 3028/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2453 - accuracy: 0.9950 - val_loss: 3.7296 - val_accuracy: 0.3376\n",
            "Epoch 3029/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2329 - accuracy: 0.9950 - val_loss: 3.6926 - val_accuracy: 0.3434\n",
            "Epoch 3030/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2274 - accuracy: 0.9950 - val_loss: 3.5269 - val_accuracy: 0.3638\n",
            "Epoch 3031/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2550 - accuracy: 0.9800 - val_loss: 3.5802 - val_accuracy: 0.3614\n",
            "Epoch 3032/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2346 - accuracy: 0.9900 - val_loss: 3.6923 - val_accuracy: 0.3459\n",
            "Epoch 3033/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2204 - accuracy: 1.0000 - val_loss: 3.6807 - val_accuracy: 0.3475\n",
            "Epoch 3034/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2363 - accuracy: 0.9900 - val_loss: 3.4924 - val_accuracy: 0.3775\n",
            "Epoch 3035/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2272 - accuracy: 0.9950 - val_loss: 3.4999 - val_accuracy: 0.3725\n",
            "Epoch 3036/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 3.5131 - val_accuracy: 0.3722\n",
            "Epoch 3037/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2465 - accuracy: 0.9900 - val_loss: 3.5911 - val_accuracy: 0.3660\n",
            "Epoch 3038/6000\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2226 - accuracy: 1.0000 - val_loss: 3.6549 - val_accuracy: 0.3635\n",
            "Epoch 3039/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 3.6613 - val_accuracy: 0.3645\n",
            "Epoch 3040/6000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.2273 - accuracy: 0.9950 - val_loss: 3.5419 - val_accuracy: 0.3671\n",
            "Epoch 3041/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2307 - accuracy: 0.9950 - val_loss: 3.4760 - val_accuracy: 0.3685\n",
            "Epoch 3042/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2331 - accuracy: 0.9900 - val_loss: 3.4034 - val_accuracy: 0.3717\n",
            "Epoch 3043/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2225 - accuracy: 0.9950 - val_loss: 3.4051 - val_accuracy: 0.3718\n",
            "Epoch 3044/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2405 - accuracy: 0.9900 - val_loss: 3.4684 - val_accuracy: 0.3679\n",
            "Epoch 3045/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2200 - accuracy: 1.0000 - val_loss: 3.4884 - val_accuracy: 0.3706\n",
            "Epoch 3046/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2251 - accuracy: 0.9900 - val_loss: 3.3950 - val_accuracy: 0.3808\n",
            "Epoch 3047/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2291 - accuracy: 0.9950 - val_loss: 3.4419 - val_accuracy: 0.3780\n",
            "Epoch 3048/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2281 - accuracy: 0.9950 - val_loss: 3.5247 - val_accuracy: 0.3694\n",
            "Epoch 3049/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2475 - accuracy: 0.9900 - val_loss: 3.5092 - val_accuracy: 0.3685\n",
            "Epoch 3050/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2482 - accuracy: 0.9800 - val_loss: 3.6821 - val_accuracy: 0.3534\n",
            "Epoch 3051/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2442 - accuracy: 0.9900 - val_loss: 3.6556 - val_accuracy: 0.3573\n",
            "Epoch 3052/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 3.7802 - val_accuracy: 0.3488\n",
            "Epoch 3053/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 3.8410 - val_accuracy: 0.3400\n",
            "Epoch 3054/6000\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2438 - accuracy: 0.9800 - val_loss: 4.0633 - val_accuracy: 0.3208\n",
            "Epoch 3055/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 4.1889 - val_accuracy: 0.3076\n",
            "Epoch 3056/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2332 - accuracy: 0.9900 - val_loss: 4.4363 - val_accuracy: 0.2924\n",
            "Epoch 3057/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2439 - accuracy: 0.9900 - val_loss: 4.1772 - val_accuracy: 0.3122\n",
            "Epoch 3058/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2267 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.3135\n",
            "Epoch 3059/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2308 - accuracy: 0.9950 - val_loss: 4.7074 - val_accuracy: 0.2922\n",
            "Epoch 3060/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2575 - accuracy: 0.9850 - val_loss: 3.8505 - val_accuracy: 0.3461\n",
            "Epoch 3061/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2283 - accuracy: 1.0000 - val_loss: 3.9801 - val_accuracy: 0.3292\n",
            "Epoch 3062/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2209 - accuracy: 1.0000 - val_loss: 3.9355 - val_accuracy: 0.3321\n",
            "Epoch 3063/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2567 - accuracy: 0.9850 - val_loss: 3.7809 - val_accuracy: 0.3339\n",
            "Epoch 3064/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2321 - accuracy: 0.9950 - val_loss: 3.7511 - val_accuracy: 0.3319\n",
            "Epoch 3065/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2294 - accuracy: 1.0000 - val_loss: 3.8796 - val_accuracy: 0.3225\n",
            "Epoch 3066/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2309 - accuracy: 0.9950 - val_loss: 4.1321 - val_accuracy: 0.3029\n",
            "Epoch 3067/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2316 - accuracy: 1.0000 - val_loss: 4.3032 - val_accuracy: 0.2956\n",
            "Epoch 3068/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2274 - accuracy: 0.9950 - val_loss: 4.2337 - val_accuracy: 0.2944\n",
            "Epoch 3069/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2809 - accuracy: 0.9800 - val_loss: 3.6096 - val_accuracy: 0.3289\n",
            "Epoch 3070/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2228 - accuracy: 1.0000 - val_loss: 3.5108 - val_accuracy: 0.3389\n",
            "Epoch 3071/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2342 - accuracy: 0.9900 - val_loss: 3.3964 - val_accuracy: 0.3512\n",
            "Epoch 3072/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2357 - accuracy: 0.9950 - val_loss: 3.4124 - val_accuracy: 0.3486\n",
            "Epoch 3073/6000\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.2349 - accuracy: 0.9950 - val_loss: 3.3733 - val_accuracy: 0.3593\n",
            "Epoch 3074/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2474 - accuracy: 0.9850 - val_loss: 4.5153 - val_accuracy: 0.2747\n",
            "Epoch 3075/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2243 - accuracy: 0.9950 - val_loss: 4.5396 - val_accuracy: 0.2777\n",
            "Epoch 3076/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2721 - accuracy: 0.9800 - val_loss: 3.7222 - val_accuracy: 0.3415\n",
            "Epoch 3077/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2238 - accuracy: 1.0000 - val_loss: 3.7806 - val_accuracy: 0.3373\n",
            "Epoch 3078/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 3.9533 - val_accuracy: 0.3266\n",
            "Epoch 3079/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2354 - accuracy: 0.9950 - val_loss: 4.5069 - val_accuracy: 0.2929\n",
            "Epoch 3080/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2631 - accuracy: 0.9900 - val_loss: 3.9108 - val_accuracy: 0.3258\n",
            "Epoch 3081/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 3.9721 - val_accuracy: 0.3262\n",
            "Epoch 3082/6000\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2436 - accuracy: 0.9900 - val_loss: 4.1626 - val_accuracy: 0.3017\n",
            "Epoch 3083/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2616 - accuracy: 0.9850 - val_loss: 4.6158 - val_accuracy: 0.2842\n",
            "Epoch 3084/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2356 - accuracy: 0.9900 - val_loss: 4.7580 - val_accuracy: 0.2738\n",
            "Epoch 3085/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2331 - accuracy: 0.9950 - val_loss: 4.2145 - val_accuracy: 0.3167\n",
            "Epoch 3086/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2304 - accuracy: 0.9950 - val_loss: 4.0883 - val_accuracy: 0.3203\n",
            "Epoch 3087/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2287 - accuracy: 1.0000 - val_loss: 4.0040 - val_accuracy: 0.3287\n",
            "Epoch 3088/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2322 - accuracy: 0.9950 - val_loss: 4.0451 - val_accuracy: 0.3308\n",
            "Epoch 3089/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2570 - accuracy: 0.9900 - val_loss: 3.7444 - val_accuracy: 0.3532\n",
            "Epoch 3090/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2226 - accuracy: 1.0000 - val_loss: 3.7828 - val_accuracy: 0.3507\n",
            "Epoch 3091/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2277 - accuracy: 0.9950 - val_loss: 3.8174 - val_accuracy: 0.3444\n",
            "Epoch 3092/6000\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2372 - accuracy: 0.9900 - val_loss: 4.0243 - val_accuracy: 0.3352\n",
            "Epoch 3093/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2485 - accuracy: 0.9850 - val_loss: 3.7731 - val_accuracy: 0.3401\n",
            "Epoch 3094/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2386 - accuracy: 0.9900 - val_loss: 3.5679 - val_accuracy: 0.3619\n",
            "Epoch 3095/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2352 - accuracy: 0.9950 - val_loss: 3.5841 - val_accuracy: 0.3590\n",
            "Epoch 3096/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2331 - accuracy: 0.9950 - val_loss: 3.8708 - val_accuracy: 0.3254\n",
            "Epoch 3097/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2395 - accuracy: 0.9900 - val_loss: 3.8740 - val_accuracy: 0.3286\n",
            "Epoch 3098/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2746 - accuracy: 0.9800 - val_loss: 3.5695 - val_accuracy: 0.3550\n",
            "Epoch 3099/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2379 - accuracy: 0.9950 - val_loss: 3.5675 - val_accuracy: 0.3632\n",
            "Epoch 3100/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2409 - accuracy: 0.9950 - val_loss: 3.6048 - val_accuracy: 0.3545\n",
            "Epoch 3101/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2383 - accuracy: 0.9950 - val_loss: 3.3216 - val_accuracy: 0.3775\n",
            "Epoch 3102/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2608 - accuracy: 0.9900 - val_loss: 3.2091 - val_accuracy: 0.3897\n",
            "Epoch 3103/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2486 - accuracy: 0.9900 - val_loss: 3.3788 - val_accuracy: 0.3696\n",
            "Epoch 3104/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2261 - accuracy: 1.0000 - val_loss: 3.3444 - val_accuracy: 0.3723\n",
            "Epoch 3105/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2531 - accuracy: 0.9950 - val_loss: 3.3005 - val_accuracy: 0.3824\n",
            "Epoch 3106/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2318 - accuracy: 0.9950 - val_loss: 3.3326 - val_accuracy: 0.3790\n",
            "Epoch 3107/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2489 - accuracy: 0.9950 - val_loss: 3.8139 - val_accuracy: 0.3311\n",
            "Epoch 3108/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2645 - accuracy: 0.9800 - val_loss: 3.6985 - val_accuracy: 0.3435\n",
            "Epoch 3109/6000\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.2356 - accuracy: 0.9950 - val_loss: 3.5626 - val_accuracy: 0.3585\n",
            "Epoch 3110/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 3.3611 - val_accuracy: 0.3705\n",
            "Epoch 3111/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2455 - accuracy: 0.9850 - val_loss: 3.2642 - val_accuracy: 0.3779\n",
            "Epoch 3112/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 3.2461 - val_accuracy: 0.3797\n",
            "Epoch 3113/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 3.2311 - val_accuracy: 0.3793\n",
            "Epoch 3114/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2365 - accuracy: 0.9900 - val_loss: 3.3554 - val_accuracy: 0.3699\n",
            "Epoch 3115/6000\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2314 - accuracy: 0.9950 - val_loss: 3.4962 - val_accuracy: 0.3603\n",
            "Epoch 3116/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2407 - accuracy: 0.9900 - val_loss: 3.5305 - val_accuracy: 0.3546\n",
            "Epoch 3117/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2425 - accuracy: 0.9900 - val_loss: 3.7169 - val_accuracy: 0.3310\n",
            "Epoch 3118/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 3.6814 - val_accuracy: 0.3359\n",
            "Epoch 3119/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2323 - accuracy: 0.9950 - val_loss: 3.5001 - val_accuracy: 0.3558\n",
            "Epoch 3120/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2248 - accuracy: 1.0000 - val_loss: 3.5291 - val_accuracy: 0.3533\n",
            "Epoch 3121/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2379 - accuracy: 0.9950 - val_loss: 3.4001 - val_accuracy: 0.3641\n",
            "Epoch 3122/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2423 - accuracy: 0.9900 - val_loss: 3.3680 - val_accuracy: 0.3642\n",
            "Epoch 3123/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2488 - accuracy: 0.9900 - val_loss: 3.5125 - val_accuracy: 0.3514\n",
            "Epoch 3124/6000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 3.4787 - val_accuracy: 0.3547\n",
            "Epoch 3125/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2374 - accuracy: 0.9950 - val_loss: 3.3583 - val_accuracy: 0.3671\n",
            "Epoch 3126/6000\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2374 - accuracy: 0.9900 - val_loss: 3.2999 - val_accuracy: 0.3732\n",
            "Epoch 3127/6000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.2359 - accuracy: 0.9950 - val_loss: 3.1944 - val_accuracy: 0.3858\n",
            "Epoch 3128/6000\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 3.1959 - val_accuracy: 0.3880\n",
            "Epoch 3129/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2271 - accuracy: 0.9950 - val_loss: 3.2436 - val_accuracy: 0.3820\n",
            "Epoch 3130/6000\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2426 - accuracy: 0.9900 - val_loss: 3.2537 - val_accuracy: 0.3751\n",
            "Epoch 3131/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 3.2694 - val_accuracy: 0.3703\n",
            "Epoch 3132/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2451 - accuracy: 0.9850 - val_loss: 3.2993 - val_accuracy: 0.3696\n",
            "Epoch 3133/6000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2447 - accuracy: 0.9900 - val_loss: 3.2662 - val_accuracy: 0.3596\n",
            "Epoch 3134/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2455 - accuracy: 0.9950 - val_loss: 3.2994 - val_accuracy: 0.3737\n",
            "Epoch 3135/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2290 - accuracy: 0.9950 - val_loss: 3.3050 - val_accuracy: 0.3768\n",
            "Epoch 3136/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2305 - accuracy: 0.9950 - val_loss: 3.2950 - val_accuracy: 0.3764\n",
            "Epoch 3137/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2409 - accuracy: 0.9950 - val_loss: 3.2338 - val_accuracy: 0.3814\n",
            "Epoch 3138/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2333 - accuracy: 0.9950 - val_loss: 3.2854 - val_accuracy: 0.3735\n",
            "Epoch 3139/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2463 - accuracy: 0.9850 - val_loss: 3.3235 - val_accuracy: 0.3713\n",
            "Epoch 3140/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2346 - accuracy: 0.9900 - val_loss: 3.2783 - val_accuracy: 0.3709\n",
            "Epoch 3141/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2523 - accuracy: 0.9900 - val_loss: 3.2532 - val_accuracy: 0.3655\n",
            "Epoch 3142/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2472 - accuracy: 0.9850 - val_loss: 3.2099 - val_accuracy: 0.3699\n",
            "Epoch 3143/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2277 - accuracy: 1.0000 - val_loss: 3.2081 - val_accuracy: 0.3706\n",
            "Epoch 3144/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2290 - accuracy: 0.9950 - val_loss: 3.4395 - val_accuracy: 0.3438\n",
            "Epoch 3145/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2324 - accuracy: 0.9950 - val_loss: 3.4126 - val_accuracy: 0.3466\n",
            "Epoch 3146/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2277 - accuracy: 1.0000 - val_loss: 3.2245 - val_accuracy: 0.3621\n",
            "Epoch 3147/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2350 - accuracy: 0.9950 - val_loss: 3.1331 - val_accuracy: 0.3782\n",
            "Epoch 3148/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2352 - accuracy: 0.9950 - val_loss: 3.1517 - val_accuracy: 0.3739\n",
            "Epoch 3149/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2289 - accuracy: 0.9950 - val_loss: 3.1313 - val_accuracy: 0.3757\n",
            "Epoch 3150/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2271 - accuracy: 1.0000 - val_loss: 3.2496 - val_accuracy: 0.3673\n",
            "Epoch 3151/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 3.2156 - val_accuracy: 0.3728\n",
            "Epoch 3152/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2301 - accuracy: 0.9950 - val_loss: 3.2247 - val_accuracy: 0.3647\n",
            "Epoch 3153/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2448 - accuracy: 0.9850 - val_loss: 3.3928 - val_accuracy: 0.3658\n",
            "Epoch 3154/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2275 - accuracy: 1.0000 - val_loss: 3.4156 - val_accuracy: 0.3601\n",
            "Epoch 3155/6000\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2689 - accuracy: 0.9900 - val_loss: 4.1695 - val_accuracy: 0.3029\n",
            "Epoch 3156/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2585 - accuracy: 0.9900 - val_loss: 3.9984 - val_accuracy: 0.3304\n",
            "Epoch 3157/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2226 - accuracy: 1.0000 - val_loss: 3.6901 - val_accuracy: 0.3500\n",
            "Epoch 3158/6000\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2392 - accuracy: 0.9900 - val_loss: 3.9997 - val_accuracy: 0.3361\n",
            "Epoch 3159/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2423 - accuracy: 0.9900 - val_loss: 3.7854 - val_accuracy: 0.3504\n",
            "Epoch 3160/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3043 - accuracy: 0.9800 - val_loss: 3.2793 - val_accuracy: 0.3870\n",
            "Epoch 3161/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2363 - accuracy: 0.9950 - val_loss: 3.3646 - val_accuracy: 0.3761\n",
            "Epoch 3162/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2284 - accuracy: 1.0000 - val_loss: 3.3599 - val_accuracy: 0.3738\n",
            "Epoch 3163/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2405 - accuracy: 0.9850 - val_loss: 3.0929 - val_accuracy: 0.3946\n",
            "Epoch 3164/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2356 - accuracy: 0.9950 - val_loss: 3.3259 - val_accuracy: 0.3780\n",
            "Epoch 3165/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2391 - accuracy: 0.9950 - val_loss: 3.4821 - val_accuracy: 0.3683\n",
            "Epoch 3166/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2324 - accuracy: 0.9950 - val_loss: 3.5439 - val_accuracy: 0.3663\n",
            "Epoch 3167/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2415 - accuracy: 0.9950 - val_loss: 4.0910 - val_accuracy: 0.3179\n",
            "Epoch 3168/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2423 - accuracy: 0.9900 - val_loss: 3.6267 - val_accuracy: 0.3415\n",
            "Epoch 3169/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2383 - accuracy: 0.9900 - val_loss: 3.7803 - val_accuracy: 0.3127\n",
            "Epoch 3170/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2373 - accuracy: 0.9900 - val_loss: 3.5747 - val_accuracy: 0.3344\n",
            "Epoch 3171/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2452 - accuracy: 0.9950 - val_loss: 3.4312 - val_accuracy: 0.3562\n",
            "Epoch 3172/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2411 - accuracy: 0.9950 - val_loss: 3.4242 - val_accuracy: 0.3579\n",
            "Epoch 3173/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2399 - accuracy: 0.9950 - val_loss: 3.4631 - val_accuracy: 0.3594\n",
            "Epoch 3174/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2434 - accuracy: 0.9950 - val_loss: 3.6940 - val_accuracy: 0.3407\n",
            "Epoch 3175/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 3.7573 - val_accuracy: 0.3395\n",
            "Epoch 3176/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2308 - accuracy: 0.9950 - val_loss: 3.9512 - val_accuracy: 0.3306\n",
            "Epoch 3177/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2636 - accuracy: 0.9900 - val_loss: 4.4264 - val_accuracy: 0.2917\n",
            "Epoch 3178/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2482 - accuracy: 0.9850 - val_loss: 3.5268 - val_accuracy: 0.3555\n",
            "Epoch 3179/6000\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2278 - accuracy: 1.0000 - val_loss: 3.5358 - val_accuracy: 0.3562\n",
            "Epoch 3180/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2369 - accuracy: 0.9950 - val_loss: 3.6481 - val_accuracy: 0.3531\n",
            "Epoch 3181/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2253 - accuracy: 1.0000 - val_loss: 3.7523 - val_accuracy: 0.3473\n",
            "Epoch 3182/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2307 - accuracy: 0.9950 - val_loss: 3.7004 - val_accuracy: 0.3488\n",
            "Epoch 3183/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2255 - accuracy: 1.0000 - val_loss: 3.7074 - val_accuracy: 0.3493\n",
            "Epoch 3184/6000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2245 - accuracy: 1.0000 - val_loss: 3.7223 - val_accuracy: 0.3489\n",
            "Epoch 3185/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2281 - accuracy: 0.9950 - val_loss: 3.7478 - val_accuracy: 0.3444\n",
            "Epoch 3186/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2330 - accuracy: 0.9950 - val_loss: 3.5909 - val_accuracy: 0.3539\n",
            "Epoch 3187/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2507 - accuracy: 0.9900 - val_loss: 3.4123 - val_accuracy: 0.3527\n",
            "Epoch 3188/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2612 - accuracy: 0.9850 - val_loss: 3.5035 - val_accuracy: 0.3545\n",
            "Epoch 3189/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 3.5155 - val_accuracy: 0.3552\n",
            "Epoch 3190/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2402 - accuracy: 0.9950 - val_loss: 3.6936 - val_accuracy: 0.3356\n",
            "Epoch 3191/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2473 - accuracy: 0.9850 - val_loss: 4.0296 - val_accuracy: 0.3097\n",
            "Epoch 3192/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2351 - accuracy: 0.9950 - val_loss: 4.0668 - val_accuracy: 0.3056\n",
            "Epoch 3193/6000\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 4.1210 - val_accuracy: 0.3004\n",
            "Epoch 3194/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2521 - accuracy: 0.9850 - val_loss: 3.9253 - val_accuracy: 0.3111\n",
            "Epoch 3195/6000\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2552 - accuracy: 0.9950 - val_loss: 4.0677 - val_accuracy: 0.2861\n",
            "Epoch 3196/6000\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2466 - accuracy: 0.9950 - val_loss: 3.7190 - val_accuracy: 0.3164\n",
            "Epoch 3197/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2681 - accuracy: 0.9800 - val_loss: 3.3855 - val_accuracy: 0.3540\n",
            "Epoch 3198/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2226 - accuracy: 1.0000 - val_loss: 3.3770 - val_accuracy: 0.3555\n",
            "Epoch 3199/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 3.3200 - val_accuracy: 0.3548\n",
            "Epoch 3200/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2655 - accuracy: 0.9800 - val_loss: 3.2480 - val_accuracy: 0.3611\n",
            "Epoch 3201/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2301 - accuracy: 1.0000 - val_loss: 3.2502 - val_accuracy: 0.3696\n",
            "Epoch 3202/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2417 - accuracy: 0.9900 - val_loss: 3.4274 - val_accuracy: 0.3570\n",
            "Epoch 3203/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2308 - accuracy: 1.0000 - val_loss: 3.3828 - val_accuracy: 0.3639\n",
            "Epoch 3204/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2951 - accuracy: 0.9800 - val_loss: 3.4441 - val_accuracy: 0.3608\n",
            "Epoch 3205/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2308 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.3614\n",
            "Epoch 3206/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 3.3689 - val_accuracy: 0.3585\n",
            "Epoch 3207/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2270 - accuracy: 1.0000 - val_loss: 3.3724 - val_accuracy: 0.3636\n",
            "Epoch 3208/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2606 - accuracy: 0.9800 - val_loss: 3.7025 - val_accuracy: 0.3214\n",
            "Epoch 3209/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2288 - accuracy: 1.0000 - val_loss: 3.6973 - val_accuracy: 0.3209\n",
            "Epoch 3210/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2653 - accuracy: 0.9800 - val_loss: 3.3493 - val_accuracy: 0.3565\n",
            "Epoch 3211/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2622 - accuracy: 0.9850 - val_loss: 3.6858 - val_accuracy: 0.3289\n",
            "Epoch 3212/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2491 - accuracy: 0.9800 - val_loss: 4.0275 - val_accuracy: 0.3048\n",
            "Epoch 3213/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3291 - accuracy: 0.9800 - val_loss: 4.0810 - val_accuracy: 0.3109\n",
            "Epoch 3214/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2591 - accuracy: 0.9900 - val_loss: 4.2801 - val_accuracy: 0.3066\n",
            "Epoch 3215/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2354 - accuracy: 0.9950 - val_loss: 4.2379 - val_accuracy: 0.3058\n",
            "Epoch 3216/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2720 - accuracy: 0.9900 - val_loss: 4.3748 - val_accuracy: 0.2904\n",
            "Epoch 3217/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 4.0603 - val_accuracy: 0.3188\n",
            "Epoch 3218/6000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2577 - accuracy: 0.9900 - val_loss: 4.4404 - val_accuracy: 0.2912\n",
            "Epoch 3219/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2641 - accuracy: 0.9900 - val_loss: 4.0162 - val_accuracy: 0.3148\n",
            "Epoch 3220/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 3.8993 - val_accuracy: 0.3266\n",
            "Epoch 3221/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2618 - accuracy: 0.9800 - val_loss: 3.9653 - val_accuracy: 0.3302\n",
            "Epoch 3222/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2530 - accuracy: 0.9900 - val_loss: 3.8782 - val_accuracy: 0.3312\n",
            "Epoch 3223/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2325 - accuracy: 1.0000 - val_loss: 3.8318 - val_accuracy: 0.3334\n",
            "Epoch 3224/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2471 - accuracy: 0.9900 - val_loss: 3.7441 - val_accuracy: 0.3576\n",
            "Epoch 3225/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2460 - accuracy: 0.9950 - val_loss: 3.9428 - val_accuracy: 0.3392\n",
            "Epoch 3226/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 3.8027 - val_accuracy: 0.3515\n",
            "Epoch 3227/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2394 - accuracy: 1.0000 - val_loss: 3.6748 - val_accuracy: 0.3582\n",
            "Epoch 3228/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2430 - accuracy: 0.9950 - val_loss: 3.5303 - val_accuracy: 0.3704\n",
            "Epoch 3229/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2376 - accuracy: 0.9950 - val_loss: 3.4160 - val_accuracy: 0.3760\n",
            "Epoch 3230/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2573 - accuracy: 0.9900 - val_loss: 3.3673 - val_accuracy: 0.3839\n",
            "Epoch 3231/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 3.3752 - val_accuracy: 0.3800\n",
            "Epoch 3232/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2402 - accuracy: 0.9950 - val_loss: 3.4272 - val_accuracy: 0.3727\n",
            "Epoch 3233/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2387 - accuracy: 0.9950 - val_loss: 3.4681 - val_accuracy: 0.3715\n",
            "Epoch 3234/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2397 - accuracy: 1.0000 - val_loss: 3.4740 - val_accuracy: 0.3692\n",
            "Epoch 3235/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 3.4639 - val_accuracy: 0.3706\n",
            "Epoch 3236/6000\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 3.3980 - val_accuracy: 0.3762\n",
            "Epoch 3237/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2547 - accuracy: 0.9900 - val_loss: 3.3570 - val_accuracy: 0.3779\n",
            "Epoch 3238/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2433 - accuracy: 0.9950 - val_loss: 3.3591 - val_accuracy: 0.3711\n",
            "Epoch 3239/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 3.3327 - val_accuracy: 0.3713\n",
            "Epoch 3240/6000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.2448 - accuracy: 0.9900 - val_loss: 3.3459 - val_accuracy: 0.3715\n",
            "Epoch 3241/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2471 - accuracy: 0.9950 - val_loss: 3.4175 - val_accuracy: 0.3609\n",
            "Epoch 3242/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2311 - accuracy: 1.0000 - val_loss: 3.4360 - val_accuracy: 0.3605\n",
            "Epoch 3243/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 3.4130 - val_accuracy: 0.3670\n",
            "Epoch 3244/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2546 - accuracy: 0.9800 - val_loss: 3.6777 - val_accuracy: 0.3405\n",
            "Epoch 3245/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 3.6911 - val_accuracy: 0.3389\n",
            "Epoch 3246/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2643 - accuracy: 0.9850 - val_loss: 3.5714 - val_accuracy: 0.3561\n",
            "Epoch 3247/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2686 - accuracy: 0.9850 - val_loss: 3.8091 - val_accuracy: 0.3405\n",
            "Epoch 3248/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2479 - accuracy: 0.9900 - val_loss: 3.9687 - val_accuracy: 0.3337\n",
            "Epoch 3249/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2388 - accuracy: 0.9950 - val_loss: 3.8377 - val_accuracy: 0.3452\n",
            "Epoch 3250/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2397 - accuracy: 0.9950 - val_loss: 3.7636 - val_accuracy: 0.3471\n",
            "Epoch 3251/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.5403 - val_accuracy: 0.3570\n",
            "Epoch 3252/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2757 - accuracy: 0.9800 - val_loss: 3.4843 - val_accuracy: 0.3662\n",
            "Epoch 3253/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2588 - accuracy: 0.9900 - val_loss: 3.5958 - val_accuracy: 0.3566\n",
            "Epoch 3254/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 3.6162 - val_accuracy: 0.3555\n",
            "Epoch 3255/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2573 - accuracy: 0.9950 - val_loss: 3.5980 - val_accuracy: 0.3597\n",
            "Epoch 3256/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 3.4860 - val_accuracy: 0.3683\n",
            "Epoch 3257/6000\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.2571 - accuracy: 0.9850 - val_loss: 3.5371 - val_accuracy: 0.3714\n",
            "Epoch 3258/6000\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 3.5133 - val_accuracy: 0.3718\n",
            "Epoch 3259/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2475 - accuracy: 0.9950 - val_loss: 3.5425 - val_accuracy: 0.3690\n",
            "Epoch 3260/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2429 - accuracy: 0.9900 - val_loss: 3.6614 - val_accuracy: 0.3625\n",
            "Epoch 3261/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2498 - accuracy: 0.9900 - val_loss: 3.6173 - val_accuracy: 0.3611\n",
            "Epoch 3262/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2440 - accuracy: 0.9900 - val_loss: 3.5697 - val_accuracy: 0.3554\n",
            "Epoch 3263/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2440 - accuracy: 0.9900 - val_loss: 3.6862 - val_accuracy: 0.3446\n",
            "Epoch 3264/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.4912 - val_accuracy: 0.3542\n",
            "Epoch 3265/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2625 - accuracy: 0.9900 - val_loss: 3.6532 - val_accuracy: 0.3367\n",
            "Epoch 3266/6000\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.2470 - accuracy: 0.9900 - val_loss: 4.0762 - val_accuracy: 0.3325\n",
            "Epoch 3267/6000\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.2568 - accuracy: 0.9900 - val_loss: 3.5946 - val_accuracy: 0.3588\n",
            "Epoch 3268/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2845 - accuracy: 0.9850 - val_loss: 3.3310 - val_accuracy: 0.3678\n",
            "Epoch 3269/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2377 - accuracy: 0.9950 - val_loss: 3.4457 - val_accuracy: 0.3498\n",
            "Epoch 3270/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2582 - accuracy: 0.9950 - val_loss: 3.6121 - val_accuracy: 0.3311\n",
            "Epoch 3271/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2366 - accuracy: 1.0000 - val_loss: 3.8437 - val_accuracy: 0.3097\n",
            "Epoch 3272/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2571 - accuracy: 0.9850 - val_loss: 3.9297 - val_accuracy: 0.3166\n",
            "Epoch 3273/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2644 - accuracy: 0.9900 - val_loss: 4.1818 - val_accuracy: 0.3002\n",
            "Epoch 3274/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2494 - accuracy: 0.9850 - val_loss: 4.2623 - val_accuracy: 0.3060\n",
            "Epoch 3275/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2471 - accuracy: 0.9850 - val_loss: 4.1724 - val_accuracy: 0.3097\n",
            "Epoch 3276/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 4.0408 - val_accuracy: 0.3208\n",
            "Epoch 3277/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 4.0071 - val_accuracy: 0.3203\n",
            "Epoch 3278/6000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2468 - accuracy: 0.9950 - val_loss: 4.3955 - val_accuracy: 0.2944\n",
            "Epoch 3279/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2448 - accuracy: 0.9950 - val_loss: 4.3840 - val_accuracy: 0.2980\n",
            "Epoch 3280/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2738 - accuracy: 0.9900 - val_loss: 4.2838 - val_accuracy: 0.3000\n",
            "Epoch 3281/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2557 - accuracy: 0.9900 - val_loss: 4.3580 - val_accuracy: 0.2930\n",
            "Epoch 3282/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2453 - accuracy: 0.9950 - val_loss: 4.1352 - val_accuracy: 0.3092\n",
            "Epoch 3283/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2469 - accuracy: 0.9900 - val_loss: 3.7933 - val_accuracy: 0.3353\n",
            "Epoch 3284/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2515 - accuracy: 0.9900 - val_loss: 3.7541 - val_accuracy: 0.3372\n",
            "Epoch 3285/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2436 - accuracy: 0.9950 - val_loss: 3.6127 - val_accuracy: 0.3562\n",
            "Epoch 3286/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2524 - accuracy: 0.9900 - val_loss: 3.6026 - val_accuracy: 0.3589\n",
            "Epoch 3287/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 3.8929 - val_accuracy: 0.3428\n",
            "Epoch 3288/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2496 - accuracy: 0.9950 - val_loss: 3.8673 - val_accuracy: 0.3473\n",
            "Epoch 3289/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2564 - accuracy: 0.9900 - val_loss: 3.3817 - val_accuracy: 0.3800\n",
            "Epoch 3290/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2549 - accuracy: 0.9900 - val_loss: 3.5244 - val_accuracy: 0.3601\n",
            "Epoch 3291/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2525 - accuracy: 0.9950 - val_loss: 3.4666 - val_accuracy: 0.3664\n",
            "Epoch 3292/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2582 - accuracy: 0.9950 - val_loss: 3.3858 - val_accuracy: 0.3734\n",
            "Epoch 3293/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2559 - accuracy: 0.9900 - val_loss: 3.4008 - val_accuracy: 0.3763\n",
            "Epoch 3294/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2449 - accuracy: 1.0000 - val_loss: 3.4719 - val_accuracy: 0.3760\n",
            "Epoch 3295/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2599 - accuracy: 0.9850 - val_loss: 3.6821 - val_accuracy: 0.3513\n",
            "Epoch 3296/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 3.7148 - val_accuracy: 0.3503\n",
            "Epoch 3297/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 3.5949 - val_accuracy: 0.3656\n",
            "Epoch 3298/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2407 - accuracy: 0.9950 - val_loss: 3.7648 - val_accuracy: 0.3566\n",
            "Epoch 3299/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2530 - accuracy: 0.9900 - val_loss: 3.9378 - val_accuracy: 0.3405\n",
            "Epoch 3300/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2402 - accuracy: 1.0000 - val_loss: 3.9219 - val_accuracy: 0.3420\n",
            "Epoch 3301/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2440 - accuracy: 0.9950 - val_loss: 3.9890 - val_accuracy: 0.3377\n",
            "Epoch 3302/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2520 - accuracy: 0.9900 - val_loss: 3.8261 - val_accuracy: 0.3386\n",
            "Epoch 3303/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2360 - accuracy: 1.0000 - val_loss: 3.9198 - val_accuracy: 0.3322\n",
            "Epoch 3304/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2594 - accuracy: 0.9900 - val_loss: 3.6837 - val_accuracy: 0.3554\n",
            "Epoch 3305/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2594 - accuracy: 0.9900 - val_loss: 3.7388 - val_accuracy: 0.3533\n",
            "Epoch 3306/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2768 - accuracy: 0.9850 - val_loss: 3.6855 - val_accuracy: 0.3576\n",
            "Epoch 3307/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2513 - accuracy: 0.9900 - val_loss: 3.8351 - val_accuracy: 0.3430\n",
            "Epoch 3308/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2442 - accuracy: 0.9950 - val_loss: 3.7848 - val_accuracy: 0.3443\n",
            "Epoch 3309/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2650 - accuracy: 0.9850 - val_loss: 3.5228 - val_accuracy: 0.3654\n",
            "Epoch 3310/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2480 - accuracy: 0.9900 - val_loss: 3.4580 - val_accuracy: 0.3717\n",
            "Epoch 3311/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2538 - accuracy: 0.9850 - val_loss: 3.5437 - val_accuracy: 0.3645\n",
            "Epoch 3312/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2410 - accuracy: 1.0000 - val_loss: 3.5753 - val_accuracy: 0.3567\n",
            "Epoch 3313/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2552 - accuracy: 0.9900 - val_loss: 3.8861 - val_accuracy: 0.3382\n",
            "Epoch 3314/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2487 - accuracy: 0.9950 - val_loss: 3.6627 - val_accuracy: 0.3522\n",
            "Epoch 3315/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2420 - accuracy: 0.9950 - val_loss: 3.7753 - val_accuracy: 0.3451\n",
            "Epoch 3316/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2516 - accuracy: 0.9950 - val_loss: 3.7919 - val_accuracy: 0.3436\n",
            "Epoch 3317/6000\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.2351 - accuracy: 1.0000 - val_loss: 3.7859 - val_accuracy: 0.3443\n",
            "Epoch 3318/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2348 - accuracy: 1.0000 - val_loss: 3.7449 - val_accuracy: 0.3472\n",
            "Epoch 3319/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 3.6172 - val_accuracy: 0.3612\n",
            "Epoch 3320/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2551 - accuracy: 0.9950 - val_loss: 3.7526 - val_accuracy: 0.3520\n",
            "Epoch 3321/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2400 - accuracy: 1.0000 - val_loss: 3.7102 - val_accuracy: 0.3579\n",
            "Epoch 3322/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2508 - accuracy: 0.9950 - val_loss: 3.6433 - val_accuracy: 0.3698\n",
            "Epoch 3323/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2577 - accuracy: 0.9850 - val_loss: 3.4930 - val_accuracy: 0.3814\n",
            "Epoch 3324/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 3.4747 - val_accuracy: 0.3821\n",
            "Epoch 3325/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2504 - accuracy: 0.9950 - val_loss: 3.4814 - val_accuracy: 0.3839\n",
            "Epoch 3326/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2497 - accuracy: 0.9900 - val_loss: 3.5063 - val_accuracy: 0.3829\n",
            "Epoch 3327/6000\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.2352 - accuracy: 1.0000 - val_loss: 3.5182 - val_accuracy: 0.3824\n",
            "Epoch 3328/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2784 - accuracy: 0.9950 - val_loss: 3.6575 - val_accuracy: 0.3707\n",
            "Epoch 3329/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2659 - accuracy: 0.9900 - val_loss: 3.4425 - val_accuracy: 0.3811\n",
            "Epoch 3330/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2667 - accuracy: 0.9750 - val_loss: 3.5027 - val_accuracy: 0.3735\n",
            "Epoch 3331/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 3.5200 - val_accuracy: 0.3738\n",
            "Epoch 3332/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2517 - accuracy: 0.9900 - val_loss: 3.4819 - val_accuracy: 0.3768\n",
            "Epoch 3333/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2400 - accuracy: 0.9950 - val_loss: 3.5201 - val_accuracy: 0.3711\n",
            "Epoch 3334/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2412 - accuracy: 0.9950 - val_loss: 3.5392 - val_accuracy: 0.3643\n",
            "Epoch 3335/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2374 - accuracy: 1.0000 - val_loss: 3.6158 - val_accuracy: 0.3581\n",
            "Epoch 3336/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2535 - accuracy: 0.9900 - val_loss: 3.7752 - val_accuracy: 0.3235\n",
            "Epoch 3337/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2477 - accuracy: 0.9900 - val_loss: 3.9382 - val_accuracy: 0.3201\n",
            "Epoch 3338/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2366 - accuracy: 1.0000 - val_loss: 4.0703 - val_accuracy: 0.3079\n",
            "Epoch 3339/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2452 - accuracy: 0.9950 - val_loss: 3.9365 - val_accuracy: 0.3260\n",
            "Epoch 3340/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2347 - accuracy: 1.0000 - val_loss: 3.7778 - val_accuracy: 0.3341\n",
            "Epoch 3341/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2319 - accuracy: 1.0000 - val_loss: 3.6986 - val_accuracy: 0.3416\n",
            "Epoch 3342/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2373 - accuracy: 1.0000 - val_loss: 3.5909 - val_accuracy: 0.3524\n",
            "Epoch 3343/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2491 - accuracy: 0.9950 - val_loss: 3.7519 - val_accuracy: 0.3329\n",
            "Epoch 3344/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.9171 - val_accuracy: 0.3242\n",
            "Epoch 3345/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2592 - accuracy: 0.9950 - val_loss: 3.9049 - val_accuracy: 0.3261\n",
            "Epoch 3346/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2439 - accuracy: 0.9950 - val_loss: 3.7277 - val_accuracy: 0.3531\n",
            "Epoch 3347/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2456 - accuracy: 0.9900 - val_loss: 3.6549 - val_accuracy: 0.3638\n",
            "Epoch 3348/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2459 - accuracy: 0.9900 - val_loss: 3.6117 - val_accuracy: 0.3682\n",
            "Epoch 3349/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.6422 - val_accuracy: 0.3645\n",
            "Epoch 3350/6000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2463 - accuracy: 0.9950 - val_loss: 3.6673 - val_accuracy: 0.3606\n",
            "Epoch 3351/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2385 - accuracy: 0.9950 - val_loss: 3.5237 - val_accuracy: 0.3662\n",
            "Epoch 3352/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2871 - accuracy: 0.9900 - val_loss: 3.5944 - val_accuracy: 0.3585\n",
            "Epoch 3353/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2448 - accuracy: 0.9950 - val_loss: 3.6123 - val_accuracy: 0.3594\n",
            "Epoch 3354/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2413 - accuracy: 0.9950 - val_loss: 3.6030 - val_accuracy: 0.3589\n",
            "Epoch 3355/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2416 - accuracy: 0.9950 - val_loss: 3.4771 - val_accuracy: 0.3632\n",
            "Epoch 3356/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2431 - accuracy: 0.9950 - val_loss: 3.4024 - val_accuracy: 0.3601\n",
            "Epoch 3357/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2577 - accuracy: 0.9950 - val_loss: 3.3915 - val_accuracy: 0.3775\n",
            "Epoch 3358/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2364 - accuracy: 1.0000 - val_loss: 3.3788 - val_accuracy: 0.3765\n",
            "Epoch 3359/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2348 - accuracy: 1.0000 - val_loss: 3.4139 - val_accuracy: 0.3760\n",
            "Epoch 3360/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2736 - accuracy: 0.9900 - val_loss: 3.4806 - val_accuracy: 0.3641\n",
            "Epoch 3361/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 3.5011 - val_accuracy: 0.3632\n",
            "Epoch 3362/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2396 - accuracy: 0.9950 - val_loss: 3.4806 - val_accuracy: 0.3731\n",
            "Epoch 3363/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2649 - accuracy: 0.9850 - val_loss: 3.6462 - val_accuracy: 0.3524\n",
            "Epoch 3364/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2420 - accuracy: 0.9950 - val_loss: 3.6361 - val_accuracy: 0.3544\n",
            "Epoch 3365/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 3.5976 - val_accuracy: 0.3525\n",
            "Epoch 3366/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2440 - accuracy: 0.9950 - val_loss: 3.6149 - val_accuracy: 0.3433\n",
            "Epoch 3367/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 3.4781 - val_accuracy: 0.3597\n",
            "Epoch 3368/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2595 - accuracy: 0.9850 - val_loss: 3.6609 - val_accuracy: 0.3543\n",
            "Epoch 3369/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2768 - accuracy: 0.9900 - val_loss: 3.4196 - val_accuracy: 0.3798\n",
            "Epoch 3370/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 3.4757 - val_accuracy: 0.3747\n",
            "Epoch 3371/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2419 - accuracy: 0.9950 - val_loss: 3.3894 - val_accuracy: 0.3702\n",
            "Epoch 3372/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 3.4406 - val_accuracy: 0.3685\n",
            "Epoch 3373/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2655 - accuracy: 0.9800 - val_loss: 3.6050 - val_accuracy: 0.3627\n",
            "Epoch 3374/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2774 - accuracy: 0.9800 - val_loss: 3.5999 - val_accuracy: 0.3589\n",
            "Epoch 3375/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2548 - accuracy: 0.9850 - val_loss: 3.7569 - val_accuracy: 0.3417\n",
            "Epoch 3376/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2403 - accuracy: 0.9950 - val_loss: 3.7075 - val_accuracy: 0.3425\n",
            "Epoch 3377/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 3.6469 - val_accuracy: 0.3488\n",
            "Epoch 3378/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2582 - accuracy: 0.9850 - val_loss: 3.6471 - val_accuracy: 0.3427\n",
            "Epoch 3379/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2569 - accuracy: 0.9950 - val_loss: 3.6624 - val_accuracy: 0.3428\n",
            "Epoch 3380/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2434 - accuracy: 0.9950 - val_loss: 3.5539 - val_accuracy: 0.3515\n",
            "Epoch 3381/6000\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.2377 - accuracy: 0.9950 - val_loss: 3.4710 - val_accuracy: 0.3557\n",
            "Epoch 3382/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2496 - accuracy: 0.9900 - val_loss: 3.9194 - val_accuracy: 0.3345\n",
            "Epoch 3383/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2417 - accuracy: 0.9950 - val_loss: 3.8296 - val_accuracy: 0.3366\n",
            "Epoch 3384/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2471 - accuracy: 0.9900 - val_loss: 3.7272 - val_accuracy: 0.3371\n",
            "Epoch 3385/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2411 - accuracy: 0.9950 - val_loss: 3.5691 - val_accuracy: 0.3530\n",
            "Epoch 3386/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2860 - accuracy: 0.9850 - val_loss: 3.9960 - val_accuracy: 0.3038\n",
            "Epoch 3387/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2534 - accuracy: 0.9900 - val_loss: 4.1322 - val_accuracy: 0.2978\n",
            "Epoch 3388/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2582 - accuracy: 0.9850 - val_loss: 3.6642 - val_accuracy: 0.3344\n",
            "Epoch 3389/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2876 - accuracy: 0.9800 - val_loss: 3.3509 - val_accuracy: 0.3577\n",
            "Epoch 3390/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2534 - accuracy: 0.9950 - val_loss: 3.2860 - val_accuracy: 0.3639\n",
            "Epoch 3391/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2672 - accuracy: 0.9900 - val_loss: 3.3072 - val_accuracy: 0.3609\n",
            "Epoch 3392/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2701 - accuracy: 0.9850 - val_loss: 3.3162 - val_accuracy: 0.3563\n",
            "Epoch 3393/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 3.3438 - val_accuracy: 0.3520\n",
            "Epoch 3394/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2450 - accuracy: 0.9900 - val_loss: 3.2247 - val_accuracy: 0.3605\n",
            "Epoch 3395/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2505 - accuracy: 0.9950 - val_loss: 3.1702 - val_accuracy: 0.3620\n",
            "Epoch 3396/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2557 - accuracy: 0.9900 - val_loss: 3.1165 - val_accuracy: 0.3686\n",
            "Epoch 3397/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 3.3698 - val_accuracy: 0.3450\n",
            "Epoch 3398/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2601 - accuracy: 0.9900 - val_loss: 3.7866 - val_accuracy: 0.3004\n",
            "Epoch 3399/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2574 - accuracy: 0.9950 - val_loss: 3.6223 - val_accuracy: 0.3189\n",
            "Epoch 3400/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2517 - accuracy: 0.9900 - val_loss: 3.6535 - val_accuracy: 0.3167\n",
            "Epoch 3401/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2577 - accuracy: 0.9900 - val_loss: 3.9664 - val_accuracy: 0.2950\n",
            "Epoch 3402/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 3.6013 - val_accuracy: 0.3263\n",
            "Epoch 3403/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2765 - accuracy: 0.9900 - val_loss: 3.6383 - val_accuracy: 0.3205\n",
            "Epoch 3404/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2571 - accuracy: 0.9900 - val_loss: 3.5490 - val_accuracy: 0.3405\n",
            "Epoch 3405/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2494 - accuracy: 0.9950 - val_loss: 3.7363 - val_accuracy: 0.3329\n",
            "Epoch 3406/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 3.7205 - val_accuracy: 0.3426\n",
            "Epoch 3407/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2385 - accuracy: 1.0000 - val_loss: 3.7317 - val_accuracy: 0.3462\n",
            "Epoch 3408/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2489 - accuracy: 0.9950 - val_loss: 3.5349 - val_accuracy: 0.3608\n",
            "Epoch 3409/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2565 - accuracy: 0.9950 - val_loss: 3.2442 - val_accuracy: 0.3884\n",
            "Epoch 3410/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 3.2701 - val_accuracy: 0.3871\n",
            "Epoch 3411/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.2841 - val_accuracy: 0.3869\n",
            "Epoch 3412/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2448 - accuracy: 0.9950 - val_loss: 3.2340 - val_accuracy: 0.3885\n",
            "Epoch 3413/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.2871 - val_accuracy: 0.3877\n",
            "Epoch 3414/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 3.3075 - val_accuracy: 0.3877\n",
            "Epoch 3415/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2985 - accuracy: 0.9800 - val_loss: 3.2510 - val_accuracy: 0.3827\n",
            "Epoch 3416/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2434 - accuracy: 1.0000 - val_loss: 3.2733 - val_accuracy: 0.3813\n",
            "Epoch 3417/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2544 - accuracy: 0.9800 - val_loss: 3.4574 - val_accuracy: 0.3729\n",
            "Epoch 3418/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2604 - accuracy: 0.9900 - val_loss: 3.3737 - val_accuracy: 0.3823\n",
            "Epoch 3419/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 3.4460 - val_accuracy: 0.3767\n",
            "Epoch 3420/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 3.7484 - val_accuracy: 0.3557\n",
            "Epoch 3421/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 3.7022 - val_accuracy: 0.3584\n",
            "Epoch 3422/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2809 - accuracy: 0.9850 - val_loss: 3.7583 - val_accuracy: 0.3608\n",
            "Epoch 3423/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2534 - accuracy: 0.9900 - val_loss: 3.8554 - val_accuracy: 0.3523\n",
            "Epoch 3424/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2471 - accuracy: 0.9950 - val_loss: 3.5175 - val_accuracy: 0.3764\n",
            "Epoch 3425/6000\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2482 - accuracy: 1.0000 - val_loss: 3.4299 - val_accuracy: 0.3916\n",
            "Epoch 3426/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2489 - accuracy: 0.9900 - val_loss: 3.3727 - val_accuracy: 0.4019\n",
            "Epoch 3427/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2585 - accuracy: 0.9900 - val_loss: 3.3984 - val_accuracy: 0.3970\n",
            "Epoch 3428/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2674 - accuracy: 0.9900 - val_loss: 3.4827 - val_accuracy: 0.3956\n",
            "Epoch 3429/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2586 - accuracy: 0.9850 - val_loss: 3.8274 - val_accuracy: 0.3514\n",
            "Epoch 3430/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2456 - accuracy: 0.9950 - val_loss: 3.6362 - val_accuracy: 0.3741\n",
            "Epoch 3431/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2506 - accuracy: 0.9900 - val_loss: 3.7581 - val_accuracy: 0.3638\n",
            "Epoch 3432/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2607 - accuracy: 0.9900 - val_loss: 3.9285 - val_accuracy: 0.3625\n",
            "Epoch 3433/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2791 - accuracy: 0.9800 - val_loss: 3.8767 - val_accuracy: 0.3490\n",
            "Epoch 3434/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2477 - accuracy: 1.0000 - val_loss: 3.7584 - val_accuracy: 0.3557\n",
            "Epoch 3435/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 3.6870 - val_accuracy: 0.3652\n",
            "Epoch 3436/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 3.5494 - val_accuracy: 0.3778\n",
            "Epoch 3437/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 3.6376 - val_accuracy: 0.3677\n",
            "Epoch 3438/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2683 - accuracy: 0.9850 - val_loss: 3.5954 - val_accuracy: 0.3720\n",
            "Epoch 3439/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2782 - accuracy: 0.9800 - val_loss: 3.6660 - val_accuracy: 0.3605\n",
            "Epoch 3440/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2665 - accuracy: 0.9950 - val_loss: 3.8190 - val_accuracy: 0.3441\n",
            "Epoch 3441/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2581 - accuracy: 0.9900 - val_loss: 4.4159 - val_accuracy: 0.3027\n",
            "Epoch 3442/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2455 - accuracy: 0.9950 - val_loss: 4.1123 - val_accuracy: 0.3130\n",
            "Epoch 3443/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 4.1169 - val_accuracy: 0.3105\n",
            "Epoch 3444/6000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2673 - accuracy: 0.9900 - val_loss: 3.8645 - val_accuracy: 0.3380\n",
            "Epoch 3445/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2727 - accuracy: 0.9850 - val_loss: 3.8539 - val_accuracy: 0.3400\n",
            "Epoch 3446/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2507 - accuracy: 0.9950 - val_loss: 3.9345 - val_accuracy: 0.3336\n",
            "Epoch 3447/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2659 - accuracy: 0.9850 - val_loss: 3.6943 - val_accuracy: 0.3474\n",
            "Epoch 3448/6000\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2590 - accuracy: 0.9950 - val_loss: 3.7274 - val_accuracy: 0.3441\n",
            "Epoch 3449/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2562 - accuracy: 0.9900 - val_loss: 3.8637 - val_accuracy: 0.3354\n",
            "Epoch 3450/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2659 - accuracy: 0.9900 - val_loss: 3.6602 - val_accuracy: 0.3525\n",
            "Epoch 3451/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 3.6786 - val_accuracy: 0.3502\n",
            "Epoch 3452/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2634 - accuracy: 0.9850 - val_loss: 3.6159 - val_accuracy: 0.3548\n",
            "Epoch 3453/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2592 - accuracy: 0.9950 - val_loss: 3.6369 - val_accuracy: 0.3549\n",
            "Epoch 3454/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2468 - accuracy: 0.9950 - val_loss: 3.6538 - val_accuracy: 0.3578\n",
            "Epoch 3455/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2677 - accuracy: 0.9850 - val_loss: 3.7562 - val_accuracy: 0.3578\n",
            "Epoch 3456/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2445 - accuracy: 0.9950 - val_loss: 3.8300 - val_accuracy: 0.3503\n",
            "Epoch 3457/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2624 - accuracy: 0.9900 - val_loss: 3.9258 - val_accuracy: 0.3534\n",
            "Epoch 3458/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 4.4725 - val_accuracy: 0.3143\n",
            "Epoch 3459/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2586 - accuracy: 0.9900 - val_loss: 4.0117 - val_accuracy: 0.3434\n",
            "Epoch 3460/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 3.9221 - val_accuracy: 0.3507\n",
            "Epoch 3461/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2584 - accuracy: 0.9900 - val_loss: 3.8850 - val_accuracy: 0.3526\n",
            "Epoch 3462/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2658 - accuracy: 0.9950 - val_loss: 4.0791 - val_accuracy: 0.3417\n",
            "Epoch 3463/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2630 - accuracy: 0.9950 - val_loss: 3.9194 - val_accuracy: 0.3489\n",
            "Epoch 3464/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2664 - accuracy: 0.9800 - val_loss: 3.5558 - val_accuracy: 0.3700\n",
            "Epoch 3465/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2643 - accuracy: 0.9900 - val_loss: 3.5828 - val_accuracy: 0.3638\n",
            "Epoch 3466/6000\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.3315 - accuracy: 0.9750 - val_loss: 3.9299 - val_accuracy: 0.3408\n",
            "Epoch 3467/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2787 - accuracy: 0.9850 - val_loss: 3.7407 - val_accuracy: 0.3407\n",
            "Epoch 3468/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2526 - accuracy: 0.9950 - val_loss: 3.7720 - val_accuracy: 0.3346\n",
            "Epoch 3469/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2547 - accuracy: 0.9950 - val_loss: 3.7210 - val_accuracy: 0.3268\n",
            "Epoch 3470/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2550 - accuracy: 0.9950 - val_loss: 3.5575 - val_accuracy: 0.3483\n",
            "Epoch 3471/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2766 - accuracy: 0.9900 - val_loss: 3.5032 - val_accuracy: 0.3575\n",
            "Epoch 3472/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2477 - accuracy: 1.0000 - val_loss: 3.4344 - val_accuracy: 0.3589\n",
            "Epoch 3473/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2805 - accuracy: 0.9900 - val_loss: 3.6364 - val_accuracy: 0.3545\n",
            "Epoch 3474/6000\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2665 - accuracy: 0.9850 - val_loss: 3.5059 - val_accuracy: 0.3574\n",
            "Epoch 3475/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 3.5559 - val_accuracy: 0.3547\n",
            "Epoch 3476/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2512 - accuracy: 0.9950 - val_loss: 3.5560 - val_accuracy: 0.3545\n",
            "Epoch 3477/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2509 - accuracy: 1.0000 - val_loss: 3.6721 - val_accuracy: 0.3463\n",
            "Epoch 3478/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2642 - accuracy: 0.9850 - val_loss: 3.9233 - val_accuracy: 0.3196\n",
            "Epoch 3479/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 3.8312 - val_accuracy: 0.3258\n",
            "Epoch 3480/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2824 - accuracy: 0.9900 - val_loss: 3.7471 - val_accuracy: 0.3343\n",
            "Epoch 3481/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2758 - accuracy: 0.9850 - val_loss: 3.7428 - val_accuracy: 0.3263\n",
            "Epoch 3482/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2822 - accuracy: 0.9850 - val_loss: 3.5299 - val_accuracy: 0.3398\n",
            "Epoch 3483/6000\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.2450 - accuracy: 1.0000 - val_loss: 3.4893 - val_accuracy: 0.3460\n",
            "Epoch 3484/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2700 - accuracy: 0.9900 - val_loss: 3.5038 - val_accuracy: 0.3446\n",
            "Epoch 3485/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 3.3716 - val_accuracy: 0.3622\n",
            "Epoch 3486/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2541 - accuracy: 0.9950 - val_loss: 3.3798 - val_accuracy: 0.3687\n",
            "Epoch 3487/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2526 - accuracy: 0.9950 - val_loss: 3.3147 - val_accuracy: 0.3786\n",
            "Epoch 3488/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2502 - accuracy: 1.0000 - val_loss: 3.4668 - val_accuracy: 0.3677\n",
            "Epoch 3489/6000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 3.4361 - val_accuracy: 0.3675\n",
            "Epoch 3490/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 3.4185 - val_accuracy: 0.3661\n",
            "Epoch 3491/6000\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.2708 - accuracy: 0.9900 - val_loss: 3.4256 - val_accuracy: 0.3647\n",
            "Epoch 3492/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2753 - accuracy: 0.9750 - val_loss: 4.1278 - val_accuracy: 0.3125\n",
            "Epoch 3493/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2628 - accuracy: 0.9900 - val_loss: 3.9871 - val_accuracy: 0.3270\n",
            "Epoch 3494/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2561 - accuracy: 0.9950 - val_loss: 3.7768 - val_accuracy: 0.3501\n",
            "Epoch 3495/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 3.6429 - val_accuracy: 0.3610\n",
            "Epoch 3496/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2465 - accuracy: 0.9950 - val_loss: 3.6029 - val_accuracy: 0.3624\n",
            "Epoch 3497/6000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2624 - accuracy: 0.9900 - val_loss: 3.4835 - val_accuracy: 0.3655\n",
            "Epoch 3498/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2697 - accuracy: 0.9950 - val_loss: 3.4250 - val_accuracy: 0.3759\n",
            "Epoch 3499/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3292 - accuracy: 0.9800 - val_loss: 3.7351 - val_accuracy: 0.3562\n",
            "Epoch 3500/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2633 - accuracy: 0.9900 - val_loss: 3.4693 - val_accuracy: 0.3745\n",
            "Epoch 3501/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 3.4842 - val_accuracy: 0.3723\n",
            "Epoch 3502/6000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2542 - accuracy: 0.9950 - val_loss: 3.4571 - val_accuracy: 0.3740\n",
            "Epoch 3503/6000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2663 - accuracy: 0.9950 - val_loss: 3.5073 - val_accuracy: 0.3749\n",
            "Epoch 3504/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2508 - accuracy: 0.9950 - val_loss: 3.4101 - val_accuracy: 0.3842\n",
            "Epoch 3505/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2545 - accuracy: 0.9950 - val_loss: 3.4305 - val_accuracy: 0.3838\n",
            "Epoch 3506/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2575 - accuracy: 0.9900 - val_loss: 3.3340 - val_accuracy: 0.3908\n",
            "Epoch 3507/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2525 - accuracy: 0.9900 - val_loss: 3.4595 - val_accuracy: 0.3751\n",
            "Epoch 3508/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2504 - accuracy: 0.9950 - val_loss: 3.4042 - val_accuracy: 0.3812\n",
            "Epoch 3509/6000\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2544 - accuracy: 0.9950 - val_loss: 3.3129 - val_accuracy: 0.3912\n",
            "Epoch 3510/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2728 - accuracy: 0.9900 - val_loss: 3.2980 - val_accuracy: 0.3966\n",
            "Epoch 3511/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2615 - accuracy: 0.9900 - val_loss: 3.2766 - val_accuracy: 0.3987\n",
            "Epoch 3512/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2789 - accuracy: 0.9900 - val_loss: 3.5105 - val_accuracy: 0.3811\n",
            "Epoch 3513/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2750 - accuracy: 0.9900 - val_loss: 3.4719 - val_accuracy: 0.3827\n",
            "Epoch 3514/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2625 - accuracy: 0.9900 - val_loss: 3.5413 - val_accuracy: 0.3776\n",
            "Epoch 3515/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 3.5232 - val_accuracy: 0.3796\n",
            "Epoch 3516/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 3.6030 - val_accuracy: 0.3734\n",
            "Epoch 3517/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2433 - accuracy: 1.0000 - val_loss: 3.7069 - val_accuracy: 0.3648\n",
            "Epoch 3518/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2785 - accuracy: 0.9950 - val_loss: 3.4241 - val_accuracy: 0.3853\n",
            "Epoch 3519/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3003 - accuracy: 0.9750 - val_loss: 3.5349 - val_accuracy: 0.3751\n",
            "Epoch 3520/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2739 - accuracy: 0.9900 - val_loss: 3.8203 - val_accuracy: 0.3547\n",
            "Epoch 3521/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2518 - accuracy: 1.0000 - val_loss: 3.8011 - val_accuracy: 0.3603\n",
            "Epoch 3522/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2677 - accuracy: 0.9850 - val_loss: 3.7812 - val_accuracy: 0.3565\n",
            "Epoch 3523/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2493 - accuracy: 0.9950 - val_loss: 3.9065 - val_accuracy: 0.3434\n",
            "Epoch 3524/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2725 - accuracy: 0.9900 - val_loss: 4.5584 - val_accuracy: 0.3069\n",
            "Epoch 3525/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2535 - accuracy: 0.9950 - val_loss: 4.2881 - val_accuracy: 0.3217\n",
            "Epoch 3526/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 4.1515 - val_accuracy: 0.3307\n",
            "Epoch 3527/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3049 - accuracy: 0.9850 - val_loss: 4.0912 - val_accuracy: 0.3160\n",
            "Epoch 3528/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2931 - accuracy: 0.9850 - val_loss: 4.0080 - val_accuracy: 0.3251\n",
            "Epoch 3529/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2798 - accuracy: 0.9850 - val_loss: 4.0877 - val_accuracy: 0.3393\n",
            "Epoch 3530/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2909 - accuracy: 0.9900 - val_loss: 3.8258 - val_accuracy: 0.3636\n",
            "Epoch 3531/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2693 - accuracy: 0.9850 - val_loss: 3.9572 - val_accuracy: 0.3536\n",
            "Epoch 3532/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2662 - accuracy: 0.9850 - val_loss: 5.1293 - val_accuracy: 0.2719\n",
            "Epoch 3533/6000\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3379 - accuracy: 0.9700 - val_loss: 4.6665 - val_accuracy: 0.2986\n",
            "Epoch 3534/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2612 - accuracy: 0.9950 - val_loss: 4.9075 - val_accuracy: 0.2888\n",
            "Epoch 3535/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2532 - accuracy: 0.9950 - val_loss: 4.9195 - val_accuracy: 0.2893\n",
            "Epoch 3536/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 4.5116 - val_accuracy: 0.3118\n",
            "Epoch 3537/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2518 - accuracy: 1.0000 - val_loss: 4.4976 - val_accuracy: 0.3131\n",
            "Epoch 3538/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3123 - accuracy: 0.9600 - val_loss: 3.8324 - val_accuracy: 0.3662\n",
            "Epoch 3539/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2659 - accuracy: 0.9900 - val_loss: 3.6346 - val_accuracy: 0.3692\n",
            "Epoch 3540/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2664 - accuracy: 0.9900 - val_loss: 3.5516 - val_accuracy: 0.3723\n",
            "Epoch 3541/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2600 - accuracy: 0.9900 - val_loss: 3.4845 - val_accuracy: 0.3718\n",
            "Epoch 3542/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 3.4488 - val_accuracy: 0.3701\n",
            "Epoch 3543/6000\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2693 - accuracy: 0.9900 - val_loss: 3.4533 - val_accuracy: 0.3730\n",
            "Epoch 3544/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 3.4356 - val_accuracy: 0.3748\n",
            "Epoch 3545/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2572 - accuracy: 0.9950 - val_loss: 3.4338 - val_accuracy: 0.3749\n",
            "Epoch 3546/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2510 - accuracy: 1.0000 - val_loss: 3.4628 - val_accuracy: 0.3785\n",
            "Epoch 3547/6000\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.2542 - accuracy: 0.9950 - val_loss: 3.5275 - val_accuracy: 0.3719\n",
            "Epoch 3548/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2666 - accuracy: 0.9900 - val_loss: 3.6534 - val_accuracy: 0.3571\n",
            "Epoch 3549/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2591 - accuracy: 0.9900 - val_loss: 3.7104 - val_accuracy: 0.3506\n",
            "Epoch 3550/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2619 - accuracy: 0.9950 - val_loss: 3.6817 - val_accuracy: 0.3583\n",
            "Epoch 3551/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2541 - accuracy: 1.0000 - val_loss: 3.7350 - val_accuracy: 0.3533\n",
            "Epoch 3552/6000\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 3.6302 - val_accuracy: 0.3591\n",
            "Epoch 3553/6000\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2579 - accuracy: 0.9950 - val_loss: 3.6418 - val_accuracy: 0.3500\n",
            "Epoch 3554/6000\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.2785 - accuracy: 0.9850 - val_loss: 3.6602 - val_accuracy: 0.3544\n",
            "Epoch 3555/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 3.7627 - val_accuracy: 0.3442\n",
            "Epoch 3556/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2810 - accuracy: 0.9900 - val_loss: 3.8783 - val_accuracy: 0.3315\n",
            "Epoch 3557/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2649 - accuracy: 0.9900 - val_loss: 3.8839 - val_accuracy: 0.3320\n",
            "Epoch 3558/6000\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.2543 - accuracy: 0.9950 - val_loss: 3.9103 - val_accuracy: 0.3343\n",
            "Epoch 3559/6000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2631 - accuracy: 0.9950 - val_loss: 3.6844 - val_accuracy: 0.3614\n",
            "Epoch 3560/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2695 - accuracy: 0.9950 - val_loss: 3.7181 - val_accuracy: 0.3578\n",
            "Epoch 3561/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 3.7630 - val_accuracy: 0.3525\n",
            "Epoch 3562/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2572 - accuracy: 0.9950 - val_loss: 3.7206 - val_accuracy: 0.3553\n",
            "Epoch 3563/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2734 - accuracy: 0.9900 - val_loss: 3.7131 - val_accuracy: 0.3637\n",
            "Epoch 3564/6000\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.3062 - accuracy: 0.9850 - val_loss: 4.5381 - val_accuracy: 0.3060\n",
            "Epoch 3565/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2513 - accuracy: 1.0000 - val_loss: 4.1539 - val_accuracy: 0.3267\n",
            "Epoch 3566/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2786 - accuracy: 0.9850 - val_loss: 3.8574 - val_accuracy: 0.3462\n",
            "Epoch 3567/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2506 - accuracy: 1.0000 - val_loss: 3.8499 - val_accuracy: 0.3449\n",
            "Epoch 3568/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 3.7223 - val_accuracy: 0.3565\n",
            "Epoch 3569/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2618 - accuracy: 0.9950 - val_loss: 3.5031 - val_accuracy: 0.3768\n",
            "Epoch 3570/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2693 - accuracy: 0.9900 - val_loss: 3.4710 - val_accuracy: 0.3764\n",
            "Epoch 3571/6000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2681 - accuracy: 0.9950 - val_loss: 3.5160 - val_accuracy: 0.3796\n",
            "Epoch 3572/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2697 - accuracy: 0.9900 - val_loss: 3.5735 - val_accuracy: 0.3680\n",
            "Epoch 3573/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2591 - accuracy: 0.9950 - val_loss: 3.4933 - val_accuracy: 0.3766\n",
            "Epoch 3574/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2598 - accuracy: 0.9900 - val_loss: 3.5697 - val_accuracy: 0.3652\n",
            "Epoch 3575/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2749 - accuracy: 0.9850 - val_loss: 3.7037 - val_accuracy: 0.3405\n",
            "Epoch 3576/6000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2635 - accuracy: 0.9900 - val_loss: 3.9301 - val_accuracy: 0.3208\n",
            "Epoch 3577/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2584 - accuracy: 0.9950 - val_loss: 3.5353 - val_accuracy: 0.3498\n",
            "Epoch 3578/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 3.3232 - val_accuracy: 0.3842\n",
            "Epoch 3579/6000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.2568 - accuracy: 0.9950 - val_loss: 3.2625 - val_accuracy: 0.3834\n",
            "Epoch 3580/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2692 - accuracy: 0.9850 - val_loss: 3.4366 - val_accuracy: 0.3790\n",
            "Epoch 3581/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2460 - accuracy: 1.0000 - val_loss: 3.4486 - val_accuracy: 0.3779\n",
            "Epoch 3582/6000\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2592 - accuracy: 0.9950 - val_loss: 3.4202 - val_accuracy: 0.3764\n",
            "Epoch 3583/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2951 - accuracy: 0.9850 - val_loss: 3.4395 - val_accuracy: 0.3824\n",
            "Epoch 3584/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2684 - accuracy: 0.9850 - val_loss: 3.4331 - val_accuracy: 0.3809\n",
            "Epoch 3585/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2576 - accuracy: 0.9950 - val_loss: 3.5391 - val_accuracy: 0.3611\n",
            "Epoch 3586/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2570 - accuracy: 0.9950 - val_loss: 3.6853 - val_accuracy: 0.3514\n",
            "Epoch 3587/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2490 - accuracy: 1.0000 - val_loss: 3.6932 - val_accuracy: 0.3444\n",
            "Epoch 3588/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2500 - accuracy: 0.9950 - val_loss: 3.6593 - val_accuracy: 0.3430\n",
            "Epoch 3589/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2743 - accuracy: 0.9800 - val_loss: 3.5104 - val_accuracy: 0.3632\n",
            "Epoch 3590/6000\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2684 - accuracy: 0.9900 - val_loss: 3.5780 - val_accuracy: 0.3473\n",
            "Epoch 3591/6000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2794 - accuracy: 0.9900 - val_loss: 3.6455 - val_accuracy: 0.3529\n",
            "Epoch 3592/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2547 - accuracy: 0.9950 - val_loss: 3.5806 - val_accuracy: 0.3602\n",
            "Epoch 3593/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2641 - accuracy: 0.9950 - val_loss: 3.5591 - val_accuracy: 0.3628\n",
            "Epoch 3594/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2518 - accuracy: 1.0000 - val_loss: 3.5752 - val_accuracy: 0.3618\n",
            "Epoch 3595/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2703 - accuracy: 0.9850 - val_loss: 3.6134 - val_accuracy: 0.3552\n",
            "Epoch 3596/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2569 - accuracy: 0.9950 - val_loss: 3.5334 - val_accuracy: 0.3675\n",
            "Epoch 3597/6000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2673 - accuracy: 0.9900 - val_loss: 3.5731 - val_accuracy: 0.3700\n",
            "Epoch 3598/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.5565 - val_accuracy: 0.3681\n",
            "Epoch 3599/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 3.5775 - val_accuracy: 0.3674\n",
            "Epoch 3600/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 3.5859 - val_accuracy: 0.3691\n",
            "Epoch 3601/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2519 - accuracy: 0.9950 - val_loss: 3.6664 - val_accuracy: 0.3572\n",
            "Epoch 3602/6000\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2707 - accuracy: 0.9900 - val_loss: 3.6700 - val_accuracy: 0.3564\n",
            "Epoch 3603/6000\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.2763 - accuracy: 0.9900 - val_loss: 3.7447 - val_accuracy: 0.3519\n",
            "Epoch 3604/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2623 - accuracy: 0.9950 - val_loss: 3.8957 - val_accuracy: 0.3418\n",
            "Epoch 3605/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2500 - accuracy: 0.9950 - val_loss: 3.9007 - val_accuracy: 0.3383\n",
            "Epoch 3606/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2462 - accuracy: 1.0000 - val_loss: 3.9749 - val_accuracy: 0.3360\n",
            "Epoch 3607/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2520 - accuracy: 0.9950 - val_loss: 4.0381 - val_accuracy: 0.3275\n",
            "Epoch 3608/6000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2519 - accuracy: 1.0000 - val_loss: 4.0375 - val_accuracy: 0.3273\n",
            "Epoch 3609/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2619 - accuracy: 0.9950 - val_loss: 3.9588 - val_accuracy: 0.3353\n",
            "Epoch 3610/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2550 - accuracy: 0.9950 - val_loss: 4.0213 - val_accuracy: 0.3267\n",
            "Epoch 3611/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2590 - accuracy: 0.9950 - val_loss: 4.0779 - val_accuracy: 0.3188\n",
            "Epoch 3612/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2512 - accuracy: 1.0000 - val_loss: 4.0105 - val_accuracy: 0.3258\n",
            "Epoch 3613/6000\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2409 - accuracy: 1.0000 - val_loss: 4.0028 - val_accuracy: 0.3267\n",
            "Epoch 3614/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2488 - accuracy: 1.0000 - val_loss: 3.9906 - val_accuracy: 0.3233\n",
            "Epoch 3615/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2533 - accuracy: 1.0000 - val_loss: 3.9957 - val_accuracy: 0.3222\n",
            "Epoch 3616/6000\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.2452 - accuracy: 1.0000 - val_loss: 3.9525 - val_accuracy: 0.3257\n",
            "Epoch 3617/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2427 - accuracy: 1.0000 - val_loss: 3.8896 - val_accuracy: 0.3304\n",
            "Epoch 3618/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2630 - accuracy: 0.9900 - val_loss: 3.9332 - val_accuracy: 0.3266\n",
            "Epoch 3619/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 3.8708 - val_accuracy: 0.3317\n",
            "Epoch 3620/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2598 - accuracy: 0.9950 - val_loss: 3.7713 - val_accuracy: 0.3416\n",
            "Epoch 3621/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 3.7659 - val_accuracy: 0.3400\n",
            "Epoch 3622/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2586 - accuracy: 0.9900 - val_loss: 3.6596 - val_accuracy: 0.3481\n",
            "Epoch 3623/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2516 - accuracy: 0.9950 - val_loss: 3.5365 - val_accuracy: 0.3683\n",
            "Epoch 3624/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2520 - accuracy: 0.9950 - val_loss: 3.6080 - val_accuracy: 0.3537\n",
            "Epoch 3625/6000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 3.6623 - val_accuracy: 0.3536\n",
            "Epoch 3626/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2497 - accuracy: 0.9950 - val_loss: 3.6068 - val_accuracy: 0.3587\n",
            "Epoch 3627/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2464 - accuracy: 0.9950 - val_loss: 3.6348 - val_accuracy: 0.3580\n",
            "Epoch 3628/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2657 - accuracy: 0.9950 - val_loss: 3.5630 - val_accuracy: 0.3701\n",
            "Epoch 3629/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2510 - accuracy: 0.9950 - val_loss: 3.5759 - val_accuracy: 0.3628\n",
            "Epoch 3630/6000\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.2480 - accuracy: 0.9950 - val_loss: 3.6071 - val_accuracy: 0.3647\n",
            "Epoch 3631/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2586 - accuracy: 0.9950 - val_loss: 3.8346 - val_accuracy: 0.3461\n",
            "Epoch 3632/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2721 - accuracy: 0.9900 - val_loss: 3.6793 - val_accuracy: 0.3557\n",
            "Epoch 3633/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2485 - accuracy: 0.9950 - val_loss: 3.6673 - val_accuracy: 0.3573\n",
            "Epoch 3634/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2436 - accuracy: 0.9950 - val_loss: 3.6537 - val_accuracy: 0.3604\n",
            "Epoch 3635/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2452 - accuracy: 1.0000 - val_loss: 3.6097 - val_accuracy: 0.3581\n",
            "Epoch 3636/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2397 - accuracy: 1.0000 - val_loss: 3.5966 - val_accuracy: 0.3576\n",
            "Epoch 3637/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2667 - accuracy: 0.9950 - val_loss: 3.6042 - val_accuracy: 0.3576\n",
            "Epoch 3638/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 3.5996 - val_accuracy: 0.3509\n",
            "Epoch 3639/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2417 - accuracy: 1.0000 - val_loss: 3.6980 - val_accuracy: 0.3437\n",
            "Epoch 3640/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2461 - accuracy: 0.9950 - val_loss: 3.8234 - val_accuracy: 0.3361\n",
            "Epoch 3641/6000\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.2455 - accuracy: 1.0000 - val_loss: 3.7751 - val_accuracy: 0.3400\n",
            "Epoch 3642/6000\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2444 - accuracy: 0.9950 - val_loss: 3.7177 - val_accuracy: 0.3460\n",
            "Epoch 3643/6000\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 3.8265 - val_accuracy: 0.3380\n",
            "Epoch 3644/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 3.7307 - val_accuracy: 0.3402\n",
            "Epoch 3645/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2508 - accuracy: 0.9900 - val_loss: 3.7686 - val_accuracy: 0.3430\n",
            "Epoch 3646/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2470 - accuracy: 0.9950 - val_loss: 3.7635 - val_accuracy: 0.3453\n",
            "Epoch 3647/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2672 - accuracy: 0.9850 - val_loss: 3.4399 - val_accuracy: 0.3666\n",
            "Epoch 3648/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2610 - accuracy: 0.9900 - val_loss: 3.6712 - val_accuracy: 0.3569\n",
            "Epoch 3649/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2382 - accuracy: 1.0000 - val_loss: 3.7629 - val_accuracy: 0.3500\n",
            "Epoch 3650/6000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2510 - accuracy: 0.9900 - val_loss: 3.7126 - val_accuracy: 0.3577\n",
            "Epoch 3651/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2473 - accuracy: 0.9950 - val_loss: 3.6157 - val_accuracy: 0.3618\n",
            "Epoch 3652/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2374 - accuracy: 0.9950 - val_loss: 3.5901 - val_accuracy: 0.3630\n",
            "Epoch 3653/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2630 - accuracy: 0.9950 - val_loss: 4.2747 - val_accuracy: 0.3188\n",
            "Epoch 3654/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2786 - accuracy: 0.9950 - val_loss: 3.9756 - val_accuracy: 0.3367\n",
            "Epoch 3655/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2512 - accuracy: 1.0000 - val_loss: 3.6793 - val_accuracy: 0.3473\n",
            "Epoch 3656/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2381 - accuracy: 0.9950 - val_loss: 3.7108 - val_accuracy: 0.3455\n",
            "Epoch 3657/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2556 - accuracy: 0.9900 - val_loss: 3.4404 - val_accuracy: 0.3458\n",
            "Epoch 3658/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2436 - accuracy: 0.9900 - val_loss: 3.4560 - val_accuracy: 0.3422\n",
            "Epoch 3659/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2474 - accuracy: 0.9950 - val_loss: 3.4658 - val_accuracy: 0.3504\n",
            "Epoch 3660/6000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2389 - accuracy: 1.0000 - val_loss: 3.4616 - val_accuracy: 0.3500\n",
            "Epoch 3661/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2388 - accuracy: 0.9900 - val_loss: 3.5354 - val_accuracy: 0.3436\n",
            "Epoch 3662/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2440 - accuracy: 0.9950 - val_loss: 3.5147 - val_accuracy: 0.3544\n",
            "Epoch 3663/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2590 - accuracy: 0.9950 - val_loss: 3.7736 - val_accuracy: 0.3301\n",
            "Epoch 3664/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2633 - accuracy: 0.9900 - val_loss: 3.3843 - val_accuracy: 0.3710\n",
            "Epoch 3665/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2510 - accuracy: 0.9950 - val_loss: 3.3396 - val_accuracy: 0.3696\n",
            "Epoch 3666/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2468 - accuracy: 0.9950 - val_loss: 3.3409 - val_accuracy: 0.3712\n",
            "Epoch 3667/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2327 - accuracy: 1.0000 - val_loss: 3.3679 - val_accuracy: 0.3688\n",
            "Epoch 3668/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2539 - accuracy: 0.9900 - val_loss: 3.4730 - val_accuracy: 0.3648\n",
            "Epoch 3669/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2580 - accuracy: 0.9950 - val_loss: 4.0786 - val_accuracy: 0.3176\n",
            "Epoch 3670/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2665 - accuracy: 0.9850 - val_loss: 3.8303 - val_accuracy: 0.3493\n",
            "Epoch 3671/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2611 - accuracy: 0.9850 - val_loss: 4.1082 - val_accuracy: 0.3267\n",
            "Epoch 3672/6000\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2408 - accuracy: 0.9950 - val_loss: 3.9698 - val_accuracy: 0.3360\n",
            "Epoch 3673/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3194 - accuracy: 0.9750 - val_loss: 3.4234 - val_accuracy: 0.3566\n",
            "Epoch 3674/6000\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2398 - accuracy: 0.9950 - val_loss: 3.5762 - val_accuracy: 0.3374\n",
            "Epoch 3675/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2443 - accuracy: 1.0000 - val_loss: 3.3958 - val_accuracy: 0.3489\n",
            "Epoch 3676/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2449 - accuracy: 0.9950 - val_loss: 3.4028 - val_accuracy: 0.3515\n",
            "Epoch 3677/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2642 - accuracy: 0.9900 - val_loss: 3.5150 - val_accuracy: 0.3486\n",
            "Epoch 3678/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2476 - accuracy: 0.9950 - val_loss: 3.4982 - val_accuracy: 0.3516\n",
            "Epoch 3679/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2502 - accuracy: 0.9900 - val_loss: 3.6253 - val_accuracy: 0.3431\n",
            "Epoch 3680/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2664 - accuracy: 0.9800 - val_loss: 3.5779 - val_accuracy: 0.3467\n",
            "Epoch 3681/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2728 - accuracy: 0.9850 - val_loss: 3.4145 - val_accuracy: 0.3630\n",
            "Epoch 3682/6000\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 3.4489 - val_accuracy: 0.3660\n",
            "Epoch 3683/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2450 - accuracy: 0.9900 - val_loss: 3.4590 - val_accuracy: 0.3596\n",
            "Epoch 3684/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2392 - accuracy: 1.0000 - val_loss: 3.5262 - val_accuracy: 0.3511\n",
            "Epoch 3685/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2523 - accuracy: 0.9900 - val_loss: 3.5257 - val_accuracy: 0.3573\n",
            "Epoch 3686/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2440 - accuracy: 0.9950 - val_loss: 3.5055 - val_accuracy: 0.3520\n",
            "Epoch 3687/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2346 - accuracy: 1.0000 - val_loss: 3.5148 - val_accuracy: 0.3512\n",
            "Epoch 3688/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2498 - accuracy: 0.9950 - val_loss: 3.5647 - val_accuracy: 0.3454\n",
            "Epoch 3689/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2519 - accuracy: 0.9900 - val_loss: 3.6116 - val_accuracy: 0.3445\n",
            "Epoch 3690/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2458 - accuracy: 0.9950 - val_loss: 3.6685 - val_accuracy: 0.3381\n",
            "Epoch 3691/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2583 - accuracy: 0.9850 - val_loss: 3.9147 - val_accuracy: 0.3272\n",
            "Epoch 3692/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2391 - accuracy: 0.9950 - val_loss: 4.0378 - val_accuracy: 0.3207\n",
            "Epoch 3693/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2467 - accuracy: 0.9950 - val_loss: 4.1156 - val_accuracy: 0.3120\n",
            "Epoch 3694/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2599 - accuracy: 0.9900 - val_loss: 3.8813 - val_accuracy: 0.3271\n",
            "Epoch 3695/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2483 - accuracy: 0.9950 - val_loss: 3.9638 - val_accuracy: 0.3229\n",
            "Epoch 3696/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 3.8429 - val_accuracy: 0.3305\n",
            "Epoch 3697/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 3.6537 - val_accuracy: 0.3427\n",
            "Epoch 3698/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2483 - accuracy: 0.9950 - val_loss: 3.5298 - val_accuracy: 0.3516\n",
            "Epoch 3699/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 3.5062 - val_accuracy: 0.3533\n",
            "Epoch 3700/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2521 - accuracy: 0.9900 - val_loss: 3.6079 - val_accuracy: 0.3392\n",
            "Epoch 3701/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2436 - accuracy: 0.9950 - val_loss: 3.6379 - val_accuracy: 0.3372\n",
            "Epoch 3702/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 3.6300 - val_accuracy: 0.3375\n",
            "Epoch 3703/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2403 - accuracy: 0.9950 - val_loss: 3.6822 - val_accuracy: 0.3351\n",
            "Epoch 3704/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 3.7205 - val_accuracy: 0.3319\n",
            "Epoch 3705/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2791 - accuracy: 0.9850 - val_loss: 3.5587 - val_accuracy: 0.3487\n",
            "Epoch 3706/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 3.5985 - val_accuracy: 0.3491\n",
            "Epoch 3707/6000\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 3.6175 - val_accuracy: 0.3465\n",
            "Epoch 3708/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.6501 - val_accuracy: 0.3423\n",
            "Epoch 3709/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2351 - accuracy: 1.0000 - val_loss: 3.6996 - val_accuracy: 0.3368\n",
            "Epoch 3710/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2498 - accuracy: 0.9950 - val_loss: 3.7621 - val_accuracy: 0.3350\n",
            "Epoch 3711/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 3.7475 - val_accuracy: 0.3394\n",
            "Epoch 3712/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2469 - accuracy: 0.9950 - val_loss: 4.3391 - val_accuracy: 0.2925\n",
            "Epoch 3713/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2367 - accuracy: 1.0000 - val_loss: 4.3512 - val_accuracy: 0.2903\n",
            "Epoch 3714/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 4.4080 - val_accuracy: 0.2854\n",
            "Epoch 3715/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 4.2051 - val_accuracy: 0.3028\n",
            "Epoch 3716/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2305 - accuracy: 1.0000 - val_loss: 4.2230 - val_accuracy: 0.3021\n",
            "Epoch 3717/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2303 - accuracy: 1.0000 - val_loss: 4.2077 - val_accuracy: 0.3022\n",
            "Epoch 3718/6000\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2515 - accuracy: 0.9900 - val_loss: 4.4906 - val_accuracy: 0.2821\n",
            "Epoch 3719/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2360 - accuracy: 0.9950 - val_loss: 4.2229 - val_accuracy: 0.2956\n",
            "Epoch 3720/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 4.3614 - val_accuracy: 0.2871\n",
            "Epoch 3721/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2334 - accuracy: 1.0000 - val_loss: 4.1530 - val_accuracy: 0.2988\n",
            "Epoch 3722/6000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2305 - accuracy: 1.0000 - val_loss: 4.0932 - val_accuracy: 0.2996\n",
            "Epoch 3723/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2483 - accuracy: 0.9950 - val_loss: 4.0091 - val_accuracy: 0.2975\n",
            "Epoch 3724/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2579 - accuracy: 0.9900 - val_loss: 4.3696 - val_accuracy: 0.2839\n",
            "Epoch 3725/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2331 - accuracy: 1.0000 - val_loss: 4.2942 - val_accuracy: 0.2877\n",
            "Epoch 3726/6000\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.2530 - accuracy: 0.9850 - val_loss: 3.7828 - val_accuracy: 0.3268\n",
            "Epoch 3727/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2514 - accuracy: 0.9950 - val_loss: 3.7277 - val_accuracy: 0.3293\n",
            "Epoch 3728/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 3.7009 - val_accuracy: 0.3328\n",
            "Epoch 3729/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2263 - accuracy: 1.0000 - val_loss: 3.6924 - val_accuracy: 0.3317\n",
            "Epoch 3730/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2314 - accuracy: 1.0000 - val_loss: 3.8353 - val_accuracy: 0.3206\n",
            "Epoch 3731/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2339 - accuracy: 0.9950 - val_loss: 4.0169 - val_accuracy: 0.3056\n",
            "Epoch 3732/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 3.8291 - val_accuracy: 0.3151\n",
            "Epoch 3733/6000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2324 - accuracy: 0.9950 - val_loss: 3.7991 - val_accuracy: 0.3166\n",
            "Epoch 3734/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2245 - accuracy: 1.0000 - val_loss: 3.8085 - val_accuracy: 0.3146\n",
            "Epoch 3735/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2278 - accuracy: 1.0000 - val_loss: 3.7464 - val_accuracy: 0.3166\n",
            "Epoch 3736/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2580 - accuracy: 0.9900 - val_loss: 3.5488 - val_accuracy: 0.3405\n",
            "Epoch 3737/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2371 - accuracy: 0.9950 - val_loss: 3.4855 - val_accuracy: 0.3499\n",
            "Epoch 3738/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2248 - accuracy: 1.0000 - val_loss: 3.5017 - val_accuracy: 0.3446\n",
            "Epoch 3739/6000\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2345 - accuracy: 0.9950 - val_loss: 3.4240 - val_accuracy: 0.3484\n",
            "Epoch 3740/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2376 - accuracy: 0.9900 - val_loss: 3.5789 - val_accuracy: 0.3257\n",
            "Epoch 3741/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2253 - accuracy: 1.0000 - val_loss: 3.5297 - val_accuracy: 0.3290\n",
            "Epoch 3742/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2259 - accuracy: 1.0000 - val_loss: 3.5615 - val_accuracy: 0.3268\n",
            "Epoch 3743/6000\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2512 - accuracy: 0.9900 - val_loss: 3.2833 - val_accuracy: 0.3636\n",
            "Epoch 3744/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2302 - accuracy: 0.9950 - val_loss: 3.5360 - val_accuracy: 0.3317\n",
            "Epoch 3745/6000\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 3.2859 - val_accuracy: 0.3691\n",
            "Epoch 3746/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2333 - accuracy: 0.9950 - val_loss: 3.1213 - val_accuracy: 0.3813\n",
            "Epoch 3747/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2385 - accuracy: 0.9950 - val_loss: 3.1152 - val_accuracy: 0.3842\n",
            "Epoch 3748/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2478 - accuracy: 0.9900 - val_loss: 3.4728 - val_accuracy: 0.3429\n",
            "Epoch 3749/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2344 - accuracy: 0.9950 - val_loss: 3.3800 - val_accuracy: 0.3540\n",
            "Epoch 3750/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2258 - accuracy: 1.0000 - val_loss: 3.3463 - val_accuracy: 0.3568\n",
            "Epoch 3751/6000\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.2375 - accuracy: 0.9900 - val_loss: 3.3472 - val_accuracy: 0.3605\n",
            "Epoch 3752/6000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.2464 - accuracy: 0.9950 - val_loss: 3.6736 - val_accuracy: 0.3229\n",
            "Epoch 3753/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2568 - accuracy: 0.9950 - val_loss: 3.4018 - val_accuracy: 0.3487\n",
            "Epoch 3754/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2379 - accuracy: 0.9900 - val_loss: 3.4183 - val_accuracy: 0.3446\n",
            "Epoch 3755/6000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2312 - accuracy: 0.9950 - val_loss: 3.5058 - val_accuracy: 0.3347\n",
            "Epoch 3756/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2234 - accuracy: 1.0000 - val_loss: 3.4869 - val_accuracy: 0.3372\n",
            "Epoch 3757/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2336 - accuracy: 0.9950 - val_loss: 3.4815 - val_accuracy: 0.3429\n",
            "Epoch 3758/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2468 - accuracy: 0.9800 - val_loss: 3.4150 - val_accuracy: 0.3538\n",
            "Epoch 3759/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2272 - accuracy: 0.9950 - val_loss: 3.5187 - val_accuracy: 0.3365\n",
            "Epoch 3760/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 3.4311 - val_accuracy: 0.3426\n",
            "Epoch 3761/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2377 - accuracy: 0.9950 - val_loss: 3.3742 - val_accuracy: 0.3518\n",
            "Epoch 3762/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2598 - accuracy: 0.9900 - val_loss: 3.2779 - val_accuracy: 0.3643\n",
            "Epoch 3763/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 3.2967 - val_accuracy: 0.3605\n",
            "Epoch 3764/6000\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 3.2942 - val_accuracy: 0.3603\n",
            "Epoch 3765/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2221 - accuracy: 1.0000 - val_loss: 3.3028 - val_accuracy: 0.3625\n",
            "Epoch 3766/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2241 - accuracy: 1.0000 - val_loss: 3.4023 - val_accuracy: 0.3526\n",
            "Epoch 3767/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 3.4250 - val_accuracy: 0.3496\n",
            "Epoch 3768/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2363 - accuracy: 0.9950 - val_loss: 3.3497 - val_accuracy: 0.3610\n",
            "Epoch 3769/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2319 - accuracy: 0.9950 - val_loss: 3.3442 - val_accuracy: 0.3558\n",
            "Epoch 3770/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2308 - accuracy: 0.9950 - val_loss: 3.2793 - val_accuracy: 0.3549\n",
            "Epoch 3771/6000\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.2214 - accuracy: 1.0000 - val_loss: 3.2862 - val_accuracy: 0.3535\n",
            "Epoch 3772/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2332 - accuracy: 0.9950 - val_loss: 3.2672 - val_accuracy: 0.3562\n",
            "Epoch 3773/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 3.2476 - val_accuracy: 0.3573\n",
            "Epoch 3774/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2540 - accuracy: 0.9850 - val_loss: 3.2425 - val_accuracy: 0.3552\n",
            "Epoch 3775/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2390 - accuracy: 0.9850 - val_loss: 3.3216 - val_accuracy: 0.3487\n",
            "Epoch 3776/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2292 - accuracy: 0.9950 - val_loss: 3.5254 - val_accuracy: 0.3397\n",
            "Epoch 3777/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2503 - accuracy: 0.9900 - val_loss: 4.4479 - val_accuracy: 0.2748\n",
            "Epoch 3778/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2507 - accuracy: 0.9850 - val_loss: 4.1524 - val_accuracy: 0.2901\n",
            "Epoch 3779/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2251 - accuracy: 1.0000 - val_loss: 4.1335 - val_accuracy: 0.2904\n",
            "Epoch 3780/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2262 - accuracy: 1.0000 - val_loss: 4.2075 - val_accuracy: 0.2867\n",
            "Epoch 3781/6000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2233 - accuracy: 1.0000 - val_loss: 3.9984 - val_accuracy: 0.2984\n",
            "Epoch 3782/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2512 - accuracy: 0.9850 - val_loss: 4.0762 - val_accuracy: 0.2982\n",
            "Epoch 3783/6000\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2369 - accuracy: 0.9950 - val_loss: 3.6894 - val_accuracy: 0.3320\n",
            "Epoch 3784/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2502 - accuracy: 0.9900 - val_loss: 3.4384 - val_accuracy: 0.3771\n",
            "Epoch 3785/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2266 - accuracy: 0.9950 - val_loss: 3.3746 - val_accuracy: 0.3802\n",
            "Epoch 3786/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2223 - accuracy: 1.0000 - val_loss: 3.3756 - val_accuracy: 0.3808\n",
            "Epoch 3787/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2209 - accuracy: 1.0000 - val_loss: 3.3761 - val_accuracy: 0.3812\n",
            "Epoch 3788/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2469 - accuracy: 0.9900 - val_loss: 3.3318 - val_accuracy: 0.3817\n",
            "Epoch 3789/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2215 - accuracy: 1.0000 - val_loss: 3.3142 - val_accuracy: 0.3830\n",
            "Epoch 3790/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2408 - accuracy: 0.9900 - val_loss: 3.2943 - val_accuracy: 0.3830\n",
            "Epoch 3791/6000\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2381 - accuracy: 0.9950 - val_loss: 3.2846 - val_accuracy: 0.3802\n",
            "Epoch 3792/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2377 - accuracy: 0.9950 - val_loss: 3.2780 - val_accuracy: 0.3812\n",
            "Epoch 3793/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2432 - accuracy: 0.9850 - val_loss: 3.2558 - val_accuracy: 0.3856\n",
            "Epoch 3794/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2549 - accuracy: 0.9900 - val_loss: 3.4055 - val_accuracy: 0.3631\n",
            "Epoch 3795/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2404 - accuracy: 0.9850 - val_loss: 3.7350 - val_accuracy: 0.3413\n",
            "Epoch 3796/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2257 - accuracy: 1.0000 - val_loss: 3.6947 - val_accuracy: 0.3446\n",
            "Epoch 3797/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2252 - accuracy: 1.0000 - val_loss: 3.6218 - val_accuracy: 0.3492\n",
            "Epoch 3798/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2231 - accuracy: 1.0000 - val_loss: 3.6463 - val_accuracy: 0.3455\n",
            "Epoch 3799/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2613 - accuracy: 0.9750 - val_loss: 4.3468 - val_accuracy: 0.2988\n",
            "Epoch 3800/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2207 - accuracy: 1.0000 - val_loss: 4.6585 - val_accuracy: 0.2779\n",
            "Epoch 3801/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2732 - accuracy: 0.9850 - val_loss: 3.6704 - val_accuracy: 0.3452\n",
            "Epoch 3802/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2276 - accuracy: 0.9950 - val_loss: 3.6153 - val_accuracy: 0.3493\n",
            "Epoch 3803/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2300 - accuracy: 1.0000 - val_loss: 3.8142 - val_accuracy: 0.3315\n",
            "Epoch 3804/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2751 - accuracy: 0.9800 - val_loss: 3.5619 - val_accuracy: 0.3507\n",
            "Epoch 3805/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2349 - accuracy: 0.9900 - val_loss: 3.3224 - val_accuracy: 0.3644\n",
            "Epoch 3806/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2384 - accuracy: 0.9900 - val_loss: 3.4172 - val_accuracy: 0.3607\n",
            "Epoch 3807/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2418 - accuracy: 0.9950 - val_loss: 3.5553 - val_accuracy: 0.3534\n",
            "Epoch 3808/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2347 - accuracy: 0.9950 - val_loss: 3.5444 - val_accuracy: 0.3503\n",
            "Epoch 3809/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2396 - accuracy: 0.9900 - val_loss: 3.3872 - val_accuracy: 0.3566\n",
            "Epoch 3810/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2341 - accuracy: 0.9900 - val_loss: 3.4516 - val_accuracy: 0.3529\n",
            "Epoch 3811/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2344 - accuracy: 0.9950 - val_loss: 3.5360 - val_accuracy: 0.3460\n",
            "Epoch 3812/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2414 - accuracy: 0.9900 - val_loss: 3.6329 - val_accuracy: 0.3372\n",
            "Epoch 3813/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2232 - accuracy: 1.0000 - val_loss: 3.6411 - val_accuracy: 0.3352\n",
            "Epoch 3814/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2370 - accuracy: 0.9950 - val_loss: 3.9082 - val_accuracy: 0.3113\n",
            "Epoch 3815/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2285 - accuracy: 0.9950 - val_loss: 4.2126 - val_accuracy: 0.2901\n",
            "Epoch 3816/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2239 - accuracy: 1.0000 - val_loss: 4.3140 - val_accuracy: 0.2817\n",
            "Epoch 3817/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2655 - accuracy: 0.9850 - val_loss: 4.0810 - val_accuracy: 0.2944\n",
            "Epoch 3818/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2345 - accuracy: 0.9950 - val_loss: 4.0849 - val_accuracy: 0.2951\n",
            "Epoch 3819/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2277 - accuracy: 1.0000 - val_loss: 3.9056 - val_accuracy: 0.3087\n",
            "Epoch 3820/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2244 - accuracy: 1.0000 - val_loss: 3.9369 - val_accuracy: 0.3066\n",
            "Epoch 3821/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2382 - accuracy: 0.9950 - val_loss: 3.9909 - val_accuracy: 0.3072\n",
            "Epoch 3822/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2303 - accuracy: 0.9950 - val_loss: 4.0907 - val_accuracy: 0.2960\n",
            "Epoch 3823/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2225 - accuracy: 1.0000 - val_loss: 4.0711 - val_accuracy: 0.2980\n",
            "Epoch 3824/6000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 4.0451 - val_accuracy: 0.3029\n",
            "Epoch 3825/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2263 - accuracy: 0.9950 - val_loss: 3.8021 - val_accuracy: 0.3258\n",
            "Epoch 3826/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2385 - accuracy: 0.9900 - val_loss: 3.9258 - val_accuracy: 0.3053\n",
            "Epoch 3827/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2508 - accuracy: 0.9950 - val_loss: 3.6964 - val_accuracy: 0.3201\n",
            "Epoch 3828/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2332 - accuracy: 0.9900 - val_loss: 4.1116 - val_accuracy: 0.3016\n",
            "Epoch 3829/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2349 - accuracy: 0.9950 - val_loss: 4.3357 - val_accuracy: 0.2795\n",
            "Epoch 3830/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2382 - accuracy: 0.9950 - val_loss: 4.8420 - val_accuracy: 0.2661\n",
            "Epoch 3831/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2539 - accuracy: 0.9900 - val_loss: 5.6781 - val_accuracy: 0.2268\n",
            "Epoch 3832/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2566 - accuracy: 0.9900 - val_loss: 4.8938 - val_accuracy: 0.2682\n",
            "Epoch 3833/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 4.6960 - val_accuracy: 0.2800\n",
            "Epoch 3834/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2409 - accuracy: 0.9950 - val_loss: 3.5718 - val_accuracy: 0.3503\n",
            "Epoch 3835/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2424 - accuracy: 0.9850 - val_loss: 3.4102 - val_accuracy: 0.3723\n",
            "Epoch 3836/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2317 - accuracy: 1.0000 - val_loss: 3.2924 - val_accuracy: 0.3810\n",
            "Epoch 3837/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2428 - accuracy: 0.9900 - val_loss: 3.3978 - val_accuracy: 0.3823\n",
            "Epoch 3838/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2853 - accuracy: 0.9900 - val_loss: 3.6782 - val_accuracy: 0.3454\n",
            "Epoch 3839/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2603 - accuracy: 0.9950 - val_loss: 3.4964 - val_accuracy: 0.3532\n",
            "Epoch 3840/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2553 - accuracy: 0.9950 - val_loss: 3.5655 - val_accuracy: 0.3446\n",
            "Epoch 3841/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2233 - accuracy: 1.0000 - val_loss: 3.6287 - val_accuracy: 0.3351\n",
            "Epoch 3842/6000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2310 - accuracy: 0.9950 - val_loss: 3.6582 - val_accuracy: 0.3323\n",
            "Epoch 3843/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 3.5828 - val_accuracy: 0.3451\n",
            "Epoch 3844/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2434 - accuracy: 0.9950 - val_loss: 3.8017 - val_accuracy: 0.3247\n",
            "Epoch 3845/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2576 - accuracy: 0.9950 - val_loss: 3.5524 - val_accuracy: 0.3461\n",
            "Epoch 3846/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2489 - accuracy: 0.9850 - val_loss: 4.2688 - val_accuracy: 0.2822\n",
            "Epoch 3847/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2278 - accuracy: 1.0000 - val_loss: 4.2045 - val_accuracy: 0.2873\n",
            "Epoch 3848/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2302 - accuracy: 0.9950 - val_loss: 4.2850 - val_accuracy: 0.2802\n",
            "Epoch 3849/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2333 - accuracy: 1.0000 - val_loss: 4.1441 - val_accuracy: 0.2885\n",
            "Epoch 3850/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2379 - accuracy: 0.9900 - val_loss: 4.2958 - val_accuracy: 0.2787\n",
            "Epoch 3851/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2357 - accuracy: 0.9950 - val_loss: 4.5167 - val_accuracy: 0.2640\n",
            "Epoch 3852/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2406 - accuracy: 0.9900 - val_loss: 4.7214 - val_accuracy: 0.2505\n",
            "Epoch 3853/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2504 - accuracy: 0.9850 - val_loss: 4.5229 - val_accuracy: 0.2594\n",
            "Epoch 3854/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2273 - accuracy: 1.0000 - val_loss: 4.5398 - val_accuracy: 0.2565\n",
            "Epoch 3855/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2522 - accuracy: 0.9900 - val_loss: 4.5328 - val_accuracy: 0.2581\n",
            "Epoch 3856/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2443 - accuracy: 0.9900 - val_loss: 4.2880 - val_accuracy: 0.2733\n",
            "Epoch 3857/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2490 - accuracy: 0.9900 - val_loss: 3.5920 - val_accuracy: 0.3362\n",
            "Epoch 3858/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2525 - accuracy: 0.9850 - val_loss: 4.0543 - val_accuracy: 0.3167\n",
            "Epoch 3859/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2398 - accuracy: 0.9900 - val_loss: 4.1307 - val_accuracy: 0.3140\n",
            "Epoch 3860/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2332 - accuracy: 0.9900 - val_loss: 3.8529 - val_accuracy: 0.3355\n",
            "Epoch 3861/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2379 - accuracy: 0.9950 - val_loss: 3.7616 - val_accuracy: 0.3311\n",
            "Epoch 3862/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2478 - accuracy: 0.9950 - val_loss: 3.7388 - val_accuracy: 0.3316\n",
            "Epoch 3863/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2308 - accuracy: 0.9950 - val_loss: 3.5226 - val_accuracy: 0.3489\n",
            "Epoch 3864/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2550 - accuracy: 0.9950 - val_loss: 3.4370 - val_accuracy: 0.3548\n",
            "Epoch 3865/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2445 - accuracy: 0.9900 - val_loss: 3.5090 - val_accuracy: 0.3498\n",
            "Epoch 3866/6000\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2527 - accuracy: 0.9950 - val_loss: 3.7584 - val_accuracy: 0.3270\n",
            "Epoch 3867/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2378 - accuracy: 1.0000 - val_loss: 3.6479 - val_accuracy: 0.3363\n",
            "Epoch 3868/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 3.6189 - val_accuracy: 0.3377\n",
            "Epoch 3869/6000\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2419 - accuracy: 0.9950 - val_loss: 3.7051 - val_accuracy: 0.3373\n",
            "Epoch 3870/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2491 - accuracy: 0.9900 - val_loss: 3.7566 - val_accuracy: 0.3339\n",
            "Epoch 3871/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2694 - accuracy: 0.9800 - val_loss: 3.8825 - val_accuracy: 0.3148\n",
            "Epoch 3872/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 3.8137 - val_accuracy: 0.3222\n",
            "Epoch 3873/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2602 - accuracy: 0.9850 - val_loss: 3.7461 - val_accuracy: 0.3250\n",
            "Epoch 3874/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2424 - accuracy: 0.9950 - val_loss: 3.5340 - val_accuracy: 0.3447\n",
            "Epoch 3875/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2283 - accuracy: 1.0000 - val_loss: 3.4976 - val_accuracy: 0.3493\n",
            "Epoch 3876/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2768 - accuracy: 0.9900 - val_loss: 3.6293 - val_accuracy: 0.3488\n",
            "Epoch 3877/6000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2502 - accuracy: 0.9900 - val_loss: 3.6514 - val_accuracy: 0.3507\n",
            "Epoch 3878/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2317 - accuracy: 0.9950 - val_loss: 3.6702 - val_accuracy: 0.3475\n",
            "Epoch 3879/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2675 - accuracy: 0.9850 - val_loss: 4.1524 - val_accuracy: 0.3068\n",
            "Epoch 3880/6000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2751 - accuracy: 0.9850 - val_loss: 3.7145 - val_accuracy: 0.3426\n",
            "Epoch 3881/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2497 - accuracy: 0.9900 - val_loss: 4.2527 - val_accuracy: 0.3188\n",
            "Epoch 3882/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2539 - accuracy: 0.9950 - val_loss: 4.8003 - val_accuracy: 0.2845\n",
            "Epoch 3883/6000\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2392 - accuracy: 0.9950 - val_loss: 4.6564 - val_accuracy: 0.2972\n",
            "Epoch 3884/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2508 - accuracy: 0.9900 - val_loss: 4.5174 - val_accuracy: 0.2819\n",
            "Epoch 3885/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2564 - accuracy: 0.9850 - val_loss: 4.8186 - val_accuracy: 0.2694\n",
            "Epoch 3886/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2310 - accuracy: 1.0000 - val_loss: 4.7367 - val_accuracy: 0.2723\n",
            "Epoch 3887/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2827 - accuracy: 0.9800 - val_loss: 3.7627 - val_accuracy: 0.3229\n",
            "Epoch 3888/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2451 - accuracy: 0.9900 - val_loss: 3.9263 - val_accuracy: 0.3206\n",
            "Epoch 3889/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 3.7389 - val_accuracy: 0.3259\n",
            "Epoch 3890/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2435 - accuracy: 0.9950 - val_loss: 3.6181 - val_accuracy: 0.3273\n",
            "Epoch 3891/6000\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.2439 - accuracy: 1.0000 - val_loss: 3.5948 - val_accuracy: 0.3320\n",
            "Epoch 3892/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2383 - accuracy: 0.9950 - val_loss: 3.7137 - val_accuracy: 0.3330\n",
            "Epoch 3893/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2458 - accuracy: 0.9950 - val_loss: 3.8564 - val_accuracy: 0.3273\n",
            "Epoch 3894/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2495 - accuracy: 0.9900 - val_loss: 3.6970 - val_accuracy: 0.3338\n",
            "Epoch 3895/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2394 - accuracy: 1.0000 - val_loss: 3.5632 - val_accuracy: 0.3427\n",
            "Epoch 3896/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2427 - accuracy: 1.0000 - val_loss: 3.5712 - val_accuracy: 0.3379\n",
            "Epoch 3897/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2670 - accuracy: 0.9850 - val_loss: 3.3055 - val_accuracy: 0.3459\n",
            "Epoch 3898/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2612 - accuracy: 0.9900 - val_loss: 3.5490 - val_accuracy: 0.3311\n",
            "Epoch 3899/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2320 - accuracy: 1.0000 - val_loss: 3.5546 - val_accuracy: 0.3298\n",
            "Epoch 3900/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2838 - accuracy: 0.9750 - val_loss: 3.6497 - val_accuracy: 0.3302\n",
            "Epoch 3901/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2441 - accuracy: 0.9950 - val_loss: 4.0291 - val_accuracy: 0.3139\n",
            "Epoch 3902/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2533 - accuracy: 0.9850 - val_loss: 3.8781 - val_accuracy: 0.3312\n",
            "Epoch 3903/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2450 - accuracy: 0.9950 - val_loss: 4.1316 - val_accuracy: 0.3110\n",
            "Epoch 3904/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2870 - accuracy: 0.9700 - val_loss: 3.1286 - val_accuracy: 0.3745\n",
            "Epoch 3905/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2592 - accuracy: 0.9900 - val_loss: 3.3327 - val_accuracy: 0.3610\n",
            "Epoch 3906/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2521 - accuracy: 0.9950 - val_loss: 3.2700 - val_accuracy: 0.3690\n",
            "Epoch 3907/6000\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2564 - accuracy: 0.9900 - val_loss: 3.3907 - val_accuracy: 0.3490\n",
            "Epoch 3908/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 3.2395 - val_accuracy: 0.3620\n",
            "Epoch 3909/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2641 - accuracy: 0.9800 - val_loss: 3.2545 - val_accuracy: 0.3641\n",
            "Epoch 3910/6000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 3.1973 - val_accuracy: 0.3684\n",
            "Epoch 3911/6000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2746 - accuracy: 0.9850 - val_loss: 3.2620 - val_accuracy: 0.3543\n",
            "Epoch 3912/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2449 - accuracy: 1.0000 - val_loss: 3.1455 - val_accuracy: 0.3631\n",
            "Epoch 3913/6000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2469 - accuracy: 1.0000 - val_loss: 3.0842 - val_accuracy: 0.3737\n",
            "Epoch 3914/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2462 - accuracy: 1.0000 - val_loss: 3.0618 - val_accuracy: 0.3698\n",
            "Epoch 3915/6000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2567 - accuracy: 0.9900 - val_loss: 3.0246 - val_accuracy: 0.3736\n",
            "Epoch 3916/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2550 - accuracy: 0.9900 - val_loss: 3.0290 - val_accuracy: 0.3775\n",
            "Epoch 3917/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2821 - accuracy: 0.9800 - val_loss: 3.2001 - val_accuracy: 0.3653\n",
            "Epoch 3918/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2415 - accuracy: 1.0000 - val_loss: 3.1068 - val_accuracy: 0.3734\n",
            "Epoch 3919/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2592 - accuracy: 0.9950 - val_loss: 3.2668 - val_accuracy: 0.3561\n",
            "Epoch 3920/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2609 - accuracy: 0.9900 - val_loss: 3.1724 - val_accuracy: 0.3677\n",
            "Epoch 3921/6000\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2525 - accuracy: 0.9850 - val_loss: 3.1643 - val_accuracy: 0.3681\n",
            "Epoch 3922/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2792 - accuracy: 0.9800 - val_loss: 3.1639 - val_accuracy: 0.3758\n",
            "Epoch 3923/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2925 - accuracy: 0.9750 - val_loss: 3.5247 - val_accuracy: 0.3594\n",
            "Epoch 3924/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2449 - accuracy: 0.9950 - val_loss: 3.5784 - val_accuracy: 0.3628\n",
            "Epoch 3925/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2425 - accuracy: 0.9950 - val_loss: 3.7420 - val_accuracy: 0.3500\n",
            "Epoch 3926/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2641 - accuracy: 0.9900 - val_loss: 3.7272 - val_accuracy: 0.3600\n",
            "Epoch 3927/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2693 - accuracy: 0.9950 - val_loss: 3.8452 - val_accuracy: 0.3380\n",
            "Epoch 3928/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2557 - accuracy: 0.9900 - val_loss: 3.9482 - val_accuracy: 0.3301\n",
            "Epoch 3929/6000\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2644 - accuracy: 0.9900 - val_loss: 3.8733 - val_accuracy: 0.3419\n",
            "Epoch 3930/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 3.8344 - val_accuracy: 0.3433\n",
            "Epoch 3931/6000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2698 - accuracy: 0.9850 - val_loss: 4.2976 - val_accuracy: 0.3040\n",
            "Epoch 3932/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2596 - accuracy: 0.9900 - val_loss: 3.7267 - val_accuracy: 0.3552\n",
            "Epoch 3933/6000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 3.6588 - val_accuracy: 0.3560\n",
            "Epoch 3934/6000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2561 - accuracy: 0.9950 - val_loss: 3.6488 - val_accuracy: 0.3592\n",
            "Epoch 3935/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2694 - accuracy: 0.9900 - val_loss: 3.4884 - val_accuracy: 0.3770\n",
            "Epoch 3936/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2543 - accuracy: 0.9950 - val_loss: 3.4809 - val_accuracy: 0.3700\n",
            "Epoch 3937/6000\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 3.6230 - val_accuracy: 0.3672\n",
            "Epoch 3938/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 3.6508 - val_accuracy: 0.3671\n",
            "Epoch 3939/6000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 3.5969 - val_accuracy: 0.3592\n",
            "Epoch 3940/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 3.7319 - val_accuracy: 0.3498\n",
            "Epoch 3941/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2480 - accuracy: 0.9900 - val_loss: 3.7553 - val_accuracy: 0.3518\n",
            "Epoch 3942/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2533 - accuracy: 0.9900 - val_loss: 4.0916 - val_accuracy: 0.3379\n",
            "Epoch 3943/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2702 - accuracy: 0.9900 - val_loss: 4.2600 - val_accuracy: 0.3292\n",
            "Epoch 3944/6000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2488 - accuracy: 0.9950 - val_loss: 4.2986 - val_accuracy: 0.3280\n",
            "Epoch 3945/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2443 - accuracy: 1.0000 - val_loss: 4.0668 - val_accuracy: 0.3409\n",
            "Epoch 3946/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 3.4913 - val_accuracy: 0.3787\n",
            "Epoch 3947/6000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2507 - accuracy: 0.9950 - val_loss: 3.3872 - val_accuracy: 0.3835\n",
            "Epoch 3948/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2586 - accuracy: 0.9900 - val_loss: 3.2852 - val_accuracy: 0.3919\n",
            "Epoch 3949/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2495 - accuracy: 0.9900 - val_loss: 3.2764 - val_accuracy: 0.3913\n",
            "Epoch 3950/6000\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2581 - accuracy: 0.9850 - val_loss: 3.4397 - val_accuracy: 0.3822\n",
            "Epoch 3951/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 3.4756 - val_accuracy: 0.3805\n",
            "Epoch 3952/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2353 - accuracy: 1.0000 - val_loss: 3.5013 - val_accuracy: 0.3782\n",
            "Epoch 3953/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2763 - accuracy: 0.9800 - val_loss: 3.3452 - val_accuracy: 0.3896\n",
            "Epoch 3954/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2519 - accuracy: 0.9900 - val_loss: 3.3804 - val_accuracy: 0.3832\n",
            "Epoch 3955/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2483 - accuracy: 0.9950 - val_loss: 3.3353 - val_accuracy: 0.3822\n",
            "Epoch 3956/6000\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2540 - accuracy: 0.9950 - val_loss: 3.3921 - val_accuracy: 0.3710\n",
            "Epoch 3957/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 3.4196 - val_accuracy: 0.3653\n",
            "Epoch 3958/6000\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2479 - accuracy: 0.9950 - val_loss: 3.3659 - val_accuracy: 0.3704\n",
            "Epoch 3959/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2383 - accuracy: 1.0000 - val_loss: 3.3705 - val_accuracy: 0.3696\n",
            "Epoch 3960/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 3.4050 - val_accuracy: 0.3615\n",
            "Epoch 3961/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 3.3607 - val_accuracy: 0.3684\n",
            "Epoch 3962/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2471 - accuracy: 0.9950 - val_loss: 3.3461 - val_accuracy: 0.3683\n",
            "Epoch 3963/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2345 - accuracy: 1.0000 - val_loss: 3.3177 - val_accuracy: 0.3686\n",
            "Epoch 3964/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2505 - accuracy: 0.9900 - val_loss: 3.4497 - val_accuracy: 0.3616\n",
            "Epoch 3965/6000\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2479 - accuracy: 0.9950 - val_loss: 3.5435 - val_accuracy: 0.3493\n",
            "Epoch 3966/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2498 - accuracy: 0.9950 - val_loss: 3.3997 - val_accuracy: 0.3684\n",
            "Epoch 3967/6000\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 3.3703 - val_accuracy: 0.3721\n",
            "Epoch 3968/6000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2379 - accuracy: 0.9950 - val_loss: 3.3285 - val_accuracy: 0.3792\n",
            "Epoch 3969/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2702 - accuracy: 0.9900 - val_loss: 3.3466 - val_accuracy: 0.3771\n",
            "Epoch 3970/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2447 - accuracy: 0.9950 - val_loss: 3.4087 - val_accuracy: 0.3766\n",
            "Epoch 3971/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2354 - accuracy: 1.0000 - val_loss: 3.4417 - val_accuracy: 0.3729\n",
            "Epoch 3972/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2428 - accuracy: 0.9950 - val_loss: 3.3500 - val_accuracy: 0.3799\n",
            "Epoch 3973/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2571 - accuracy: 0.9900 - val_loss: 3.4916 - val_accuracy: 0.3700\n",
            "Epoch 3974/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2444 - accuracy: 0.9950 - val_loss: 3.5461 - val_accuracy: 0.3679\n",
            "Epoch 3975/6000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2415 - accuracy: 0.9950 - val_loss: 3.5663 - val_accuracy: 0.3658\n",
            "Epoch 3976/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2517 - accuracy: 0.9950 - val_loss: 3.4063 - val_accuracy: 0.3777\n",
            "Epoch 3977/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 3.3430 - val_accuracy: 0.3795\n",
            "Epoch 3978/6000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2456 - accuracy: 0.9950 - val_loss: 3.3401 - val_accuracy: 0.3833\n",
            "Epoch 3979/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2496 - accuracy: 0.9900 - val_loss: 3.3519 - val_accuracy: 0.3768\n",
            "Epoch 3980/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2360 - accuracy: 1.0000 - val_loss: 3.3396 - val_accuracy: 0.3760\n",
            "Epoch 3981/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2346 - accuracy: 1.0000 - val_loss: 3.3371 - val_accuracy: 0.3766\n",
            "Epoch 3982/6000\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2395 - accuracy: 1.0000 - val_loss: 3.3187 - val_accuracy: 0.3725\n",
            "Epoch 3983/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2337 - accuracy: 1.0000 - val_loss: 3.3163 - val_accuracy: 0.3726\n",
            "Epoch 3984/6000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 3.3043 - val_accuracy: 0.3683\n",
            "Epoch 3985/6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2393 - accuracy: 0.9900 - val_loss: 3.2632 - val_accuracy: 0.3740\n",
            "Epoch 3986/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 3.2648 - val_accuracy: 0.3723\n",
            "Epoch 3987/6000\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2415 - accuracy: 0.9950 - val_loss: 3.3319 - val_accuracy: 0.3710\n",
            "Epoch 3988/6000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 3.3234 - val_accuracy: 0.3755\n",
            "Epoch 3989/6000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2393 - accuracy: 0.9950 - val_loss: 3.3699 - val_accuracy: 0.3749\n",
            "Epoch 3990/6000\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2708 - accuracy: 0.9900 - val_loss: 3.4759 - val_accuracy: 0.3607\n",
            "Epoch 3991/6000\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2343 - accuracy: 1.0000 - val_loss: 3.4638 - val_accuracy: 0.3588\n",
            "Epoch 3992/6000\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 3.4176 - val_accuracy: 0.3608\n",
            "Epoch 3993/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2375 - accuracy: 1.0000 - val_loss: 3.3613 - val_accuracy: 0.3593\n",
            "Epoch 3994/6000\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.2481 - accuracy: 0.9850 - val_loss: 3.3685 - val_accuracy: 0.3605\n",
            "Epoch 3995/6000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2394 - accuracy: 0.9950 - val_loss: 3.3268 - val_accuracy: 0.3638\n",
            "Epoch 3996/6000\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2460 - accuracy: 0.9950 - val_loss: 3.3248 - val_accuracy: 0.3584\n",
            "Epoch 3997/6000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2396 - accuracy: 0.9950 - val_loss: 3.5139 - val_accuracy: 0.3432\n",
            "Epoch 3998/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2662 - accuracy: 0.9850 - val_loss: 3.6416 - val_accuracy: 0.3524\n",
            "Epoch 3999/6000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 3.7134 - val_accuracy: 0.3452\n",
            "Epoch 4000/6000\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.2512 - accuracy: 0.9900 - val_loss: 3.8476 - val_accuracy: 0.3342\n",
            "Epoch 4001/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2406 - accuracy: 0.9950 - val_loss: 3.7257 - val_accuracy: 0.3362\n",
            "Epoch 4002/6000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2428 - accuracy: 0.9950 - val_loss: 3.6991 - val_accuracy: 0.3401\n",
            "Epoch 4003/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2385 - accuracy: 0.9950 - val_loss: 3.5110 - val_accuracy: 0.3521\n",
            "Epoch 4004/6000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2361 - accuracy: 0.9950 - val_loss: 3.5897 - val_accuracy: 0.3521\n",
            "Epoch 4005/6000\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2553 - accuracy: 0.9950 - val_loss: 3.6312 - val_accuracy: 0.3466\n",
            "Epoch 4006/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2593 - accuracy: 0.9850 - val_loss: 3.7436 - val_accuracy: 0.3443\n",
            "Epoch 4007/6000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2518 - accuracy: 0.9950 - val_loss: 3.6325 - val_accuracy: 0.3480\n",
            "Epoch 4008/6000\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2300 - accuracy: 1.0000 - val_loss: 3.6236 - val_accuracy: 0.3457\n",
            "Epoch 4009/6000\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2361 - accuracy: 0.9950 - val_loss: 3.5678 - val_accuracy: 0.3463\n",
            "Epoch 4010/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2516 - accuracy: 0.9900 - val_loss: 3.3880 - val_accuracy: 0.3604\n",
            "Epoch 4011/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2418 - accuracy: 0.9950 - val_loss: 3.4611 - val_accuracy: 0.3550\n",
            "Epoch 4012/6000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2353 - accuracy: 1.0000 - val_loss: 3.3471 - val_accuracy: 0.3657\n",
            "Epoch 4013/6000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2375 - accuracy: 0.9950 - val_loss: 3.7354 - val_accuracy: 0.3206\n",
            "Epoch 4014/6000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2277 - accuracy: 1.0000 - val_loss: 3.8019 - val_accuracy: 0.3128\n",
            "Epoch 4015/6000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2605 - accuracy: 0.9900 - val_loss: 3.6972 - val_accuracy: 0.3272\n",
            "Epoch 4016/6000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2491 - accuracy: 0.9850 - val_loss: 3.8231 - val_accuracy: 0.3241\n",
            "Epoch 4017/6000\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2466 - accuracy: 0.9900 - val_loss: 3.8233 - val_accuracy: 0.3247\n",
            "Epoch 4018/6000\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2400 - accuracy: 0.9900 - val_loss: 3.8599 - val_accuracy: 0.3174\n",
            "Epoch 4019/6000\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2491 - accuracy: 0.9950 - val_loss: 3.9786 - val_accuracy: 0.3091\n",
            "Epoch 4020/6000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2386 - accuracy: 0.9950 - val_loss: 3.7969 - val_accuracy: 0.3270\n",
            "Epoch 4021/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2598 - accuracy: 0.9950 - val_loss: 3.8476 - val_accuracy: 0.3224\n",
            "Epoch 4022/6000\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2581 - accuracy: 0.9900 - val_loss: 3.5306 - val_accuracy: 0.3474\n",
            "Epoch 4023/6000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2441 - accuracy: 0.9950 - val_loss: 3.4089 - val_accuracy: 0.3546\n",
            "Epoch 4024/6000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2384 - accuracy: 0.9950 - val_loss: 3.3582 - val_accuracy: 0.3591\n",
            "Epoch 4025/6000\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2312 - accuracy: 1.0000 - val_loss: 3.3552 - val_accuracy: 0.3586\n",
            "Epoch 4026/6000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2469 - accuracy: 0.9950 - val_loss: 3.6891 - val_accuracy: 0.3362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "mfqpXUHc8RQc",
        "outputId": "2e587d4b-da61-4921-d2d4-ec503ad3f449"
      },
      "source": [
        "# show results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range((len(acc)))\n",
        "\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JM-zidSqC2f"
      },
      "source": [
        "# pretext task with unlabeld data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Eh0PTSw7Hi"
      },
      "source": [
        "## prepare data for pretext (Rotation Prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s15TSsEq5Isq"
      },
      "source": [
        "create rotated image and save them in directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw5Y3l19y1pO",
        "outputId": "3af5f0cb-eecf-4bc1-ce4e-2acba0ab3314"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "!mkdir train\n",
        "counter = 0\n",
        "\n",
        "!mkdir train/z_angle\n",
        "training_data = []\n",
        "for i in range (len(x_unlabeld)):\n",
        "  image = x_unlabeld[i]\n",
        "  training_data.append(image)\n",
        "  cv2.imwrite('/content/train/z_angle/image'+str(counter)+'.png',image) \n",
        "  counter = counter +1\n",
        "print(\"zero degree rotation complete!\")\n",
        "\n",
        "!mkdir train/n_angle\n",
        "training_data = []\n",
        "for i in range (len(x_unlabeld)):\n",
        "  image = x_unlabeld[i]\n",
        "  image_aug = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "  training_data.append(image_aug)\n",
        "  cv2.imwrite('/content/train/n_angle/image'+str(counter)+'.png',image_aug) \n",
        "  counter = counter +1\n",
        "print(\"90 degree rotation complete!\")\n",
        "\n",
        "!mkdir train/e_angle\n",
        "training_data = []\n",
        "for i in range (len(x_unlabeld)):\n",
        "  image = x_unlabeld[i]\n",
        "  image_aug = cv2.rotate(image, cv2.ROTATE_180)\n",
        "  training_data.append(image_aug)\n",
        "  cv2.imwrite('/content/train/e_angle/image'+str(counter)+'.png',image_aug) \n",
        "  counter = counter +1\n",
        "print(\"180 degree rotation complete!\")\n",
        "\n",
        "!mkdir train/m_angle\n",
        "training_data = []\n",
        "for i in range (len(x_unlabeld)):\n",
        "  image = x_unlabeld[i]\n",
        "  image_aug = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "  training_data.append(image_aug)\n",
        "  cv2.imwrite('/content/train/m_angle/image'+str(counter)+'.png',image_aug) \n",
        "  counter = counter +1\n",
        "print(\"270 degree rotation complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zero degree rotation complete!\n",
            "90 degree rotation complete!\n",
            "180 degree rotation complete!\n",
            "270 degree rotation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR20b27-5Y50"
      },
      "source": [
        "show one example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "M1LasnkgH1ty",
        "outputId": "eea1041f-e46e-42d3-d0c1-1a4bfe2e1b07"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "img = cv2.imread('/content/train/z_angle/image113.png') \n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "plt.imshow(image_aug)\n",
        "plt.show()\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9eyqEok5c91"
      },
      "source": [
        "collect all images in one directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSO625NzUYxt",
        "outputId": "beae8c5f-79e9-41f1-8e10-6dff0cd71452"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "!mkdir all_images\n",
        "train_dir = '/content/train'\n",
        "dest_dir = '/content/all_images'\n",
        "counter = 0\n",
        "\n",
        "for subdir, dirs, files in os.walk(train_dir):\n",
        "    for file in files:\n",
        "        full_path = os.path.join(subdir, file)\n",
        "        shutil.copy(full_path, dest_dir)\n",
        "        counter = counter + 1\n",
        "\n",
        "print(counter) #199200 = 4 X 49800"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbpwjcLC5i-F"
      },
      "source": [
        "The next step is to store the name of each data point (ie name of each image) in one array (let’s name the array as filename). One more thing is to store the labels associated with each data point in another array(let’s call this array as labels).\n",
        "Below is a script storing the names of each image in the filename array and labels associated with that image in labels array.\n",
        "Note: Keep in mind that the name of each data point should be unique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tso0rVJPUZBF",
        "outputId": "81534255-6433-4cdc-f646-c36925b6e3b4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "filenames = []\n",
        "labels = np.zeros((counter, 1))\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "images_dir = '/content/all_images'\n",
        "filenames_counter = 0\n",
        "labels_counter = -1\n",
        "\n",
        "for subdir, dirs, files in os.walk(train_dir):\n",
        "    #print(files)\n",
        "    for file in files:\n",
        "        filenames.append(file)\n",
        "        labels[filenames_counter, 0] = labels_counter\n",
        "        filenames_counter = filenames_counter + 1\n",
        "    labels_counter = labels_counter+1\n",
        "    \n",
        "print(len(filenames))\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199200\n",
            "(199200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcsFuh-u58xg"
      },
      "source": [
        "Now, you can save the “all_images” folder, “filename” array and the “labels” array for later use.\n",
        "\n",
        "Below we create a numpy array of filename and labels and save them as a .npy file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7POM20SlUZIt"
      },
      "source": [
        "# saving the filename array as .npy file\n",
        "np.save('filenames.npy', filenames)\n",
        "\n",
        "# One hot vector representation of labels\n",
        "y_labels_one_hot = tf.keras.utils.to_categorical(labels)\n",
        "\n",
        "# saving the y_labels_one_hot array as a .npy file\n",
        "np.save('y_labels_one_hot.npy', y_labels_one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHDyplUZ6D1Z"
      },
      "source": [
        "Shuffling and Splitting of the Dataset In Train and Validation Set.\n",
        "\n",
        "The next step is to shuffle the dataset so as to remove any symmetry from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuVqiv1SUZPy"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "filenames_shuffled, y_labels_one_hot_shuffled = shuffle(filenames, y_labels_one_hot)\n",
        "\n",
        "# saving the shuffled file.\n",
        "# you can load them later using np.load().\n",
        "np.save('y_labels_one_hot_shuffled.npy', y_labels_one_hot_shuffled)\n",
        "np.save('filenames_shuffled.npy', filenames_shuffled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuwtsS1S6QIF"
      },
      "source": [
        "Now, let’s split the dataset into a train and validation set. \n",
        "\n",
        "We can save these files also as these will be used later for training and validating of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCRyk7icUZWT",
        "outputId": "b0914795-f8b3-414a-96db-60c50cbf23b5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Used this line as our filename array is not a numpy array.\n",
        "filenames_shuffled_numpy = np.array(filenames_shuffled)\n",
        "\n",
        "X_train_filenames, X_val_filenames, Y_train, Y_val = train_test_split(\n",
        "    filenames_shuffled_numpy, y_labels_one_hot_shuffled, test_size=0.2, random_state=1)\n",
        "\n",
        "print(X_train_filenames.shape) # (159360,) \n",
        "print(Y_train.shape)           # (159360, 4)\n",
        "\n",
        "print(X_val_filenames.shape)   # (39840,)\n",
        "print(Y_val.shape)             # (39840, 4)\n",
        "\n",
        "# You can save these files as well. As you will be using them later for training and validation of your model.\n",
        "np.save('X_train_filenames.npy', X_train_filenames)\n",
        "np.save('y_train.npy', Y_train)\n",
        "\n",
        "np.save('X_val_filenames.npy', X_val_filenames)\n",
        "np.save('y_val.npy', Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159360,)\n",
            "(159360, 4)\n",
            "(39840,)\n",
            "(39840, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyw3KaJ_6Z7F"
      },
      "source": [
        "These lines of code just create an “all_images.zip” folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pJRJtDEru5BQ",
        "outputId": "36ae84dc-19be-4e91-d0a0-b39f0fcdbde5"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"all_images\", \"zip\", \"all_images\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/all_images.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbA-SBMC6iqs"
      },
      "source": [
        "Creation of Custom Generator\n",
        "\n",
        "Note: As our dataset is too large to fit in memory, we have to load the dataset from the hard disk in batches to our memory.\n",
        "\n",
        "To do so, we are going to create a custom generator. Our Custom Generator is going to load the dataset from the hard disk in batches to memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkc4vRHzUZdD"
      },
      "source": [
        "import cv2\n",
        "\n",
        "class My_Custom_Generator(keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, image_filenames, labels, batch_size) :\n",
        "    self.image_filenames = image_filenames\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "\n",
        "    return np.array([\n",
        "            (cv2.imread('/content/all_images/' + str(file_name)))\n",
        "               for file_name in batch_x])/255.0, np.array(batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SerV7rfp6q5Y"
      },
      "source": [
        "Ok, so we have created our data generator. Next step is to create instances of this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg03ZxRBWCos"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(X_train_filenames, Y_train, batch_size)\n",
        "my_validation_batch_generator = My_Custom_Generator(X_val_filenames, Y_val, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CF7I24PQofS"
      },
      "source": [
        "## train pretext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y4Q8F-wEqo-",
        "outputId": "9ad9892c-8fcd-4229-fe79-71fc32665eca"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# define regularization norm 2\n",
        "reg = tf.keras.regularizers.l2(0.001)\n",
        "\n",
        "# input layer\n",
        "# model.add(tf.keras.Input(X_train[0].shape))  # 32x32 RGB images\n",
        "model.add(tf.keras.layers.Input((32,32,3)))\n",
        "\n",
        "# create the base model\n",
        "# First convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_1'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_1'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_1'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_1'))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_2'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_2'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_2'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_2'))\n",
        "\n",
        "# Third convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_3'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_3'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_3'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_3'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_3'))\n",
        "\n",
        "\n",
        "# add a Flatten layer\n",
        "model.add(tf.keras.layers.Flatten(name='Flatten'))\n",
        "\n",
        "# let's add fully-connected layers\n",
        "model.add(tf.keras.layers.Dense(1024, kernel_regularizer=reg, name='Dense_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_4'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_4'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_4'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, kernel_regularizer=reg, name='Dense_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_5'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_5'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_5'))\n",
        "\n",
        "\n",
        "# and a logistic layer -- let's say we have 4 classes[0, 90, 180, 270] degrees\n",
        "model.add(tf.keras.layers.Dense(4, kernel_regularizer=reg, name='Dense_3'))\n",
        "model.add(tf.keras.layers.Activation('softmax', name='Act_6'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "BatchN_1 (BatchNormalization (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_1 (Activation)           (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_1 (MaxPooling2D)        (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "Drop_1 (Dropout)             (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 13, 13, 128)       147584    \n",
            "_________________________________________________________________\n",
            "BatchN_2 (BatchNormalization (None, 13, 13, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_2 (Activation)           (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_2 (MaxPooling2D)        (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_2 (Dropout)             (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "BatchN_3 (BatchNormalization (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "Act_3 (Activation)           (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "pool_3 (MaxPooling2D)        (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_3 (Dropout)             (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "Act_4 (Activation)           (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "BatchN_4 (BatchNormalization (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "Drop_4 (Dropout)             (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "Act_5 (Activation)           (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "BatchN_5 (BatchNormalization (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "Drop_5 (Dropout)             (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "Dense_3 (Dense)              (None, 4)                 516       \n",
            "_________________________________________________________________\n",
            "Act_6 (Activation)           (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 961,924\n",
            "Trainable params: 958,852\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_haBt40rCrR",
        "outputId": "91a4f496-e0fb-436a-b664-3d847197ab30"
      },
      "source": [
        "# save the best weights to use in Downstream task\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True)\n",
        "\n",
        "# train and test the model on the unlabeld data for some epochs\n",
        "history = model.fit_generator(generator=my_training_batch_generator,\n",
        "                   steps_per_epoch = int(159360 // batch_size),\n",
        "                   epochs = 200,\n",
        "                   verbose = 1,\n",
        "                   validation_data = my_validation_batch_generator,\n",
        "                   validation_steps = int(39840 // batch_size),\n",
        "                   callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "311/311 [==============================] - 59s 80ms/step - loss: 2.7910 - accuracy: 0.3452 - val_loss: 2.1579 - val_accuracy: 0.4228\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.15787, saving model to best_weights.hdf5\n",
            "Epoch 2/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.8355 - accuracy: 0.4954 - val_loss: 1.5852 - val_accuracy: 0.5531\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.15787 to 1.58522, saving model to best_weights.hdf5\n",
            "Epoch 3/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.4092 - accuracy: 0.5435 - val_loss: 1.3887 - val_accuracy: 0.5066\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.58522 to 1.38870, saving model to best_weights.hdf5\n",
            "Epoch 4/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.1950 - accuracy: 0.5765 - val_loss: 1.2496 - val_accuracy: 0.5556\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.38870 to 1.24955, saving model to best_weights.hdf5\n",
            "Epoch 5/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.1174 - accuracy: 0.5980 - val_loss: 1.0499 - val_accuracy: 0.6316\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.24955 to 1.04994, saving model to best_weights.hdf5\n",
            "Epoch 6/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0812 - accuracy: 0.6153 - val_loss: 1.0645 - val_accuracy: 0.6228\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.04994\n",
            "Epoch 7/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0751 - accuracy: 0.6234 - val_loss: 1.1459 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.04994\n",
            "Epoch 8/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0724 - accuracy: 0.6313 - val_loss: 1.0500 - val_accuracy: 0.6470\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.04994\n",
            "Epoch 9/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0671 - accuracy: 0.6366 - val_loss: 1.0438 - val_accuracy: 0.6454\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.04994 to 1.04376, saving model to best_weights.hdf5\n",
            "Epoch 10/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0557 - accuracy: 0.6464 - val_loss: 1.0657 - val_accuracy: 0.6469\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.04376\n",
            "Epoch 11/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0537 - accuracy: 0.6508 - val_loss: 1.1242 - val_accuracy: 0.6290\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.04376\n",
            "Epoch 12/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0600 - accuracy: 0.6511 - val_loss: 1.1333 - val_accuracy: 0.6135\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.04376\n",
            "Epoch 13/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0515 - accuracy: 0.6570 - val_loss: 1.0593 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.04376\n",
            "Epoch 14/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0489 - accuracy: 0.6583 - val_loss: 1.0398 - val_accuracy: 0.6814\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.04376 to 1.03982, saving model to best_weights.hdf5\n",
            "Epoch 15/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0460 - accuracy: 0.6617 - val_loss: 1.0433 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.03982\n",
            "Epoch 16/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0415 - accuracy: 0.6642 - val_loss: 1.0343 - val_accuracy: 0.6672\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.03982 to 1.03426, saving model to best_weights.hdf5\n",
            "Epoch 17/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0411 - accuracy: 0.6667 - val_loss: 1.0127 - val_accuracy: 0.6861\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.03426 to 1.01269, saving model to best_weights.hdf5\n",
            "Epoch 18/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0288 - accuracy: 0.6716 - val_loss: 1.0618 - val_accuracy: 0.6506\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.01269\n",
            "Epoch 19/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0322 - accuracy: 0.6700 - val_loss: 1.0463 - val_accuracy: 0.6623\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.01269\n",
            "Epoch 20/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0327 - accuracy: 0.6712 - val_loss: 1.0494 - val_accuracy: 0.6657\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.01269\n",
            "Epoch 21/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0277 - accuracy: 0.6731 - val_loss: 1.0372 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.01269\n",
            "Epoch 22/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0270 - accuracy: 0.6739 - val_loss: 1.0804 - val_accuracy: 0.6427\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.01269\n",
            "Epoch 23/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0232 - accuracy: 0.6776 - val_loss: 1.0085 - val_accuracy: 0.6805\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.01269 to 1.00852, saving model to best_weights.hdf5\n",
            "Epoch 24/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0320 - accuracy: 0.6733 - val_loss: 1.0436 - val_accuracy: 0.6696\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.00852\n",
            "Epoch 25/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 1.0243 - accuracy: 0.6757 - val_loss: 1.0148 - val_accuracy: 0.6828\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.00852\n",
            "Epoch 26/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0291 - accuracy: 0.6764 - val_loss: 1.0419 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.00852\n",
            "Epoch 27/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0242 - accuracy: 0.6778 - val_loss: 1.0132 - val_accuracy: 0.6720\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.00852\n",
            "Epoch 28/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0241 - accuracy: 0.6783 - val_loss: 0.9795 - val_accuracy: 0.6940\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.00852 to 0.97951, saving model to best_weights.hdf5\n",
            "Epoch 29/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0189 - accuracy: 0.6803 - val_loss: 1.0068 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.97951\n",
            "Epoch 30/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0206 - accuracy: 0.6795 - val_loss: 0.9855 - val_accuracy: 0.6974\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.97951\n",
            "Epoch 31/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0172 - accuracy: 0.6810 - val_loss: 0.9791 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.97951 to 0.97914, saving model to best_weights.hdf5\n",
            "Epoch 32/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0163 - accuracy: 0.6807 - val_loss: 1.0812 - val_accuracy: 0.6430\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.97914\n",
            "Epoch 33/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0207 - accuracy: 0.6796 - val_loss: 1.0601 - val_accuracy: 0.6617\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.97914\n",
            "Epoch 34/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0142 - accuracy: 0.6828 - val_loss: 1.0302 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.97914\n",
            "Epoch 35/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0163 - accuracy: 0.6813 - val_loss: 1.0041 - val_accuracy: 0.7043\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.97914\n",
            "Epoch 36/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0134 - accuracy: 0.6819 - val_loss: 1.0486 - val_accuracy: 0.6661\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.97914\n",
            "Epoch 37/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0178 - accuracy: 0.6827 - val_loss: 1.0405 - val_accuracy: 0.6671\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.97914\n",
            "Epoch 38/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0194 - accuracy: 0.6801 - val_loss: 0.9950 - val_accuracy: 0.6888\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.97914\n",
            "Epoch 39/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0088 - accuracy: 0.6866 - val_loss: 1.0337 - val_accuracy: 0.6680\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.97914\n",
            "Epoch 40/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0073 - accuracy: 0.6857 - val_loss: 1.0147 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.97914\n",
            "Epoch 41/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0090 - accuracy: 0.6832 - val_loss: 1.0111 - val_accuracy: 0.6825\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.97914\n",
            "Epoch 42/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0052 - accuracy: 0.6864 - val_loss: 1.0287 - val_accuracy: 0.6718\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.97914\n",
            "Epoch 43/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0123 - accuracy: 0.6855 - val_loss: 0.9783 - val_accuracy: 0.6975\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.97914 to 0.97832, saving model to best_weights.hdf5\n",
            "Epoch 44/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0107 - accuracy: 0.6863 - val_loss: 1.0248 - val_accuracy: 0.6725\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.97832\n",
            "Epoch 45/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0081 - accuracy: 0.6850 - val_loss: 1.0393 - val_accuracy: 0.6712\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.97832\n",
            "Epoch 46/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0107 - accuracy: 0.6824 - val_loss: 1.0685 - val_accuracy: 0.6589\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.97832\n",
            "Epoch 47/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0106 - accuracy: 0.6835 - val_loss: 0.9593 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.97832 to 0.95934, saving model to best_weights.hdf5\n",
            "Epoch 48/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0084 - accuracy: 0.6846 - val_loss: 1.0064 - val_accuracy: 0.6852\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.95934\n",
            "Epoch 49/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0099 - accuracy: 0.6849 - val_loss: 1.0000 - val_accuracy: 0.6841\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.95934\n",
            "Epoch 50/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0065 - accuracy: 0.6868 - val_loss: 0.9957 - val_accuracy: 0.7010\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.95934\n",
            "Epoch 51/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0110 - accuracy: 0.6840 - val_loss: 1.0058 - val_accuracy: 0.6873\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.95934\n",
            "Epoch 52/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0097 - accuracy: 0.6831 - val_loss: 1.0111 - val_accuracy: 0.6979\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.95934\n",
            "Epoch 53/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0053 - accuracy: 0.6870 - val_loss: 0.9546 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.95934 to 0.95464, saving model to best_weights.hdf5\n",
            "Epoch 54/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0054 - accuracy: 0.6866 - val_loss: 0.9885 - val_accuracy: 0.6929\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.95464\n",
            "Epoch 55/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0044 - accuracy: 0.6867 - val_loss: 0.9392 - val_accuracy: 0.7273\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.95464 to 0.93918, saving model to best_weights.hdf5\n",
            "Epoch 56/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0080 - accuracy: 0.6852 - val_loss: 1.0256 - val_accuracy: 0.6688\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.93918\n",
            "Epoch 57/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0025 - accuracy: 0.6874 - val_loss: 1.0390 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.93918\n",
            "Epoch 58/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0029 - accuracy: 0.6855 - val_loss: 0.9949 - val_accuracy: 0.6850\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.93918\n",
            "Epoch 59/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9998 - accuracy: 0.6887 - val_loss: 1.0513 - val_accuracy: 0.6614\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.93918\n",
            "Epoch 60/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0021 - accuracy: 0.6882 - val_loss: 1.0922 - val_accuracy: 0.6487\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.93918\n",
            "Epoch 61/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0020 - accuracy: 0.6885 - val_loss: 1.0638 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.93918\n",
            "Epoch 62/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9977 - accuracy: 0.6899 - val_loss: 0.9420 - val_accuracy: 0.7283\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.93918\n",
            "Epoch 63/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9996 - accuracy: 0.6893 - val_loss: 1.0777 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.93918\n",
            "Epoch 64/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9966 - accuracy: 0.6912 - val_loss: 0.9585 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.93918\n",
            "Epoch 65/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9983 - accuracy: 0.6878 - val_loss: 1.0638 - val_accuracy: 0.6498\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.93918\n",
            "Epoch 66/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0012 - accuracy: 0.6869 - val_loss: 0.9411 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.93918\n",
            "Epoch 67/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9933 - accuracy: 0.6909 - val_loss: 0.9760 - val_accuracy: 0.7107\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.93918\n",
            "Epoch 68/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9971 - accuracy: 0.6896 - val_loss: 1.0307 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.93918\n",
            "Epoch 69/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9952 - accuracy: 0.6917 - val_loss: 1.0164 - val_accuracy: 0.6807\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.93918\n",
            "Epoch 70/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 1.0029 - accuracy: 0.6874 - val_loss: 1.1291 - val_accuracy: 0.6162\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.93918\n",
            "Epoch 71/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9920 - accuracy: 0.6907 - val_loss: 0.9983 - val_accuracy: 0.6866\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.93918\n",
            "Epoch 72/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9978 - accuracy: 0.6902 - val_loss: 1.0535 - val_accuracy: 0.6612\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.93918\n",
            "Epoch 73/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9939 - accuracy: 0.6892 - val_loss: 0.9694 - val_accuracy: 0.7016\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.93918\n",
            "Epoch 74/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9884 - accuracy: 0.6940 - val_loss: 1.1268 - val_accuracy: 0.6345\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.93918\n",
            "Epoch 75/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9962 - accuracy: 0.6898 - val_loss: 0.9526 - val_accuracy: 0.7146\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.93918\n",
            "Epoch 76/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9952 - accuracy: 0.6905 - val_loss: 0.9828 - val_accuracy: 0.6940\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.93918\n",
            "Epoch 77/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9925 - accuracy: 0.6895 - val_loss: 0.9641 - val_accuracy: 0.7144\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.93918\n",
            "Epoch 78/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9964 - accuracy: 0.6873 - val_loss: 1.1112 - val_accuracy: 0.6279\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.93918\n",
            "Epoch 79/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9922 - accuracy: 0.6920 - val_loss: 1.0161 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.93918\n",
            "Epoch 80/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9934 - accuracy: 0.6911 - val_loss: 1.0497 - val_accuracy: 0.6566\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.93918\n",
            "Epoch 81/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9939 - accuracy: 0.6908 - val_loss: 1.0234 - val_accuracy: 0.6728\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.93918\n",
            "Epoch 82/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9876 - accuracy: 0.6919 - val_loss: 1.0202 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.93918\n",
            "Epoch 83/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9896 - accuracy: 0.6916 - val_loss: 0.9986 - val_accuracy: 0.6889\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.93918\n",
            "Epoch 84/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9866 - accuracy: 0.6928 - val_loss: 1.0048 - val_accuracy: 0.6828\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.93918\n",
            "Epoch 85/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9890 - accuracy: 0.6933 - val_loss: 1.0146 - val_accuracy: 0.6891\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.93918\n",
            "Epoch 86/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9899 - accuracy: 0.6908 - val_loss: 1.0672 - val_accuracy: 0.6553\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.93918\n",
            "Epoch 87/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9888 - accuracy: 0.6938 - val_loss: 1.0719 - val_accuracy: 0.6555\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.93918\n",
            "Epoch 88/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9888 - accuracy: 0.6928 - val_loss: 1.2583 - val_accuracy: 0.5740\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.93918\n",
            "Epoch 89/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9935 - accuracy: 0.6916 - val_loss: 1.1540 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.93918\n",
            "Epoch 90/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9827 - accuracy: 0.6937 - val_loss: 1.3308 - val_accuracy: 0.5446\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.93918\n",
            "Epoch 91/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9883 - accuracy: 0.6932 - val_loss: 0.9538 - val_accuracy: 0.7107\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.93918\n",
            "Epoch 92/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9913 - accuracy: 0.6913 - val_loss: 0.9443 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.93918\n",
            "Epoch 93/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9895 - accuracy: 0.6915 - val_loss: 1.0752 - val_accuracy: 0.6591\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.93918\n",
            "Epoch 94/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9824 - accuracy: 0.6942 - val_loss: 1.0096 - val_accuracy: 0.6869\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.93918\n",
            "Epoch 95/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9868 - accuracy: 0.6913 - val_loss: 0.9784 - val_accuracy: 0.7005\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.93918\n",
            "Epoch 96/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9837 - accuracy: 0.6944 - val_loss: 1.0631 - val_accuracy: 0.6619\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.93918\n",
            "Epoch 97/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9869 - accuracy: 0.6920 - val_loss: 0.9999 - val_accuracy: 0.6826\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.93918\n",
            "Epoch 98/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9852 - accuracy: 0.6921 - val_loss: 1.0126 - val_accuracy: 0.6836\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.93918\n",
            "Epoch 99/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9848 - accuracy: 0.6949 - val_loss: 0.9614 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.93918\n",
            "Epoch 100/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9834 - accuracy: 0.6935 - val_loss: 1.0150 - val_accuracy: 0.6831\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.93918\n",
            "Epoch 101/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9815 - accuracy: 0.6938 - val_loss: 1.1086 - val_accuracy: 0.6315\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.93918\n",
            "Epoch 102/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9866 - accuracy: 0.6922 - val_loss: 1.2192 - val_accuracy: 0.5853\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.93918\n",
            "Epoch 103/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9843 - accuracy: 0.6929 - val_loss: 1.0367 - val_accuracy: 0.6713\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.93918\n",
            "Epoch 104/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9862 - accuracy: 0.6912 - val_loss: 1.0650 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.93918\n",
            "Epoch 105/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9869 - accuracy: 0.6914 - val_loss: 1.3672 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.93918\n",
            "Epoch 106/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9870 - accuracy: 0.6909 - val_loss: 0.9534 - val_accuracy: 0.6985\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.93918\n",
            "Epoch 107/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9842 - accuracy: 0.6933 - val_loss: 0.9915 - val_accuracy: 0.6936\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.93918\n",
            "Epoch 108/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9876 - accuracy: 0.6918 - val_loss: 0.9435 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.93918\n",
            "Epoch 109/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9832 - accuracy: 0.6935 - val_loss: 0.9817 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.93918\n",
            "Epoch 110/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9827 - accuracy: 0.6957 - val_loss: 1.0386 - val_accuracy: 0.6627\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.93918\n",
            "Epoch 111/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9854 - accuracy: 0.6921 - val_loss: 0.9433 - val_accuracy: 0.7122\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.93918\n",
            "Epoch 112/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9853 - accuracy: 0.6916 - val_loss: 0.9472 - val_accuracy: 0.7170\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.93918\n",
            "Epoch 113/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9885 - accuracy: 0.6911 - val_loss: 1.0634 - val_accuracy: 0.6537\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.93918\n",
            "Epoch 114/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9794 - accuracy: 0.6957 - val_loss: 0.9471 - val_accuracy: 0.7195\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.93918\n",
            "Epoch 115/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9833 - accuracy: 0.6930 - val_loss: 1.0118 - val_accuracy: 0.6840\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.93918\n",
            "Epoch 116/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9833 - accuracy: 0.6933 - val_loss: 0.9707 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.93918\n",
            "Epoch 117/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9870 - accuracy: 0.6913 - val_loss: 0.9983 - val_accuracy: 0.6843\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.93918\n",
            "Epoch 118/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9831 - accuracy: 0.6943 - val_loss: 0.9576 - val_accuracy: 0.7074\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.93918\n",
            "Epoch 119/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9803 - accuracy: 0.6955 - val_loss: 1.0871 - val_accuracy: 0.6459\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.93918\n",
            "Epoch 120/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9807 - accuracy: 0.6939 - val_loss: 0.9882 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.93918\n",
            "Epoch 121/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9882 - accuracy: 0.6923 - val_loss: 1.0128 - val_accuracy: 0.6785\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.93918\n",
            "Epoch 122/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9814 - accuracy: 0.6936 - val_loss: 1.0138 - val_accuracy: 0.6762\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.93918\n",
            "Epoch 123/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9824 - accuracy: 0.6928 - val_loss: 0.9560 - val_accuracy: 0.7125\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.93918\n",
            "Epoch 124/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9767 - accuracy: 0.6941 - val_loss: 1.0526 - val_accuracy: 0.6589\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.93918\n",
            "Epoch 125/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9812 - accuracy: 0.6944 - val_loss: 1.4331 - val_accuracy: 0.5582\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.93918\n",
            "Epoch 126/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9787 - accuracy: 0.6943 - val_loss: 1.0007 - val_accuracy: 0.6904\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.93918\n",
            "Epoch 127/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9773 - accuracy: 0.6956 - val_loss: 0.9954 - val_accuracy: 0.6891\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.93918\n",
            "Epoch 128/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9896 - accuracy: 0.6909 - val_loss: 0.9921 - val_accuracy: 0.6852\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.93918\n",
            "Epoch 129/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9849 - accuracy: 0.6921 - val_loss: 1.3830 - val_accuracy: 0.5633\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.93918\n",
            "Epoch 130/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9761 - accuracy: 0.6957 - val_loss: 0.9802 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.93918\n",
            "Epoch 131/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9799 - accuracy: 0.6961 - val_loss: 0.9935 - val_accuracy: 0.6890\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.93918\n",
            "Epoch 132/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9810 - accuracy: 0.6926 - val_loss: 0.9413 - val_accuracy: 0.7081\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.93918\n",
            "Epoch 133/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9825 - accuracy: 0.6946 - val_loss: 0.9395 - val_accuracy: 0.7198\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.93918\n",
            "Epoch 134/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9819 - accuracy: 0.6931 - val_loss: 0.9877 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.93918\n",
            "Epoch 135/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9767 - accuracy: 0.6960 - val_loss: 1.0416 - val_accuracy: 0.6585\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.93918\n",
            "Epoch 136/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9832 - accuracy: 0.6922 - val_loss: 1.0525 - val_accuracy: 0.6659\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.93918\n",
            "Epoch 137/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9787 - accuracy: 0.6945 - val_loss: 1.2022 - val_accuracy: 0.6124\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.93918\n",
            "Epoch 138/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9816 - accuracy: 0.6938 - val_loss: 1.0249 - val_accuracy: 0.6853\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.93918\n",
            "Epoch 139/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9813 - accuracy: 0.6925 - val_loss: 1.1340 - val_accuracy: 0.6153\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.93918\n",
            "Epoch 140/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9827 - accuracy: 0.6912 - val_loss: 1.0616 - val_accuracy: 0.6586\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.93918\n",
            "Epoch 141/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9835 - accuracy: 0.6939 - val_loss: 0.9682 - val_accuracy: 0.7004\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.93918\n",
            "Epoch 142/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9804 - accuracy: 0.6940 - val_loss: 0.9641 - val_accuracy: 0.7024\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.93918\n",
            "Epoch 143/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9772 - accuracy: 0.6979 - val_loss: 0.9904 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.93918\n",
            "Epoch 144/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9815 - accuracy: 0.6955 - val_loss: 1.0689 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.93918\n",
            "Epoch 145/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9802 - accuracy: 0.6949 - val_loss: 1.0009 - val_accuracy: 0.6808\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.93918\n",
            "Epoch 146/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9808 - accuracy: 0.6955 - val_loss: 1.0697 - val_accuracy: 0.6641\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.93918\n",
            "Epoch 147/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9788 - accuracy: 0.6958 - val_loss: 1.0257 - val_accuracy: 0.6756\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.93918\n",
            "Epoch 148/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9808 - accuracy: 0.6948 - val_loss: 0.9055 - val_accuracy: 0.7341\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.93918 to 0.90550, saving model to best_weights.hdf5\n",
            "Epoch 149/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9799 - accuracy: 0.6944 - val_loss: 0.9877 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.90550\n",
            "Epoch 150/200\n",
            "311/311 [==============================] - 24s 78ms/step - loss: 0.9780 - accuracy: 0.6953 - val_loss: 1.0206 - val_accuracy: 0.6794\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.90550\n",
            "Epoch 151/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9801 - accuracy: 0.6945 - val_loss: 1.1430 - val_accuracy: 0.6208\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.90550\n",
            "Epoch 152/200\n",
            "311/311 [==============================] - 24s 79ms/step - loss: 0.9753 - accuracy: 0.6950 - val_loss: 0.9921 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.90550\n",
            "Epoch 153/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9729 - accuracy: 0.6970 - val_loss: 0.9656 - val_accuracy: 0.7049\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.90550\n",
            "Epoch 154/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9791 - accuracy: 0.6940 - val_loss: 0.9763 - val_accuracy: 0.6905\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.90550\n",
            "Epoch 155/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9778 - accuracy: 0.6950 - val_loss: 1.2024 - val_accuracy: 0.5998\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.90550\n",
            "Epoch 156/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9839 - accuracy: 0.6937 - val_loss: 1.0138 - val_accuracy: 0.6765\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.90550\n",
            "Epoch 157/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9721 - accuracy: 0.6985 - val_loss: 0.9184 - val_accuracy: 0.7278\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.90550\n",
            "Epoch 158/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9792 - accuracy: 0.6947 - val_loss: 1.1413 - val_accuracy: 0.6090\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.90550\n",
            "Epoch 159/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9776 - accuracy: 0.6946 - val_loss: 1.0168 - val_accuracy: 0.6770\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.90550\n",
            "Epoch 160/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9818 - accuracy: 0.6932 - val_loss: 0.9182 - val_accuracy: 0.7285\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.90550\n",
            "Epoch 161/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9774 - accuracy: 0.6955 - val_loss: 1.0057 - val_accuracy: 0.6726\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.90550\n",
            "Epoch 162/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9777 - accuracy: 0.6962 - val_loss: 0.9855 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.90550\n",
            "Epoch 163/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9812 - accuracy: 0.6937 - val_loss: 1.1641 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.90550\n",
            "Epoch 164/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9736 - accuracy: 0.6966 - val_loss: 0.9621 - val_accuracy: 0.7085\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.90550\n",
            "Epoch 165/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9827 - accuracy: 0.6952 - val_loss: 1.4266 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.90550\n",
            "Epoch 166/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9814 - accuracy: 0.6948 - val_loss: 1.0230 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.90550\n",
            "Epoch 167/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9735 - accuracy: 0.6979 - val_loss: 0.9540 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.90550\n",
            "Epoch 168/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9815 - accuracy: 0.6945 - val_loss: 1.1020 - val_accuracy: 0.6475\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.90550\n",
            "Epoch 169/200\n",
            "311/311 [==============================] - 25s 79ms/step - loss: 0.9758 - accuracy: 0.6962 - val_loss: 0.9813 - val_accuracy: 0.6898\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.90550\n",
            "Epoch 170/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9734 - accuracy: 0.6969 - val_loss: 1.0102 - val_accuracy: 0.6771\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.90550\n",
            "Epoch 171/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9835 - accuracy: 0.6940 - val_loss: 0.9426 - val_accuracy: 0.7226\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.90550\n",
            "Epoch 172/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9764 - accuracy: 0.6937 - val_loss: 1.0206 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.90550\n",
            "Epoch 173/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9774 - accuracy: 0.6965 - val_loss: 1.0102 - val_accuracy: 0.6734\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.90550\n",
            "Epoch 174/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9741 - accuracy: 0.6973 - val_loss: 0.9986 - val_accuracy: 0.6858\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.90550\n",
            "Epoch 175/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9764 - accuracy: 0.6951 - val_loss: 0.9977 - val_accuracy: 0.6825\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.90550\n",
            "Epoch 176/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9812 - accuracy: 0.6946 - val_loss: 0.9512 - val_accuracy: 0.7081\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.90550\n",
            "Epoch 177/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9763 - accuracy: 0.6961 - val_loss: 0.9671 - val_accuracy: 0.6960\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.90550\n",
            "Epoch 178/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9754 - accuracy: 0.6955 - val_loss: 1.1420 - val_accuracy: 0.6300\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.90550\n",
            "Epoch 179/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9725 - accuracy: 0.6974 - val_loss: 1.0757 - val_accuracy: 0.6496\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.90550\n",
            "Epoch 180/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9786 - accuracy: 0.6960 - val_loss: 0.9551 - val_accuracy: 0.7093\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.90550\n",
            "Epoch 181/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9749 - accuracy: 0.6967 - val_loss: 1.0357 - val_accuracy: 0.6694\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.90550\n",
            "Epoch 182/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9696 - accuracy: 0.7006 - val_loss: 1.0395 - val_accuracy: 0.6597\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.90550\n",
            "Epoch 183/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9822 - accuracy: 0.6939 - val_loss: 1.0550 - val_accuracy: 0.6590\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.90550\n",
            "Epoch 184/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9811 - accuracy: 0.6946 - val_loss: 0.9773 - val_accuracy: 0.6942\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.90550\n",
            "Epoch 185/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9811 - accuracy: 0.6932 - val_loss: 0.9933 - val_accuracy: 0.6882\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.90550\n",
            "Epoch 186/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9707 - accuracy: 0.6976 - val_loss: 0.9704 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.90550\n",
            "Epoch 187/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9782 - accuracy: 0.6969 - val_loss: 1.2937 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.90550\n",
            "Epoch 188/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9796 - accuracy: 0.6947 - val_loss: 0.9745 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.90550\n",
            "Epoch 189/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9750 - accuracy: 0.6968 - val_loss: 1.0123 - val_accuracy: 0.6736\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.90550\n",
            "Epoch 190/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9770 - accuracy: 0.6969 - val_loss: 1.0012 - val_accuracy: 0.6816\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.90550\n",
            "Epoch 191/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9755 - accuracy: 0.6963 - val_loss: 0.9783 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.90550\n",
            "Epoch 192/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9717 - accuracy: 0.6980 - val_loss: 1.0003 - val_accuracy: 0.6944\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.90550\n",
            "Epoch 193/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9802 - accuracy: 0.6933 - val_loss: 0.9941 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.90550\n",
            "Epoch 194/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9743 - accuracy: 0.6971 - val_loss: 0.9745 - val_accuracy: 0.6996\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.90550\n",
            "Epoch 195/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9786 - accuracy: 0.6934 - val_loss: 1.0669 - val_accuracy: 0.6538\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.90550\n",
            "Epoch 196/200\n",
            "311/311 [==============================] - 25s 80ms/step - loss: 0.9779 - accuracy: 0.6941 - val_loss: 1.0799 - val_accuracy: 0.6450\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.90550\n",
            "Epoch 197/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9783 - accuracy: 0.6929 - val_loss: 1.0140 - val_accuracy: 0.6740\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.90550\n",
            "Epoch 198/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9693 - accuracy: 0.7006 - val_loss: 0.9356 - val_accuracy: 0.7220\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.90550\n",
            "Epoch 199/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9768 - accuracy: 0.6957 - val_loss: 0.9828 - val_accuracy: 0.6960\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.90550\n",
            "Epoch 200/200\n",
            "311/311 [==============================] - 25s 81ms/step - loss: 0.9716 - accuracy: 0.6997 - val_loss: 1.1647 - val_accuracy: 0.6143\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.90550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "f0QIpdYi-hMF",
        "outputId": "14ee98d9-7e82-4654-e877-9d83553c6e05"
      },
      "source": [
        "# show results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range((len(acc)))\n",
        "\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZxjVZn+v6eSSmqvruqqXqr3laVZpWUXkF1GFgcHWVQcBWdccNSfC+q44TrjvqAjCiqgIiKbCrQgO7J0Aw1NN91NL/Re3dVd+5akkvP7470n9+QmqSRVSVdRfZ/Ppz6V3NzcnNzc+5znPO973qO01vjw4cOHj4mLsrFugA8fPnz4KC18ovfhw4ePCQ6f6H348OFjgsMneh8+fPiY4PCJ3ocPHz4mOHyi9+HDh48JDp/oD0Aope5XSl1Z7H3HEkqp15VSZ5bguI8qpa5yHl+hlPp7PvuO4HNmK6V6lVKBkbbVh49s8In+DQKHBMxfQik1YD2/opBjaa3fprX+bbH3HY9QSl2rlHo8w/YmpVRUKXVYvsfSWv9Oa312kdqV0jFprbdqrWu01vFiHD/D5yml1Cal1JpSHN/H+IZP9G8QOCRQo7WuAbYC51vbfmf2U0oFx66V4xK3AicqpeZ5tl8KrNJavzIGbRoLnAJMAeYrpd68Pz/YvybHHj7Rv8GhlDpNKbVdKfVZpVQr8GulVINS6q9KqTalVIfzeKb1HtuOeJ9S6kml1HedfTcrpd42wn3nKaUeV0r1KKUeUkpdr5S6NUu782nj15RSTznH+7tSqsl6/T1KqS1KqX1KqS9kOz9a6+3Aw8B7PC+9F7g5Vzs8bX6fUupJ6/lZSqm1SqkupdRPAWW9tkAp9bDTvr1Kqd8ppSY5r90CzAb+4ozIPqOUmquU0oYUlVItSql7lVLtSqkNSqmrrWN/RSl1u1LqZufcrFZKLc12DhxcCdwD3Oc8tr/XEqXUg85n7VZKfd7ZHlBKfV4ptdH5nOeVUrO8bXX29V4nTymlfqCU2gd8Zbjz4bxnllLqTud32KeU+qlSKuS06XBrvylKqX6lVHOO7+vDgk/0EwPTgEZgDvBB5Hf9tfN8NjAA/HSY9x8HrAOagP8FblRKqRHs+3vgOWAy8BXSydVGPm28HPh3RImGgE8BKKUOBX7uHL/F+byM5Ozgt3ZblFIHAUc57S30XJljNAF3Av+NnIuNwEn2LsC3nPYdAsxCzgla6/eQOir73wwfcRuw3Xn/O4FvKqVOt16/wNlnEnDvcG1WSlU5x/id83epUirkvFYLPAQ84HzWQuAfzls/CVwGnAfUAe8H+oc9MS6OAzYBU4FvDHc+lMQl/gpsAeYCM4DbtNZR5zu+2zruZcA/tNZtebbDB4DW2v97g/0BrwNnOo9PA6JAxTD7HwV0WM8fBa5yHr8P2GC9VgVoYFoh+yIkOQRUWa/fCtya53fK1Mb/tp5/GHjAefwlhAjMa9XOOTgzy7GrgG7gROf5N4B7RniunnQevxd4xtpPIcR8VZbjXgS8mOk3dJ7Pdc5lECHBOFBrvf4t4DfO468AD1mvHQoMDHNu3w20OceuALqAdzivXWa3y/O+dcCFGbYn2zrMedqa4/dOng/gBNO+DPsdh3SKynm+ArhkLO+/N+Kfr+gnBtq01oPmiVKqSin1C8fa6AYeByap7BkdreaB1tootpoC920B2q1tANuyNTjPNrZaj/utNrXYx9Za9wH7sn2W06Y/Ae91Rh9XADcX0I5M8LZB28+VUlOVUrcppXY4x70VUf75wJzLHmvbFkTpGnjPTYXK7oVfCdyutR5yrpM/49o3s5DRSCYM91oupPz2Oc7HLGCL1nrIexCt9bPI9ztNKXUwMuK4d4RtOmDhE/3EgLcE6f8DDgKO01rXIYE4sDzkEmAX0OjYBAazhtl/NG3cZR/b+czJOd7zW+AS4CygFvjLKNvhbYMi9ft+E/ldDneO+27PMYcrG7sTOZe11rbZwI4cbUqDE284HXi3UqpVSRznncB5jv20DZif5e3bgAUZtvc5/+3feppnH+/3G+58bANmD9NR/dbZ/z3AHbao8ZEffKKfmKhFvOZOpVQj8OVSf6DWegsyrP6KE0Q7ATi/RG28A3i7Uupkx2u+jtzX8hNAJ3ADrv87mnb8DViilPpXh6A+RirZ1QK9QJdSagbwac/7d5OFYLXW24B/At9SSlUopY4APoCo4ELxHmA90pkd5fwtRmymyxBvfLpS6uNKqbBSqlYpdZzz3l8BX1NKLVKCI5RSk7X44zuQziOglHo/mTsEG8Odj+eQjvPbSqlq5zvb8Y5bgXcgZH/zCM7BAQ+f6CcmfghUAnuBZ5BA2/7AFYjfug/4OvBHIJJl3xG3UWu9GvgIEkzdBXQgxDXcezRCEnNIJYsRtUNrvRf4N+DbyPddBDxl7fJV4E2IH/43JHBr41vAfyulOpVSn8rwEZchXvhO4C7gy1rrh/JpmwdXAj/TWrfaf8D/AVc69tBZSKfcCrwGvNV57/eB24G/IzGOG5FzBXA1Qtb7gCVIxzQcsp4PLXMHzkdsma3Ib/ku6/VtwAvIiOCJwk+BDxPg8OGj6FBK/RFYq7Uu+YjCx8SGUuomYKfW+r/Hui1vRPhE76NoUDIRpx3YDJwN3A2coLV+cUwb5uMNDaXUXGAlcLTWevPYtuaNCd+68VFMTEPS7HqBHwMf8knex2iglPoa8ArwHZ/kR468FL1S6lzgR0AA+JXW+tue13+A6+tVAVO01mYWYBxY5by2VWt9QZHa7sOHDx8+8kBOonfyidcjAZvtwHLgMq11xuJISqlrkCHW+53nvVrqs/jw4cOHjzFAPsWGjkVmQ24CUErdBlwIZKuCdxmjSOdramrSc+fOHenbffjw4eOAxPPPP79Xa52xBlA+RD+D1Flu25FpyWlQSs0B5iFFpAwqlFIrkOnx39Za353hfR9EarQwe/ZsVqxYkUezfPjw4cOHgVJqS7bXih2MvRSZuWbX1J6jtV6KFKj6oVIqbWKF1voGrfVSrfXS5ma/KJ0PHz58FBP5EP0OUqd2zyT7VOxLgT/YG7TWO5z/m5CMjKMLbqUPHz58+Bgx8iH65cAiJbXGQwiZpxUVcgoONQBPW9salFJh53ETUsbVX+HGhw8fPvYjcnr0WushpdRHgWVIeuVNWuvVSqnrgBVaa0P6lyI1ROw0nkOAXyilEkin8u1s2To+fPjw4aM0GHczY5cuXar9YKwPHz58FAal1PNOPDQN/sxYHz58+Jjg8Inehw8fPiY4fKL34cNHcRAfghdulv8+xhV8ovfhw0dxsPWfcO81sOWp3Pv62K/wid6HDx/FQcRZ4nagY2zb4SMNPtH78OGjOIg6S8kOdo3+WENRSMRz7+cjL/hE7yMd/e2w+fH89r3rQ/DA50rbnlLguV/Clqdz7+cjfxiij3QX9r7da+Cx76Ruu/EseOx/i9MuHz7R+8iA534Jt7wD4rHc++56CXa/Uvo2FROJBCz7Arw4krW2fWRFrF/+F6roV98Jj3wdhqzlhfdthPZNxWvbAQ6f6H2ko3c3JIZchTYcYv0QGyx9m4qJrm0Qj8DQwFi3ZGIhOkKij/TKfyMstIZob37Xn4+84BO9j3QMtMt/o9CGQ2wAhjIQ/b6NsHOcriK4b4P8L2UHpfWBl2YYMx59gdZN1AniJhyij/UDDtmPFFrDkz+Azm259x1L9Lfvl+C1T/Q+0tHvEH00X6KPpG9/+Ovwh8vlhhtvSBJ9Ht9vpFhzD3xnwYGlSkcajDXvM4reKPzRnLve3fDQV2BN2vIX4wt//oCkpJYYPtH7SEdS0edp3WRS9JFu6NkJ3dkqWo8hDNFnanexsPsVGOwcXlH2t8Pt73U71v2B7l3w0zfDnleLf+xiWTdGyY+mIzapnpFRjAr2B7p2yOi3xPCJ3kc6+p2hZC5FH4/JcDsTYRpbZNtzxW1bMbD3NflfSkXfu1v+9+xK3a61+/k7XxTlv30/FvHb9CjsXQ+bnyj+sWMjzLoxxB6Ppj4fjXVj7CND+OMVkR7oaS35x/hE70Pw0m3wu0vksVH0uYbOMSeYmYnoTaBz+/LitK+YMAqqlB59b5v89xL98l/BT5dKG8z5G+iQc333h6F3T+naBO7vYUY1xcRoFX1iKPX5aKwb09kU2unsb0R75X7LZH8WET7R+xCsXwavLYOBTlfp5rJukkSf4SI1JFoo0d/3GVh1hzx++mfw6l8Le38uxAYk68Y8LhX6HMK2iX6wGx79tvN6m0X07ZKmuvJ3+c9fGClKSfQjTa80wdg0RV8Moh/Hij6RcNtnRoAlgk/0PgQdm+X/7tXutlzWjbmxhwbTg65G0e96qTC1sup2WH2XPH7ie/DyH/N/bz5o3wRoqJhUYuvGIfpui+if/in075XHsX738wc6oH+fPO7bm/vYnVth5R9y7+dFtN/9fUui6B2CjvQIieULr0dvyG9ocOSzY80xRmP/lBqxPsC5b3p8ovexP2Amp9iTn/JV9JBO5rFBqGwUlbbrpfzbMRQRIov2CSkalVcsGH982uGlC8Zq7RK9rehfuRNqW+RxbMA9f/3tLsEbwh8OL9wCd/9n4cP9XStBx6HlaDnHxbauksJAF2aZeLNubHIeqap/I3j0dqC4t7Q+vU/0BwI6t0HH69lf7293h9utq9ztORW9TfQe0hgagJnOYjdt6/Jrp9ZynM6tbrZKscnYEG/TIlHUudI/Iz3wp39PVea5EOmWCVn254Gc48kL5HE0i6Lvz0PR5xtD8cLYNkdcCmh3FFcsxPoBJY/ztW/iQ+7oz+TR29/L+x2jfemW24Z/pCv/ZNZNgUQ/0AkPfklq7ZQadttKHJD1if5AwN/+H9z1n9lft294W9HnDMZaHcFQRG4SkyoYG4TaafI4X3WXGAKdkLRE045i33Am4FdRL5+Vq8zDzhdlin4h3rlR88GK1Bs42gvVzfI41p/q0Zvz1rdXOp/nfunESwbgf+fD2r+5xzETbAq1JbavgIZ5MOtYeV5s+ybaBzVT5XG+v7n9HczoLTKMor/jA/CX/3Kft74Ct/6rkL2NXB79hofgp8emH3/To/DUj2T0U2r4RO+jqOhrg/Zh1Jv9mp1fXZB1Mwh/+RjcebWjzAdcUst3pqSt3k1N82IrekP0oRr5n8unNzdgIUNrQ/RTl8j7E3FRrrF+qJnifO6AR9Eb66ZdfoP7PgXr7hOl378vdaRlOoVCc8T3bYAph8Lkhe7zYiLW73bu+Sr6FKJ3fpuoRYDea7B7RyopmiCmd3ZpLqLf+izsXZc+e7uYFThzwf6e48G6UUqdq5Rap5TaoJS6NsPrP1BKrXT+1iulOq3XrlRKveb8XVnMxk9oJBLwj68Nb7nki2iv3BDZ1Ksh+oa5LrGGavMPxoK8r3uX/BnvOFQthJrv8Nn2jF9/0jlukdPODNGH65zj5+hIDKkUEiwz5DP9SPHE+/a6hJYk+r5Uj962bswkM9um6Gtzj59U9AVYN1rLtdQwFyrqRHnvLSLRJ+JyLuucGEQmonzie3DTuanbIgUq+njU/Q3BPRfeDtu2bjLZc4ZYdzyfun2kmUMjgWljIDT2wVilVAC4HngbcChwmVLqUHsfrfUntNZHaa2PAn4C3Om8txH4MnAccCzwZaVUQ3G/wgRF11Z44rvw6l9Gf6xIL6Czp3C1b4La6a7SK6+Gqobcater6KN9QmDGcw1WQrgWInneNDbp7l0v/+PFJnrHyw3nqejNOStEcRlSnn6k/O/Z6RJ9VROostRg7EBnajC2a7s8jva5RJeR6AtQ9L175Ls2zpPnkxfCvtfyf3/belj5++wxDdPO2unyP9Mobss/YevTqa/ZRJ6PRz8UyY/ozWfoeOY02p4sRG8+r5D6MxseGlnQ17yncf64UPTHAhu01pu01lHgNuDCYfa/DDC5X+cAD2qt27XWHcCDwLlZ33kgor8dHvg89HmyLUzwb6Az/T2FwhBC9075PxQRn7Nzqzzv2CwXm7lJqxqF7Av16GMOMRllXl4hyjmXdfPzk2H5jZnVeykUvSqD8ip5bkggPgTr/55OZCaYWpCi3wMqAFOWOO9tdVVquEY+2w7GRrpcu6e/3SV628e30y7NNVEI0XdYozaAuhn5+8Kr74IbToW7P5R9ur75LnWG6DN07uZ6s+1B276ws27Kgu5jG2mK3pyLLIre+9ggSfQvZP4e+Sr6gU649Z2pJa/t/PjhYK6JyQvHhUc/A7ALdmx3tqVBKTUHmAc8XOh7D0hoLQWNnrk+fZ3NHoeUR1vZTmv3ojOWwK6X4PnfSLofiHXTME9ufoDKBghV5T8zFhxF3y9/tqKvqBs+MBePwe5VkpmTcYZtCYi+LAjllfLcdEpr7obf/1vqPAJwCT4fxRWPCWH37obqJqh3zmf3Tvc3CNXKZ9skDvJ7B0KiQPescdrW73rURtHHh9wRUiHWjbEAGxxFX1GXvwq95xrXcvIqYIM0Re8hSq1dorcD/inWjZVHb4K6XgLP27qxrrlsRF8WlMlzdideqEcfGwC0K6IAVtwI31/izo4e6ICbL4IVv87cxqZF0pGXsNppsYOxlwJ3aK0LmuWglPqgUmqFUmpFW1tb7jdMFLzwW1jrzPz0XqhG0Q8WoOhf+XP6qklRa1KGuRhNLnnrKrnReluhca7rr1Y1iuosxLqJDbrEZLbno+jNa7F+l9RVwH295ETvfEcTlOvzlCAoRNGvuAl+eATsXCnEWD1FRg89ra5yDdc653Yg/fxOXiT/d70s/6O2onfuC5uAClH07ZsBBZNmOe1wOuBc6aWxQWn7Ue+WeEsuog/XOXEZz2/eu8ftyE1H5v0O9sxY07FE++Chr8rcAUhfYnA4j75qsnMMD9HHh+R8zjlJnu+0VH1S0ed535k229bazpXSGS93MqdueQdseiRdzEV60IEQQ7WzAM1QdyuDsdIsn5gP0e8AZlnPZzrbMuFSXNsm7/dqrW/QWi/VWi9tbm7Oo0kTBC/cApPmyGPvTdszAuvm71+Ep36Yus0+riH6fRbRm4t82pGWom+UQGouxWgv3DE04O5vskLyUfTmhhoadInA+Mj1s0qQdRN3iL7K/Vxws1q8Sq53t5B1tCf3+ehrk/Owe5WQfCAomUc9u9KtG9MhKusWbF4s/7st68Yo2oEOUbz2CK9QRV8/E4JheV5RJ51erjIQ5rernAQtR6N3PM9ANE50KEEi4XYS2/c41lKoyuncPddt5xb5rwIpo6a4LQJsj75Gsnd6e7oYev4W4usecN6Q6tH3dgrB7mzzWJ+D3a5wifSgteZXT2ziwp8+yd1PvQhoIvPPQqsAQ1utMh3O+W7ds5tv37+Wa//8MtvaUzuReELzyNo9rNrexVBMhMim1zfz3pueY/XOruTkQ/3cDZL62fqKpPN6RhbxwR66E2Gue0za/r27HudDtz5PPJGj8x0BgnnssxxYpJSah5D0pcDl3p2UUgcDDYAtKZcB37QCsGcDb8AFRouITY+Jmpz5ZiHcxefKTeAdovYUqOgTCSGlnqbU7ZEMRG8U/b7XJJCEgtnHSclUEEU/oApT9AOdJEcOJoMkL0Xf6R7LdBxNB0nqX9MiGVprDUoN35Z8kRiCsoDkuIM7aar1Zet7OIj0QLQX3Xwwqm2tnN/G+dmPbWc1GUVaNZlEfzt79+1lCojaDYmij0X66AtMZtJQm/u9Laze0kqgfDcHm6b37qXMJvpIL539UV7c2klDdYg7nt/G4+v38rMr3sRhM+qTu2mtibZtJNwwlw17eviv21byvXnIcSPd0p5scDq+9kQlq/pmcULb7Rz5pb8QpRyARVNqWDS1ht7Vz3JzCHb0B5hRUU9ioIuNu3uYVl/Bc5vbWfXAQ3wcWF9xGAt3r4Z4gtuf307rAy/xceejbn7yNSrUNt7e28ljnVHO1opbHn2J/wjs5ZnXdrF9+TYuHoqyc283v7h7FQGluOD1rRyjYMVr2/nTjc9y6PQ61rd28etoD73hqdSwig3bdvLL51fxxxXbaK4Nc9P9L3BRGD5yfwdfLZ/Ec0+u4M6tz7K7e5BruzdzOrBhy3Zu3LyJMqV4fH0bV504gxkvfI9Ni97P8m3d/OeuL3Jt7EriZUEeKIeBjl282NnB+T95kucqXqVXzWTuwHaGdqzk6WO+z5TVN1K1azdThuKEgzJi3bB9F5XxCtZ2BaEcXt6wldPOPZ5AWZGudQs5iV5rPaSU+ihC2gHgJq31aqXUdcAKrfW9zq6XArdp7Y4FtdbtSqmvIZ0FwHVa6/1YfHsc4oFrRdFdfrvcRNMOl3ou2aybfBV9/z4hMW9Qxx62JhX9BlHbQwMyqph2uDOByPnpqiaLZVJIMHbA+llNTnheir7LPZaxaRafLfGE6UfBxodleGyUaBbs6R7kZ49uZFfXAP9+0jyOndvI9o4B7npxB0vnNnDSwia27OujoX+QGhVgTVuUw0Csie4dSaX8t+de5fHXX+b/nb2YKVGxa/7a1sz5rGXLlk38z/0dvPOYmRw/fzL3rNxJX2SI2oog0+orOaizhyll5cTLa3isrZ7v/vBxvtcfYHDPJu59ZSVfLYcrblnDd1E00su+9k5ah+p5U5kQ/WY1g3nWd2pr7+CJp9fxReFUrvjx3ziiri+plP7x8iY+9ujD9EVluB8sU9RWBHnfr5fzybMWs7c3QkV5Gfe/0sovdr/G7qmn8sU/vczqnd3c0LaX7wfgvT97kIMPX8qSljp+9cRmAmWKmQ2VzGqs4ti5jRwT3Ecd8NW/b0fHpnJqYIhvnVTGrurFRIcSPLO5nUfWtvGlg+pgM3z6ng18AUXX7s1cvtKdZPaFWhml3NV3OJ8te4nzvnEba/rr+V5THBwt0tHTxw/ueJlzwz3EKqsY0lWcN22Qst2aMFE+9+cXuaQiQSiguftFuZavDg1CDJY0l/PjrkGe2rCXw5pklHT3Js27A3D9Ayu5K1HL1W+Zx+fedgibntoH/4C3nXA0tWvvZEGwjLaeCLMbq5kZ19ALRzYrVn/4XF7b08N7bnyOvz5wP3eGb+eXz/RxSKCRY8vW8fXj47wcnwkvw6LqAZ685nR+8+hqmp7r4Jmmd7CxPMBdu6fw16eaubkyRFN/G5d851G0hqpwgC907WZxRR0fPn4JPA7vP246Z5wyjJAYBfJR9Git7wPu82z7kuf5V7K89ybgphG2b2LBBKR0QiZrgKi4YGUG66bAYKwZAfTuEQ8y4Py0RtHXtgjRJ+IytDzobVILfaAdjniX7FM5Cc7/Ecx/Kzzzs/xKIIRqpO324hl9tqKvd2yZKARD6cdIEr27JGF0xnGsn/YODt58s1ygQ4M8v6OP3d0Rjp8vvuvW9n5e2NLB/a/s4tVdPfRGhgiWKeoqy1m2ejfBMkVCa8woeM7kKrbs6+dbwW28NRDnA79bzbMV8Men17F62Tauc5qzfdcu7tqxg7tX7uDs6tf4CbAhsBDiT/CdOx7n/sRx3LeqlfrKcroGUuclfDm4nYsD5ZzY/x1ivZUcOz9Mz0Adc0M7eOdB9bAOeqnk1b1DNKl9TFUDtMw+ArZLPvuHlvXxgNWfnTCrgnlNzeCUCjptBkS73I67t6eL0w+ZyqVvnoVufYV50xoYqJvPO//vaT5/lzvBal4dTFGd/GZHmJXxTq67cAnrn3gV+qGlMsYNj4vVsGhKDVPqwqza0cWy1a38/NGNnFy2iltDEA/V8qkr3gG3/ICLp+6GYy9I/R1f+iNshqbGBgb6JnNwcDPfu/BIWrsHmVRVzqWty2B9M5efdTHcfSsXz+zmw0tP4192PA4rwhCPcM2pc3n7IadQ+/MI57/5INTKFcxBrusjW6r44ZGHwN9ganWQVz5xjnzud6+BGCyoVzx05akk4gnKenfCD2D+/MWw5R9cfVwzXzrzLBqq5fpbWCH3xMWnHgM76ziiJsQDV5wix7spAL1Qq3shWMaSlnr+es3JxNf1wP3wgeonxdrshKNbqjl6+gx4GUKD+whVBPivY8rhOXj7aSfDYRdz7GCMD+zp5cjldxPZ1MqSKXVMqgrRMxhjyuAQU5qamLVkFjwOZyysp1TIi+h9FAmDXS6hv/ag/J+8wMlwsUhVa1eZD3a51kV/u2QszDsl/dhJJe/ky5uMD/N5zQfB60+IVxuPwoIzYOMjorbnnOge55j3yX/jIw+HWL9k6ER7aduzi2R0xVL0HYkKGoBdbXt4ZGuCkxZOZs7karoHY/zoodeoXb2CjwMbduzh5j+/wHXAx/60hgd2bOKqis38N7By824u+91GokPpFRHPa2rj/EXQOf0kLpn8OpMHt3B38Bw27+0jFCzj4jfN5M8vbOe5ze2894S5HL+2npq9FXzzomPhHtjcuo8j6tpIoIioSt55aA1nn3UKtzy9hZk7XoFWuOaKi+HmX/PWGQk+f/np/Oafr7O2tYdrTl/I4qm1dA/EaO0eZOZTf6Via5gfXXoKR8ycRHNtGO5dCOteY1pzAF4r557/Op3um28kurOTuqE4oZY5sKMMdIIP/svJRB+uIpToh4pJhBODzKl1h/H/sbQO+ofgAaCygQsX1HPhO4+WF/96jdQHOvydPPaJH7BvUDGjoZLBaILqjjXwS5i7aAlXNszhPcfPYbD5eLgVvv0vc7k8/CZ2dg5y1qFTk7ZBZCjOPzfuY2jVNngFvn3FW6iZuVhGe8bmsuFcZz9+z0mwcjM8/AQXL6mFipny+s1bYNJsZi06AoAPHAoc0QKbe+Ua6m2lLBFjwSQ5F4RrJE7kpHMG4xHOXzIZ/obr0WudGowd6KDsR0fCaTLmOfHoI2ELHNqooNoSGT2tgJI4SrAydWSaIeumZVIlhEWElEW63KyneNQNxuq4tMUUB3Sym2oryjl6dgOsqqMy0c+vrnyz+1m/UFBd745WS1iT3if6/QmTHw2SzlcWlGBsebXHBukQdVvbIso+0iMWyDM/l9mFn9smN4ENO/2vp9UlehMAaj5IIv9bnRBK02KxbLY8lUr0BqEquaEcJa615tH1bTyydg+zGqo4bn4jh0b62TdUxVRg5bpNnOUky7y68XUOAa76wyvUtW7n+0kSuzMAACAASURBVCF414//zlY9lYryMk5bPIUVG1tpjyT4WpP48mGizKpV0A1r9kT53NuOonr1C7AHPnLz00xtmMU3Ljqcta3dhAJlTKuv5LAZdcy85xLY8gK881W48d3Qu5t/++xVKV/l42cudp/sCUNfmDMOmwP3wLVnzJaMm+B8KssCVAb6mdxUzZfOPxT++TC0QnDaEigr5+LFQZhUyefPOyTl+PWV5cxqrIKXAlAe5oxDprovVjXKqCnSk5ykVVdbB+E4RAfld6yYBINd/OuJS2BFs8RsmhZJbCPWLwFMHZdg72AXoCRwbo8CIz0waTas+hP1dTOoP+urcl5j3fCXj0CwkksufAc0SPC/stYJmw12c8SCSRwxM/XnDwcDvPWgKdBbCa9ATV2jiI3a6W7aoA1z/YaqxHIDCXDPPVked26V7SbbyQTBI72SidS/V4KxhmhDTtDaxG3iUTcGYog+1u8SbWxA7q/BLrfMdXWz3GPe9MreVomhBJzsK/t1O48+kYAyJ1huOpTG+ZKBFetLJXqQjC0zy7zRNuFwJg72pMabIj0i9Ey8qIRLW/pEXwhe+bOQwtlfH9n77fVT2zfJRIlA0MlwsW5aY8NMOUSIfrBTiL7jdbnhu7YLcTsYjMXZsHadeM7A669vYO7MY+SJuYibHLLb9CgAd22t5PT551Ff1QjVTTy4ZjfLX2/ngiNbOHR6HRFVSSVwx7PreLUjwIvrN7N6TxSCFUQcZX17aCcJymguK+NNzQlw3Jt9bTugDLqiAS45ZjGsgo+e2MyiI0/k/x7byAuv7+WRwEfoPPNaZul6eBJm1SiuOr4FlsFvrj6Z+bNnQcNBcCccOb2Sj7/rzSyeWsspi62srHhM0v1i/fDXT0DbWkA5mTVWiqYNk14ZDMu+sQGZwGPq0tjB795WCIRFcdZMzZ1imRiCQHnqtspGN3YSqpVt5ZVC4omYkFlVo7S3rEzy77u2iSLc+rR8t+pmicH0tQkRVtRLkNuOocSH4OB/kd/7nz+GQy+AGcfAXz8Je9bC5bclSR5wS0B44yd9++TzWxyyNsrW7F/dlLnCphmRlle7RL9zpRB9Ii6jjUMukPMJVipln3SAZeWyzVyv4Vq3HhEICZpZ0obwvRlIpq0mBbSiziVYkGyfNfdI0oHJ0y+vSk2NNN9DJ+SerHC+d3+7dLiX3y6/xU3npHY+ILZp+yb5zSs9BQDCte6ym6azi/bKd0wSva/oxwdevh22PjNyojcrG1U6Ks+UHPBaN90W0W/8hwRkJ81Ojgh2b13PgJrJnMlVaA0f+8OLvGX9Wg4OlhEkwa/uf5rpsWP48GkLINKLAj76eIAf6jKCq/5El67mE3/bTl3FIq56yznsunMVf3hOJrMYv/Zdgdf5n3L43l9eZF+wmUfDn6Hr0LNYcPn36RmM8eCa3bQ8oqlrmk5Z6xYmK7ejOmm6gt3wp2tOl5t9FVxyWD3MbuAX71kqJPftDmojm1LUmXIUzfzpDpkHZLj9s3ctgam16eezdZUQYSAknTAAWs5X9eTMv4EheqWciUsDQuALz5Kb0MxQNfGU2mmyb82U3JOm4jF3RqeByeXu3OKWXQhVucP/8kohBfO+qsmSWljhEHm0X/ZXZU76ZsSZ0FadSrgJ57PP+YbMzXj2F/CvN0D7Rph/Giw8M7VdYed8ejOinrleZilf66RDRrrlsw3pVjVBx5b07x7rExIPBKGmWUYcZh2C3t3Svkmz5XUVcEnNkF0gJJ2VETyh6tRR61DUrWRq8ugN0Vc2ynVgvkuynlFtKtEvv1EmMwEsOsc9//ZoOtbnJioMdrlEP9AuMaymRaAXAkrak6Lo24ToM2VmJTvWHpfoIz3SvqR14yv68YH2zc6QbhjFaGPni7DsC/CuW0W1dW0X5TL/NCl9m6wt45mcZAKxU8QiGOprZ1d7PzM6t1IG/OTOh7k1XsbUujAfCj1A175pvGXGEAF1EHrvek6ZFuODy9axansXF3Vu4FygtXIhv5/5c47c+Uf6q1r4w5kn8J1la/n+g1JT5orjZvPxMxezbHUrbT0RlrRvhlfh7g8eReOMRZR/azstgZ0QLGNyTZhLj50tuVS1dbA3nLJghjKPTa0bSCUUk5bZs8tVwLEB9+Y3F36uIa1ZePzUz8DDXxfPtW+P3JRZiT7ukmp5pSi1aI+QU/8+qbHT3w43Xyhe9IIzZN/aae7MzmxIxNIVfVWj/O/YClOcRMlyK52xvBIWne0S3NL3y8ivY4tbD6fcKQ7Xt1dIzBB9p0W4ceezK+rF8ksu5jGUOWPJ/C5eRT/QKaMaYzEMdsu+xsKobsq8OIrpkAymH+mW+jW/vVG5wbCrziO9kt8fCDqK3hB9TerxbEVviNwQfd0MORfeORDhWmfk4xxz5wvSaekE1BpFX5maJhztlw6pfaMzupvlflal81sq5XRMHqLv3SOlJmYdl35+bKKvmeJWMw3X+Yp+TNG9C355Orz7DhnWJxLONHItF5S5gb3ob5fKi4deIDXEtzwFT18PZ3xRiL6uBaYf4RC9LEKhQ9X0tm3h3me3cML8yVTt2Mw04JneKRwPfOzXj7As3s268E7KFBzX2MfBJx3Gzlf/yfu2/JKTm49nTiiKqmyBwS7Ompngw4sWcNvybbw50kYkVMWfPnQSSikkC1bw5w+dSPfgEKFAGZUh6bjefbwzvF+7AV6FqRVx6HNGGPY0b5ALtbxKCN1Wu/37hEwDQVcRDXZJfOHwS8R+ArEzzOsxp3RCIOx6mCZLJ1tN+m3PQt1MOPFjQiaTF0qpZDsDyAuTRw/SdkPeNVOlPQOdErRufRnO+DIce7W8XlGfu2ZPfEg6chuGHCJdripOIfoqONWKKRz0Nvn/yLecSWiOAgzXuhZDZYOMDgwpai3n1Hx2IOhaCvFo+igD5ByEatO/k70OcHmFo2qtbJCqJukchiIywq2dDovOlI6l3FLg04+CdfcLsZmgvvnegZCl6J3YRSCU6tF7rRubVL1EXz9DZtumEb01S3coIhOXjv0PEQIHn++2yYiseEzaUNfiEL11vP721Hs+GJb9beumfaPc40emTTOyBI8pX2FNoEuOcnxFv/+xe7Uo650vCtH3trqKwvuj23jpD7Ds83DNC+7Q9dlfwAkfkYugfhYbQwezAHj//QOsWvYQ36Gf2ZEOvnCX1AD5RvAl3hao4ZN/28U/K+Dtiyo5Z940go+IN37erCiB4+fAps8AsHDwFUhUywhgoAPV28pn3nEwnzr7IKJ33UX49fqME46UUtRXlqdtB1w1Fe13CcWOMYCjNivlotdWRkw86vrRYYckdqyQEgHBSlhwumzraSU5yQotpGPUDaQq+q3PCvG3HO2+vu05WUQjGIazv+aWMRhuOb7EkFtiIVjhquLqKcmgaLIuzNJ/d2/QUE36VPpMxw54rRvrOglnIvrKzMcy57+/XVR0dbNMcCsLin8fqklfgs98dlm5O8s00yjDIFO9GxP8jPUL0Ue63d8QpC0go4uHvy6xokVnCpnbVkvLUYAWcjUdu/muwbBL9BHHuikrl+9hznGoxmPdDFrWTQZFr+OulRVwRgyhGjfQu/sVORezj4clF7nHtRW9OZ9mRq09h2Wg3Z05DnJO4xFL0StZ1F4n3OvbRoWl6O3/5voKVpSU6P2FR7LB2CcmMGovzjFcbrupMrj1GSH6ljdBtIc9D/2Q7t2beba9krPuSvCuwPdpOOhk3rKwiViggqmVcR78xCl88x2Hc07LIOHm+fz4/W8F4LxFlVw417lZyoIEurcLqa1/QJSTqTdfO00uUifVsqxMURHvS1VG+cKos1i/S/AD7Z76NgOOorfI2UzpL3e2mQt8yz/d4xkF1bMr9VwOdqbaDEErcPfAtVLiwaBji5QKmH28u82o54Fcit6ybsx3q5kiHiwadq8RNVgxyX1fqDr3Qh+JWHZFD6nBWAOb9G2Y7X175XHDXAlodm6VzsME8LV2ST2p6EOWoh9KxjrSEK5LLyFtirwZ0rF9anCJvmeXiB8zy9pr3dTPcvcz14wh7mA4PRgbcIg+ksGjN4HaJBFqGWEnid4h5u5dcq6mHyHnuqzM9ehNlcoZb0r9vuVVzmhhyL0uMxVm6+9I/S291k3NFLl+a6bKrHcvklZZNqIP+9bNmCC54ITz315ubxgiGejZSyWQeOVOynp380zLe0kEyznk+Rupop918TouP242nz7nbFdN378AVj7Doqm1LJpaC09vh5lLWbpolqjPgU43NbPlTaJCX/qjEOy//hKudy6s2ulycZpFO0DIIDwCojc3WbQ3NS20Z5cEm7R2VF+lS8hlQblwBzpEuYPcwMFKJyOGlIlRJGJCXCZ9cKAjtdMIWEGqwa5Upf7Uj+TzFp/jbjPqeVjrxuPRm5FIzVSX2FtfFp/WHgWFa5ysiSwTv8D1yW1UTkLWUdXW6CAPRW+Ivt8h+hOvkVHRhofEugmG5ZwNRSxFb1k3SfWbIUBsUJGhPEVS0Tv/B7vdQmgg1g24/nvPTiHnWH+qdROyhELSKjPXhENqibh8XsgQfdRKr6x2j2c8czszLTEk10sglNr5VNRLWRFzHYVrpX07X5S211vfxW7T0ICbEGGUu52BNdCROjoznak593UzRGwd/HY3nmHDGxNJWje+oh9bJKsWGqJ/3X0ti6Jv74vy7GrJWinb+BAA31tVyT3V76RB9RJUCd577sl8/aLDUy0TUxJYa7lBu7YJmSolRDHY6WbszDlRLqj190v1vebFbunZmqmi6gc73RvVDI0LhW3d2ERvfPp4VEiyvNK9qUzQEFxFD6mK0F5wwxzHpLr1t6e+zw5SRXudmb0JmUTzwm9lcpeprw5u9saw1k08nXhAyKLSIfq2dUIuKefDuSGHqxhpjxYMygKux53Rusmi6M35Tww5Hn0NXHYbnP0NOPLS1PYYK8N8tlGbIP+zWTfh2vRgrFH0yeunyw0kgkuq9hJ8+zbIaMO8BpZQsAqzea2bZJXTSmljwloovLzKPYZJC7VtpsSQCKDKBrdD6GmVtp7yKXifUxW2rkXulzX3iJr3WpjJKqYDbiyhdiqgXEVv1lqotEZ4Js5gzrMZVRxyPhlh7K+konfOe2j/KHqf6LMhqegt68bcsB7F+OymfXzyjys5/ydPEoymDoW/eNW7+J9PfBBmOgsyexUFyEWt43LRdG0TAjUpWhWTpGPp2iZDRycTh47XXS/QlFutne4OO19zFtGI9qbeqPnCa90YAjdEb4a55VUuOYesm9NW5vbne+uwg7vO6IDXujHBWKfuTiImWTVPfE9utFM+k3ocpdzU1WywydiMOqomOxkrzo2s4+m/kyHp4Wq4Z1L05vhgdYK2dZND0YN7TgPlcOJH5dqwR1xGVZZl8OhzWTfZFH2KdZPBo99pLZ79+hOyIpptWSQXdulLvVbA6Ygi7mcEK117JjYAKLkOkkQ/12mLXenSUfRm7QRwFb2NEz4isZZor3uf2Ei20+qQQjVyboxHb+73jNaNc55bjob62e4EMS+S14/zHcyxTXt9RT9GSFP0myVlTJUlFX1nf5TP3vEy77rhGR5d38b85mqOatLuBdG4gCMWOFMOT/2MXNCGqG0YAoj2pU2hprLBtW7qZ6YS0EIn9W/x2TIcbpwndWrqZ8Ht74WHvpIyI7MgJBV9n0wwmeFMwDKetq3Gkoq+yr1xbKKq8BC994JOEr3HurGDsUZJd+2QIOyC090UORtVjXlk3VjWDbgjCluxpSl6Q6yO6osNwo+OklWpksfO4NGbNoGl6C2LIx+iz7SP3R6j6G3rxixikcu68XZctqI3KyXZv1/FJDnenlcBJffDyt/La3ZaYXmlvG7X1DffKVghnXeS6MOuFWLiPkrBorPghI/CNCmbkDL6SAy5eejm/Ay0p7YV5PW3/wA+sVpI34tMij5UDZX1rqI3I/iUrBuPdXPyJ+BjL2QfPQXDco+a820yqEyVU1/RjxFsj96kVjbOJx6u56/Prub8nzzJmd9/jDte2M5/nrqApz57Ord84DhqdC/Me4uQulkzFOSi/ZxD1l7YpGqI3ij6pHUjGTtJAqptgWYnL/uQC+BT691Vja55Xohw9Z3uhJRCYdRurF+Cnk2LZfhpJnPZN69R4baiLx+Boo/2eIjeOa5N3B2b5c+aGZyCqsmFE321M0GrYjii91g3Ax3Sjo0Pu/vEM8yMBbfjN+chn2Bsio9fneF1SxxkDMbmY91kqCxqe/TRXqfujPX7KSXnWMfld5s0W1IbAyEJgtr7lTuWZMxr3TjtSy45WekGY022D4gdcs433O/qtW7iMflc+/x4Fb1B/czM5yGToi+vkuOYkaH5b892NaOSeFRiTGWB7Oc52TZrBNW7R65Dc82VWNH7wdhMSMTF16twSLZjM/TvI1o3hz3RSgKJDuqag0yqquPatx3Mkhbr4hpwIu+X/i7VP4b01DsD+2Jr3yQXrunpKyZJFkikW4qZ1U4XZbDwdNdvNF6+QTAsyn7jw4AamaIvK5Mc9c1PiLKpnyk3XlLRWzevIWc7JS5okZlRWfWzU4OxyckrLaltNzDBWHsG6ObH5SZvykL0lQ3uwuKZkMmjz6joc1g3JtW2zVr/NJt6NkpwpNZNpn3s9hiyMERjrJtEQs5vNuumoi69smgy62bA7QS85FnV5BTOmynnu+N1sS68E7NC1c5M05C0KTniCLv1nMBRu+XyPDaY3vmZtnmJPhGTa8/uFAu1KVMUvbFuqkVEbXpM7M+s1k3M6UiznF8v7Fm6fXucWjyO1vYV/Rigr01uEFPvY8M/APjhi7BnqIrjpil+d9Xx3PK+N7Fk9ffcpd8SCcfTnCS2ijMhKidSrJvNbiAW5Ebq2Snqat6p0lm85044/UvZjweu1YJ21WihOPrdsNVJi0wSvfHos1g3mRR9/SyxohrmpN5QZnRjFD1kUfRWcHXjI/K/aVHmNlc15s6jT7NuprjtN6rYrPxlkPyNHEVvbsq2de4+2Tz6So91Y+eH50qvhMwLg6RYNx6P3qhj73YvTIDwpd/LBC1wyTc24KpPrx1ifPr6We7yh5lSCk1pD2PHGARDTkkDy6M3oxCTyWXDXBNe68ac7xSbsMBSv/Yi8caWK6+S2et9e8SiymTd2B79iIh+b2rwOliRumJbkeETfSYYf75Fcm4HXpI6Kvfsm0HL9BYaTV2Xf1wnaX7//Ik8j3QBOr2gUS54rZvGue5rS/8dTnMmYB18nmybe3Jmf9qGiSeAm8JVKI650p1cVDfDQ/TWMDdoBWOTPqx1s771C3DVQ25dEaMaTRzCBJDBk5PvTDXvsxR9lzOTNSvRO9ZNtrVQMwVjDdGbkVGoJv039Hr0hqR6drmBtUSGmbEAVc6xvIq+LJh9uJ+rM7Dbk5ZeWe6qTXu7F4bAH/ySrG8KbgceG3A9ai95GoKaNMv9HWYdm358U5U15smxD1Z4grFhORdxZ2lD+xowr0N6MDZp3YyG6DMp+ioRVSBFALNZNybrJpdlY2BbZb17ZJJesh0VvqLf7zD+vDMLM7zzWbYwnd989DymTW2RHv61B6VKYHk1vLbMWc/TueFtCyAflFsZFE4sIImpS+C0z+Y/OjAI17ge/kisGxBiP+Tt8rh+hpsrHI+5fmawwr0Rs6VXhqqEHMwsxKEBuVFyKXrzPLkGrfFuZ2TvvCobxT/2Toc3GC4YCzIa8+bQg5UHbRS9VZbBzBGIxzLbcybrxhwjU8Dai1w+fsb0So91k+wAsmXdWNPyI71ia5lRwNCgS0rhDNYNiKJffA4c/m9iFaa1scotzGZ/n0BYzl+KR+8o5KGB9O9rLLwU6ybuWmV2J+IdfeSCTfR2Bc5Js6BxAWx+TK6/QDi1XXZnmreir0sNxprYEPhZN2MCR9FHmg8HoAxNzaKTZTJTZYPMknvxVlGiF/xYbpStT7tDvIoCid6os73r5eIdbl3SQmBmAY4kGGtwxpcljbF+lpMrrJ2iW84EsvqZqYo+lEHRG5i6IrEBeb1uhow6Uoje4/PaefFGPWZT8+CSarYUS++EKUi94aYcnD57EizrxrlR7Ztyj+PTZ8u6Ofh8WQyj0emsA+WyXzZ/HlLP37CK3kqvDHitG09+vRe2nx2PpNdlTyr6Yaybuha4+FeZCdb+vdOsG2sx+GCFk0dvsm681k0mos9m3RQqsqz4WKxPrjdzHuefJpMP+9rEtrE7f1OYLZtdlwlm3oLWcswam+h9j37/o6cVjeJTy/ayV8sFPPngt8hrVY1ys299BmafIEWoAmFYe587k26k1k2rs/xbsYjesZ5GrOhBRhKnf0Eu8qlLZFvrKqlhUjNVbI9k1k11Zo/eoLzS8mwrpGDYpX9IHW5nVPSOdWNGKNkCsWDNjs1SpiKlqFkGRX/JLXDBT9PfZ+yFpHVj3ZTGp8+WdVPTDKddmzpjsrxqeKIvK3NJKJNHn0xfzJR1U6B1Y2DHNmKD+Vk3w8HU4zHF7wwC4dSSBobo47mIPot1YzpOGEEw1iwS7yh6u50L3iod6ao/pd/TIwnGmqybSI98d9u68RX9/kescwddgQb+8soe1z82NVXMD97bKgGoULX0/Ov+ZtXHHqF10ypFzZLe9Wix+BzpjKYeXpzjTV0inv3OlbB7FUx1ljoxN2a5NW09q6IfcBdfqJkCB52beqN6Fb1dFyVJ9MMoehP4zBaQta2buW8R28E+nlIZC8ChVGq9G5N1Ewi7mTfD5ax7YcczsiF5XjOcy2T6Yn8Gjz6Un3VTN0NeM7aLHQuxs2685HnoRXDW16A5w5wQG8a68QZY02bGVrhFzTISvQnGZsi6MefbdIYjDsaaWIIVGzn47XDed6VU9RGXpL7PlGwoyKN3grEmh77aV/Rjht7IEC+9uo7tsTq+cv6hNE2fI+Rusgvsnt1kGix4q9RsMQWeRmPdBMKpVfJGg/qZ8P4Hcgdu80V5JUw5VMoD71kL0xyiz5VHn3x/lXtDeTsCezKNDZv4TSaRWcEoE4yiX3EjvHBz+us20U9eILZDpnrtmRCqtbJuHPU17TA5F1DYML68cnhFD26nmSmPHtx89EwePbhEmslOAlHmn94o2VWQmsZqgrGBcPpvWdUIJ30sc02XlPZbv3eKdRP2BGMrrKybDERvOqoURR9PPd/mHBXq0QdCYh+arBu7nUrJqPOK22VCVMr7wm6doUKIXsfdiqk1GTz6bEkEo0ReRK+UOlcptU4ptUEpdW2WfS5RSq1RSq1WSv3e2h5XSq10/u4tVsNLgYFonPf/ejmBwU6mTZvB+06aB2/5lAzlzUVtiN6eIDLlUPlviokVquiDYSenPC6597luoLFEy1HyPRMxd6SQkl6ZhbDBuYGdFaC85JFUr8MQ/bxTJftoVoZUPoPa6RIsXP8A3PeZ9Ndtj75QhGtcVWnUV/0siQeYKpLZSNWL8jwUvTmX2ToE7zT8pEfv/DdZJNnmb4AQo4k/2EvqxQbFZiiUOG2Eqi2rzg7Geog76dEPZRYB5loyHZp5nLBSG83xC1X0ZmRksm4y2WSZMNJgLCQXPE9T9DqR+h2LiJxXvFIqAFwPnAVsB5Yrpe7VWq+x9lkEfA44SWvdoZSyzCcGtNbDSLDxgURC88nbV7J8SzsLJ8epbXJ8yNme1WKMYpx2hEtCxrvevlwuylxKzQulRJFEe4rnz5cKLUfDi7fI46SitydMZZgUZGCIbaAj/YY0BO/tIEzGRahGOsBc2UehKpkl/Oi34PHvpi7GDKkefaEIVad79BV1qao6X3U3+4TcJGrOoXcheAPjdWeaGQsW0ecgIhPDsa2bWD/EGFmdJIPyKglweksYJ9MlnRhA0qOPukXcbGSqFmo8eq91M6K6TpXuzNhsoycvRpJHbwqfbXlK/ns9ehBVn+81VADykY7HAhu01pu01lHgNuBCzz5XA9drrTsAtNZ7itvM0uMHD63n/lda+fzbDqGW/uzKwCj6mUvdbdVN8qMNDRYeiDUwF+obgehBSMbYWRnz6LMpesQ/976efF8Gjx6yk10mlAWc4+vUFYAgc4XJfBGqSZ8wZYjFdAD5Hvtfvgtn5Jj0lrRusil64xN7OhlD+CZdMNcow5xbO65h0isLVcje42qnbrw3GAsyYlBlbozGBGjTZsZmuJZMnRnbulGBwq4TA5P2G+vLX9EHw04cJJI/Mc89Wb7n2vvkuXfCFJTMp8+H6GcA26zn251tNhYDi5VSTymlnlFKnWu9VqGUWuFsv4gMUEp90NlnRVtbW6ZdSopH1u7hJw9v4N+OmclVb5nnrKqTRRnUzYCDzpMl8WxMdeybQv15A3OBNhYpEFsqTF0iF+uUQ1xLwC5TbIajJs3RRrLGens6eSXroGTIuoHCU0SzrTc7GqI3tc3t4xoiNERfTDUWqkIqOWYgOnADeGkzY41105f6POvneBS9CrgzY0dr3YCTG+8JxoIo+mCFOzHOwGvfZVLMyWCsc75DVdLWTIH0XDCxBK9HPxwCVmdayMzYuSdJ51DZkHqtlHiB8GKZwUFgEXAacBnwS6WUYbw5WuulwOXAD5VSaWNvrfUNWuulWuulzc3N3peLj0gvvPg7iPTStmsr9//xZxwyrZavXXQYyviE2ZRMoBwu+wPMPCZ1+xTHvinUnzcof4MQfTAMh78zdTm2yQskRbFpoeShX/2IZCJ5YW72eCQD0WdT9M5NVGiKaKYbJ5EA9CgVval142QCmUlHSUVfRKIvryRZyTETkj5xhqwbcIOxuYjIELK9Jq0Jxo5G0afU67GUtpfoIbUz8pKtUu4owMzUNr9r0qOvGrnNZKybrh35J0KYz4325k/0AIuchXJs2wZKrujzueJ3kFwKHYCZzjYb24FntdYxYLNSaj1C/Mu11jsAtNablFKPAkcDG0fb8FFhzd1wz0fgkW9Q19/F/+peYkYDvQAAIABJREFUtp1xOhXlAejz1InOF0bRT3TrBuAd/5f6vHGe+OIGmSYcQfo0eBs5FX2BZRwyKXqzdmlRPPpBIR1DSqYDyKWeC/q8muGtBLM2qtejL9i6cTpRk3VT1eimV47Go8+2kpYhxsEud3uKos9gVZlMnVC1tMvMqjXn+81XuTPaC0V5lVSHjfW5i5zkgul4or2FjeIWnwPLPueW3TAYB4p+ObBIKTVPKRUCLgW82TN3I2oepVQTYuVsUko1KKXC1vaTgDWMNZJF/yexRck0/FkJp4aLWUOz0At8ShGsm7KgVHicqBiuImMwRzC2YEWfQSHlmimaC+Eay7qJpJZ/KIWif/MHZEWpbEhO2vHWozfplflaN0bROx590RR9lrr79gSo5DKUto2Rhejt4wx5UkcXvBWOumyE7ayUVbIgveJsNiStm77CFP3kBZKt5k0qyGY1Fgk5r3it9ZBS6qPAMiAA3KS1Xq2Uug5YobW+13ntbKXUGiAOfFprvU8pdSLwC6VUAulUvm1n64wZnBS5zisf5oJv/J01oSspMylP2aZ950LzwRJYsivcFYLKBpkoVUxFON4wXHneXHn0BXv0maybURJ9qNad9j4Ukc9II/oi/n4zjrGqkGZAMCQ+eqbqlZC/dVMWEHI1ir6yQZYGHM7CzAfZCrPZ1o2pm2Or4kyKPuAJysc81s1oUF7pXhveqqXZYD53JFky/35feruT1+vYWTdore8D7vNs+5L1WAOfdP7sff4JFGlaZhER6YZQLY+9to/BRIBYzQzCZsGPZGnWAi/wUBX822/c1XAKxZlfHX490omAlJs9WzA2S9bNeFH0IL/T0CDJVYPAVfolSI3LCpNe6fXoyyy1aT8fDqFqi+gbpUQvFM+6CWXKuulyPfFcRG8XzoP85gjkC/u6zNe6SVk3ocDOJpOIHGtFPyER6YZwLY+s3UNjdYjQlEWyyrx5DUZ2gR/qzTotALnqhkwEpCj6bOmVpVT0RfDoQUg9HnUUvRWUg+Iq+lywc88htdYNWGSYB9GHa1yir6h3j1k06yaDojelMCA/jx7cDsP8rsWwyuzidvmmZ9rntBhtKLGiH8dTMEuISA/xUA1/X7ObMw+Zgpo8H/Ztksk1I7VufOTGiBR9EdMrk4Q4UqL3KvoK93NKkV6ZC0GPojffK+AJxubTJvPdvCs2jSq9MkcwFiyPPph5X+9+dllh77FGCnNd5uvPez+3GL95iRX9AUv0eyIh+qNxrn7LfCkfG+mS/O6RWjc+cmO4YKxR+NnqnIw4vbKY1o1Vk34o4lROtLIvoLjB2FwIOCs1mXxyk4bpnRmbr3UDTudl/Qajsm6s3ywlvdJeRSyTos+QaWTP1QCL6Ith3ThtyNefBw/RF6GzGQ8e/UTD0EA3m3vLeNth06TGfJcTAW/fODrrxsfwCIYBBeh0Qq+YJK9lmxVZVEU/ijx6cBS9ybrxWDf7M5ieMg0/g5VQiHVjl66wf5ui5dHbWTcZFH3K5KEME8QMmSatmxwF2wpqp9O2ESv6YhC979GPHns3QN30pGrp6WqnM97ER966UF43uevtm8S6CdWMfHjvIzuSBaT60m/mI94lKWfeCWfJCVOF5tFnUvTGox8p0VuLfSSzbjzWzf5W9PFI+hKGprMpyLqxFL0dPxmNdZMs1pfwWDeWPZf06O1g7HCK3mvdFIPojXUzUkVfTOvG9+hHjhvPlPVdHcQHuglU1HHYDEetTJojF+S+jc60b9+2KRmSVSo9N3NFHSw4PX3/8eTRJ62bHivrxlRiHIOsm2DIqvlidV4jsm4sRR8skqI3xfogczAW3N+pLFfWjZkB67VuxkjRB0tl3fge/ciQcIoqrb0PtGZP9yCheB9Tmu2CQiFZJ7R9o6wS5ds2pUNyvdQs9Vu8GPGEKUvR79sIy28sgkfvXBfJrJsST5jKBbNAtbc88oisG1vRF8mjB9dqyVS90nwe5JF1YxXOg9y19gtBwzzpQHItpGKj2NZNwM+6GR1MD9m1Ffa8yrJXdlLDILOnexbjmLxIFv4YbcU+H8NjuDVlM8H8FpmKpA0HW9G/dBv87ZMWOYwyjz7S7UyUCbmfk+8s1GIiEJayDkOeVY68WTf5fN9wBo++GBZmsgPJZt14at0EQpk/07yn3JNeWQxFP/80+OzrqQuB5EKxrZtAUH4nX9GPEPaJe20Zj6x6nTKlaWxsSt2v+SBZIWqgw0+tLCWGWx4vExaeAe+9V6plFgLb8zRqe7SzV80EqUiPG4z1Wjf7VdFbpQ7s72Tn0dvZOMMhJevGOXfFEDzl1aQsuG23z3weWMXJslwXQQ/RFzO9Uiky1rwfDsVW9CDnwlf0I4RF9ENrH2DtFqlpo7zBvSmHyL5t63zrppQo1LopC8D8Uwv/nLIyx9oYdDNikkQ/CpVq1v3MFozd33n05rOzZd3k256UrJtRLOKRdtwMi6Db1Si9Hn22kZ75rsGQdGqjHZ2NFiUh+rCv6EcMc0HUzyKw/TmadLs89xK9WXg6HvWtm1IiOTGqwFW4RgKjkIql6MEh+m6X6ANBCeSXotZNLiRL5fZ7sm6cx4XUYUlOmLLWiC2Koq/KvGqTt4hdcgGRHEQfCDsWRxGDsSNBsa0bILlubAkw8YneDIVajkKR4Ihyp8KyV600LXYf+9ZN6VCodTMaGIWUJPoilClIKvrBVPJJlinez8FYcBR9FmskXyvJ9tJNJ1yM+yBUnSOLxkv0WcoymxFAwCj6IhY1GwmCpSD6sPu9ioyJn0fv9Py6cQEKOGXSXugmXdFX1EHdTOje7ls3pUTSutmfit5r3Yzisq+olxTceMSyH8Jjl3UD4tFXNqZvhxFYN1bWTTHug+M/BL2707d7rZuAh/i9SLFuAhPUuvEV/cjh9JD7wlI0bEm5U3c+0wSc5oPkv2/dlA7lzvJ4+0OJpSn6Ilk3Zm3VoEX0ZsWp/Z1HD/K97O+UKTCbC5nSK4txH8w9GQ67OH27abvXo8+m6MebdZPJKhstzNKQJcDEJ3qnh3yht4GEVkyNbJbtGYne8el9oi8dKhvkbyRrexYKr0cfK1Iw1iy5l1SjVrrgWHn0Ntko5bYj3xFGpvTKUlqYyXRJz8zYXB69CcYmO9Yxsm7Kyqxqob6iH3s4J25du2avmkSwd5dsz0T0Uxyi962b0uHEa+C99+yfz0pT9AXklWdDuFZScM3x7f+w/+vRQ3p6JbjkU3Aw1ilqtuB0mHNScdqZCd5zZ9qZbSF0r0dvMFbWjWmL/X+0KKGiPwA8eiH69e0xusqnMiXm3KSZiH7uyVLJstCcbR/5o6px5KtwFYpSePThWkA7x89A9GORR68T6YTurU2fC8a6Ka8Utfqeu4rTxmxInjtP9cqs1o01erJHZGNl3ZjPjhWxDUde5hP9iOF49Gv3xog2tkDnWrm4Mv04jfPhYy/s5wb6KBmCYQmcFjvrJnn8DNP3xyKPHtI7mECB1k3NVDjzK6NbPKcQmHOWrEcfQKqXZrFuTJA2GPYo+jEk+qA1yigGjry0OMfJgIlP9E7QpjNaRrBhJnTip08eKAhWQGSHu6ZqUSZMWddOwBNQVIH9E3vwfj6kl14o1LpRCk7+RHHalQ+8C4mAtDkb0S84XZbbnHb4yILNpUCxrZsS4gAgehkKRQhRM2UubKbwkrc+3pgIht0MGbCqOY5G0VtEn5z0UyCpFgs2wXiVbbEDhcVG0FLoBud+E2Ydl3n/UDWc/HF5bH4/VTa25cQDBdpjY4iJT/ROvm1EhWia4dSd94n+wECwAgba3edFt24MwRv7YQyJ3ks2yYXCx+ktnhwNWQr+zVfl995CM4pKhUCRrZsSIq+sG6XUuUqpdUqpDUqpa7Psc4lSao1SarVS6vfW9iuVUq85f1cWq+F5Y2iQBIoZjfWEG2fLNp/oDwwEwxKoNChaMNYc36NK92flSkidnZmWdTPO1WamQHa+MN91rAk2MM5HTRZyXplKqQBwPXAWsB1YrpS6V2u9xtpnEfA54CStdYdSaoqzvRH4MrAUSVV43nlvR/G/ShYMDRKlnINb6qB+hmzz0ycPDHhT9YpO9B6yGk+KfrxbN7mqVQ6HJNGP8WjFfIfxOmqykI+iPxbYoLXepLWOArcB3tD81cD1hsC11nuc7ecAD2qt253XHgTOLU7T88NQZIABHWLRlFqoniI3gK/oDwx41WIxgrF2ID85dM+w7un+QGC4rJtxbt0EKyR4PZJzNl6sm2Jn3ZQQ+RD9DGCb9Xy7s83GYmCxUuoppdQzSqlzC3gvSqkPKqVWKKVWtLW15d/6PNDb10uEcuY3V0t+8BHvkoUGfEx8lETRZwrGGkW/n0k102Ij3ufj1bppmFvY0n02TEc91gQ7kaybAo6zCDgNmAk8rpQ6PN83a61vAG4AWLp0qS5SmwDo7+slqkMsaHZm/l10fTEP72M8I83/dS4tNcoSCN7je2d37i+k5NFnS68cpyR03H/CsVeP7L3jyrpRY5v5kyfyUfQ7gFnW85nONhvbgXu11jGt9WZgPUL8+by3pBgY6GOQEHObMtTE9jGxkaLorfz20Shve0Hwce3RB1P/jzeUlY28Yxwv1k0gJH/7c+7ECJEP0S8HFiml5imlQsClwL2efe5G1DxKqSbEytkELAPOVko1KKUagLOdbfsN0cF+EoEQNeFxesH7KB1sxVs5yX08WgVmVH3Q69Hv52usLOCOTrJ59OPVuhkNkop+nBD9GwA5iV5rPQR8FCHoV4HbtdarlVLXKaUucHZbBuxTSq0BHgE+rbXep7VuB76GdBbLgeucbfsN8cgAan/UPvcx/mDnaJt67cWYvWqIPllT3WRfjAHxJC2aN5h1MxokPfrxQPRvjI40Lwmitb4PuM+z7UvWYw180vnzvvcm4KbRNXPk0LEBgjWTcu/oY+LBLpxlimUVw8owAdnk8T2rJO1PBENS5iNtZuw4t25Gg/Fi3VQ2pI4UxzEm4FXgorM/SiARpbwiS0U8HxMbhoBD1cXNjAnXiZo3I4PAeFD0XutmjMoy7A+MF1vq1M+MPKC8nzGhiX7T3j7qiVJR6QdiD0ikEL1ZyagYRF+b6v+P1cxYsMovZJsZOxGtm3Hi0e/PktujxIReeGRzWx9hFaO62if6AxKGgEM1nnK4o0Qa0XuWw9ufyKZuJ7R1kyUA7SMrJuBV4GJLez+nEqWqumasm+JjLFAqRb/kImiY4z4fS5skW2rnRLZuxouifwNhQhN9e1+EShUlkG3VGh8TG0lFX21lxhThkj/4X+TP+zljMXEmm6L3rRsfFia0ddPeFyVMbGQV8ny88VEqRZ/2OWM0YQpye/QT0roZJ1k3byBMaKLv6BkgSHxkFfJ8vPFRKo/ei7EqagbZLZpC14x9I8FX9AVjAnb3Lvr6euSBr+gPTNiKvpQKdywVfbbJWhPauvGDsYVighO9U60w6Cv6AxK2R29y3ktJ9GOSXpltZqzp2CYgGfqKvmBMWOsmkdBEBhyiL68YfmcfExPllYByJzhBaYh+rJYShOyTtZLWzQTUcj7RF4wJS/RdAzHKickTb11yHwcGgmG45LfwpveU1qMfq8XBYZiZsRPZuvGDsYViAnb3gn19USqIyhOf6A9cHOoshlbSrJsSHjvnZ2fLo/etGx8uJqyib7eJ3s+68VHKVaDGcnJSNo/et258WJjARB8hrIx142fdHPDYL4p+HHn0E7pMsW/dFIoJTPQxy7rxFf0Bj5J69BXQcjRMO6z4x8752Vly+H3rxoeFCTiuE7T3RQgnid5X9Ac8SmndlJXBBx8t/nHzQbb5AeNlXdVSYLwsPPIGwoRV9Pv6otSXJ+SJ79H7GMuAaSmRbVbutMNh2hHQMG//t6nU8K2bgjHBrnoX7X1RWsJxiOJn3fgoraIfS2SzaCYvgP98Yv+3Z3/At24KxoRV9O19USaFHEXvE72PpKIfgwqTpcRE7cCGg0/0BWNiE315XJ74M2N9BIpYpng8oeVomHXcG2bt0qLAr3VTMCY00dcHHaL3Fb2Piaro554MH/j7gaVufUVfMPIieqXUuUqpdUqpDUqpazO8/j6lVJtSaqXzd5X1Wtzafm8xG58R3TvRmx6TYGwwIsEq/4LwcSBaHBMVPtEXjJxXvVIqAFwPnAVsB5Yrpe7VWq/x7PpHrfVHMxxiQGt91Oibmiee+TmsuIno0A3UqgiE/WUEfTBxFf2BiIk8R6BEyEfRHwts0Fpv0lpHgduAC0vbrFEgNoCK9hIgTrXul0UnfPiYqOmVByL8PPqCkQ/RzwC2Wc+3O9u8uFgp9bJS6g6l1Cxre4VSaoVS6hml1EWZPkAp9UFnnxVtbW35tz4TElL2oIYBKnS/lKj14aOYa8b6GFv41k3BKFYw9i/AXK31EcCDwG+t1+bo/9/e/UdHVd6JH39/MgkESIpAolLABi0gUgyQgCwgP/oTlZIqUMD1LKlbVFaPBNftAfyxiLq1K+sRz7H0myoqlC9QvhS+QVEWikFOwTYhJggIgpBKLKVsKIE00MxkPvvH3IyTkB8TMpkJN5/XOXMy95l773zmmZvPPPPcZ56rmgncC7wsIjfV31hVc1U1U1UzU1NTWxdJjQ+AZLlIor/Kum5MgLXo3SN1cGCkUergWEdy1Qgn0X8BhLbQ+zplQaparqp/dxZfAzJCHvvC+XscyAeGtyLe5oW06DvVVEHn5DZ9OnOViIsHibNE7wbJ1wVGGiVfF+tIrhrhJPoCYICI9BeRTsAsoM7oGRHpHbI4FfjEKe8hIp2d+ynAWKD+SdzIqqlN9FUk+Cqtj94EiMB134BeX491JMZEXbPNG1X1icgjwDbAA6xU1YMishQoVNU84FERmQr4gLNAtrP5YOD/iIifwIfKCw2M1oms2ha9XMTj/Zu16M2X3DolgDHNCOt7rKpuBbbWK3s65P4iYFED2+0BhrYyxpap7aPnInGW6I0xxoW/jK0JTE3cXf6GeP9mXTfGmA7PfYne6bq5Ib4isGwtemNMB+e+RO903fTx/DWwbMMrjTEdnPsSvdOi7x13NrBsLXpjTAfnvkTvDK9MVSfRd7JEb4zp2NyX6P2BrpsUf3lg2bpujDEdnPsSvdOi76JVgWXrujHGdHDuS/ROH32QDa80xnRw7kv0zqibIJu90hjTwbku0Wv9Fr310RtjOjj3JXpfSKL3dPryEnLGGNNBuS/Rh7borX/eGGPcl+ip8eJT52VZt40xxrgv0YvfxzmcBG8nYo0xxo2J3ss5dRK9dd0YY4zLEr2/BkH5a7BFbz+WMsYYdyV651ex59RJ8NZHb4wxLkv0zoibv1rXjTHGBLkr0Tst+gtxtS16OxlrjDHuSvTOzJWVHifBW9eNMcaEd3Hwq4bToq+M+wqMzoHB349xQMYYE3thtehFZLKIHBGRYyKysIHHs0XkjIgUO7cfhzw2R0SOOrc5kQz+MrW/ipUE+M4zcP3QNn06Y4y5GjTbohcRD/Aq8B2gDCgQkTxVPVRv1fWq+ki9bXsC/w5kAgrsc7b9a0Sir89p0eNx1xcVY4xpjXBa9KOAY6p6XFWrgXVAVpj7/x6wXVXPOsl9OzD5ykINg5PoNS6hzZ7CGGOuNuEk+j7AyZDlMqesvmkisl9E/p+I9GvJtiLygIgUikjhmTNnwgy9AX5r0RtjTH2RGnWzBUhT1VsJtNrfasnGqpqrqpmqmpmamnrlUTgXHdG4Tle+D2OMcZlwEv0XQL+Q5b5OWZCqlqvq353F14CMcLeNKKdFLx7rujHGmFrhJPoCYICI9BeRTsAsIC90BRHpHbI4FfjEub8N+K6I9BCRHsB3nbK2UWOJ3hhj6mu2M1tVfSLyCIEE7QFWqupBEVkKFKpqHvCoiEwFfMBZINvZ9qyIPEvgwwJgqaqebYPXEWAtemOMuUxYZy1VdSuwtV7Z0yH3FwGLGtl2JbCyFTGGz+mjt0RvjDFfctkUCE6LPt4SvTHG1HJXonf66OOsRW+MMUHuSvTOpGZx8Ta80hhjarkr0de26K3rxhhjgtyV6K2P3hhjLuOuRO+06D0e67oxxpha7kr0Th+9x/rojTEmyFWJ3u+rBsCTYIneGGNquSrR1/icrhvrozfGmCCXJfpAi95G3RhjzJdclehru24SrOvGGGOCXJbovXjVQ0K8J9ahGGNMu+GuRF/jxYeHTh5XvSxjjGkVV2VEv68aLx4S4l31sowxplVclRHVV+206CXWoRhjTLvhqqto+2u81BBPgnXdGGNMkKsyotZ4qbZEb4wxdbgqI6rPi089dLI+emOMCXJVRlR/YNSNteiNMeZL7sqINV68NrzSGGPqcFdGdMbRJ8TbqBtjjKkVVqIXkckickREjonIwibWmyYiKiKZznKaiFwUkWLn9otIBd4gvw+fnYw1xpg6mh1eKSIe4FXgO0AZUCAieap6qN56ycB84Pf1dvGZqg6LULxNs64bY4y5TDgZcRRwTFWPq2o1sA7IamC9Z4GfAZciGF/L+H026sYYY+oJ5wdTfYCTIctlwG2hK4jICKCfqr4jIv9Wb/v+IvIRcB54UlV3138CEXkAeADghhtuaEH49fZjo26My3i9XsrKyrh0KXbtJ9O+JCYm0rdvXxISwp+OvdW/jBWROOAlILuBh08BN6hquYhkAJtFZIiqng9dSVVzgVyAzMxMveJY/D68JJJgUyAYlygrKyM5OZm0tDRE7Lju6FSV8vJyysrK6N+/f9jbhdP0/QLoF7Lc1ymrlQx8A8gXkVJgNJAnIpmq+ndVLXcC3Ad8BgwMO7oWsha9cZtLly7Rq1cvS/IGABGhV69eLf6GF05GLAAGiEh/EekEzALyah9U1QpVTVHVNFVNAz4EpqpqoYikOidzEZEbgQHA8RZF2AKBFr2djDXuYknehLqS46HZrhtV9YnII8A2wAOsVNWDIrIUKFTVvCY2Hw8sFREv4AceUtWzLY4yTOL3UUM8cXH2j2GMMbXCavqq6lZVHaiqN6nq807Z0w0leVWdqKqFzv2NqjpEVYep6ghV3RLZ8OuKUx9+cdWEnMbEVHl5OcOGDWPYsGFcf/319OnTJ7hcXV3d5LaFhYU8+uijzT7HmDFjIhUuADk5OfTp0we/3x/R/V7NXJUV49SHP84uI2hMpPTq1Yvi4mIAlixZQlJSEo8//njwcZ/PR3x8w2kkMzOTzMzMZp9jz549kQkW8Pv9bNq0iX79+rFr1y4mTZoUsX2Haup1t0dXT6RhiPP78Ev4Q46MuZo8s+Ugh/50vvkVW+CWr36Ff//+kBZtk52dTWJiIh999BFjx45l1qxZzJ8/n0uXLtGlSxfeeOMNBg0aRH5+PsuWLePtt99myZIlfP755xw/fpzPP/+cnJycYGs/KSmJyspK8vPzWbJkCSkpKRw4cICMjAx+9atfISJs3bqVxx57jG7dujF27FiOHz/O22+/fVls+fn5DBkyhJkzZ7J27dpgoj99+jQPPfQQx48HThGuWLGCMWPGsGrVKpYtW4aIcOutt7J69Wqys7OZMmUK06dPvyy+p556ih49enD48GE+/fRTfvCDH3Dy5EkuXbrE/PnzeeCBBwB47733WLx4MTU1NaSkpLB9+3YGDRrEnj17SE1Nxe/3M3DgQPbu3UtqauoVv3/hcleiVx/+OFe9JGPapbKyMvbs2YPH4+H8+fPs3r2b+Ph4duzYweLFi9m4ceNl2xw+fJj333+fCxcuMGjQIObNm3fZWPCPPvqIgwcP8tWvfpWxY8fyu9/9jszMTB588EE++OAD+vfvz+zZsxuNa+3atcyePZusrCwWL16M1+slISGBRx99lAkTJrBp0yZqamqorKzk4MGDPPfcc+zZs4eUlBTOnm3+9GFRUREHDhwIDm1cuXIlPXv25OLFi4wcOZJp06bh9/uZO3duMN6zZ88SFxfHfffdx5o1a8jJyWHHjh2kp6dHJcmDCxO9WqI3LtXSlndbmjFjBh5PoJu0oqKCOXPmcPToUUQEr9fb4DZ33XUXnTt3pnPnzlx77bWcPn2avn371lln1KhRwbJhw4ZRWlpKUlISN954YzC5zp49m9zc3Mv2X11dzdatW3nppZdITk7mtttuY9u2bUyZMoWdO3eyatUqADweD927d2fVqlXMmDGDlJQUAHr27Nns6x41alSd8euvvPIKmzZtAuDkyZMcPXqUM2fOMH78+OB6tfu9//77ycrKIicnh5UrV/KjH/2o2eeLFFdlRY8lemOiolu3bsH7Tz31FJMmTWLTpk2UlpYyceLEBrfp3Llz8L7H48Hn813ROo3Ztm0b586dY+jQoQBUVVXRpUsXpkyZEvY+AOLj44Mncv1+f52TzqGvOz8/nx07drB37166du3KxIkTmxzf3q9fP6677jp27tzJH/7wB9asWdOiuFrDPQPOVYnHh8ZZH70x0VRRUUGfPn0AePPNNyO+/0GDBnH8+HFKS0sBWL9+fYPrrV27ltdee43S0lJKS0s5ceIE27dvp6qqim9961usWLECgJqaGioqKvjmN7/Jhg0bKC8vBwh23aSlpbFv3z4A8vLyGv2GUlFRQY8ePejatSuHDx/mww8/BGD06NF88MEHnDhxos5+AX784x9z33331flGFA3uSfT+wCe/teiNia6f/OQnLFq0iOHDh7eoBR6uLl268POf/5zJkyeTkZFBcnIy3bt3r7NOVVUV7733HnfddVewrFu3bowbN44tW7awfPly3n//fYYOHUpGRgaHDh1iyJAhPPHEE0yYMIH09HQee+wxAObOncuuXbtIT09n7969dVrxoSZPnozP52Pw4MEsXLiQ0aNHA5Camkpubi733HMP6enpzJw5M7jN1KlTqaysjGq3DYCoXvHUMm0iMzNTCwsLW75hdRX8R29+lfQj7nv85cgHZkwMfPLJJwwePDjWYcRcZWUlSUlJqCrnd/9jAAALL0lEQVQPP/wwAwYMYMGCBbEOq8UKCwtZsGABu3dfNrdjizR0XIjIPlVtcDyri1r0ztcr67oxxnV++ctfMmzYMIYMGUJFRQUPPvhgrENqsRdeeIFp06bx05/+NOrP7Z5+jhqn68Zjid4Yt1mwYMFV2YIPtXDhQhYubPQCfW3KPS16EQ7ED+F8wrWxjsQYY9oV97Tou/ZkQdefMqB7UqwjMcaYdsU9LXqgusZvc9EbY0w9rsqKXp/f5qI3xph6XJUVq2uUBLswuDERM2nSJLZt21an7OWXX2bevHmNbjNx4kRqh0jfeeednDt37rJ1lixZwrJly5p87s2bN3Po0KHg8tNPP82OHTtaEn6TOtJ0xq7Kit4aa9EbE0mzZ89m3bp1dcrWrVvX5MRiobZu3co111xzRc9dP9EvXbqUb3/721e0r/rqT2fcVtriB2RXwj0nYwkkerswuHGtdxfCnz+O7D6vHwp3vNDow9OnT+fJJ5+kurqaTp06UVpayp/+9Cduv/125s2bR0FBARcvXmT69Ok888wzl22flpZGYWEhKSkpPP/887z11ltce+219OvXj4yMDCAwRj43N5fq6mq+/vWvs3r1aoqLi8nLy2PXrl0899xzbNy4kWeffTY4ffBvf/tbHn/8cXw+HyNHjmTFihV07tyZtLQ05syZw5YtW/B6vWzYsIGbb775srg62nTGrmr+VvvsZKwxkdSzZ09GjRrFu+++CwRa8z/84Q8REZ5//nkKCwvZv38/u3btYv/+/Y3uZ9++faxbt47i4mK2bt1KQUFB8LF77rmHgoICSkpKGDx4MK+//jpjxoxh6tSpvPjiixQXF3PTTTcF17906RLZ2dmsX7+ejz/+GJ/PF5zHBiAlJYWioiLmzZvXaPdQ7XTGd999N++8805wPpva6YxLSkooKipiyJAhwemMd+7cSUlJCcuXL2+23oqKili+fDmffvopEJjOeN++fRQWFvLKK69QXl7OmTNnmDt3Lhs3bqSkpIQNGzbUmc4YiNh0xq5p0fv9is+vluiNezXR8m5Ltd03WVlZrFu3jtdffx2AX//61+Tm5uLz+Th16hSHDh3i1ltvbXAfu3fv5u6776Zr165AYM6XWgcOHODJJ5/k3LlzVFZW8r3vfa/JeI4cOUL//v0ZOHAgAHPmzOHVV18lJycHCHxwAGRkZPCb3/zmsu074nTGrkn0XueESic7GWtMRGVlZbFgwQKKioqoqqoiIyODEydOsGzZMgoKCujRowfZ2dlNTtHblOzsbDZv3kx6ejpvvvkm+fn5rYq3dqrjxqY57ojTGYeVFUVksogcEZFjItLob3hFZJqIqIhkhpQtcrY7IiJNf1S3grcmMDmbnYw1JrKSkpKYNGkS999/f/Ak7Pnz5+nWrRvdu3fn9OnTwa6dxowfP57Nmzdz8eJFLly4wJYtW4KPXbhwgd69e+P1euskteTkZC5cuHDZvgYNGkRpaSnHjh0DYPXq1UyYMCHs19MRpzNuNiuKiAd4FbgDuAWYLSK3NLBeMjAf+H1I2S3ALGAIMBn4ubO/iPP6Ap+sdjLWmMibPXs2JSUlwUSfnp7O8OHDufnmm7n33nsZO3Zsk9uPGDGCmTNnkp6ezh133MHIkSODjz377LPcdtttjB07ts6J01mzZvHiiy8yfPhwPvvss2B5YmIib7zxBjNmzGDo0KHExcXx0EMPhfU6Oux0xqra5A34B2BbyPIiYFED670M3AXkA5kNrQtsA/6hqefLyMjQK3Guqlr/Zc0+zT/ylyva3pj26NChQ7EOwcRAQUGBjhs3rtHHGzougEJtJK+G08/RBzgZslzmlAWJyAign6q+09JtI6V7lwRevXcEEwZG52K7xhjTFtpiOuNWd2iLSBzwEvCvrdjHAyJSKCKFZ86caW1Ixhhz1Vq4cCF//OMfGTduXMT2GU6i/wLoF7Lc1ymrlQx8A8gXkVJgNJDnnJBtblsAVDVXVTNVNbO140WNcRttZ1eBM7F1JcdDOIm+ABggIv1FpBOBk6t5IU9aoaopqpqmqmnAh8BUVS101pslIp1FpD8wAPhDi6M0poNKTEykvLzckr0BAkm+vLycxMTEFm3X7Dh6VfWJyCMETqR6gJWqelBElhLo/M9rYtuDIvJr4BDgAx5W1ZoWRWhMB9a3b1/KysqwLk1TKzExkb59+7ZoG/dcHNwYYzqwjnFxcGOMMQ2yRG+MMS5nid4YY1yu3fXRi8gZ4I+t2EUK8D8RCieSLK6Waa9xQfuNzeJqmfYaF1xZbF9T1QbHp7e7RN9aIlLY2AmJWLK4Wqa9xgXtNzaLq2Xaa1wQ+dis68YYY1zOEr0xxricGxN9bqwDaITF1TLtNS5ov7FZXC3TXuOCCMfmuj56Y4wxdbmxRW+MMSaEJXpjjHE51yT6cK9rG4U4+onI+yJySEQOish8p3yJiHwhIsXO7c4YxVcqIh87MRQ6ZT1FZLuIHHX+9ohyTINC6qVYRM6LSE4s6kxEVorIX0TkQEhZg/UjAa84x9x+5wI80YzrRRE57Dz3JhG5xilPE5GLIfX2i7aKq4nYGn3vonUd6UbiWh8SU6mIFDvlUauzJnJE2x1njV166mq6EZhV8zPgRqATUALcEqNYegMjnPvJwKcErrW7BHi8HdRVKZBSr+w/gYXO/YXAz2L8Xv4Z+Fos6gwYD4wADjRXP8CdwLuAELgOw++jHNd3gXjn/s9C4koLXS9Gddbge+f8L5QAnYH+zv+tJ1px1Xv8v4Cno11nTeSINjvO3NKiHwUcU9XjqloNrAOyYhGIqp5S1SLn/gXgE9ro8okRlAW85dx/C/hBDGP5FvCZqrbm19FXTFU/AM7WK26sfrKAVRrwIXCNiPSOVlyq+t+q6nMWPyRwYZ+oa6TOGpMFrFPVv6vqCeAYgf/fqMYlIgL8EFjbFs/dlCZyRJsdZ25J9FG7Nm1LiEgaMBz4vVP0iPPVa2W0u0dCKPDfIrJPRB5wyq5T1VPO/T8D18UmNCBwYZvQf772UGeN1U97Ou7uJ9Dqq9VfRD4SkV0icnuMYmrovWsvdXY7cFpVj4aURb3O6uWINjvO3JLo2x0RSQI2Ajmqeh5YAdwEDANOEfjaGAvjVHUEcAfwsIiMD31QA98VYzLmVgJXMJsKbHCK2kudBcWyfhojIk8QuLDPGqfoFHCDqg4HHgP+r4h8Jcphtbv3rp7Z1G1QRL3OGsgRQZE+ztyS6MO6Nm20iEgCgTdwjar+BkBVT6tqjar6gV/SRl9Xm6OqXzh//wJscuI4XftV0Pn7l1jERuDDp0hVTzsxtos6o/H6iflxJyLZwBTgH53kgNMtUu7c30egH3xgNONq4r1rD3UWD9wDrK8ti3adNZQjaMPjzC2Jvsnr2kaT0/f3OvCJqr4UUh7ap3Y3cKD+tlGIrZuIJNfeJ3Ay7wCBuprjrDYH+P/Rjs1Rp5XVHurM0Vj95AH/5IyKGA1UhHz1bnMiMhn4CYFrNFeFlKeKiMe5fyOBazUfj1ZczvM29t61h+tIfxs4rKpltQXRrLPGcgRteZxF4yxzNG4Ezkx/SuCT+IkYxjGOwFeu/UCxc7sTWA187JTnAb1jENuNBEY8lAAHa+sJ6AX8FjgK7AB6xiC2bkA50D2kLOp1RuCD5hTgJdAX+s+N1Q+BURCvOsfcx0BmlOM6RqDvtvY4+4Wz7jTn/S0GioDvx6DOGn3vgCecOjsC3BHNuJzyN4GH6q0btTprIke02XFmUyAYY4zLuaXrxhhjTCMs0RtjjMtZojfGGJezRG+MMS5nid4YY1zOEr0xxricJXpjjHG5/wVCrzKM6gz4eAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8rGKtRJqT97"
      },
      "source": [
        "# Second model\n",
        "training with 200 labeled data + pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cCgfuM7xc8j",
        "outputId": "faa70a9b-e0a3-4837-cbcd-26a03407a761"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# define regularization norm 2\n",
        "reg = tf.keras.regularizers.l2(0.001)\n",
        "\n",
        "# input layer\n",
        "# model.add(tf.keras.Input(X_train[0].shape))  # 32x32 RGB images\n",
        "model.add(tf.keras.layers.Input((32,32,3)))\n",
        "\n",
        "# create the base model\n",
        "# First convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_1'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_1'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_1'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_1'))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_2'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_2'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_2'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_2'))\n",
        "\n",
        "# Third convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_regularizer=reg, name='conv_3'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_3'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_3'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool_3'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_3'))\n",
        "\n",
        "\n",
        "# add a Flatten layer\n",
        "model.add(tf.keras.layers.Flatten(name='Flatten'))\n",
        "\n",
        "# let's add fully-connected layers\n",
        "model.add(tf.keras.layers.Dense(1024, kernel_regularizer=reg, name='Dense_1'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_4'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_4'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_4'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, kernel_regularizer=reg, name='Dense_2'))\n",
        "model.add(tf.keras.layers.Activation('relu', name='Act_5'))\n",
        "model.add(tf.keras.layers.BatchNormalization(name='BatchN_5'))\n",
        "model.add(tf.keras.layers.Dropout(0.5, name='Drop_5'))\n",
        "\n",
        "\n",
        "# and a logistic layer -- let's say we have 4 classes[0, 90, 180, 270] degrees\n",
        "model.add(tf.keras.layers.Dense(4, kernel_regularizer=reg, name='Dense_3'))\n",
        "model.add(tf.keras.layers.Activation('softmax', name='Act_6'))\n",
        "\n",
        "# load weight layers of pretext model\n",
        "model.load_weights('best_weights.hdf5')\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "# drop out last two layers of pretext model\n",
        "model.pop()\n",
        "model.pop()\n",
        "\n",
        "# add two new layers. we have 10 classes in Downstream task\n",
        "model.add(tf.keras.layers.Dense(10, kernel_regularizer=reg, name='10_clasifier'))\n",
        "model.add(tf.keras.layers.Activation('softmax', name='Act_classifier'))\n",
        "\n",
        "# compile the model\n",
        "# use smaller learning rates\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(lr=0.000008), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "BatchN_1 (BatchNormalization (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_1 (Activation)           (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_1 (MaxPooling2D)        (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "Drop_1 (Dropout)             (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 13, 13, 128)       147584    \n",
            "_________________________________________________________________\n",
            "BatchN_2 (BatchNormalization (None, 13, 13, 128)       512       \n",
            "_________________________________________________________________\n",
            "Act_2 (Activation)           (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "pool_2 (MaxPooling2D)        (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_2 (Dropout)             (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "BatchN_3 (BatchNormalization (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "Act_3 (Activation)           (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "pool_3 (MaxPooling2D)        (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Drop_3 (Dropout)             (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "Act_4 (Activation)           (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "BatchN_4 (BatchNormalization (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "Drop_4 (Dropout)             (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "Act_5 (Activation)           (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "BatchN_5 (BatchNormalization (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "Drop_5 (Dropout)             (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "10_clasifier (Dense)         (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "Act_classifier (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 962,698\n",
            "Trainable params: 959,626\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTXDzKaFqSnk",
        "outputId": "d5c18885-dbed-419b-a280-e96484418dda"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=600)\n",
        "\n",
        "# train the model on the 200 labeld data for some epochs with using pretext task weights\n",
        "# test the model on the 10000 labeld data\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=6000,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3501/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7074 - accuracy: 0.8700 - val_loss: 1.8599 - val_accuracy: 0.4507\n",
            "Epoch 3502/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6931 - accuracy: 0.8500 - val_loss: 1.8594 - val_accuracy: 0.4509\n",
            "Epoch 3503/6000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.6748 - accuracy: 0.8700 - val_loss: 1.8596 - val_accuracy: 0.4506\n",
            "Epoch 3504/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6895 - accuracy: 0.8800 - val_loss: 1.8592 - val_accuracy: 0.4508\n",
            "Epoch 3505/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6836 - accuracy: 0.8700 - val_loss: 1.8590 - val_accuracy: 0.4511\n",
            "Epoch 3506/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6497 - accuracy: 0.8800 - val_loss: 1.8591 - val_accuracy: 0.4508\n",
            "Epoch 3507/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7501 - accuracy: 0.8300 - val_loss: 1.8582 - val_accuracy: 0.4508\n",
            "Epoch 3508/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6934 - accuracy: 0.9000 - val_loss: 1.8576 - val_accuracy: 0.4511\n",
            "Epoch 3509/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6691 - accuracy: 0.8950 - val_loss: 1.8568 - val_accuracy: 0.4511\n",
            "Epoch 3510/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6590 - accuracy: 0.8950 - val_loss: 1.8558 - val_accuracy: 0.4511\n",
            "Epoch 3511/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6795 - accuracy: 0.8750 - val_loss: 1.8553 - val_accuracy: 0.4508\n",
            "Epoch 3512/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6356 - accuracy: 0.9050 - val_loss: 1.8557 - val_accuracy: 0.4512\n",
            "Epoch 3513/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6710 - accuracy: 0.8900 - val_loss: 1.8557 - val_accuracy: 0.4514\n",
            "Epoch 3514/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6798 - accuracy: 0.8650 - val_loss: 1.8544 - val_accuracy: 0.4517\n",
            "Epoch 3515/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6725 - accuracy: 0.8800 - val_loss: 1.8547 - val_accuracy: 0.4516\n",
            "Epoch 3516/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6954 - accuracy: 0.8850 - val_loss: 1.8547 - val_accuracy: 0.4516\n",
            "Epoch 3517/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6822 - accuracy: 0.8700 - val_loss: 1.8547 - val_accuracy: 0.4517\n",
            "Epoch 3518/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6848 - accuracy: 0.8650 - val_loss: 1.8544 - val_accuracy: 0.4513\n",
            "Epoch 3519/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.7171 - accuracy: 0.8600 - val_loss: 1.8549 - val_accuracy: 0.4514\n",
            "Epoch 3520/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6324 - accuracy: 0.9050 - val_loss: 1.8553 - val_accuracy: 0.4517\n",
            "Epoch 3521/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.7329 - accuracy: 0.8300 - val_loss: 1.8553 - val_accuracy: 0.4517\n",
            "Epoch 3522/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6257 - accuracy: 0.8800 - val_loss: 1.8546 - val_accuracy: 0.4516\n",
            "Epoch 3523/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6446 - accuracy: 0.8800 - val_loss: 1.8547 - val_accuracy: 0.4515\n",
            "Epoch 3524/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6977 - accuracy: 0.8450 - val_loss: 1.8551 - val_accuracy: 0.4511\n",
            "Epoch 3525/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.7066 - accuracy: 0.8800 - val_loss: 1.8554 - val_accuracy: 0.4511\n",
            "Epoch 3526/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6878 - accuracy: 0.8750 - val_loss: 1.8557 - val_accuracy: 0.4514\n",
            "Epoch 3527/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.7091 - accuracy: 0.8500 - val_loss: 1.8574 - val_accuracy: 0.4512\n",
            "Epoch 3528/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6596 - accuracy: 0.8950 - val_loss: 1.8573 - val_accuracy: 0.4516\n",
            "Epoch 3529/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6552 - accuracy: 0.8950 - val_loss: 1.8571 - val_accuracy: 0.4511\n",
            "Epoch 3530/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.6683 - accuracy: 0.8550 - val_loss: 1.8568 - val_accuracy: 0.4515\n",
            "Epoch 3531/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6732 - accuracy: 0.8650 - val_loss: 1.8566 - val_accuracy: 0.4515\n",
            "Epoch 3532/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7168 - accuracy: 0.8550 - val_loss: 1.8573 - val_accuracy: 0.4517\n",
            "Epoch 3533/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6539 - accuracy: 0.8800 - val_loss: 1.8573 - val_accuracy: 0.4515\n",
            "Epoch 3534/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7018 - accuracy: 0.8650 - val_loss: 1.8569 - val_accuracy: 0.4518\n",
            "Epoch 3535/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6500 - accuracy: 0.9000 - val_loss: 1.8562 - val_accuracy: 0.4518\n",
            "Epoch 3536/6000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.6673 - accuracy: 0.8750 - val_loss: 1.8546 - val_accuracy: 0.4517\n",
            "Epoch 3537/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.6632 - accuracy: 0.8700 - val_loss: 1.8551 - val_accuracy: 0.4516\n",
            "Epoch 3538/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6932 - accuracy: 0.9000 - val_loss: 1.8559 - val_accuracy: 0.4515\n",
            "Epoch 3539/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.7391 - accuracy: 0.8650 - val_loss: 1.8567 - val_accuracy: 0.4514\n",
            "Epoch 3540/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6679 - accuracy: 0.8750 - val_loss: 1.8573 - val_accuracy: 0.4512\n",
            "Epoch 3541/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6599 - accuracy: 0.8950 - val_loss: 1.8566 - val_accuracy: 0.4514\n",
            "Epoch 3542/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6938 - accuracy: 0.8700 - val_loss: 1.8571 - val_accuracy: 0.4512\n",
            "Epoch 3543/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.6649 - accuracy: 0.8950 - val_loss: 1.8576 - val_accuracy: 0.4507\n",
            "Epoch 3544/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7156 - accuracy: 0.8700 - val_loss: 1.8577 - val_accuracy: 0.4504\n",
            "Epoch 3545/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7027 - accuracy: 0.8450 - val_loss: 1.8574 - val_accuracy: 0.4505\n",
            "Epoch 3546/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.7093 - accuracy: 0.8500 - val_loss: 1.8568 - val_accuracy: 0.4506\n",
            "Epoch 3547/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6769 - accuracy: 0.8500 - val_loss: 1.8570 - val_accuracy: 0.4504\n",
            "Epoch 3548/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6386 - accuracy: 0.8850 - val_loss: 1.8568 - val_accuracy: 0.4507\n",
            "Epoch 3549/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6775 - accuracy: 0.8800 - val_loss: 1.8568 - val_accuracy: 0.4509\n",
            "Epoch 3550/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6533 - accuracy: 0.8950 - val_loss: 1.8558 - val_accuracy: 0.4512\n",
            "Epoch 3551/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6718 - accuracy: 0.8850 - val_loss: 1.8555 - val_accuracy: 0.4509\n",
            "Epoch 3552/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.7113 - accuracy: 0.8500 - val_loss: 1.8547 - val_accuracy: 0.4514\n",
            "Epoch 3553/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6458 - accuracy: 0.8700 - val_loss: 1.8558 - val_accuracy: 0.4513\n",
            "Epoch 3554/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6677 - accuracy: 0.8700 - val_loss: 1.8552 - val_accuracy: 0.4517\n",
            "Epoch 3555/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6837 - accuracy: 0.8800 - val_loss: 1.8563 - val_accuracy: 0.4510\n",
            "Epoch 3556/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.7032 - accuracy: 0.8750 - val_loss: 1.8570 - val_accuracy: 0.4512\n",
            "Epoch 3557/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7280 - accuracy: 0.8550 - val_loss: 1.8577 - val_accuracy: 0.4511\n",
            "Epoch 3558/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6873 - accuracy: 0.8700 - val_loss: 1.8588 - val_accuracy: 0.4507\n",
            "Epoch 3559/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6245 - accuracy: 0.9100 - val_loss: 1.8590 - val_accuracy: 0.4509\n",
            "Epoch 3560/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6239 - accuracy: 0.9000 - val_loss: 1.8595 - val_accuracy: 0.4510\n",
            "Epoch 3561/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7055 - accuracy: 0.8700 - val_loss: 1.8600 - val_accuracy: 0.4510\n",
            "Epoch 3562/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6538 - accuracy: 0.8950 - val_loss: 1.8613 - val_accuracy: 0.4510\n",
            "Epoch 3563/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7377 - accuracy: 0.8750 - val_loss: 1.8619 - val_accuracy: 0.4507\n",
            "Epoch 3564/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6228 - accuracy: 0.9200 - val_loss: 1.8626 - val_accuracy: 0.4505\n",
            "Epoch 3565/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6969 - accuracy: 0.8800 - val_loss: 1.8632 - val_accuracy: 0.4500\n",
            "Epoch 3566/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.7189 - accuracy: 0.8550 - val_loss: 1.8637 - val_accuracy: 0.4506\n",
            "Epoch 3567/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6182 - accuracy: 0.9150 - val_loss: 1.8645 - val_accuracy: 0.4508\n",
            "Epoch 3568/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6422 - accuracy: 0.8800 - val_loss: 1.8642 - val_accuracy: 0.4509\n",
            "Epoch 3569/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6719 - accuracy: 0.8650 - val_loss: 1.8649 - val_accuracy: 0.4510\n",
            "Epoch 3570/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6725 - accuracy: 0.8750 - val_loss: 1.8652 - val_accuracy: 0.4512\n",
            "Epoch 3571/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6383 - accuracy: 0.9000 - val_loss: 1.8648 - val_accuracy: 0.4510\n",
            "Epoch 3572/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7138 - accuracy: 0.8650 - val_loss: 1.8648 - val_accuracy: 0.4509\n",
            "Epoch 3573/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6369 - accuracy: 0.8900 - val_loss: 1.8655 - val_accuracy: 0.4508\n",
            "Epoch 3574/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7114 - accuracy: 0.8550 - val_loss: 1.8654 - val_accuracy: 0.4509\n",
            "Epoch 3575/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6741 - accuracy: 0.8800 - val_loss: 1.8647 - val_accuracy: 0.4509\n",
            "Epoch 3576/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5841 - accuracy: 0.9200 - val_loss: 1.8646 - val_accuracy: 0.4507\n",
            "Epoch 3577/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6871 - accuracy: 0.8650 - val_loss: 1.8650 - val_accuracy: 0.4510\n",
            "Epoch 3578/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6618 - accuracy: 0.8700 - val_loss: 1.8639 - val_accuracy: 0.4512\n",
            "Epoch 3579/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6542 - accuracy: 0.9000 - val_loss: 1.8635 - val_accuracy: 0.4506\n",
            "Epoch 3580/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.6434 - accuracy: 0.8750 - val_loss: 1.8633 - val_accuracy: 0.4509\n",
            "Epoch 3581/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6668 - accuracy: 0.8850 - val_loss: 1.8637 - val_accuracy: 0.4507\n",
            "Epoch 3582/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6051 - accuracy: 0.9150 - val_loss: 1.8640 - val_accuracy: 0.4504\n",
            "Epoch 3583/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6573 - accuracy: 0.8600 - val_loss: 1.8641 - val_accuracy: 0.4508\n",
            "Epoch 3584/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6295 - accuracy: 0.9200 - val_loss: 1.8639 - val_accuracy: 0.4508\n",
            "Epoch 3585/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6515 - accuracy: 0.8950 - val_loss: 1.8635 - val_accuracy: 0.4505\n",
            "Epoch 3586/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7230 - accuracy: 0.8550 - val_loss: 1.8638 - val_accuracy: 0.4510\n",
            "Epoch 3587/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6279 - accuracy: 0.8900 - val_loss: 1.8633 - val_accuracy: 0.4507\n",
            "Epoch 3588/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6319 - accuracy: 0.8950 - val_loss: 1.8638 - val_accuracy: 0.4514\n",
            "Epoch 3589/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6726 - accuracy: 0.8900 - val_loss: 1.8640 - val_accuracy: 0.4516\n",
            "Epoch 3590/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6774 - accuracy: 0.8750 - val_loss: 1.8632 - val_accuracy: 0.4511\n",
            "Epoch 3591/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6811 - accuracy: 0.8800 - val_loss: 1.8641 - val_accuracy: 0.4516\n",
            "Epoch 3592/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6911 - accuracy: 0.8800 - val_loss: 1.8649 - val_accuracy: 0.4514\n",
            "Epoch 3593/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6084 - accuracy: 0.8950 - val_loss: 1.8645 - val_accuracy: 0.4517\n",
            "Epoch 3594/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6487 - accuracy: 0.9000 - val_loss: 1.8636 - val_accuracy: 0.4518\n",
            "Epoch 3595/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6713 - accuracy: 0.8750 - val_loss: 1.8638 - val_accuracy: 0.4519\n",
            "Epoch 3596/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6142 - accuracy: 0.9100 - val_loss: 1.8623 - val_accuracy: 0.4523\n",
            "Epoch 3597/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6389 - accuracy: 0.9000 - val_loss: 1.8620 - val_accuracy: 0.4523\n",
            "Epoch 3598/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6486 - accuracy: 0.8900 - val_loss: 1.8621 - val_accuracy: 0.4523\n",
            "Epoch 3599/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6467 - accuracy: 0.8900 - val_loss: 1.8613 - val_accuracy: 0.4524\n",
            "Epoch 3600/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6329 - accuracy: 0.8900 - val_loss: 1.8613 - val_accuracy: 0.4525\n",
            "Epoch 3601/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6958 - accuracy: 0.8700 - val_loss: 1.8627 - val_accuracy: 0.4521\n",
            "Epoch 3602/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6313 - accuracy: 0.9000 - val_loss: 1.8624 - val_accuracy: 0.4519\n",
            "Epoch 3603/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.6356 - accuracy: 0.8750 - val_loss: 1.8613 - val_accuracy: 0.4524\n",
            "Epoch 3604/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6271 - accuracy: 0.8700 - val_loss: 1.8613 - val_accuracy: 0.4523\n",
            "Epoch 3605/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6630 - accuracy: 0.8700 - val_loss: 1.8603 - val_accuracy: 0.4521\n",
            "Epoch 3606/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6624 - accuracy: 0.8800 - val_loss: 1.8599 - val_accuracy: 0.4520\n",
            "Epoch 3607/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6861 - accuracy: 0.8750 - val_loss: 1.8592 - val_accuracy: 0.4525\n",
            "Epoch 3608/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6768 - accuracy: 0.8800 - val_loss: 1.8597 - val_accuracy: 0.4521\n",
            "Epoch 3609/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6549 - accuracy: 0.8900 - val_loss: 1.8588 - val_accuracy: 0.4524\n",
            "Epoch 3610/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6590 - accuracy: 0.8550 - val_loss: 1.8586 - val_accuracy: 0.4520\n",
            "Epoch 3611/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6234 - accuracy: 0.9000 - val_loss: 1.8586 - val_accuracy: 0.4518\n",
            "Epoch 3612/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6790 - accuracy: 0.8600 - val_loss: 1.8581 - val_accuracy: 0.4518\n",
            "Epoch 3613/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6366 - accuracy: 0.8700 - val_loss: 1.8577 - val_accuracy: 0.4516\n",
            "Epoch 3614/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7015 - accuracy: 0.8750 - val_loss: 1.8579 - val_accuracy: 0.4515\n",
            "Epoch 3615/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.6779 - accuracy: 0.8700 - val_loss: 1.8582 - val_accuracy: 0.4518\n",
            "Epoch 3616/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.7015 - accuracy: 0.8750 - val_loss: 1.8583 - val_accuracy: 0.4520\n",
            "Epoch 3617/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6185 - accuracy: 0.9050 - val_loss: 1.8583 - val_accuracy: 0.4517\n",
            "Epoch 3618/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6748 - accuracy: 0.8850 - val_loss: 1.8590 - val_accuracy: 0.4520\n",
            "Epoch 3619/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6702 - accuracy: 0.9200 - val_loss: 1.8584 - val_accuracy: 0.4520\n",
            "Epoch 3620/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6618 - accuracy: 0.8950 - val_loss: 1.8600 - val_accuracy: 0.4517\n",
            "Epoch 3621/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5972 - accuracy: 0.9100 - val_loss: 1.8596 - val_accuracy: 0.4518\n",
            "Epoch 3622/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6834 - accuracy: 0.8900 - val_loss: 1.8601 - val_accuracy: 0.4525\n",
            "Epoch 3623/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6488 - accuracy: 0.8800 - val_loss: 1.8601 - val_accuracy: 0.4518\n",
            "Epoch 3624/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.6207 - accuracy: 0.8750 - val_loss: 1.8598 - val_accuracy: 0.4514\n",
            "Epoch 3625/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6439 - accuracy: 0.8850 - val_loss: 1.8597 - val_accuracy: 0.4513\n",
            "Epoch 3626/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6395 - accuracy: 0.9050 - val_loss: 1.8589 - val_accuracy: 0.4519\n",
            "Epoch 3627/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6351 - accuracy: 0.9150 - val_loss: 1.8592 - val_accuracy: 0.4519\n",
            "Epoch 3628/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6875 - accuracy: 0.8650 - val_loss: 1.8589 - val_accuracy: 0.4516\n",
            "Epoch 3629/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6587 - accuracy: 0.8950 - val_loss: 1.8593 - val_accuracy: 0.4519\n",
            "Epoch 3630/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6580 - accuracy: 0.8850 - val_loss: 1.8599 - val_accuracy: 0.4517\n",
            "Epoch 3631/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7002 - accuracy: 0.8700 - val_loss: 1.8595 - val_accuracy: 0.4519\n",
            "Epoch 3632/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6243 - accuracy: 0.9100 - val_loss: 1.8607 - val_accuracy: 0.4518\n",
            "Epoch 3633/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5807 - accuracy: 0.9000 - val_loss: 1.8606 - val_accuracy: 0.4518\n",
            "Epoch 3634/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.7104 - accuracy: 0.9000 - val_loss: 1.8614 - val_accuracy: 0.4515\n",
            "Epoch 3635/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6520 - accuracy: 0.8850 - val_loss: 1.8610 - val_accuracy: 0.4519\n",
            "Epoch 3636/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6658 - accuracy: 0.8800 - val_loss: 1.8604 - val_accuracy: 0.4522\n",
            "Epoch 3637/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6549 - accuracy: 0.9000 - val_loss: 1.8602 - val_accuracy: 0.4521\n",
            "Epoch 3638/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6180 - accuracy: 0.8900 - val_loss: 1.8603 - val_accuracy: 0.4521\n",
            "Epoch 3639/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.7464 - accuracy: 0.8450 - val_loss: 1.8604 - val_accuracy: 0.4519\n",
            "Epoch 3640/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6257 - accuracy: 0.8950 - val_loss: 1.8596 - val_accuracy: 0.4525\n",
            "Epoch 3641/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6347 - accuracy: 0.9050 - val_loss: 1.8599 - val_accuracy: 0.4519\n",
            "Epoch 3642/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6603 - accuracy: 0.8850 - val_loss: 1.8596 - val_accuracy: 0.4520\n",
            "Epoch 3643/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6096 - accuracy: 0.8900 - val_loss: 1.8599 - val_accuracy: 0.4522\n",
            "Epoch 3644/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6690 - accuracy: 0.8900 - val_loss: 1.8595 - val_accuracy: 0.4515\n",
            "Epoch 3645/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6536 - accuracy: 0.9200 - val_loss: 1.8596 - val_accuracy: 0.4515\n",
            "Epoch 3646/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6702 - accuracy: 0.8850 - val_loss: 1.8607 - val_accuracy: 0.4513\n",
            "Epoch 3647/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.7487 - accuracy: 0.8350 - val_loss: 1.8618 - val_accuracy: 0.4517\n",
            "Epoch 3648/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.6409 - accuracy: 0.8950 - val_loss: 1.8619 - val_accuracy: 0.4515\n",
            "Epoch 3649/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6123 - accuracy: 0.8850 - val_loss: 1.8624 - val_accuracy: 0.4514\n",
            "Epoch 3650/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6635 - accuracy: 0.8650 - val_loss: 1.8625 - val_accuracy: 0.4516\n",
            "Epoch 3651/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6548 - accuracy: 0.8650 - val_loss: 1.8630 - val_accuracy: 0.4515\n",
            "Epoch 3652/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6729 - accuracy: 0.8950 - val_loss: 1.8627 - val_accuracy: 0.4516\n",
            "Epoch 3653/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.5980 - accuracy: 0.9050 - val_loss: 1.8637 - val_accuracy: 0.4512\n",
            "Epoch 3654/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6478 - accuracy: 0.8650 - val_loss: 1.8628 - val_accuracy: 0.4512\n",
            "Epoch 3655/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6345 - accuracy: 0.8800 - val_loss: 1.8627 - val_accuracy: 0.4514\n",
            "Epoch 3656/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6264 - accuracy: 0.9150 - val_loss: 1.8621 - val_accuracy: 0.4518\n",
            "Epoch 3657/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6955 - accuracy: 0.8350 - val_loss: 1.8624 - val_accuracy: 0.4515\n",
            "Epoch 3658/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6283 - accuracy: 0.8900 - val_loss: 1.8630 - val_accuracy: 0.4515\n",
            "Epoch 3659/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.7067 - accuracy: 0.8600 - val_loss: 1.8629 - val_accuracy: 0.4515\n",
            "Epoch 3660/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6381 - accuracy: 0.8900 - val_loss: 1.8634 - val_accuracy: 0.4512\n",
            "Epoch 3661/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6359 - accuracy: 0.8750 - val_loss: 1.8640 - val_accuracy: 0.4514\n",
            "Epoch 3662/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5908 - accuracy: 0.9100 - val_loss: 1.8636 - val_accuracy: 0.4518\n",
            "Epoch 3663/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6723 - accuracy: 0.8750 - val_loss: 1.8635 - val_accuracy: 0.4519\n",
            "Epoch 3664/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6406 - accuracy: 0.8900 - val_loss: 1.8651 - val_accuracy: 0.4512\n",
            "Epoch 3665/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6853 - accuracy: 0.8900 - val_loss: 1.8649 - val_accuracy: 0.4514\n",
            "Epoch 3666/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6739 - accuracy: 0.8700 - val_loss: 1.8656 - val_accuracy: 0.4508\n",
            "Epoch 3667/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6229 - accuracy: 0.8700 - val_loss: 1.8659 - val_accuracy: 0.4509\n",
            "Epoch 3668/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6609 - accuracy: 0.8900 - val_loss: 1.8660 - val_accuracy: 0.4514\n",
            "Epoch 3669/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6374 - accuracy: 0.8950 - val_loss: 1.8657 - val_accuracy: 0.4517\n",
            "Epoch 3670/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6384 - accuracy: 0.9150 - val_loss: 1.8652 - val_accuracy: 0.4521\n",
            "Epoch 3671/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6045 - accuracy: 0.9000 - val_loss: 1.8656 - val_accuracy: 0.4517\n",
            "Epoch 3672/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6448 - accuracy: 0.8850 - val_loss: 1.8666 - val_accuracy: 0.4513\n",
            "Epoch 3673/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6630 - accuracy: 0.8700 - val_loss: 1.8661 - val_accuracy: 0.4512\n",
            "Epoch 3674/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6719 - accuracy: 0.8850 - val_loss: 1.8657 - val_accuracy: 0.4513\n",
            "Epoch 3675/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6544 - accuracy: 0.8900 - val_loss: 1.8650 - val_accuracy: 0.4515\n",
            "Epoch 3676/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6264 - accuracy: 0.9000 - val_loss: 1.8638 - val_accuracy: 0.4521\n",
            "Epoch 3677/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5952 - accuracy: 0.8950 - val_loss: 1.8633 - val_accuracy: 0.4522\n",
            "Epoch 3678/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5965 - accuracy: 0.9150 - val_loss: 1.8644 - val_accuracy: 0.4524\n",
            "Epoch 3679/6000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.6279 - accuracy: 0.8950 - val_loss: 1.8648 - val_accuracy: 0.4524\n",
            "Epoch 3680/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6324 - accuracy: 0.9200 - val_loss: 1.8657 - val_accuracy: 0.4519\n",
            "Epoch 3681/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6374 - accuracy: 0.8900 - val_loss: 1.8661 - val_accuracy: 0.4523\n",
            "Epoch 3682/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5995 - accuracy: 0.9200 - val_loss: 1.8664 - val_accuracy: 0.4514\n",
            "Epoch 3683/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6473 - accuracy: 0.8750 - val_loss: 1.8664 - val_accuracy: 0.4517\n",
            "Epoch 3684/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6047 - accuracy: 0.9300 - val_loss: 1.8672 - val_accuracy: 0.4514\n",
            "Epoch 3685/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6593 - accuracy: 0.8850 - val_loss: 1.8678 - val_accuracy: 0.4511\n",
            "Epoch 3686/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6222 - accuracy: 0.9000 - val_loss: 1.8678 - val_accuracy: 0.4512\n",
            "Epoch 3687/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5889 - accuracy: 0.9200 - val_loss: 1.8679 - val_accuracy: 0.4512\n",
            "Epoch 3688/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6639 - accuracy: 0.8900 - val_loss: 1.8684 - val_accuracy: 0.4524\n",
            "Epoch 3689/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6148 - accuracy: 0.8900 - val_loss: 1.8688 - val_accuracy: 0.4521\n",
            "Epoch 3690/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6436 - accuracy: 0.8800 - val_loss: 1.8696 - val_accuracy: 0.4529\n",
            "Epoch 3691/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6542 - accuracy: 0.8800 - val_loss: 1.8693 - val_accuracy: 0.4528\n",
            "Epoch 3692/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6812 - accuracy: 0.8600 - val_loss: 1.8695 - val_accuracy: 0.4532\n",
            "Epoch 3693/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6825 - accuracy: 0.8900 - val_loss: 1.8697 - val_accuracy: 0.4526\n",
            "Epoch 3694/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6492 - accuracy: 0.8800 - val_loss: 1.8709 - val_accuracy: 0.4525\n",
            "Epoch 3695/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.6084 - accuracy: 0.9050 - val_loss: 1.8715 - val_accuracy: 0.4520\n",
            "Epoch 3696/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6570 - accuracy: 0.8750 - val_loss: 1.8715 - val_accuracy: 0.4519\n",
            "Epoch 3697/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6120 - accuracy: 0.8950 - val_loss: 1.8722 - val_accuracy: 0.4518\n",
            "Epoch 3698/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6566 - accuracy: 0.8900 - val_loss: 1.8720 - val_accuracy: 0.4520\n",
            "Epoch 3699/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6444 - accuracy: 0.8600 - val_loss: 1.8720 - val_accuracy: 0.4522\n",
            "Epoch 3700/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5978 - accuracy: 0.9100 - val_loss: 1.8718 - val_accuracy: 0.4524\n",
            "Epoch 3701/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5961 - accuracy: 0.9250 - val_loss: 1.8720 - val_accuracy: 0.4522\n",
            "Epoch 3702/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6303 - accuracy: 0.9150 - val_loss: 1.8708 - val_accuracy: 0.4531\n",
            "Epoch 3703/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6426 - accuracy: 0.8750 - val_loss: 1.8704 - val_accuracy: 0.4524\n",
            "Epoch 3704/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6727 - accuracy: 0.8600 - val_loss: 1.8708 - val_accuracy: 0.4530\n",
            "Epoch 3705/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6385 - accuracy: 0.9200 - val_loss: 1.8715 - val_accuracy: 0.4522\n",
            "Epoch 3706/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6420 - accuracy: 0.8750 - val_loss: 1.8714 - val_accuracy: 0.4527\n",
            "Epoch 3707/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5791 - accuracy: 0.9200 - val_loss: 1.8718 - val_accuracy: 0.4523\n",
            "Epoch 3708/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6586 - accuracy: 0.8650 - val_loss: 1.8711 - val_accuracy: 0.4526\n",
            "Epoch 3709/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5853 - accuracy: 0.9050 - val_loss: 1.8711 - val_accuracy: 0.4519\n",
            "Epoch 3710/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6345 - accuracy: 0.9050 - val_loss: 1.8718 - val_accuracy: 0.4518\n",
            "Epoch 3711/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6110 - accuracy: 0.8950 - val_loss: 1.8719 - val_accuracy: 0.4515\n",
            "Epoch 3712/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6606 - accuracy: 0.8800 - val_loss: 1.8705 - val_accuracy: 0.4517\n",
            "Epoch 3713/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6364 - accuracy: 0.9150 - val_loss: 1.8697 - val_accuracy: 0.4523\n",
            "Epoch 3714/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5942 - accuracy: 0.9100 - val_loss: 1.8704 - val_accuracy: 0.4520\n",
            "Epoch 3715/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6353 - accuracy: 0.8750 - val_loss: 1.8710 - val_accuracy: 0.4521\n",
            "Epoch 3716/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6199 - accuracy: 0.9050 - val_loss: 1.8708 - val_accuracy: 0.4525\n",
            "Epoch 3717/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6351 - accuracy: 0.8850 - val_loss: 1.8695 - val_accuracy: 0.4523\n",
            "Epoch 3718/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.6590 - accuracy: 0.9050 - val_loss: 1.8688 - val_accuracy: 0.4519\n",
            "Epoch 3719/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6423 - accuracy: 0.8750 - val_loss: 1.8684 - val_accuracy: 0.4519\n",
            "Epoch 3720/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6242 - accuracy: 0.9050 - val_loss: 1.8681 - val_accuracy: 0.4519\n",
            "Epoch 3721/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6457 - accuracy: 0.9050 - val_loss: 1.8684 - val_accuracy: 0.4519\n",
            "Epoch 3722/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5559 - accuracy: 0.9450 - val_loss: 1.8679 - val_accuracy: 0.4516\n",
            "Epoch 3723/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6860 - accuracy: 0.8550 - val_loss: 1.8689 - val_accuracy: 0.4519\n",
            "Epoch 3724/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6495 - accuracy: 0.8750 - val_loss: 1.8680 - val_accuracy: 0.4519\n",
            "Epoch 3725/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6229 - accuracy: 0.8850 - val_loss: 1.8679 - val_accuracy: 0.4522\n",
            "Epoch 3726/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6501 - accuracy: 0.8900 - val_loss: 1.8683 - val_accuracy: 0.4522\n",
            "Epoch 3727/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6197 - accuracy: 0.8950 - val_loss: 1.8687 - val_accuracy: 0.4524\n",
            "Epoch 3728/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6533 - accuracy: 0.8650 - val_loss: 1.8689 - val_accuracy: 0.4525\n",
            "Epoch 3729/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5761 - accuracy: 0.9200 - val_loss: 1.8696 - val_accuracy: 0.4522\n",
            "Epoch 3730/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6797 - accuracy: 0.8600 - val_loss: 1.8722 - val_accuracy: 0.4523\n",
            "Epoch 3731/6000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.6797 - accuracy: 0.8800 - val_loss: 1.8716 - val_accuracy: 0.4525\n",
            "Epoch 3732/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5805 - accuracy: 0.9300 - val_loss: 1.8708 - val_accuracy: 0.4525\n",
            "Epoch 3733/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5958 - accuracy: 0.9000 - val_loss: 1.8708 - val_accuracy: 0.4523\n",
            "Epoch 3734/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6134 - accuracy: 0.9100 - val_loss: 1.8722 - val_accuracy: 0.4528\n",
            "Epoch 3735/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6122 - accuracy: 0.9050 - val_loss: 1.8715 - val_accuracy: 0.4531\n",
            "Epoch 3736/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6138 - accuracy: 0.9100 - val_loss: 1.8707 - val_accuracy: 0.4523\n",
            "Epoch 3737/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6392 - accuracy: 0.8700 - val_loss: 1.8699 - val_accuracy: 0.4519\n",
            "Epoch 3738/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6534 - accuracy: 0.8700 - val_loss: 1.8704 - val_accuracy: 0.4518\n",
            "Epoch 3739/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5757 - accuracy: 0.9250 - val_loss: 1.8701 - val_accuracy: 0.4521\n",
            "Epoch 3740/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5856 - accuracy: 0.9000 - val_loss: 1.8711 - val_accuracy: 0.4521\n",
            "Epoch 3741/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6082 - accuracy: 0.8900 - val_loss: 1.8727 - val_accuracy: 0.4525\n",
            "Epoch 3742/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6310 - accuracy: 0.9000 - val_loss: 1.8725 - val_accuracy: 0.4522\n",
            "Epoch 3743/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5760 - accuracy: 0.9250 - val_loss: 1.8727 - val_accuracy: 0.4528\n",
            "Epoch 3744/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.6057 - accuracy: 0.9000 - val_loss: 1.8730 - val_accuracy: 0.4528\n",
            "Epoch 3745/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5825 - accuracy: 0.9200 - val_loss: 1.8737 - val_accuracy: 0.4526\n",
            "Epoch 3746/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5935 - accuracy: 0.8950 - val_loss: 1.8739 - val_accuracy: 0.4527\n",
            "Epoch 3747/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6369 - accuracy: 0.8750 - val_loss: 1.8739 - val_accuracy: 0.4531\n",
            "Epoch 3748/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6270 - accuracy: 0.9050 - val_loss: 1.8737 - val_accuracy: 0.4530\n",
            "Epoch 3749/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6155 - accuracy: 0.9250 - val_loss: 1.8735 - val_accuracy: 0.4530\n",
            "Epoch 3750/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5451 - accuracy: 0.9300 - val_loss: 1.8733 - val_accuracy: 0.4528\n",
            "Epoch 3751/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6266 - accuracy: 0.9050 - val_loss: 1.8734 - val_accuracy: 0.4528\n",
            "Epoch 3752/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6641 - accuracy: 0.8700 - val_loss: 1.8738 - val_accuracy: 0.4528\n",
            "Epoch 3753/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6384 - accuracy: 0.8900 - val_loss: 1.8734 - val_accuracy: 0.4528\n",
            "Epoch 3754/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6054 - accuracy: 0.9150 - val_loss: 1.8740 - val_accuracy: 0.4526\n",
            "Epoch 3755/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6336 - accuracy: 0.8800 - val_loss: 1.8739 - val_accuracy: 0.4525\n",
            "Epoch 3756/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6160 - accuracy: 0.8650 - val_loss: 1.8741 - val_accuracy: 0.4525\n",
            "Epoch 3757/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6164 - accuracy: 0.9050 - val_loss: 1.8758 - val_accuracy: 0.4523\n",
            "Epoch 3758/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6361 - accuracy: 0.8850 - val_loss: 1.8764 - val_accuracy: 0.4525\n",
            "Epoch 3759/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6065 - accuracy: 0.9050 - val_loss: 1.8765 - val_accuracy: 0.4523\n",
            "Epoch 3760/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6067 - accuracy: 0.9150 - val_loss: 1.8777 - val_accuracy: 0.4518\n",
            "Epoch 3761/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6329 - accuracy: 0.8850 - val_loss: 1.8774 - val_accuracy: 0.4518\n",
            "Epoch 3762/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6330 - accuracy: 0.8950 - val_loss: 1.8769 - val_accuracy: 0.4521\n",
            "Epoch 3763/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5920 - accuracy: 0.9050 - val_loss: 1.8781 - val_accuracy: 0.4518\n",
            "Epoch 3764/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6201 - accuracy: 0.8800 - val_loss: 1.8779 - val_accuracy: 0.4517\n",
            "Epoch 3765/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6218 - accuracy: 0.9000 - val_loss: 1.8779 - val_accuracy: 0.4520\n",
            "Epoch 3766/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6089 - accuracy: 0.9150 - val_loss: 1.8790 - val_accuracy: 0.4521\n",
            "Epoch 3767/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6109 - accuracy: 0.9150 - val_loss: 1.8800 - val_accuracy: 0.4518\n",
            "Epoch 3768/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6436 - accuracy: 0.8900 - val_loss: 1.8805 - val_accuracy: 0.4521\n",
            "Epoch 3769/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6509 - accuracy: 0.8750 - val_loss: 1.8802 - val_accuracy: 0.4523\n",
            "Epoch 3770/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5822 - accuracy: 0.9250 - val_loss: 1.8815 - val_accuracy: 0.4520\n",
            "Epoch 3771/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5699 - accuracy: 0.9400 - val_loss: 1.8800 - val_accuracy: 0.4521\n",
            "Epoch 3772/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5948 - accuracy: 0.9100 - val_loss: 1.8805 - val_accuracy: 0.4523\n",
            "Epoch 3773/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6936 - accuracy: 0.8750 - val_loss: 1.8802 - val_accuracy: 0.4521\n",
            "Epoch 3774/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6016 - accuracy: 0.9000 - val_loss: 1.8799 - val_accuracy: 0.4521\n",
            "Epoch 3775/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5739 - accuracy: 0.9150 - val_loss: 1.8797 - val_accuracy: 0.4518\n",
            "Epoch 3776/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6380 - accuracy: 0.9100 - val_loss: 1.8791 - val_accuracy: 0.4518\n",
            "Epoch 3777/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6078 - accuracy: 0.9000 - val_loss: 1.8781 - val_accuracy: 0.4523\n",
            "Epoch 3778/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5864 - accuracy: 0.9000 - val_loss: 1.8780 - val_accuracy: 0.4523\n",
            "Epoch 3779/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6169 - accuracy: 0.8800 - val_loss: 1.8777 - val_accuracy: 0.4527\n",
            "Epoch 3780/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6058 - accuracy: 0.9000 - val_loss: 1.8768 - val_accuracy: 0.4524\n",
            "Epoch 3781/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5875 - accuracy: 0.9100 - val_loss: 1.8762 - val_accuracy: 0.4522\n",
            "Epoch 3782/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6190 - accuracy: 0.8950 - val_loss: 1.8761 - val_accuracy: 0.4521\n",
            "Epoch 3783/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6099 - accuracy: 0.9050 - val_loss: 1.8755 - val_accuracy: 0.4526\n",
            "Epoch 3784/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5944 - accuracy: 0.9250 - val_loss: 1.8751 - val_accuracy: 0.4525\n",
            "Epoch 3785/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5867 - accuracy: 0.8850 - val_loss: 1.8754 - val_accuracy: 0.4525\n",
            "Epoch 3786/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5850 - accuracy: 0.9000 - val_loss: 1.8752 - val_accuracy: 0.4527\n",
            "Epoch 3787/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5989 - accuracy: 0.8950 - val_loss: 1.8749 - val_accuracy: 0.4532\n",
            "Epoch 3788/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6373 - accuracy: 0.8750 - val_loss: 1.8750 - val_accuracy: 0.4530\n",
            "Epoch 3789/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6801 - accuracy: 0.8550 - val_loss: 1.8742 - val_accuracy: 0.4536\n",
            "Epoch 3790/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6311 - accuracy: 0.8900 - val_loss: 1.8733 - val_accuracy: 0.4536\n",
            "Epoch 3791/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5833 - accuracy: 0.9000 - val_loss: 1.8729 - val_accuracy: 0.4530\n",
            "Epoch 3792/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.6374 - accuracy: 0.8900 - val_loss: 1.8721 - val_accuracy: 0.4528\n",
            "Epoch 3793/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5997 - accuracy: 0.9300 - val_loss: 1.8706 - val_accuracy: 0.4524\n",
            "Epoch 3794/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5493 - accuracy: 0.9050 - val_loss: 1.8705 - val_accuracy: 0.4524\n",
            "Epoch 3795/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5643 - accuracy: 0.9150 - val_loss: 1.8706 - val_accuracy: 0.4525\n",
            "Epoch 3796/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.6466 - accuracy: 0.8800 - val_loss: 1.8693 - val_accuracy: 0.4527\n",
            "Epoch 3797/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5928 - accuracy: 0.8850 - val_loss: 1.8703 - val_accuracy: 0.4523\n",
            "Epoch 3798/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5360 - accuracy: 0.9350 - val_loss: 1.8703 - val_accuracy: 0.4524\n",
            "Epoch 3799/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6538 - accuracy: 0.8600 - val_loss: 1.8711 - val_accuracy: 0.4528\n",
            "Epoch 3800/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5730 - accuracy: 0.9250 - val_loss: 1.8708 - val_accuracy: 0.4526\n",
            "Epoch 3801/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5863 - accuracy: 0.9300 - val_loss: 1.8716 - val_accuracy: 0.4525\n",
            "Epoch 3802/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5872 - accuracy: 0.9100 - val_loss: 1.8720 - val_accuracy: 0.4523\n",
            "Epoch 3803/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6489 - accuracy: 0.8850 - val_loss: 1.8712 - val_accuracy: 0.4528\n",
            "Epoch 3804/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6287 - accuracy: 0.9000 - val_loss: 1.8709 - val_accuracy: 0.4525\n",
            "Epoch 3805/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6124 - accuracy: 0.9050 - val_loss: 1.8707 - val_accuracy: 0.4525\n",
            "Epoch 3806/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6230 - accuracy: 0.8900 - val_loss: 1.8709 - val_accuracy: 0.4525\n",
            "Epoch 3807/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6433 - accuracy: 0.9000 - val_loss: 1.8709 - val_accuracy: 0.4521\n",
            "Epoch 3808/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6112 - accuracy: 0.8900 - val_loss: 1.8710 - val_accuracy: 0.4522\n",
            "Epoch 3809/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6322 - accuracy: 0.9000 - val_loss: 1.8705 - val_accuracy: 0.4524\n",
            "Epoch 3810/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6054 - accuracy: 0.9050 - val_loss: 1.8715 - val_accuracy: 0.4523\n",
            "Epoch 3811/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5844 - accuracy: 0.9050 - val_loss: 1.8718 - val_accuracy: 0.4523\n",
            "Epoch 3812/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6333 - accuracy: 0.8850 - val_loss: 1.8726 - val_accuracy: 0.4529\n",
            "Epoch 3813/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6387 - accuracy: 0.8900 - val_loss: 1.8726 - val_accuracy: 0.4527\n",
            "Epoch 3814/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6191 - accuracy: 0.9200 - val_loss: 1.8729 - val_accuracy: 0.4531\n",
            "Epoch 3815/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5903 - accuracy: 0.9150 - val_loss: 1.8729 - val_accuracy: 0.4536\n",
            "Epoch 3816/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5530 - accuracy: 0.9200 - val_loss: 1.8727 - val_accuracy: 0.4536\n",
            "Epoch 3817/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5900 - accuracy: 0.9000 - val_loss: 1.8717 - val_accuracy: 0.4534\n",
            "Epoch 3818/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6009 - accuracy: 0.8950 - val_loss: 1.8717 - val_accuracy: 0.4533\n",
            "Epoch 3819/6000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.5772 - accuracy: 0.9150 - val_loss: 1.8720 - val_accuracy: 0.4533\n",
            "Epoch 3820/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6525 - accuracy: 0.8800 - val_loss: 1.8719 - val_accuracy: 0.4532\n",
            "Epoch 3821/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6882 - accuracy: 0.8600 - val_loss: 1.8716 - val_accuracy: 0.4532\n",
            "Epoch 3822/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6101 - accuracy: 0.9150 - val_loss: 1.8722 - val_accuracy: 0.4528\n",
            "Epoch 3823/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5775 - accuracy: 0.9250 - val_loss: 1.8710 - val_accuracy: 0.4533\n",
            "Epoch 3824/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5906 - accuracy: 0.8800 - val_loss: 1.8711 - val_accuracy: 0.4531\n",
            "Epoch 3825/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6216 - accuracy: 0.9050 - val_loss: 1.8706 - val_accuracy: 0.4525\n",
            "Epoch 3826/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5944 - accuracy: 0.9150 - val_loss: 1.8713 - val_accuracy: 0.4525\n",
            "Epoch 3827/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6375 - accuracy: 0.8900 - val_loss: 1.8715 - val_accuracy: 0.4526\n",
            "Epoch 3828/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6237 - accuracy: 0.8950 - val_loss: 1.8726 - val_accuracy: 0.4523\n",
            "Epoch 3829/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6231 - accuracy: 0.8500 - val_loss: 1.8740 - val_accuracy: 0.4523\n",
            "Epoch 3830/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5889 - accuracy: 0.9300 - val_loss: 1.8742 - val_accuracy: 0.4525\n",
            "Epoch 3831/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5826 - accuracy: 0.8950 - val_loss: 1.8742 - val_accuracy: 0.4523\n",
            "Epoch 3832/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5939 - accuracy: 0.9150 - val_loss: 1.8751 - val_accuracy: 0.4523\n",
            "Epoch 3833/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6060 - accuracy: 0.8950 - val_loss: 1.8761 - val_accuracy: 0.4521\n",
            "Epoch 3834/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6270 - accuracy: 0.8750 - val_loss: 1.8768 - val_accuracy: 0.4516\n",
            "Epoch 3835/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5828 - accuracy: 0.9150 - val_loss: 1.8769 - val_accuracy: 0.4510\n",
            "Epoch 3836/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5555 - accuracy: 0.9000 - val_loss: 1.8770 - val_accuracy: 0.4511\n",
            "Epoch 3837/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5821 - accuracy: 0.9200 - val_loss: 1.8775 - val_accuracy: 0.4510\n",
            "Epoch 3838/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5548 - accuracy: 0.9250 - val_loss: 1.8783 - val_accuracy: 0.4509\n",
            "Epoch 3839/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5699 - accuracy: 0.8950 - val_loss: 1.8792 - val_accuracy: 0.4512\n",
            "Epoch 3840/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5766 - accuracy: 0.9200 - val_loss: 1.8789 - val_accuracy: 0.4507\n",
            "Epoch 3841/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5629 - accuracy: 0.9300 - val_loss: 1.8792 - val_accuracy: 0.4507\n",
            "Epoch 3842/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5620 - accuracy: 0.9500 - val_loss: 1.8797 - val_accuracy: 0.4505\n",
            "Epoch 3843/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.6195 - accuracy: 0.8850 - val_loss: 1.8801 - val_accuracy: 0.4506\n",
            "Epoch 3844/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6577 - accuracy: 0.8700 - val_loss: 1.8810 - val_accuracy: 0.4513\n",
            "Epoch 3845/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6091 - accuracy: 0.8800 - val_loss: 1.8800 - val_accuracy: 0.4512\n",
            "Epoch 3846/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5787 - accuracy: 0.9200 - val_loss: 1.8806 - val_accuracy: 0.4511\n",
            "Epoch 3847/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6019 - accuracy: 0.9050 - val_loss: 1.8804 - val_accuracy: 0.4513\n",
            "Epoch 3848/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.5904 - accuracy: 0.9250 - val_loss: 1.8807 - val_accuracy: 0.4513\n",
            "Epoch 3849/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5623 - accuracy: 0.9250 - val_loss: 1.8805 - val_accuracy: 0.4516\n",
            "Epoch 3850/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6046 - accuracy: 0.9050 - val_loss: 1.8793 - val_accuracy: 0.4518\n",
            "Epoch 3851/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6227 - accuracy: 0.8900 - val_loss: 1.8785 - val_accuracy: 0.4521\n",
            "Epoch 3852/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5916 - accuracy: 0.9150 - val_loss: 1.8781 - val_accuracy: 0.4513\n",
            "Epoch 3853/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5376 - accuracy: 0.9300 - val_loss: 1.8776 - val_accuracy: 0.4514\n",
            "Epoch 3854/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5586 - accuracy: 0.9000 - val_loss: 1.8769 - val_accuracy: 0.4511\n",
            "Epoch 3855/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5537 - accuracy: 0.9150 - val_loss: 1.8766 - val_accuracy: 0.4514\n",
            "Epoch 3856/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.6417 - accuracy: 0.9000 - val_loss: 1.8754 - val_accuracy: 0.4513\n",
            "Epoch 3857/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5944 - accuracy: 0.8950 - val_loss: 1.8760 - val_accuracy: 0.4513\n",
            "Epoch 3858/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6100 - accuracy: 0.8900 - val_loss: 1.8752 - val_accuracy: 0.4511\n",
            "Epoch 3859/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5294 - accuracy: 0.9250 - val_loss: 1.8746 - val_accuracy: 0.4512\n",
            "Epoch 3860/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6163 - accuracy: 0.9300 - val_loss: 1.8756 - val_accuracy: 0.4511\n",
            "Epoch 3861/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.5910 - accuracy: 0.9100 - val_loss: 1.8755 - val_accuracy: 0.4516\n",
            "Epoch 3862/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6273 - accuracy: 0.9000 - val_loss: 1.8754 - val_accuracy: 0.4517\n",
            "Epoch 3863/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5733 - accuracy: 0.9100 - val_loss: 1.8761 - val_accuracy: 0.4518\n",
            "Epoch 3864/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6014 - accuracy: 0.8800 - val_loss: 1.8770 - val_accuracy: 0.4518\n",
            "Epoch 3865/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5859 - accuracy: 0.9200 - val_loss: 1.8766 - val_accuracy: 0.4519\n",
            "Epoch 3866/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.5498 - accuracy: 0.9450 - val_loss: 1.8769 - val_accuracy: 0.4520\n",
            "Epoch 3867/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5833 - accuracy: 0.9200 - val_loss: 1.8772 - val_accuracy: 0.4513\n",
            "Epoch 3868/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.6059 - accuracy: 0.9050 - val_loss: 1.8776 - val_accuracy: 0.4517\n",
            "Epoch 3869/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6008 - accuracy: 0.9100 - val_loss: 1.8773 - val_accuracy: 0.4513\n",
            "Epoch 3870/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6075 - accuracy: 0.8950 - val_loss: 1.8776 - val_accuracy: 0.4519\n",
            "Epoch 3871/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5864 - accuracy: 0.9050 - val_loss: 1.8778 - val_accuracy: 0.4518\n",
            "Epoch 3872/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6345 - accuracy: 0.8850 - val_loss: 1.8778 - val_accuracy: 0.4523\n",
            "Epoch 3873/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5487 - accuracy: 0.9400 - val_loss: 1.8783 - val_accuracy: 0.4531\n",
            "Epoch 3874/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5998 - accuracy: 0.9400 - val_loss: 1.8785 - val_accuracy: 0.4531\n",
            "Epoch 3875/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6411 - accuracy: 0.8800 - val_loss: 1.8790 - val_accuracy: 0.4521\n",
            "Epoch 3876/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5895 - accuracy: 0.9050 - val_loss: 1.8780 - val_accuracy: 0.4525\n",
            "Epoch 3877/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6061 - accuracy: 0.8950 - val_loss: 1.8778 - val_accuracy: 0.4525\n",
            "Epoch 3878/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5861 - accuracy: 0.9150 - val_loss: 1.8762 - val_accuracy: 0.4526\n",
            "Epoch 3879/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5681 - accuracy: 0.9150 - val_loss: 1.8758 - val_accuracy: 0.4525\n",
            "Epoch 3880/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5506 - accuracy: 0.9250 - val_loss: 1.8752 - val_accuracy: 0.4526\n",
            "Epoch 3881/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5492 - accuracy: 0.9500 - val_loss: 1.8745 - val_accuracy: 0.4523\n",
            "Epoch 3882/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5793 - accuracy: 0.9050 - val_loss: 1.8739 - val_accuracy: 0.4525\n",
            "Epoch 3883/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6277 - accuracy: 0.8750 - val_loss: 1.8737 - val_accuracy: 0.4525\n",
            "Epoch 3884/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6108 - accuracy: 0.9100 - val_loss: 1.8734 - val_accuracy: 0.4526\n",
            "Epoch 3885/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5711 - accuracy: 0.9100 - val_loss: 1.8734 - val_accuracy: 0.4525\n",
            "Epoch 3886/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5849 - accuracy: 0.8950 - val_loss: 1.8729 - val_accuracy: 0.4524\n",
            "Epoch 3887/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5718 - accuracy: 0.9300 - val_loss: 1.8731 - val_accuracy: 0.4525\n",
            "Epoch 3888/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5738 - accuracy: 0.9100 - val_loss: 1.8728 - val_accuracy: 0.4529\n",
            "Epoch 3889/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5961 - accuracy: 0.9200 - val_loss: 1.8722 - val_accuracy: 0.4532\n",
            "Epoch 3890/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6059 - accuracy: 0.9050 - val_loss: 1.8717 - val_accuracy: 0.4532\n",
            "Epoch 3891/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5850 - accuracy: 0.9000 - val_loss: 1.8720 - val_accuracy: 0.4529\n",
            "Epoch 3892/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6338 - accuracy: 0.8750 - val_loss: 1.8716 - val_accuracy: 0.4532\n",
            "Epoch 3893/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6255 - accuracy: 0.8850 - val_loss: 1.8708 - val_accuracy: 0.4527\n",
            "Epoch 3894/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5685 - accuracy: 0.9300 - val_loss: 1.8702 - val_accuracy: 0.4528\n",
            "Epoch 3895/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5553 - accuracy: 0.9300 - val_loss: 1.8701 - val_accuracy: 0.4527\n",
            "Epoch 3896/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5562 - accuracy: 0.9250 - val_loss: 1.8710 - val_accuracy: 0.4529\n",
            "Epoch 3897/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5959 - accuracy: 0.9200 - val_loss: 1.8704 - val_accuracy: 0.4523\n",
            "Epoch 3898/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5808 - accuracy: 0.9000 - val_loss: 1.8707 - val_accuracy: 0.4527\n",
            "Epoch 3899/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5854 - accuracy: 0.9150 - val_loss: 1.8705 - val_accuracy: 0.4529\n",
            "Epoch 3900/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5602 - accuracy: 0.9250 - val_loss: 1.8699 - val_accuracy: 0.4533\n",
            "Epoch 3901/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5575 - accuracy: 0.9050 - val_loss: 1.8699 - val_accuracy: 0.4535\n",
            "Epoch 3902/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5690 - accuracy: 0.9350 - val_loss: 1.8699 - val_accuracy: 0.4533\n",
            "Epoch 3903/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5630 - accuracy: 0.9250 - val_loss: 1.8705 - val_accuracy: 0.4535\n",
            "Epoch 3904/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6543 - accuracy: 0.8750 - val_loss: 1.8714 - val_accuracy: 0.4537\n",
            "Epoch 3905/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6420 - accuracy: 0.8900 - val_loss: 1.8707 - val_accuracy: 0.4539\n",
            "Epoch 3906/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6475 - accuracy: 0.8950 - val_loss: 1.8717 - val_accuracy: 0.4534\n",
            "Epoch 3907/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5801 - accuracy: 0.9200 - val_loss: 1.8724 - val_accuracy: 0.4533\n",
            "Epoch 3908/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5853 - accuracy: 0.9100 - val_loss: 1.8734 - val_accuracy: 0.4527\n",
            "Epoch 3909/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5920 - accuracy: 0.9150 - val_loss: 1.8746 - val_accuracy: 0.4527\n",
            "Epoch 3910/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5935 - accuracy: 0.8900 - val_loss: 1.8746 - val_accuracy: 0.4527\n",
            "Epoch 3911/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5935 - accuracy: 0.9000 - val_loss: 1.8744 - val_accuracy: 0.4524\n",
            "Epoch 3912/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5623 - accuracy: 0.9200 - val_loss: 1.8744 - val_accuracy: 0.4527\n",
            "Epoch 3913/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6061 - accuracy: 0.8850 - val_loss: 1.8751 - val_accuracy: 0.4533\n",
            "Epoch 3914/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5417 - accuracy: 0.9400 - val_loss: 1.8751 - val_accuracy: 0.4525\n",
            "Epoch 3915/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6110 - accuracy: 0.9050 - val_loss: 1.8749 - val_accuracy: 0.4521\n",
            "Epoch 3916/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5670 - accuracy: 0.8900 - val_loss: 1.8753 - val_accuracy: 0.4524\n",
            "Epoch 3917/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5849 - accuracy: 0.9100 - val_loss: 1.8757 - val_accuracy: 0.4524\n",
            "Epoch 3918/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6133 - accuracy: 0.8850 - val_loss: 1.8763 - val_accuracy: 0.4528\n",
            "Epoch 3919/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5824 - accuracy: 0.9050 - val_loss: 1.8767 - val_accuracy: 0.4534\n",
            "Epoch 3920/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5918 - accuracy: 0.8950 - val_loss: 1.8778 - val_accuracy: 0.4533\n",
            "Epoch 3921/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6056 - accuracy: 0.8750 - val_loss: 1.8780 - val_accuracy: 0.4537\n",
            "Epoch 3922/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5994 - accuracy: 0.9000 - val_loss: 1.8785 - val_accuracy: 0.4536\n",
            "Epoch 3923/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5735 - accuracy: 0.9250 - val_loss: 1.8797 - val_accuracy: 0.4541\n",
            "Epoch 3924/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5868 - accuracy: 0.9150 - val_loss: 1.8801 - val_accuracy: 0.4533\n",
            "Epoch 3925/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5672 - accuracy: 0.9250 - val_loss: 1.8794 - val_accuracy: 0.4535\n",
            "Epoch 3926/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5443 - accuracy: 0.9450 - val_loss: 1.8788 - val_accuracy: 0.4535\n",
            "Epoch 3927/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5980 - accuracy: 0.9150 - val_loss: 1.8798 - val_accuracy: 0.4531\n",
            "Epoch 3928/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5741 - accuracy: 0.9100 - val_loss: 1.8797 - val_accuracy: 0.4533\n",
            "Epoch 3929/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5476 - accuracy: 0.9200 - val_loss: 1.8809 - val_accuracy: 0.4531\n",
            "Epoch 3930/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5601 - accuracy: 0.9250 - val_loss: 1.8818 - val_accuracy: 0.4532\n",
            "Epoch 3931/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5847 - accuracy: 0.9050 - val_loss: 1.8824 - val_accuracy: 0.4529\n",
            "Epoch 3932/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5643 - accuracy: 0.9150 - val_loss: 1.8831 - val_accuracy: 0.4527\n",
            "Epoch 3933/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5345 - accuracy: 0.9300 - val_loss: 1.8837 - val_accuracy: 0.4531\n",
            "Epoch 3934/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5922 - accuracy: 0.9050 - val_loss: 1.8840 - val_accuracy: 0.4532\n",
            "Epoch 3935/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6256 - accuracy: 0.8900 - val_loss: 1.8836 - val_accuracy: 0.4532\n",
            "Epoch 3936/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6057 - accuracy: 0.9000 - val_loss: 1.8822 - val_accuracy: 0.4530\n",
            "Epoch 3937/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5636 - accuracy: 0.9350 - val_loss: 1.8814 - val_accuracy: 0.4534\n",
            "Epoch 3938/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.5935 - accuracy: 0.9150 - val_loss: 1.8811 - val_accuracy: 0.4535\n",
            "Epoch 3939/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5965 - accuracy: 0.9150 - val_loss: 1.8812 - val_accuracy: 0.4535\n",
            "Epoch 3940/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5662 - accuracy: 0.9200 - val_loss: 1.8811 - val_accuracy: 0.4538\n",
            "Epoch 3941/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5575 - accuracy: 0.9250 - val_loss: 1.8817 - val_accuracy: 0.4535\n",
            "Epoch 3942/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5509 - accuracy: 0.9150 - val_loss: 1.8829 - val_accuracy: 0.4537\n",
            "Epoch 3943/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6068 - accuracy: 0.8950 - val_loss: 1.8835 - val_accuracy: 0.4541\n",
            "Epoch 3944/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6320 - accuracy: 0.9050 - val_loss: 1.8840 - val_accuracy: 0.4538\n",
            "Epoch 3945/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5363 - accuracy: 0.9200 - val_loss: 1.8846 - val_accuracy: 0.4542\n",
            "Epoch 3946/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5299 - accuracy: 0.9300 - val_loss: 1.8843 - val_accuracy: 0.4544\n",
            "Epoch 3947/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5061 - accuracy: 0.9550 - val_loss: 1.8819 - val_accuracy: 0.4544\n",
            "Epoch 3948/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5461 - accuracy: 0.9400 - val_loss: 1.8810 - val_accuracy: 0.4541\n",
            "Epoch 3949/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5934 - accuracy: 0.9000 - val_loss: 1.8824 - val_accuracy: 0.4534\n",
            "Epoch 3950/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5920 - accuracy: 0.9150 - val_loss: 1.8822 - val_accuracy: 0.4532\n",
            "Epoch 3951/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6170 - accuracy: 0.8850 - val_loss: 1.8833 - val_accuracy: 0.4533\n",
            "Epoch 3952/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5316 - accuracy: 0.9200 - val_loss: 1.8829 - val_accuracy: 0.4532\n",
            "Epoch 3953/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5989 - accuracy: 0.8950 - val_loss: 1.8832 - val_accuracy: 0.4535\n",
            "Epoch 3954/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.6148 - accuracy: 0.8900 - val_loss: 1.8825 - val_accuracy: 0.4533\n",
            "Epoch 3955/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5370 - accuracy: 0.9150 - val_loss: 1.8831 - val_accuracy: 0.4536\n",
            "Epoch 3956/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.6345 - accuracy: 0.8950 - val_loss: 1.8827 - val_accuracy: 0.4533\n",
            "Epoch 3957/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5317 - accuracy: 0.9100 - val_loss: 1.8820 - val_accuracy: 0.4534\n",
            "Epoch 3958/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5697 - accuracy: 0.9100 - val_loss: 1.8819 - val_accuracy: 0.4533\n",
            "Epoch 3959/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5494 - accuracy: 0.9100 - val_loss: 1.8813 - val_accuracy: 0.4533\n",
            "Epoch 3960/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6145 - accuracy: 0.9050 - val_loss: 1.8820 - val_accuracy: 0.4531\n",
            "Epoch 3961/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5333 - accuracy: 0.9400 - val_loss: 1.8827 - val_accuracy: 0.4535\n",
            "Epoch 3962/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5339 - accuracy: 0.9150 - val_loss: 1.8824 - val_accuracy: 0.4540\n",
            "Epoch 3963/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5545 - accuracy: 0.9350 - val_loss: 1.8828 - val_accuracy: 0.4540\n",
            "Epoch 3964/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5758 - accuracy: 0.9350 - val_loss: 1.8825 - val_accuracy: 0.4535\n",
            "Epoch 3965/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6397 - accuracy: 0.8900 - val_loss: 1.8830 - val_accuracy: 0.4537\n",
            "Epoch 3966/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5737 - accuracy: 0.9150 - val_loss: 1.8841 - val_accuracy: 0.4539\n",
            "Epoch 3967/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5498 - accuracy: 0.9250 - val_loss: 1.8861 - val_accuracy: 0.4546\n",
            "Epoch 3968/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5208 - accuracy: 0.9450 - val_loss: 1.8862 - val_accuracy: 0.4543\n",
            "Epoch 3969/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5455 - accuracy: 0.9050 - val_loss: 1.8871 - val_accuracy: 0.4540\n",
            "Epoch 3970/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5105 - accuracy: 0.9350 - val_loss: 1.8866 - val_accuracy: 0.4542\n",
            "Epoch 3971/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.6395 - accuracy: 0.9050 - val_loss: 1.8861 - val_accuracy: 0.4534\n",
            "Epoch 3972/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5173 - accuracy: 0.9300 - val_loss: 1.8857 - val_accuracy: 0.4534\n",
            "Epoch 3973/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5518 - accuracy: 0.9150 - val_loss: 1.8863 - val_accuracy: 0.4534\n",
            "Epoch 3974/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5762 - accuracy: 0.9250 - val_loss: 1.8859 - val_accuracy: 0.4533\n",
            "Epoch 3975/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6000 - accuracy: 0.9150 - val_loss: 1.8863 - val_accuracy: 0.4531\n",
            "Epoch 3976/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.6051 - accuracy: 0.9150 - val_loss: 1.8867 - val_accuracy: 0.4532\n",
            "Epoch 3977/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5636 - accuracy: 0.9200 - val_loss: 1.8870 - val_accuracy: 0.4532\n",
            "Epoch 3978/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5609 - accuracy: 0.9150 - val_loss: 1.8901 - val_accuracy: 0.4536\n",
            "Epoch 3979/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5591 - accuracy: 0.9100 - val_loss: 1.8895 - val_accuracy: 0.4539\n",
            "Epoch 3980/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5316 - accuracy: 0.9200 - val_loss: 1.8889 - val_accuracy: 0.4539\n",
            "Epoch 3981/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.6586 - accuracy: 0.8800 - val_loss: 1.8878 - val_accuracy: 0.4531\n",
            "Epoch 3982/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5900 - accuracy: 0.9200 - val_loss: 1.8874 - val_accuracy: 0.4533\n",
            "Epoch 3983/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5999 - accuracy: 0.9050 - val_loss: 1.8882 - val_accuracy: 0.4535\n",
            "Epoch 3984/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5662 - accuracy: 0.9200 - val_loss: 1.8882 - val_accuracy: 0.4532\n",
            "Epoch 3985/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5364 - accuracy: 0.9250 - val_loss: 1.8878 - val_accuracy: 0.4531\n",
            "Epoch 3986/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5706 - accuracy: 0.9050 - val_loss: 1.8870 - val_accuracy: 0.4534\n",
            "Epoch 3987/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.6120 - accuracy: 0.9000 - val_loss: 1.8871 - val_accuracy: 0.4540\n",
            "Epoch 3988/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.6034 - accuracy: 0.8900 - val_loss: 1.8869 - val_accuracy: 0.4537\n",
            "Epoch 3989/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5220 - accuracy: 0.9250 - val_loss: 1.8864 - val_accuracy: 0.4538\n",
            "Epoch 3990/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5750 - accuracy: 0.9000 - val_loss: 1.8860 - val_accuracy: 0.4539\n",
            "Epoch 3991/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5573 - accuracy: 0.9150 - val_loss: 1.8854 - val_accuracy: 0.4538\n",
            "Epoch 3992/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5556 - accuracy: 0.9100 - val_loss: 1.8857 - val_accuracy: 0.4540\n",
            "Epoch 3993/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5662 - accuracy: 0.9050 - val_loss: 1.8862 - val_accuracy: 0.4536\n",
            "Epoch 3994/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5981 - accuracy: 0.8900 - val_loss: 1.8858 - val_accuracy: 0.4535\n",
            "Epoch 3995/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5889 - accuracy: 0.9100 - val_loss: 1.8858 - val_accuracy: 0.4535\n",
            "Epoch 3996/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5930 - accuracy: 0.9000 - val_loss: 1.8855 - val_accuracy: 0.4534\n",
            "Epoch 3997/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5283 - accuracy: 0.9300 - val_loss: 1.8853 - val_accuracy: 0.4539\n",
            "Epoch 3998/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5955 - accuracy: 0.8900 - val_loss: 1.8843 - val_accuracy: 0.4540\n",
            "Epoch 3999/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5758 - accuracy: 0.8800 - val_loss: 1.8828 - val_accuracy: 0.4539\n",
            "Epoch 4000/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5905 - accuracy: 0.9200 - val_loss: 1.8823 - val_accuracy: 0.4537\n",
            "Epoch 4001/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5946 - accuracy: 0.9100 - val_loss: 1.8821 - val_accuracy: 0.4536\n",
            "Epoch 4002/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5365 - accuracy: 0.9350 - val_loss: 1.8821 - val_accuracy: 0.4538\n",
            "Epoch 4003/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5708 - accuracy: 0.9100 - val_loss: 1.8818 - val_accuracy: 0.4538\n",
            "Epoch 4004/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6019 - accuracy: 0.8950 - val_loss: 1.8819 - val_accuracy: 0.4539\n",
            "Epoch 4005/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5570 - accuracy: 0.9150 - val_loss: 1.8822 - val_accuracy: 0.4539\n",
            "Epoch 4006/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5539 - accuracy: 0.9150 - val_loss: 1.8822 - val_accuracy: 0.4539\n",
            "Epoch 4007/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5240 - accuracy: 0.9150 - val_loss: 1.8827 - val_accuracy: 0.4535\n",
            "Epoch 4008/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5456 - accuracy: 0.9100 - val_loss: 1.8825 - val_accuracy: 0.4533\n",
            "Epoch 4009/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5195 - accuracy: 0.9450 - val_loss: 1.8830 - val_accuracy: 0.4531\n",
            "Epoch 4010/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5593 - accuracy: 0.9350 - val_loss: 1.8841 - val_accuracy: 0.4534\n",
            "Epoch 4011/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5318 - accuracy: 0.9350 - val_loss: 1.8840 - val_accuracy: 0.4538\n",
            "Epoch 4012/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6472 - accuracy: 0.8750 - val_loss: 1.8841 - val_accuracy: 0.4543\n",
            "Epoch 4013/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5659 - accuracy: 0.9050 - val_loss: 1.8834 - val_accuracy: 0.4544\n",
            "Epoch 4014/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5482 - accuracy: 0.9050 - val_loss: 1.8832 - val_accuracy: 0.4545\n",
            "Epoch 4015/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5719 - accuracy: 0.9100 - val_loss: 1.8847 - val_accuracy: 0.4545\n",
            "Epoch 4016/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5470 - accuracy: 0.9250 - val_loss: 1.8844 - val_accuracy: 0.4551\n",
            "Epoch 4017/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5273 - accuracy: 0.9150 - val_loss: 1.8839 - val_accuracy: 0.4548\n",
            "Epoch 4018/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5970 - accuracy: 0.8900 - val_loss: 1.8835 - val_accuracy: 0.4548\n",
            "Epoch 4019/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4985 - accuracy: 0.9550 - val_loss: 1.8832 - val_accuracy: 0.4552\n",
            "Epoch 4020/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5930 - accuracy: 0.8850 - val_loss: 1.8832 - val_accuracy: 0.4547\n",
            "Epoch 4021/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5714 - accuracy: 0.9050 - val_loss: 1.8836 - val_accuracy: 0.4548\n",
            "Epoch 4022/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6268 - accuracy: 0.8850 - val_loss: 1.8832 - val_accuracy: 0.4547\n",
            "Epoch 4023/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5913 - accuracy: 0.9050 - val_loss: 1.8842 - val_accuracy: 0.4548\n",
            "Epoch 4024/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5574 - accuracy: 0.9200 - val_loss: 1.8838 - val_accuracy: 0.4547\n",
            "Epoch 4025/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5569 - accuracy: 0.9150 - val_loss: 1.8845 - val_accuracy: 0.4550\n",
            "Epoch 4026/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.6027 - accuracy: 0.8750 - val_loss: 1.8840 - val_accuracy: 0.4548\n",
            "Epoch 4027/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5299 - accuracy: 0.9400 - val_loss: 1.8848 - val_accuracy: 0.4546\n",
            "Epoch 4028/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5578 - accuracy: 0.9000 - val_loss: 1.8847 - val_accuracy: 0.4551\n",
            "Epoch 4029/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.6292 - accuracy: 0.8950 - val_loss: 1.8845 - val_accuracy: 0.4554\n",
            "Epoch 4030/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5816 - accuracy: 0.8900 - val_loss: 1.8857 - val_accuracy: 0.4554\n",
            "Epoch 4031/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5877 - accuracy: 0.9000 - val_loss: 1.8864 - val_accuracy: 0.4552\n",
            "Epoch 4032/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6027 - accuracy: 0.8750 - val_loss: 1.8870 - val_accuracy: 0.4553\n",
            "Epoch 4033/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5709 - accuracy: 0.8900 - val_loss: 1.8862 - val_accuracy: 0.4555\n",
            "Epoch 4034/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5724 - accuracy: 0.9150 - val_loss: 1.8865 - val_accuracy: 0.4553\n",
            "Epoch 4035/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.5354 - accuracy: 0.9450 - val_loss: 1.8862 - val_accuracy: 0.4548\n",
            "Epoch 4036/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.6122 - accuracy: 0.9200 - val_loss: 1.8868 - val_accuracy: 0.4551\n",
            "Epoch 4037/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6134 - accuracy: 0.8800 - val_loss: 1.8858 - val_accuracy: 0.4555\n",
            "Epoch 4038/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5485 - accuracy: 0.8900 - val_loss: 1.8868 - val_accuracy: 0.4549\n",
            "Epoch 4039/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5495 - accuracy: 0.9300 - val_loss: 1.8860 - val_accuracy: 0.4550\n",
            "Epoch 4040/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5708 - accuracy: 0.9150 - val_loss: 1.8864 - val_accuracy: 0.4550\n",
            "Epoch 4041/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.6214 - accuracy: 0.8650 - val_loss: 1.8865 - val_accuracy: 0.4546\n",
            "Epoch 4042/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5581 - accuracy: 0.9400 - val_loss: 1.8877 - val_accuracy: 0.4543\n",
            "Epoch 4043/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.6284 - accuracy: 0.8600 - val_loss: 1.8878 - val_accuracy: 0.4539\n",
            "Epoch 4044/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4988 - accuracy: 0.9250 - val_loss: 1.8887 - val_accuracy: 0.4541\n",
            "Epoch 4045/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5381 - accuracy: 0.8950 - val_loss: 1.8883 - val_accuracy: 0.4538\n",
            "Epoch 4046/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5767 - accuracy: 0.9100 - val_loss: 1.8879 - val_accuracy: 0.4536\n",
            "Epoch 4047/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5466 - accuracy: 0.9200 - val_loss: 1.8884 - val_accuracy: 0.4537\n",
            "Epoch 4048/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5616 - accuracy: 0.9150 - val_loss: 1.8898 - val_accuracy: 0.4540\n",
            "Epoch 4049/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5285 - accuracy: 0.9450 - val_loss: 1.8902 - val_accuracy: 0.4541\n",
            "Epoch 4050/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5202 - accuracy: 0.9400 - val_loss: 1.8898 - val_accuracy: 0.4540\n",
            "Epoch 4051/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5253 - accuracy: 0.9250 - val_loss: 1.8899 - val_accuracy: 0.4546\n",
            "Epoch 4052/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5707 - accuracy: 0.9100 - val_loss: 1.8913 - val_accuracy: 0.4545\n",
            "Epoch 4053/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5677 - accuracy: 0.9200 - val_loss: 1.8917 - val_accuracy: 0.4544\n",
            "Epoch 4054/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5420 - accuracy: 0.9350 - val_loss: 1.8914 - val_accuracy: 0.4542\n",
            "Epoch 4055/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5184 - accuracy: 0.9200 - val_loss: 1.8918 - val_accuracy: 0.4546\n",
            "Epoch 4056/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4957 - accuracy: 0.9500 - val_loss: 1.8921 - val_accuracy: 0.4545\n",
            "Epoch 4057/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5617 - accuracy: 0.9200 - val_loss: 1.8921 - val_accuracy: 0.4538\n",
            "Epoch 4058/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5514 - accuracy: 0.9300 - val_loss: 1.8909 - val_accuracy: 0.4538\n",
            "Epoch 4059/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5907 - accuracy: 0.8900 - val_loss: 1.8914 - val_accuracy: 0.4541\n",
            "Epoch 4060/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5319 - accuracy: 0.9250 - val_loss: 1.8917 - val_accuracy: 0.4541\n",
            "Epoch 4061/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5864 - accuracy: 0.8900 - val_loss: 1.8924 - val_accuracy: 0.4542\n",
            "Epoch 4062/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5825 - accuracy: 0.9100 - val_loss: 1.8918 - val_accuracy: 0.4539\n",
            "Epoch 4063/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5927 - accuracy: 0.9100 - val_loss: 1.8921 - val_accuracy: 0.4537\n",
            "Epoch 4064/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5639 - accuracy: 0.9300 - val_loss: 1.8917 - val_accuracy: 0.4535\n",
            "Epoch 4065/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5646 - accuracy: 0.9000 - val_loss: 1.8909 - val_accuracy: 0.4529\n",
            "Epoch 4066/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5149 - accuracy: 0.9350 - val_loss: 1.8911 - val_accuracy: 0.4524\n",
            "Epoch 4067/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5540 - accuracy: 0.8950 - val_loss: 1.8911 - val_accuracy: 0.4521\n",
            "Epoch 4068/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.5692 - accuracy: 0.9200 - val_loss: 1.8909 - val_accuracy: 0.4519\n",
            "Epoch 4069/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5446 - accuracy: 0.9050 - val_loss: 1.8913 - val_accuracy: 0.4524\n",
            "Epoch 4070/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5412 - accuracy: 0.9550 - val_loss: 1.8919 - val_accuracy: 0.4522\n",
            "Epoch 4071/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5660 - accuracy: 0.9000 - val_loss: 1.8920 - val_accuracy: 0.4530\n",
            "Epoch 4072/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5650 - accuracy: 0.9000 - val_loss: 1.8914 - val_accuracy: 0.4526\n",
            "Epoch 4073/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5514 - accuracy: 0.9250 - val_loss: 1.8919 - val_accuracy: 0.4529\n",
            "Epoch 4074/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5283 - accuracy: 0.9250 - val_loss: 1.8911 - val_accuracy: 0.4527\n",
            "Epoch 4075/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5753 - accuracy: 0.9200 - val_loss: 1.8903 - val_accuracy: 0.4526\n",
            "Epoch 4076/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5397 - accuracy: 0.9300 - val_loss: 1.8909 - val_accuracy: 0.4527\n",
            "Epoch 4077/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5258 - accuracy: 0.9250 - val_loss: 1.8921 - val_accuracy: 0.4530\n",
            "Epoch 4078/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5377 - accuracy: 0.9250 - val_loss: 1.8913 - val_accuracy: 0.4527\n",
            "Epoch 4079/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5040 - accuracy: 0.9300 - val_loss: 1.8917 - val_accuracy: 0.4527\n",
            "Epoch 4080/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5459 - accuracy: 0.9300 - val_loss: 1.8919 - val_accuracy: 0.4525\n",
            "Epoch 4081/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5487 - accuracy: 0.9300 - val_loss: 1.8927 - val_accuracy: 0.4527\n",
            "Epoch 4082/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4865 - accuracy: 0.9350 - val_loss: 1.8928 - val_accuracy: 0.4525\n",
            "Epoch 4083/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5763 - accuracy: 0.9200 - val_loss: 1.8932 - val_accuracy: 0.4527\n",
            "Epoch 4084/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6274 - accuracy: 0.8650 - val_loss: 1.8947 - val_accuracy: 0.4523\n",
            "Epoch 4085/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5678 - accuracy: 0.8900 - val_loss: 1.8951 - val_accuracy: 0.4517\n",
            "Epoch 4086/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4872 - accuracy: 0.9700 - val_loss: 1.8954 - val_accuracy: 0.4517\n",
            "Epoch 4087/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5949 - accuracy: 0.8950 - val_loss: 1.8964 - val_accuracy: 0.4518\n",
            "Epoch 4088/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5091 - accuracy: 0.9350 - val_loss: 1.8973 - val_accuracy: 0.4517\n",
            "Epoch 4089/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5440 - accuracy: 0.9250 - val_loss: 1.8987 - val_accuracy: 0.4518\n",
            "Epoch 4090/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5199 - accuracy: 0.9050 - val_loss: 1.8991 - val_accuracy: 0.4521\n",
            "Epoch 4091/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5204 - accuracy: 0.9250 - val_loss: 1.8989 - val_accuracy: 0.4523\n",
            "Epoch 4092/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5159 - accuracy: 0.9300 - val_loss: 1.8994 - val_accuracy: 0.4520\n",
            "Epoch 4093/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5224 - accuracy: 0.9250 - val_loss: 1.8999 - val_accuracy: 0.4519\n",
            "Epoch 4094/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5347 - accuracy: 0.9500 - val_loss: 1.8989 - val_accuracy: 0.4521\n",
            "Epoch 4095/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5219 - accuracy: 0.9400 - val_loss: 1.8993 - val_accuracy: 0.4523\n",
            "Epoch 4096/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5379 - accuracy: 0.9100 - val_loss: 1.8995 - val_accuracy: 0.4528\n",
            "Epoch 4097/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5582 - accuracy: 0.9250 - val_loss: 1.8978 - val_accuracy: 0.4523\n",
            "Epoch 4098/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5098 - accuracy: 0.9350 - val_loss: 1.8991 - val_accuracy: 0.4523\n",
            "Epoch 4099/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5808 - accuracy: 0.9050 - val_loss: 1.8999 - val_accuracy: 0.4522\n",
            "Epoch 4100/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.5362 - accuracy: 0.9200 - val_loss: 1.9006 - val_accuracy: 0.4526\n",
            "Epoch 4101/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5513 - accuracy: 0.9150 - val_loss: 1.8997 - val_accuracy: 0.4522\n",
            "Epoch 4102/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5781 - accuracy: 0.9000 - val_loss: 1.8985 - val_accuracy: 0.4520\n",
            "Epoch 4103/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5095 - accuracy: 0.9500 - val_loss: 1.8979 - val_accuracy: 0.4522\n",
            "Epoch 4104/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5682 - accuracy: 0.9150 - val_loss: 1.8967 - val_accuracy: 0.4520\n",
            "Epoch 4105/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.6035 - accuracy: 0.9050 - val_loss: 1.8966 - val_accuracy: 0.4519\n",
            "Epoch 4106/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5908 - accuracy: 0.9200 - val_loss: 1.8952 - val_accuracy: 0.4518\n",
            "Epoch 4107/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5869 - accuracy: 0.9150 - val_loss: 1.8952 - val_accuracy: 0.4518\n",
            "Epoch 4108/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5447 - accuracy: 0.9100 - val_loss: 1.8941 - val_accuracy: 0.4523\n",
            "Epoch 4109/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5197 - accuracy: 0.9250 - val_loss: 1.8940 - val_accuracy: 0.4526\n",
            "Epoch 4110/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5900 - accuracy: 0.9000 - val_loss: 1.8935 - val_accuracy: 0.4531\n",
            "Epoch 4111/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5614 - accuracy: 0.9200 - val_loss: 1.8935 - val_accuracy: 0.4529\n",
            "Epoch 4112/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5649 - accuracy: 0.9250 - val_loss: 1.8931 - val_accuracy: 0.4532\n",
            "Epoch 4113/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5483 - accuracy: 0.9200 - val_loss: 1.8934 - val_accuracy: 0.4536\n",
            "Epoch 4114/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5331 - accuracy: 0.9450 - val_loss: 1.8934 - val_accuracy: 0.4536\n",
            "Epoch 4115/6000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.6138 - accuracy: 0.8950 - val_loss: 1.8936 - val_accuracy: 0.4537\n",
            "Epoch 4116/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5424 - accuracy: 0.9350 - val_loss: 1.8926 - val_accuracy: 0.4544\n",
            "Epoch 4117/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5981 - accuracy: 0.9000 - val_loss: 1.8927 - val_accuracy: 0.4544\n",
            "Epoch 4118/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5212 - accuracy: 0.9350 - val_loss: 1.8926 - val_accuracy: 0.4543\n",
            "Epoch 4119/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5173 - accuracy: 0.9500 - val_loss: 1.8936 - val_accuracy: 0.4543\n",
            "Epoch 4120/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5426 - accuracy: 0.9300 - val_loss: 1.8938 - val_accuracy: 0.4544\n",
            "Epoch 4121/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5185 - accuracy: 0.9300 - val_loss: 1.8937 - val_accuracy: 0.4546\n",
            "Epoch 4122/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5514 - accuracy: 0.9250 - val_loss: 1.8936 - val_accuracy: 0.4542\n",
            "Epoch 4123/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5546 - accuracy: 0.9100 - val_loss: 1.8935 - val_accuracy: 0.4544\n",
            "Epoch 4124/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5179 - accuracy: 0.9350 - val_loss: 1.8937 - val_accuracy: 0.4543\n",
            "Epoch 4125/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4862 - accuracy: 0.9550 - val_loss: 1.8944 - val_accuracy: 0.4546\n",
            "Epoch 4126/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5345 - accuracy: 0.9150 - val_loss: 1.8951 - val_accuracy: 0.4545\n",
            "Epoch 4127/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5254 - accuracy: 0.9250 - val_loss: 1.8950 - val_accuracy: 0.4547\n",
            "Epoch 4128/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4872 - accuracy: 0.9450 - val_loss: 1.8955 - val_accuracy: 0.4548\n",
            "Epoch 4129/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5273 - accuracy: 0.9250 - val_loss: 1.8954 - val_accuracy: 0.4550\n",
            "Epoch 4130/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5412 - accuracy: 0.9100 - val_loss: 1.8945 - val_accuracy: 0.4550\n",
            "Epoch 4131/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5392 - accuracy: 0.9100 - val_loss: 1.8943 - val_accuracy: 0.4552\n",
            "Epoch 4132/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5468 - accuracy: 0.9150 - val_loss: 1.8953 - val_accuracy: 0.4553\n",
            "Epoch 4133/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5399 - accuracy: 0.9000 - val_loss: 1.8951 - val_accuracy: 0.4551\n",
            "Epoch 4134/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5779 - accuracy: 0.9350 - val_loss: 1.8957 - val_accuracy: 0.4554\n",
            "Epoch 4135/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5450 - accuracy: 0.9200 - val_loss: 1.8962 - val_accuracy: 0.4553\n",
            "Epoch 4136/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5475 - accuracy: 0.8850 - val_loss: 1.8966 - val_accuracy: 0.4553\n",
            "Epoch 4137/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5850 - accuracy: 0.8950 - val_loss: 1.8960 - val_accuracy: 0.4551\n",
            "Epoch 4138/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5748 - accuracy: 0.9150 - val_loss: 1.8955 - val_accuracy: 0.4551\n",
            "Epoch 4139/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5101 - accuracy: 0.9400 - val_loss: 1.8960 - val_accuracy: 0.4549\n",
            "Epoch 4140/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5498 - accuracy: 0.9150 - val_loss: 1.8957 - val_accuracy: 0.4551\n",
            "Epoch 4141/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5230 - accuracy: 0.9400 - val_loss: 1.8966 - val_accuracy: 0.4551\n",
            "Epoch 4142/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4694 - accuracy: 0.9700 - val_loss: 1.8966 - val_accuracy: 0.4550\n",
            "Epoch 4143/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5236 - accuracy: 0.9200 - val_loss: 1.8967 - val_accuracy: 0.4556\n",
            "Epoch 4144/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5832 - accuracy: 0.9200 - val_loss: 1.8973 - val_accuracy: 0.4558\n",
            "Epoch 4145/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4571 - accuracy: 0.9750 - val_loss: 1.8980 - val_accuracy: 0.4559\n",
            "Epoch 4146/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5392 - accuracy: 0.9150 - val_loss: 1.8975 - val_accuracy: 0.4558\n",
            "Epoch 4147/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5168 - accuracy: 0.9250 - val_loss: 1.8987 - val_accuracy: 0.4555\n",
            "Epoch 4148/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5617 - accuracy: 0.9450 - val_loss: 1.8988 - val_accuracy: 0.4554\n",
            "Epoch 4149/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.5513 - accuracy: 0.9250 - val_loss: 1.8985 - val_accuracy: 0.4560\n",
            "Epoch 4150/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4976 - accuracy: 0.9450 - val_loss: 1.8991 - val_accuracy: 0.4554\n",
            "Epoch 4151/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5762 - accuracy: 0.8850 - val_loss: 1.9002 - val_accuracy: 0.4551\n",
            "Epoch 4152/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5466 - accuracy: 0.9100 - val_loss: 1.9006 - val_accuracy: 0.4553\n",
            "Epoch 4153/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5532 - accuracy: 0.9050 - val_loss: 1.9021 - val_accuracy: 0.4553\n",
            "Epoch 4154/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5389 - accuracy: 0.9300 - val_loss: 1.9021 - val_accuracy: 0.4553\n",
            "Epoch 4155/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5618 - accuracy: 0.9100 - val_loss: 1.9042 - val_accuracy: 0.4555\n",
            "Epoch 4156/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4828 - accuracy: 0.9400 - val_loss: 1.9051 - val_accuracy: 0.4552\n",
            "Epoch 4157/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5341 - accuracy: 0.9200 - val_loss: 1.9057 - val_accuracy: 0.4551\n",
            "Epoch 4158/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.5386 - accuracy: 0.9050 - val_loss: 1.9076 - val_accuracy: 0.4551\n",
            "Epoch 4159/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5199 - accuracy: 0.9250 - val_loss: 1.9070 - val_accuracy: 0.4556\n",
            "Epoch 4160/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5207 - accuracy: 0.9500 - val_loss: 1.9067 - val_accuracy: 0.4555\n",
            "Epoch 4161/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5160 - accuracy: 0.9200 - val_loss: 1.9066 - val_accuracy: 0.4553\n",
            "Epoch 4162/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5505 - accuracy: 0.9050 - val_loss: 1.9063 - val_accuracy: 0.4552\n",
            "Epoch 4163/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5635 - accuracy: 0.8900 - val_loss: 1.9070 - val_accuracy: 0.4548\n",
            "Epoch 4164/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5473 - accuracy: 0.9300 - val_loss: 1.9059 - val_accuracy: 0.4548\n",
            "Epoch 4165/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5536 - accuracy: 0.9250 - val_loss: 1.9053 - val_accuracy: 0.4551\n",
            "Epoch 4166/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5698 - accuracy: 0.9050 - val_loss: 1.9050 - val_accuracy: 0.4548\n",
            "Epoch 4167/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5291 - accuracy: 0.9150 - val_loss: 1.9049 - val_accuracy: 0.4549\n",
            "Epoch 4168/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5312 - accuracy: 0.9450 - val_loss: 1.9062 - val_accuracy: 0.4544\n",
            "Epoch 4169/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6053 - accuracy: 0.9150 - val_loss: 1.9060 - val_accuracy: 0.4549\n",
            "Epoch 4170/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5372 - accuracy: 0.9200 - val_loss: 1.9061 - val_accuracy: 0.4545\n",
            "Epoch 4171/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5252 - accuracy: 0.9250 - val_loss: 1.9071 - val_accuracy: 0.4546\n",
            "Epoch 4172/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5215 - accuracy: 0.9250 - val_loss: 1.9076 - val_accuracy: 0.4542\n",
            "Epoch 4173/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5467 - accuracy: 0.9050 - val_loss: 1.9081 - val_accuracy: 0.4549\n",
            "Epoch 4174/6000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.5452 - accuracy: 0.9250 - val_loss: 1.9080 - val_accuracy: 0.4546\n",
            "Epoch 4175/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5321 - accuracy: 0.9350 - val_loss: 1.9076 - val_accuracy: 0.4545\n",
            "Epoch 4176/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5299 - accuracy: 0.9400 - val_loss: 1.9071 - val_accuracy: 0.4544\n",
            "Epoch 4177/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5646 - accuracy: 0.9150 - val_loss: 1.9083 - val_accuracy: 0.4548\n",
            "Epoch 4178/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5109 - accuracy: 0.9300 - val_loss: 1.9096 - val_accuracy: 0.4547\n",
            "Epoch 4179/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5645 - accuracy: 0.8950 - val_loss: 1.9087 - val_accuracy: 0.4551\n",
            "Epoch 4180/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4930 - accuracy: 0.9400 - val_loss: 1.9091 - val_accuracy: 0.4549\n",
            "Epoch 4181/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5692 - accuracy: 0.8950 - val_loss: 1.9095 - val_accuracy: 0.4551\n",
            "Epoch 4182/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.5264 - accuracy: 0.9200 - val_loss: 1.9101 - val_accuracy: 0.4548\n",
            "Epoch 4183/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5148 - accuracy: 0.9450 - val_loss: 1.9102 - val_accuracy: 0.4551\n",
            "Epoch 4184/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5486 - accuracy: 0.9300 - val_loss: 1.9098 - val_accuracy: 0.4547\n",
            "Epoch 4185/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5285 - accuracy: 0.9400 - val_loss: 1.9095 - val_accuracy: 0.4550\n",
            "Epoch 4186/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5802 - accuracy: 0.9050 - val_loss: 1.9092 - val_accuracy: 0.4551\n",
            "Epoch 4187/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5428 - accuracy: 0.9200 - val_loss: 1.9090 - val_accuracy: 0.4550\n",
            "Epoch 4188/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5204 - accuracy: 0.9350 - val_loss: 1.9101 - val_accuracy: 0.4553\n",
            "Epoch 4189/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5113 - accuracy: 0.9450 - val_loss: 1.9100 - val_accuracy: 0.4552\n",
            "Epoch 4190/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4668 - accuracy: 0.9550 - val_loss: 1.9098 - val_accuracy: 0.4549\n",
            "Epoch 4191/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4951 - accuracy: 0.9400 - val_loss: 1.9103 - val_accuracy: 0.4549\n",
            "Epoch 4192/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5037 - accuracy: 0.9400 - val_loss: 1.9097 - val_accuracy: 0.4549\n",
            "Epoch 4193/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5562 - accuracy: 0.9100 - val_loss: 1.9101 - val_accuracy: 0.4553\n",
            "Epoch 4194/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5149 - accuracy: 0.9250 - val_loss: 1.9102 - val_accuracy: 0.4558\n",
            "Epoch 4195/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5292 - accuracy: 0.9250 - val_loss: 1.9097 - val_accuracy: 0.4559\n",
            "Epoch 4196/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5698 - accuracy: 0.9000 - val_loss: 1.9071 - val_accuracy: 0.4556\n",
            "Epoch 4197/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5325 - accuracy: 0.9300 - val_loss: 1.9068 - val_accuracy: 0.4551\n",
            "Epoch 4198/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5318 - accuracy: 0.9250 - val_loss: 1.9072 - val_accuracy: 0.4554\n",
            "Epoch 4199/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5689 - accuracy: 0.9200 - val_loss: 1.9081 - val_accuracy: 0.4552\n",
            "Epoch 4200/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5298 - accuracy: 0.9050 - val_loss: 1.9067 - val_accuracy: 0.4562\n",
            "Epoch 4201/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5466 - accuracy: 0.9200 - val_loss: 1.9063 - val_accuracy: 0.4563\n",
            "Epoch 4202/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5299 - accuracy: 0.9350 - val_loss: 1.9058 - val_accuracy: 0.4563\n",
            "Epoch 4203/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5744 - accuracy: 0.9300 - val_loss: 1.9058 - val_accuracy: 0.4560\n",
            "Epoch 4204/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5721 - accuracy: 0.8900 - val_loss: 1.9053 - val_accuracy: 0.4561\n",
            "Epoch 4205/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6211 - accuracy: 0.8900 - val_loss: 1.9058 - val_accuracy: 0.4560\n",
            "Epoch 4206/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5300 - accuracy: 0.9150 - val_loss: 1.9062 - val_accuracy: 0.4562\n",
            "Epoch 4207/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5563 - accuracy: 0.9150 - val_loss: 1.9063 - val_accuracy: 0.4556\n",
            "Epoch 4208/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4817 - accuracy: 0.9500 - val_loss: 1.9056 - val_accuracy: 0.4556\n",
            "Epoch 4209/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4956 - accuracy: 0.9450 - val_loss: 1.9065 - val_accuracy: 0.4553\n",
            "Epoch 4210/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5901 - accuracy: 0.9000 - val_loss: 1.9058 - val_accuracy: 0.4556\n",
            "Epoch 4211/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5268 - accuracy: 0.9450 - val_loss: 1.9067 - val_accuracy: 0.4556\n",
            "Epoch 4212/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5382 - accuracy: 0.9300 - val_loss: 1.9072 - val_accuracy: 0.4557\n",
            "Epoch 4213/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5097 - accuracy: 0.9400 - val_loss: 1.9083 - val_accuracy: 0.4552\n",
            "Epoch 4214/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5111 - accuracy: 0.9250 - val_loss: 1.9075 - val_accuracy: 0.4556\n",
            "Epoch 4215/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5578 - accuracy: 0.9300 - val_loss: 1.9080 - val_accuracy: 0.4555\n",
            "Epoch 4216/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5127 - accuracy: 0.9100 - val_loss: 1.9073 - val_accuracy: 0.4554\n",
            "Epoch 4217/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5800 - accuracy: 0.9150 - val_loss: 1.9065 - val_accuracy: 0.4553\n",
            "Epoch 4218/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5305 - accuracy: 0.9150 - val_loss: 1.9064 - val_accuracy: 0.4553\n",
            "Epoch 4219/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4936 - accuracy: 0.9350 - val_loss: 1.9062 - val_accuracy: 0.4555\n",
            "Epoch 4220/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5269 - accuracy: 0.9250 - val_loss: 1.9061 - val_accuracy: 0.4553\n",
            "Epoch 4221/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5770 - accuracy: 0.9000 - val_loss: 1.9071 - val_accuracy: 0.4555\n",
            "Epoch 4222/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5340 - accuracy: 0.9100 - val_loss: 1.9071 - val_accuracy: 0.4551\n",
            "Epoch 4223/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5033 - accuracy: 0.9300 - val_loss: 1.9063 - val_accuracy: 0.4552\n",
            "Epoch 4224/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5182 - accuracy: 0.9350 - val_loss: 1.9065 - val_accuracy: 0.4550\n",
            "Epoch 4225/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5314 - accuracy: 0.9200 - val_loss: 1.9076 - val_accuracy: 0.4552\n",
            "Epoch 4226/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5075 - accuracy: 0.9350 - val_loss: 1.9079 - val_accuracy: 0.4554\n",
            "Epoch 4227/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5640 - accuracy: 0.9100 - val_loss: 1.9078 - val_accuracy: 0.4549\n",
            "Epoch 4228/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5712 - accuracy: 0.8950 - val_loss: 1.9080 - val_accuracy: 0.4555\n",
            "Epoch 4229/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5620 - accuracy: 0.9050 - val_loss: 1.9072 - val_accuracy: 0.4555\n",
            "Epoch 4230/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5113 - accuracy: 0.9200 - val_loss: 1.9083 - val_accuracy: 0.4554\n",
            "Epoch 4231/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5235 - accuracy: 0.9250 - val_loss: 1.9082 - val_accuracy: 0.4555\n",
            "Epoch 4232/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5236 - accuracy: 0.9200 - val_loss: 1.9061 - val_accuracy: 0.4553\n",
            "Epoch 4233/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5651 - accuracy: 0.9000 - val_loss: 1.9065 - val_accuracy: 0.4553\n",
            "Epoch 4234/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5372 - accuracy: 0.9300 - val_loss: 1.9062 - val_accuracy: 0.4553\n",
            "Epoch 4235/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4905 - accuracy: 0.9500 - val_loss: 1.9068 - val_accuracy: 0.4556\n",
            "Epoch 4236/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5418 - accuracy: 0.9200 - val_loss: 1.9067 - val_accuracy: 0.4554\n",
            "Epoch 4237/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5411 - accuracy: 0.9350 - val_loss: 1.9064 - val_accuracy: 0.4555\n",
            "Epoch 4238/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5000 - accuracy: 0.9300 - val_loss: 1.9067 - val_accuracy: 0.4555\n",
            "Epoch 4239/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4961 - accuracy: 0.9400 - val_loss: 1.9075 - val_accuracy: 0.4554\n",
            "Epoch 4240/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4768 - accuracy: 0.9500 - val_loss: 1.9086 - val_accuracy: 0.4560\n",
            "Epoch 4241/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5080 - accuracy: 0.9300 - val_loss: 1.9075 - val_accuracy: 0.4559\n",
            "Epoch 4242/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5468 - accuracy: 0.9200 - val_loss: 1.9066 - val_accuracy: 0.4562\n",
            "Epoch 4243/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5129 - accuracy: 0.9200 - val_loss: 1.9057 - val_accuracy: 0.4558\n",
            "Epoch 4244/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5758 - accuracy: 0.9100 - val_loss: 1.9054 - val_accuracy: 0.4559\n",
            "Epoch 4245/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5163 - accuracy: 0.9400 - val_loss: 1.9047 - val_accuracy: 0.4564\n",
            "Epoch 4246/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4912 - accuracy: 0.9400 - val_loss: 1.9051 - val_accuracy: 0.4562\n",
            "Epoch 4247/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5211 - accuracy: 0.9250 - val_loss: 1.9044 - val_accuracy: 0.4564\n",
            "Epoch 4248/6000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.5396 - accuracy: 0.9100 - val_loss: 1.9033 - val_accuracy: 0.4562\n",
            "Epoch 4249/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4677 - accuracy: 0.9650 - val_loss: 1.9029 - val_accuracy: 0.4563\n",
            "Epoch 4250/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5009 - accuracy: 0.9350 - val_loss: 1.9033 - val_accuracy: 0.4562\n",
            "Epoch 4251/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5429 - accuracy: 0.9150 - val_loss: 1.9028 - val_accuracy: 0.4566\n",
            "Epoch 4252/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4988 - accuracy: 0.9400 - val_loss: 1.9027 - val_accuracy: 0.4565\n",
            "Epoch 4253/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4925 - accuracy: 0.9300 - val_loss: 1.9031 - val_accuracy: 0.4565\n",
            "Epoch 4254/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5210 - accuracy: 0.9200 - val_loss: 1.9027 - val_accuracy: 0.4562\n",
            "Epoch 4255/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4916 - accuracy: 0.9500 - val_loss: 1.9011 - val_accuracy: 0.4560\n",
            "Epoch 4256/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5380 - accuracy: 0.9250 - val_loss: 1.9012 - val_accuracy: 0.4562\n",
            "Epoch 4257/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4844 - accuracy: 0.9450 - val_loss: 1.9014 - val_accuracy: 0.4565\n",
            "Epoch 4258/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5625 - accuracy: 0.9150 - val_loss: 1.9020 - val_accuracy: 0.4565\n",
            "Epoch 4259/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5804 - accuracy: 0.9000 - val_loss: 1.9023 - val_accuracy: 0.4564\n",
            "Epoch 4260/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5029 - accuracy: 0.9350 - val_loss: 1.9025 - val_accuracy: 0.4561\n",
            "Epoch 4261/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4910 - accuracy: 0.9450 - val_loss: 1.9018 - val_accuracy: 0.4564\n",
            "Epoch 4262/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.5451 - accuracy: 0.9150 - val_loss: 1.9025 - val_accuracy: 0.4565\n",
            "Epoch 4263/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4992 - accuracy: 0.9450 - val_loss: 1.9028 - val_accuracy: 0.4564\n",
            "Epoch 4264/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5082 - accuracy: 0.9300 - val_loss: 1.9041 - val_accuracy: 0.4564\n",
            "Epoch 4265/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4947 - accuracy: 0.9450 - val_loss: 1.9049 - val_accuracy: 0.4562\n",
            "Epoch 4266/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5608 - accuracy: 0.9150 - val_loss: 1.9047 - val_accuracy: 0.4559\n",
            "Epoch 4267/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5450 - accuracy: 0.9100 - val_loss: 1.9050 - val_accuracy: 0.4562\n",
            "Epoch 4268/6000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.5403 - accuracy: 0.9100 - val_loss: 1.9066 - val_accuracy: 0.4558\n",
            "Epoch 4269/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5076 - accuracy: 0.9350 - val_loss: 1.9064 - val_accuracy: 0.4559\n",
            "Epoch 4270/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5475 - accuracy: 0.9300 - val_loss: 1.9068 - val_accuracy: 0.4564\n",
            "Epoch 4271/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4991 - accuracy: 0.9450 - val_loss: 1.9068 - val_accuracy: 0.4561\n",
            "Epoch 4272/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.5367 - accuracy: 0.9050 - val_loss: 1.9075 - val_accuracy: 0.4561\n",
            "Epoch 4273/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4986 - accuracy: 0.9250 - val_loss: 1.9082 - val_accuracy: 0.4557\n",
            "Epoch 4274/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5136 - accuracy: 0.9450 - val_loss: 1.9084 - val_accuracy: 0.4553\n",
            "Epoch 4275/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5729 - accuracy: 0.9150 - val_loss: 1.9068 - val_accuracy: 0.4554\n",
            "Epoch 4276/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5289 - accuracy: 0.9150 - val_loss: 1.9063 - val_accuracy: 0.4558\n",
            "Epoch 4277/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5227 - accuracy: 0.9200 - val_loss: 1.9073 - val_accuracy: 0.4554\n",
            "Epoch 4278/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4838 - accuracy: 0.9300 - val_loss: 1.9075 - val_accuracy: 0.4557\n",
            "Epoch 4279/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5459 - accuracy: 0.9250 - val_loss: 1.9077 - val_accuracy: 0.4558\n",
            "Epoch 4280/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4907 - accuracy: 0.9500 - val_loss: 1.9087 - val_accuracy: 0.4552\n",
            "Epoch 4281/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5521 - accuracy: 0.9200 - val_loss: 1.9090 - val_accuracy: 0.4554\n",
            "Epoch 4282/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5554 - accuracy: 0.9300 - val_loss: 1.9097 - val_accuracy: 0.4556\n",
            "Epoch 4283/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5027 - accuracy: 0.9450 - val_loss: 1.9101 - val_accuracy: 0.4553\n",
            "Epoch 4284/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5210 - accuracy: 0.9300 - val_loss: 1.9110 - val_accuracy: 0.4553\n",
            "Epoch 4285/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5123 - accuracy: 0.9250 - val_loss: 1.9106 - val_accuracy: 0.4553\n",
            "Epoch 4286/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5458 - accuracy: 0.9050 - val_loss: 1.9103 - val_accuracy: 0.4552\n",
            "Epoch 4287/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5442 - accuracy: 0.9150 - val_loss: 1.9102 - val_accuracy: 0.4551\n",
            "Epoch 4288/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5602 - accuracy: 0.9100 - val_loss: 1.9091 - val_accuracy: 0.4551\n",
            "Epoch 4289/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5724 - accuracy: 0.9150 - val_loss: 1.9090 - val_accuracy: 0.4548\n",
            "Epoch 4290/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5484 - accuracy: 0.9200 - val_loss: 1.9092 - val_accuracy: 0.4549\n",
            "Epoch 4291/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4411 - accuracy: 0.9600 - val_loss: 1.9099 - val_accuracy: 0.4547\n",
            "Epoch 4292/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5355 - accuracy: 0.9250 - val_loss: 1.9097 - val_accuracy: 0.4544\n",
            "Epoch 4293/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5118 - accuracy: 0.9450 - val_loss: 1.9096 - val_accuracy: 0.4544\n",
            "Epoch 4294/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5447 - accuracy: 0.9300 - val_loss: 1.9093 - val_accuracy: 0.4545\n",
            "Epoch 4295/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5186 - accuracy: 0.9400 - val_loss: 1.9096 - val_accuracy: 0.4545\n",
            "Epoch 4296/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5094 - accuracy: 0.9400 - val_loss: 1.9098 - val_accuracy: 0.4541\n",
            "Epoch 4297/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5443 - accuracy: 0.8950 - val_loss: 1.9096 - val_accuracy: 0.4540\n",
            "Epoch 4298/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5293 - accuracy: 0.9100 - val_loss: 1.9092 - val_accuracy: 0.4539\n",
            "Epoch 4299/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5102 - accuracy: 0.9300 - val_loss: 1.9088 - val_accuracy: 0.4541\n",
            "Epoch 4300/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5634 - accuracy: 0.9350 - val_loss: 1.9089 - val_accuracy: 0.4542\n",
            "Epoch 4301/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5237 - accuracy: 0.9200 - val_loss: 1.9095 - val_accuracy: 0.4543\n",
            "Epoch 4302/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4746 - accuracy: 0.9550 - val_loss: 1.9101 - val_accuracy: 0.4542\n",
            "Epoch 4303/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4999 - accuracy: 0.9350 - val_loss: 1.9096 - val_accuracy: 0.4544\n",
            "Epoch 4304/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4933 - accuracy: 0.9300 - val_loss: 1.9102 - val_accuracy: 0.4547\n",
            "Epoch 4305/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5043 - accuracy: 0.9400 - val_loss: 1.9113 - val_accuracy: 0.4542\n",
            "Epoch 4306/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5039 - accuracy: 0.9150 - val_loss: 1.9104 - val_accuracy: 0.4548\n",
            "Epoch 4307/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5034 - accuracy: 0.9450 - val_loss: 1.9101 - val_accuracy: 0.4551\n",
            "Epoch 4308/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5185 - accuracy: 0.9250 - val_loss: 1.9105 - val_accuracy: 0.4551\n",
            "Epoch 4309/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5304 - accuracy: 0.9000 - val_loss: 1.9105 - val_accuracy: 0.4550\n",
            "Epoch 4310/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5185 - accuracy: 0.9300 - val_loss: 1.9102 - val_accuracy: 0.4552\n",
            "Epoch 4311/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5010 - accuracy: 0.9350 - val_loss: 1.9104 - val_accuracy: 0.4555\n",
            "Epoch 4312/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.5391 - accuracy: 0.9200 - val_loss: 1.9106 - val_accuracy: 0.4560\n",
            "Epoch 4313/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4572 - accuracy: 0.9550 - val_loss: 1.9112 - val_accuracy: 0.4564\n",
            "Epoch 4314/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5079 - accuracy: 0.9400 - val_loss: 1.9101 - val_accuracy: 0.4568\n",
            "Epoch 4315/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5317 - accuracy: 0.9200 - val_loss: 1.9105 - val_accuracy: 0.4564\n",
            "Epoch 4316/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5329 - accuracy: 0.9250 - val_loss: 1.9100 - val_accuracy: 0.4564\n",
            "Epoch 4317/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4930 - accuracy: 0.9250 - val_loss: 1.9097 - val_accuracy: 0.4566\n",
            "Epoch 4318/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5114 - accuracy: 0.9100 - val_loss: 1.9089 - val_accuracy: 0.4566\n",
            "Epoch 4319/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5093 - accuracy: 0.9400 - val_loss: 1.9076 - val_accuracy: 0.4566\n",
            "Epoch 4320/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5117 - accuracy: 0.9550 - val_loss: 1.9084 - val_accuracy: 0.4562\n",
            "Epoch 4321/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5069 - accuracy: 0.9300 - val_loss: 1.9079 - val_accuracy: 0.4562\n",
            "Epoch 4322/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4880 - accuracy: 0.9400 - val_loss: 1.9079 - val_accuracy: 0.4558\n",
            "Epoch 4323/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4911 - accuracy: 0.9500 - val_loss: 1.9069 - val_accuracy: 0.4553\n",
            "Epoch 4324/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4932 - accuracy: 0.9500 - val_loss: 1.9069 - val_accuracy: 0.4557\n",
            "Epoch 4325/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5361 - accuracy: 0.9250 - val_loss: 1.9074 - val_accuracy: 0.4558\n",
            "Epoch 4326/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4804 - accuracy: 0.9550 - val_loss: 1.9080 - val_accuracy: 0.4554\n",
            "Epoch 4327/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4808 - accuracy: 0.9350 - val_loss: 1.9087 - val_accuracy: 0.4555\n",
            "Epoch 4328/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4655 - accuracy: 0.9600 - val_loss: 1.9080 - val_accuracy: 0.4555\n",
            "Epoch 4329/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4781 - accuracy: 0.9600 - val_loss: 1.9075 - val_accuracy: 0.4558\n",
            "Epoch 4330/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5100 - accuracy: 0.9250 - val_loss: 1.9064 - val_accuracy: 0.4563\n",
            "Epoch 4331/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5621 - accuracy: 0.9050 - val_loss: 1.9062 - val_accuracy: 0.4565\n",
            "Epoch 4332/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4886 - accuracy: 0.9250 - val_loss: 1.9061 - val_accuracy: 0.4569\n",
            "Epoch 4333/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5121 - accuracy: 0.9350 - val_loss: 1.9054 - val_accuracy: 0.4571\n",
            "Epoch 4334/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4959 - accuracy: 0.9300 - val_loss: 1.9058 - val_accuracy: 0.4566\n",
            "Epoch 4335/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4865 - accuracy: 0.9550 - val_loss: 1.9060 - val_accuracy: 0.4568\n",
            "Epoch 4336/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4795 - accuracy: 0.9400 - val_loss: 1.9058 - val_accuracy: 0.4568\n",
            "Epoch 4337/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5357 - accuracy: 0.9100 - val_loss: 1.9065 - val_accuracy: 0.4568\n",
            "Epoch 4338/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4887 - accuracy: 0.9400 - val_loss: 1.9064 - val_accuracy: 0.4571\n",
            "Epoch 4339/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5011 - accuracy: 0.9500 - val_loss: 1.9060 - val_accuracy: 0.4571\n",
            "Epoch 4340/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4916 - accuracy: 0.9300 - val_loss: 1.9071 - val_accuracy: 0.4566\n",
            "Epoch 4341/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4673 - accuracy: 0.9500 - val_loss: 1.9080 - val_accuracy: 0.4571\n",
            "Epoch 4342/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5016 - accuracy: 0.9400 - val_loss: 1.9080 - val_accuracy: 0.4570\n",
            "Epoch 4343/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.5961 - accuracy: 0.9050 - val_loss: 1.9078 - val_accuracy: 0.4568\n",
            "Epoch 4344/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4605 - accuracy: 0.9550 - val_loss: 1.9080 - val_accuracy: 0.4568\n",
            "Epoch 4345/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4984 - accuracy: 0.9600 - val_loss: 1.9077 - val_accuracy: 0.4566\n",
            "Epoch 4346/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5048 - accuracy: 0.9350 - val_loss: 1.9075 - val_accuracy: 0.4565\n",
            "Epoch 4347/6000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.5236 - accuracy: 0.9450 - val_loss: 1.9068 - val_accuracy: 0.4567\n",
            "Epoch 4348/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5107 - accuracy: 0.9300 - val_loss: 1.9061 - val_accuracy: 0.4572\n",
            "Epoch 4349/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5378 - accuracy: 0.9150 - val_loss: 1.9059 - val_accuracy: 0.4576\n",
            "Epoch 4350/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5192 - accuracy: 0.9300 - val_loss: 1.9063 - val_accuracy: 0.4575\n",
            "Epoch 4351/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4786 - accuracy: 0.9550 - val_loss: 1.9074 - val_accuracy: 0.4570\n",
            "Epoch 4352/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5910 - accuracy: 0.9000 - val_loss: 1.9080 - val_accuracy: 0.4570\n",
            "Epoch 4353/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4829 - accuracy: 0.9600 - val_loss: 1.9092 - val_accuracy: 0.4575\n",
            "Epoch 4354/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5490 - accuracy: 0.9050 - val_loss: 1.9100 - val_accuracy: 0.4568\n",
            "Epoch 4355/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5082 - accuracy: 0.9450 - val_loss: 1.9099 - val_accuracy: 0.4569\n",
            "Epoch 4356/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4981 - accuracy: 0.9400 - val_loss: 1.9098 - val_accuracy: 0.4569\n",
            "Epoch 4357/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4456 - accuracy: 0.9650 - val_loss: 1.9106 - val_accuracy: 0.4565\n",
            "Epoch 4358/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5009 - accuracy: 0.9400 - val_loss: 1.9116 - val_accuracy: 0.4566\n",
            "Epoch 4359/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4673 - accuracy: 0.9400 - val_loss: 1.9116 - val_accuracy: 0.4566\n",
            "Epoch 4360/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5597 - accuracy: 0.9050 - val_loss: 1.9121 - val_accuracy: 0.4565\n",
            "Epoch 4361/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4725 - accuracy: 0.9500 - val_loss: 1.9126 - val_accuracy: 0.4565\n",
            "Epoch 4362/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4965 - accuracy: 0.9300 - val_loss: 1.9138 - val_accuracy: 0.4569\n",
            "Epoch 4363/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4698 - accuracy: 0.9500 - val_loss: 1.9143 - val_accuracy: 0.4567\n",
            "Epoch 4364/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5679 - accuracy: 0.9250 - val_loss: 1.9143 - val_accuracy: 0.4566\n",
            "Epoch 4365/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5213 - accuracy: 0.9350 - val_loss: 1.9152 - val_accuracy: 0.4561\n",
            "Epoch 4366/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4972 - accuracy: 0.9250 - val_loss: 1.9166 - val_accuracy: 0.4564\n",
            "Epoch 4367/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4784 - accuracy: 0.9350 - val_loss: 1.9156 - val_accuracy: 0.4563\n",
            "Epoch 4368/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4731 - accuracy: 0.9550 - val_loss: 1.9165 - val_accuracy: 0.4565\n",
            "Epoch 4369/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5244 - accuracy: 0.9250 - val_loss: 1.9183 - val_accuracy: 0.4556\n",
            "Epoch 4370/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4993 - accuracy: 0.9450 - val_loss: 1.9190 - val_accuracy: 0.4557\n",
            "Epoch 4371/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5204 - accuracy: 0.9200 - val_loss: 1.9200 - val_accuracy: 0.4557\n",
            "Epoch 4372/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5115 - accuracy: 0.9450 - val_loss: 1.9212 - val_accuracy: 0.4563\n",
            "Epoch 4373/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4980 - accuracy: 0.9300 - val_loss: 1.9210 - val_accuracy: 0.4559\n",
            "Epoch 4374/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5200 - accuracy: 0.9200 - val_loss: 1.9206 - val_accuracy: 0.4562\n",
            "Epoch 4375/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5202 - accuracy: 0.9300 - val_loss: 1.9204 - val_accuracy: 0.4564\n",
            "Epoch 4376/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4795 - accuracy: 0.9400 - val_loss: 1.9205 - val_accuracy: 0.4565\n",
            "Epoch 4377/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.5048 - accuracy: 0.9250 - val_loss: 1.9201 - val_accuracy: 0.4564\n",
            "Epoch 4378/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5198 - accuracy: 0.9450 - val_loss: 1.9205 - val_accuracy: 0.4567\n",
            "Epoch 4379/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4950 - accuracy: 0.9500 - val_loss: 1.9197 - val_accuracy: 0.4567\n",
            "Epoch 4380/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5191 - accuracy: 0.9400 - val_loss: 1.9198 - val_accuracy: 0.4564\n",
            "Epoch 4381/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4911 - accuracy: 0.9300 - val_loss: 1.9191 - val_accuracy: 0.4562\n",
            "Epoch 4382/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5097 - accuracy: 0.9400 - val_loss: 1.9187 - val_accuracy: 0.4564\n",
            "Epoch 4383/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5775 - accuracy: 0.9250 - val_loss: 1.9190 - val_accuracy: 0.4562\n",
            "Epoch 4384/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.5205 - accuracy: 0.9200 - val_loss: 1.9195 - val_accuracy: 0.4564\n",
            "Epoch 4385/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4557 - accuracy: 0.9650 - val_loss: 1.9190 - val_accuracy: 0.4560\n",
            "Epoch 4386/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5049 - accuracy: 0.9450 - val_loss: 1.9200 - val_accuracy: 0.4565\n",
            "Epoch 4387/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4978 - accuracy: 0.9400 - val_loss: 1.9194 - val_accuracy: 0.4562\n",
            "Epoch 4388/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4930 - accuracy: 0.9400 - val_loss: 1.9191 - val_accuracy: 0.4562\n",
            "Epoch 4389/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4634 - accuracy: 0.9500 - val_loss: 1.9193 - val_accuracy: 0.4560\n",
            "Epoch 4390/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4613 - accuracy: 0.9650 - val_loss: 1.9195 - val_accuracy: 0.4555\n",
            "Epoch 4391/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4822 - accuracy: 0.9400 - val_loss: 1.9192 - val_accuracy: 0.4556\n",
            "Epoch 4392/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4840 - accuracy: 0.9350 - val_loss: 1.9181 - val_accuracy: 0.4554\n",
            "Epoch 4393/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4472 - accuracy: 0.9650 - val_loss: 1.9166 - val_accuracy: 0.4560\n",
            "Epoch 4394/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5147 - accuracy: 0.9150 - val_loss: 1.9156 - val_accuracy: 0.4566\n",
            "Epoch 4395/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4934 - accuracy: 0.9400 - val_loss: 1.9151 - val_accuracy: 0.4567\n",
            "Epoch 4396/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5025 - accuracy: 0.8950 - val_loss: 1.9148 - val_accuracy: 0.4569\n",
            "Epoch 4397/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4619 - accuracy: 0.9450 - val_loss: 1.9149 - val_accuracy: 0.4567\n",
            "Epoch 4398/6000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.5240 - accuracy: 0.9100 - val_loss: 1.9136 - val_accuracy: 0.4570\n",
            "Epoch 4399/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5254 - accuracy: 0.9250 - val_loss: 1.9136 - val_accuracy: 0.4566\n",
            "Epoch 4400/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5375 - accuracy: 0.9000 - val_loss: 1.9136 - val_accuracy: 0.4566\n",
            "Epoch 4401/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4893 - accuracy: 0.9300 - val_loss: 1.9132 - val_accuracy: 0.4567\n",
            "Epoch 4402/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4398 - accuracy: 0.9500 - val_loss: 1.9128 - val_accuracy: 0.4569\n",
            "Epoch 4403/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5250 - accuracy: 0.9300 - val_loss: 1.9121 - val_accuracy: 0.4565\n",
            "Epoch 4404/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5131 - accuracy: 0.9250 - val_loss: 1.9114 - val_accuracy: 0.4566\n",
            "Epoch 4405/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4859 - accuracy: 0.9300 - val_loss: 1.9112 - val_accuracy: 0.4569\n",
            "Epoch 4406/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4839 - accuracy: 0.9450 - val_loss: 1.9114 - val_accuracy: 0.4568\n",
            "Epoch 4407/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4828 - accuracy: 0.9350 - val_loss: 1.9114 - val_accuracy: 0.4570\n",
            "Epoch 4408/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4868 - accuracy: 0.9500 - val_loss: 1.9113 - val_accuracy: 0.4566\n",
            "Epoch 4409/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5224 - accuracy: 0.9150 - val_loss: 1.9112 - val_accuracy: 0.4566\n",
            "Epoch 4410/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5160 - accuracy: 0.9200 - val_loss: 1.9091 - val_accuracy: 0.4574\n",
            "Epoch 4411/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4917 - accuracy: 0.9100 - val_loss: 1.9093 - val_accuracy: 0.4575\n",
            "Epoch 4412/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5343 - accuracy: 0.9350 - val_loss: 1.9087 - val_accuracy: 0.4571\n",
            "Epoch 4413/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4837 - accuracy: 0.9250 - val_loss: 1.9098 - val_accuracy: 0.4572\n",
            "Epoch 4414/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5145 - accuracy: 0.9450 - val_loss: 1.9103 - val_accuracy: 0.4569\n",
            "Epoch 4415/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5017 - accuracy: 0.9200 - val_loss: 1.9106 - val_accuracy: 0.4567\n",
            "Epoch 4416/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4714 - accuracy: 0.9400 - val_loss: 1.9108 - val_accuracy: 0.4569\n",
            "Epoch 4417/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5021 - accuracy: 0.9550 - val_loss: 1.9120 - val_accuracy: 0.4563\n",
            "Epoch 4418/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4890 - accuracy: 0.9500 - val_loss: 1.9124 - val_accuracy: 0.4566\n",
            "Epoch 4419/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4930 - accuracy: 0.9400 - val_loss: 1.9128 - val_accuracy: 0.4567\n",
            "Epoch 4420/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5262 - accuracy: 0.9300 - val_loss: 1.9148 - val_accuracy: 0.4570\n",
            "Epoch 4421/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4810 - accuracy: 0.9450 - val_loss: 1.9158 - val_accuracy: 0.4564\n",
            "Epoch 4422/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5494 - accuracy: 0.9200 - val_loss: 1.9158 - val_accuracy: 0.4565\n",
            "Epoch 4423/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5740 - accuracy: 0.9100 - val_loss: 1.9158 - val_accuracy: 0.4565\n",
            "Epoch 4424/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5168 - accuracy: 0.9200 - val_loss: 1.9155 - val_accuracy: 0.4564\n",
            "Epoch 4425/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5149 - accuracy: 0.9300 - val_loss: 1.9162 - val_accuracy: 0.4563\n",
            "Epoch 4426/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4776 - accuracy: 0.9400 - val_loss: 1.9158 - val_accuracy: 0.4568\n",
            "Epoch 4427/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5258 - accuracy: 0.9150 - val_loss: 1.9169 - val_accuracy: 0.4566\n",
            "Epoch 4428/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4542 - accuracy: 0.9450 - val_loss: 1.9175 - val_accuracy: 0.4567\n",
            "Epoch 4429/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4855 - accuracy: 0.9400 - val_loss: 1.9174 - val_accuracy: 0.4562\n",
            "Epoch 4430/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5551 - accuracy: 0.8900 - val_loss: 1.9162 - val_accuracy: 0.4565\n",
            "Epoch 4431/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4890 - accuracy: 0.9350 - val_loss: 1.9161 - val_accuracy: 0.4568\n",
            "Epoch 4432/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4803 - accuracy: 0.9500 - val_loss: 1.9166 - val_accuracy: 0.4563\n",
            "Epoch 4433/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5185 - accuracy: 0.9200 - val_loss: 1.9173 - val_accuracy: 0.4566\n",
            "Epoch 4434/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4809 - accuracy: 0.9550 - val_loss: 1.9168 - val_accuracy: 0.4564\n",
            "Epoch 4435/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4880 - accuracy: 0.9550 - val_loss: 1.9149 - val_accuracy: 0.4568\n",
            "Epoch 4436/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5447 - accuracy: 0.9050 - val_loss: 1.9147 - val_accuracy: 0.4568\n",
            "Epoch 4437/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5038 - accuracy: 0.9400 - val_loss: 1.9161 - val_accuracy: 0.4562\n",
            "Epoch 4438/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4892 - accuracy: 0.9350 - val_loss: 1.9158 - val_accuracy: 0.4561\n",
            "Epoch 4439/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4811 - accuracy: 0.9300 - val_loss: 1.9156 - val_accuracy: 0.4564\n",
            "Epoch 4440/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5204 - accuracy: 0.9300 - val_loss: 1.9142 - val_accuracy: 0.4572\n",
            "Epoch 4441/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4653 - accuracy: 0.9450 - val_loss: 1.9146 - val_accuracy: 0.4568\n",
            "Epoch 4442/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5179 - accuracy: 0.9300 - val_loss: 1.9150 - val_accuracy: 0.4566\n",
            "Epoch 4443/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4953 - accuracy: 0.9050 - val_loss: 1.9153 - val_accuracy: 0.4570\n",
            "Epoch 4444/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4753 - accuracy: 0.9500 - val_loss: 1.9149 - val_accuracy: 0.4569\n",
            "Epoch 4445/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4695 - accuracy: 0.9400 - val_loss: 1.9141 - val_accuracy: 0.4570\n",
            "Epoch 4446/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4748 - accuracy: 0.9650 - val_loss: 1.9151 - val_accuracy: 0.4566\n",
            "Epoch 4447/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4779 - accuracy: 0.9300 - val_loss: 1.9159 - val_accuracy: 0.4564\n",
            "Epoch 4448/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4936 - accuracy: 0.9400 - val_loss: 1.9164 - val_accuracy: 0.4563\n",
            "Epoch 4449/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5338 - accuracy: 0.9150 - val_loss: 1.9166 - val_accuracy: 0.4564\n",
            "Epoch 4450/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4835 - accuracy: 0.9250 - val_loss: 1.9166 - val_accuracy: 0.4566\n",
            "Epoch 4451/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.5404 - accuracy: 0.9100 - val_loss: 1.9152 - val_accuracy: 0.4573\n",
            "Epoch 4452/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4560 - accuracy: 0.9400 - val_loss: 1.9153 - val_accuracy: 0.4573\n",
            "Epoch 4453/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4939 - accuracy: 0.9500 - val_loss: 1.9156 - val_accuracy: 0.4570\n",
            "Epoch 4454/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5125 - accuracy: 0.9350 - val_loss: 1.9158 - val_accuracy: 0.4571\n",
            "Epoch 4455/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5130 - accuracy: 0.9300 - val_loss: 1.9162 - val_accuracy: 0.4570\n",
            "Epoch 4456/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4965 - accuracy: 0.9400 - val_loss: 1.9156 - val_accuracy: 0.4568\n",
            "Epoch 4457/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5086 - accuracy: 0.9250 - val_loss: 1.9156 - val_accuracy: 0.4565\n",
            "Epoch 4458/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4883 - accuracy: 0.9150 - val_loss: 1.9162 - val_accuracy: 0.4567\n",
            "Epoch 4459/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4701 - accuracy: 0.9500 - val_loss: 1.9164 - val_accuracy: 0.4565\n",
            "Epoch 4460/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5503 - accuracy: 0.8900 - val_loss: 1.9169 - val_accuracy: 0.4560\n",
            "Epoch 4461/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5128 - accuracy: 0.9350 - val_loss: 1.9178 - val_accuracy: 0.4560\n",
            "Epoch 4462/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4742 - accuracy: 0.9550 - val_loss: 1.9179 - val_accuracy: 0.4560\n",
            "Epoch 4463/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5100 - accuracy: 0.9050 - val_loss: 1.9185 - val_accuracy: 0.4561\n",
            "Epoch 4464/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4784 - accuracy: 0.9350 - val_loss: 1.9195 - val_accuracy: 0.4558\n",
            "Epoch 4465/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4842 - accuracy: 0.9400 - val_loss: 1.9197 - val_accuracy: 0.4558\n",
            "Epoch 4466/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5288 - accuracy: 0.9100 - val_loss: 1.9209 - val_accuracy: 0.4556\n",
            "Epoch 4467/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5002 - accuracy: 0.9400 - val_loss: 1.9220 - val_accuracy: 0.4558\n",
            "Epoch 4468/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4639 - accuracy: 0.9550 - val_loss: 1.9224 - val_accuracy: 0.4556\n",
            "Epoch 4469/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5335 - accuracy: 0.9150 - val_loss: 1.9227 - val_accuracy: 0.4558\n",
            "Epoch 4470/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5584 - accuracy: 0.9150 - val_loss: 1.9226 - val_accuracy: 0.4560\n",
            "Epoch 4471/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4992 - accuracy: 0.9350 - val_loss: 1.9226 - val_accuracy: 0.4557\n",
            "Epoch 4472/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5106 - accuracy: 0.9600 - val_loss: 1.9224 - val_accuracy: 0.4559\n",
            "Epoch 4473/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4896 - accuracy: 0.9350 - val_loss: 1.9230 - val_accuracy: 0.4558\n",
            "Epoch 4474/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5762 - accuracy: 0.9000 - val_loss: 1.9241 - val_accuracy: 0.4557\n",
            "Epoch 4475/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4750 - accuracy: 0.9600 - val_loss: 1.9244 - val_accuracy: 0.4554\n",
            "Epoch 4476/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4573 - accuracy: 0.9500 - val_loss: 1.9244 - val_accuracy: 0.4557\n",
            "Epoch 4477/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5176 - accuracy: 0.9250 - val_loss: 1.9255 - val_accuracy: 0.4557\n",
            "Epoch 4478/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4843 - accuracy: 0.9500 - val_loss: 1.9257 - val_accuracy: 0.4559\n",
            "Epoch 4479/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4457 - accuracy: 0.9550 - val_loss: 1.9265 - val_accuracy: 0.4552\n",
            "Epoch 4480/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4933 - accuracy: 0.9250 - val_loss: 1.9278 - val_accuracy: 0.4554\n",
            "Epoch 4481/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5434 - accuracy: 0.9000 - val_loss: 1.9292 - val_accuracy: 0.4540\n",
            "Epoch 4482/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4499 - accuracy: 0.9600 - val_loss: 1.9303 - val_accuracy: 0.4537\n",
            "Epoch 4483/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4911 - accuracy: 0.9300 - val_loss: 1.9301 - val_accuracy: 0.4539\n",
            "Epoch 4484/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4653 - accuracy: 0.9400 - val_loss: 1.9311 - val_accuracy: 0.4539\n",
            "Epoch 4485/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5388 - accuracy: 0.9300 - val_loss: 1.9325 - val_accuracy: 0.4547\n",
            "Epoch 4486/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5478 - accuracy: 0.9250 - val_loss: 1.9328 - val_accuracy: 0.4548\n",
            "Epoch 4487/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5202 - accuracy: 0.9300 - val_loss: 1.9353 - val_accuracy: 0.4542\n",
            "Epoch 4488/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4511 - accuracy: 0.9500 - val_loss: 1.9353 - val_accuracy: 0.4540\n",
            "Epoch 4489/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5075 - accuracy: 0.9200 - val_loss: 1.9343 - val_accuracy: 0.4544\n",
            "Epoch 4490/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4567 - accuracy: 0.9550 - val_loss: 1.9333 - val_accuracy: 0.4544\n",
            "Epoch 4491/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4666 - accuracy: 0.9450 - val_loss: 1.9339 - val_accuracy: 0.4545\n",
            "Epoch 4492/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4831 - accuracy: 0.9250 - val_loss: 1.9334 - val_accuracy: 0.4544\n",
            "Epoch 4493/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4656 - accuracy: 0.9650 - val_loss: 1.9332 - val_accuracy: 0.4542\n",
            "Epoch 4494/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4881 - accuracy: 0.9450 - val_loss: 1.9334 - val_accuracy: 0.4545\n",
            "Epoch 4495/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4947 - accuracy: 0.9450 - val_loss: 1.9330 - val_accuracy: 0.4543\n",
            "Epoch 4496/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4785 - accuracy: 0.9450 - val_loss: 1.9323 - val_accuracy: 0.4545\n",
            "Epoch 4497/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4851 - accuracy: 0.9250 - val_loss: 1.9323 - val_accuracy: 0.4541\n",
            "Epoch 4498/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4509 - accuracy: 0.9650 - val_loss: 1.9326 - val_accuracy: 0.4546\n",
            "Epoch 4499/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4891 - accuracy: 0.9450 - val_loss: 1.9326 - val_accuracy: 0.4544\n",
            "Epoch 4500/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4488 - accuracy: 0.9550 - val_loss: 1.9317 - val_accuracy: 0.4550\n",
            "Epoch 4501/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4661 - accuracy: 0.9550 - val_loss: 1.9311 - val_accuracy: 0.4554\n",
            "Epoch 4502/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4566 - accuracy: 0.9550 - val_loss: 1.9313 - val_accuracy: 0.4554\n",
            "Epoch 4503/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4863 - accuracy: 0.9400 - val_loss: 1.9315 - val_accuracy: 0.4555\n",
            "Epoch 4504/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4468 - accuracy: 0.9550 - val_loss: 1.9309 - val_accuracy: 0.4555\n",
            "Epoch 4505/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5161 - accuracy: 0.9300 - val_loss: 1.9307 - val_accuracy: 0.4554\n",
            "Epoch 4506/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4859 - accuracy: 0.9300 - val_loss: 1.9295 - val_accuracy: 0.4552\n",
            "Epoch 4507/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5211 - accuracy: 0.9250 - val_loss: 1.9283 - val_accuracy: 0.4551\n",
            "Epoch 4508/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5385 - accuracy: 0.9350 - val_loss: 1.9274 - val_accuracy: 0.4551\n",
            "Epoch 4509/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4935 - accuracy: 0.9400 - val_loss: 1.9270 - val_accuracy: 0.4549\n",
            "Epoch 4510/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5061 - accuracy: 0.9300 - val_loss: 1.9272 - val_accuracy: 0.4551\n",
            "Epoch 4511/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4829 - accuracy: 0.9500 - val_loss: 1.9272 - val_accuracy: 0.4551\n",
            "Epoch 4512/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4925 - accuracy: 0.9450 - val_loss: 1.9264 - val_accuracy: 0.4549\n",
            "Epoch 4513/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5072 - accuracy: 0.9400 - val_loss: 1.9258 - val_accuracy: 0.4549\n",
            "Epoch 4514/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5011 - accuracy: 0.9250 - val_loss: 1.9251 - val_accuracy: 0.4551\n",
            "Epoch 4515/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5101 - accuracy: 0.9500 - val_loss: 1.9257 - val_accuracy: 0.4550\n",
            "Epoch 4516/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4624 - accuracy: 0.9600 - val_loss: 1.9263 - val_accuracy: 0.4551\n",
            "Epoch 4517/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5438 - accuracy: 0.9100 - val_loss: 1.9261 - val_accuracy: 0.4557\n",
            "Epoch 4518/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4381 - accuracy: 0.9600 - val_loss: 1.9254 - val_accuracy: 0.4554\n",
            "Epoch 4519/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5259 - accuracy: 0.9250 - val_loss: 1.9257 - val_accuracy: 0.4555\n",
            "Epoch 4520/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4818 - accuracy: 0.9450 - val_loss: 1.9252 - val_accuracy: 0.4555\n",
            "Epoch 4521/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4697 - accuracy: 0.9550 - val_loss: 1.9241 - val_accuracy: 0.4555\n",
            "Epoch 4522/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4733 - accuracy: 0.9550 - val_loss: 1.9246 - val_accuracy: 0.4557\n",
            "Epoch 4523/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5306 - accuracy: 0.9200 - val_loss: 1.9251 - val_accuracy: 0.4559\n",
            "Epoch 4524/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5234 - accuracy: 0.9150 - val_loss: 1.9258 - val_accuracy: 0.4560\n",
            "Epoch 4525/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4786 - accuracy: 0.9500 - val_loss: 1.9257 - val_accuracy: 0.4559\n",
            "Epoch 4526/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5133 - accuracy: 0.9350 - val_loss: 1.9253 - val_accuracy: 0.4557\n",
            "Epoch 4527/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4755 - accuracy: 0.9400 - val_loss: 1.9258 - val_accuracy: 0.4560\n",
            "Epoch 4528/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4631 - accuracy: 0.9400 - val_loss: 1.9262 - val_accuracy: 0.4562\n",
            "Epoch 4529/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4611 - accuracy: 0.9550 - val_loss: 1.9264 - val_accuracy: 0.4563\n",
            "Epoch 4530/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4746 - accuracy: 0.9400 - val_loss: 1.9269 - val_accuracy: 0.4564\n",
            "Epoch 4531/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5176 - accuracy: 0.9400 - val_loss: 1.9265 - val_accuracy: 0.4565\n",
            "Epoch 4532/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5202 - accuracy: 0.9300 - val_loss: 1.9270 - val_accuracy: 0.4567\n",
            "Epoch 4533/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4880 - accuracy: 0.9550 - val_loss: 1.9274 - val_accuracy: 0.4567\n",
            "Epoch 4534/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5579 - accuracy: 0.9300 - val_loss: 1.9281 - val_accuracy: 0.4560\n",
            "Epoch 4535/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4465 - accuracy: 0.9600 - val_loss: 1.9278 - val_accuracy: 0.4564\n",
            "Epoch 4536/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4519 - accuracy: 0.9600 - val_loss: 1.9285 - val_accuracy: 0.4564\n",
            "Epoch 4537/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4847 - accuracy: 0.9300 - val_loss: 1.9276 - val_accuracy: 0.4563\n",
            "Epoch 4538/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4508 - accuracy: 0.9600 - val_loss: 1.9266 - val_accuracy: 0.4561\n",
            "Epoch 4539/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4300 - accuracy: 0.9750 - val_loss: 1.9267 - val_accuracy: 0.4562\n",
            "Epoch 4540/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4875 - accuracy: 0.9200 - val_loss: 1.9257 - val_accuracy: 0.4565\n",
            "Epoch 4541/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4823 - accuracy: 0.9450 - val_loss: 1.9254 - val_accuracy: 0.4567\n",
            "Epoch 4542/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4709 - accuracy: 0.9350 - val_loss: 1.9245 - val_accuracy: 0.4569\n",
            "Epoch 4543/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4388 - accuracy: 0.9450 - val_loss: 1.9238 - val_accuracy: 0.4570\n",
            "Epoch 4544/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4500 - accuracy: 0.9500 - val_loss: 1.9237 - val_accuracy: 0.4571\n",
            "Epoch 4545/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4914 - accuracy: 0.9500 - val_loss: 1.9238 - val_accuracy: 0.4571\n",
            "Epoch 4546/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4773 - accuracy: 0.9550 - val_loss: 1.9241 - val_accuracy: 0.4569\n",
            "Epoch 4547/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4719 - accuracy: 0.9500 - val_loss: 1.9248 - val_accuracy: 0.4567\n",
            "Epoch 4548/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4586 - accuracy: 0.9400 - val_loss: 1.9241 - val_accuracy: 0.4569\n",
            "Epoch 4549/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4935 - accuracy: 0.9300 - val_loss: 1.9236 - val_accuracy: 0.4572\n",
            "Epoch 4550/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4927 - accuracy: 0.9350 - val_loss: 1.9226 - val_accuracy: 0.4568\n",
            "Epoch 4551/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4850 - accuracy: 0.9400 - val_loss: 1.9237 - val_accuracy: 0.4568\n",
            "Epoch 4552/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4508 - accuracy: 0.9550 - val_loss: 1.9237 - val_accuracy: 0.4570\n",
            "Epoch 4553/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.5223 - accuracy: 0.9250 - val_loss: 1.9241 - val_accuracy: 0.4571\n",
            "Epoch 4554/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4232 - accuracy: 0.9650 - val_loss: 1.9240 - val_accuracy: 0.4572\n",
            "Epoch 4555/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4784 - accuracy: 0.9500 - val_loss: 1.9238 - val_accuracy: 0.4570\n",
            "Epoch 4556/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4850 - accuracy: 0.9350 - val_loss: 1.9244 - val_accuracy: 0.4569\n",
            "Epoch 4557/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4680 - accuracy: 0.9400 - val_loss: 1.9248 - val_accuracy: 0.4567\n",
            "Epoch 4558/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5097 - accuracy: 0.9250 - val_loss: 1.9246 - val_accuracy: 0.4567\n",
            "Epoch 4559/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5165 - accuracy: 0.9250 - val_loss: 1.9254 - val_accuracy: 0.4569\n",
            "Epoch 4560/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4683 - accuracy: 0.9450 - val_loss: 1.9247 - val_accuracy: 0.4571\n",
            "Epoch 4561/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4991 - accuracy: 0.9200 - val_loss: 1.9255 - val_accuracy: 0.4574\n",
            "Epoch 4562/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4724 - accuracy: 0.9350 - val_loss: 1.9255 - val_accuracy: 0.4572\n",
            "Epoch 4563/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4628 - accuracy: 0.9450 - val_loss: 1.9264 - val_accuracy: 0.4573\n",
            "Epoch 4564/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4714 - accuracy: 0.9400 - val_loss: 1.9262 - val_accuracy: 0.4574\n",
            "Epoch 4565/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4513 - accuracy: 0.9600 - val_loss: 1.9259 - val_accuracy: 0.4572\n",
            "Epoch 4566/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4790 - accuracy: 0.9400 - val_loss: 1.9252 - val_accuracy: 0.4571\n",
            "Epoch 4567/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4755 - accuracy: 0.9650 - val_loss: 1.9259 - val_accuracy: 0.4573\n",
            "Epoch 4568/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4709 - accuracy: 0.9350 - val_loss: 1.9263 - val_accuracy: 0.4575\n",
            "Epoch 4569/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4996 - accuracy: 0.9300 - val_loss: 1.9270 - val_accuracy: 0.4573\n",
            "Epoch 4570/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4512 - accuracy: 0.9500 - val_loss: 1.9269 - val_accuracy: 0.4572\n",
            "Epoch 4571/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5214 - accuracy: 0.9100 - val_loss: 1.9258 - val_accuracy: 0.4572\n",
            "Epoch 4572/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4478 - accuracy: 0.9450 - val_loss: 1.9246 - val_accuracy: 0.4573\n",
            "Epoch 4573/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4982 - accuracy: 0.9350 - val_loss: 1.9244 - val_accuracy: 0.4571\n",
            "Epoch 4574/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5134 - accuracy: 0.9250 - val_loss: 1.9245 - val_accuracy: 0.4571\n",
            "Epoch 4575/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4735 - accuracy: 0.9300 - val_loss: 1.9248 - val_accuracy: 0.4571\n",
            "Epoch 4576/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4726 - accuracy: 0.9350 - val_loss: 1.9251 - val_accuracy: 0.4569\n",
            "Epoch 4577/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4338 - accuracy: 0.9500 - val_loss: 1.9249 - val_accuracy: 0.4571\n",
            "Epoch 4578/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5491 - accuracy: 0.9000 - val_loss: 1.9243 - val_accuracy: 0.4573\n",
            "Epoch 4579/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4528 - accuracy: 0.9550 - val_loss: 1.9235 - val_accuracy: 0.4575\n",
            "Epoch 4580/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4823 - accuracy: 0.9300 - val_loss: 1.9236 - val_accuracy: 0.4575\n",
            "Epoch 4581/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4782 - accuracy: 0.9600 - val_loss: 1.9241 - val_accuracy: 0.4578\n",
            "Epoch 4582/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5348 - accuracy: 0.9250 - val_loss: 1.9239 - val_accuracy: 0.4579\n",
            "Epoch 4583/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4883 - accuracy: 0.9200 - val_loss: 1.9245 - val_accuracy: 0.4581\n",
            "Epoch 4584/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4620 - accuracy: 0.9500 - val_loss: 1.9243 - val_accuracy: 0.4579\n",
            "Epoch 4585/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4838 - accuracy: 0.9550 - val_loss: 1.9246 - val_accuracy: 0.4583\n",
            "Epoch 4586/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5320 - accuracy: 0.9100 - val_loss: 1.9239 - val_accuracy: 0.4579\n",
            "Epoch 4587/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4512 - accuracy: 0.9600 - val_loss: 1.9241 - val_accuracy: 0.4576\n",
            "Epoch 4588/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4788 - accuracy: 0.9500 - val_loss: 1.9248 - val_accuracy: 0.4580\n",
            "Epoch 4589/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4784 - accuracy: 0.9400 - val_loss: 1.9243 - val_accuracy: 0.4581\n",
            "Epoch 4590/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4590 - accuracy: 0.9450 - val_loss: 1.9247 - val_accuracy: 0.4581\n",
            "Epoch 4591/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5128 - accuracy: 0.9400 - val_loss: 1.9267 - val_accuracy: 0.4583\n",
            "Epoch 4592/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4921 - accuracy: 0.9400 - val_loss: 1.9277 - val_accuracy: 0.4580\n",
            "Epoch 4593/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5126 - accuracy: 0.9300 - val_loss: 1.9271 - val_accuracy: 0.4583\n",
            "Epoch 4594/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4525 - accuracy: 0.9350 - val_loss: 1.9268 - val_accuracy: 0.4581\n",
            "Epoch 4595/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4682 - accuracy: 0.9450 - val_loss: 1.9276 - val_accuracy: 0.4582\n",
            "Epoch 4596/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4813 - accuracy: 0.9450 - val_loss: 1.9302 - val_accuracy: 0.4576\n",
            "Epoch 4597/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.5328 - accuracy: 0.9200 - val_loss: 1.9310 - val_accuracy: 0.4581\n",
            "Epoch 4598/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4214 - accuracy: 0.9800 - val_loss: 1.9320 - val_accuracy: 0.4577\n",
            "Epoch 4599/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4531 - accuracy: 0.9600 - val_loss: 1.9325 - val_accuracy: 0.4579\n",
            "Epoch 4600/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4640 - accuracy: 0.9350 - val_loss: 1.9332 - val_accuracy: 0.4579\n",
            "Epoch 4601/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4830 - accuracy: 0.9400 - val_loss: 1.9348 - val_accuracy: 0.4572\n",
            "Epoch 4602/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5036 - accuracy: 0.9250 - val_loss: 1.9354 - val_accuracy: 0.4569\n",
            "Epoch 4603/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.5097 - accuracy: 0.9350 - val_loss: 1.9347 - val_accuracy: 0.4574\n",
            "Epoch 4604/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4455 - accuracy: 0.9500 - val_loss: 1.9352 - val_accuracy: 0.4570\n",
            "Epoch 4605/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4925 - accuracy: 0.9400 - val_loss: 1.9362 - val_accuracy: 0.4569\n",
            "Epoch 4606/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4335 - accuracy: 0.9550 - val_loss: 1.9365 - val_accuracy: 0.4572\n",
            "Epoch 4607/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5037 - accuracy: 0.9400 - val_loss: 1.9367 - val_accuracy: 0.4569\n",
            "Epoch 4608/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4732 - accuracy: 0.9550 - val_loss: 1.9371 - val_accuracy: 0.4571\n",
            "Epoch 4609/6000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.5010 - accuracy: 0.9450 - val_loss: 1.9381 - val_accuracy: 0.4572\n",
            "Epoch 4610/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4757 - accuracy: 0.9600 - val_loss: 1.9387 - val_accuracy: 0.4573\n",
            "Epoch 4611/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5114 - accuracy: 0.9300 - val_loss: 1.9378 - val_accuracy: 0.4569\n",
            "Epoch 4612/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4994 - accuracy: 0.9350 - val_loss: 1.9377 - val_accuracy: 0.4569\n",
            "Epoch 4613/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4688 - accuracy: 0.9500 - val_loss: 1.9372 - val_accuracy: 0.4569\n",
            "Epoch 4614/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4830 - accuracy: 0.9200 - val_loss: 1.9367 - val_accuracy: 0.4566\n",
            "Epoch 4615/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4649 - accuracy: 0.9450 - val_loss: 1.9375 - val_accuracy: 0.4566\n",
            "Epoch 4616/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4787 - accuracy: 0.9400 - val_loss: 1.9356 - val_accuracy: 0.4566\n",
            "Epoch 4617/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4216 - accuracy: 0.9800 - val_loss: 1.9352 - val_accuracy: 0.4568\n",
            "Epoch 4618/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4880 - accuracy: 0.9450 - val_loss: 1.9332 - val_accuracy: 0.4570\n",
            "Epoch 4619/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4830 - accuracy: 0.9350 - val_loss: 1.9328 - val_accuracy: 0.4573\n",
            "Epoch 4620/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4262 - accuracy: 0.9650 - val_loss: 1.9318 - val_accuracy: 0.4573\n",
            "Epoch 4621/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4872 - accuracy: 0.9500 - val_loss: 1.9300 - val_accuracy: 0.4577\n",
            "Epoch 4622/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4350 - accuracy: 0.9750 - val_loss: 1.9290 - val_accuracy: 0.4576\n",
            "Epoch 4623/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4903 - accuracy: 0.9300 - val_loss: 1.9294 - val_accuracy: 0.4576\n",
            "Epoch 4624/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4537 - accuracy: 0.9500 - val_loss: 1.9278 - val_accuracy: 0.4581\n",
            "Epoch 4625/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4743 - accuracy: 0.9500 - val_loss: 1.9276 - val_accuracy: 0.4577\n",
            "Epoch 4626/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4708 - accuracy: 0.9300 - val_loss: 1.9275 - val_accuracy: 0.4577\n",
            "Epoch 4627/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4512 - accuracy: 0.9450 - val_loss: 1.9273 - val_accuracy: 0.4577\n",
            "Epoch 4628/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4719 - accuracy: 0.9450 - val_loss: 1.9269 - val_accuracy: 0.4578\n",
            "Epoch 4629/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4854 - accuracy: 0.9200 - val_loss: 1.9260 - val_accuracy: 0.4576\n",
            "Epoch 4630/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4165 - accuracy: 0.9650 - val_loss: 1.9252 - val_accuracy: 0.4570\n",
            "Epoch 4631/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4836 - accuracy: 0.9600 - val_loss: 1.9258 - val_accuracy: 0.4574\n",
            "Epoch 4632/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4824 - accuracy: 0.9350 - val_loss: 1.9268 - val_accuracy: 0.4578\n",
            "Epoch 4633/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4414 - accuracy: 0.9600 - val_loss: 1.9273 - val_accuracy: 0.4577\n",
            "Epoch 4634/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5144 - accuracy: 0.9300 - val_loss: 1.9289 - val_accuracy: 0.4576\n",
            "Epoch 4635/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5200 - accuracy: 0.9450 - val_loss: 1.9294 - val_accuracy: 0.4577\n",
            "Epoch 4636/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5031 - accuracy: 0.9450 - val_loss: 1.9296 - val_accuracy: 0.4578\n",
            "Epoch 4637/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4403 - accuracy: 0.9550 - val_loss: 1.9299 - val_accuracy: 0.4572\n",
            "Epoch 4638/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4728 - accuracy: 0.9250 - val_loss: 1.9303 - val_accuracy: 0.4575\n",
            "Epoch 4639/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4717 - accuracy: 0.9450 - val_loss: 1.9311 - val_accuracy: 0.4574\n",
            "Epoch 4640/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4658 - accuracy: 0.9400 - val_loss: 1.9321 - val_accuracy: 0.4571\n",
            "Epoch 4641/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5017 - accuracy: 0.9400 - val_loss: 1.9322 - val_accuracy: 0.4573\n",
            "Epoch 4642/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4498 - accuracy: 0.9650 - val_loss: 1.9326 - val_accuracy: 0.4570\n",
            "Epoch 4643/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4714 - accuracy: 0.9250 - val_loss: 1.9330 - val_accuracy: 0.4571\n",
            "Epoch 4644/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5639 - accuracy: 0.8850 - val_loss: 1.9326 - val_accuracy: 0.4576\n",
            "Epoch 4645/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4756 - accuracy: 0.9600 - val_loss: 1.9332 - val_accuracy: 0.4573\n",
            "Epoch 4646/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5226 - accuracy: 0.9350 - val_loss: 1.9344 - val_accuracy: 0.4570\n",
            "Epoch 4647/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4433 - accuracy: 0.9450 - val_loss: 1.9348 - val_accuracy: 0.4572\n",
            "Epoch 4648/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5123 - accuracy: 0.9250 - val_loss: 1.9343 - val_accuracy: 0.4573\n",
            "Epoch 4649/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4205 - accuracy: 0.9650 - val_loss: 1.9359 - val_accuracy: 0.4572\n",
            "Epoch 4650/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4675 - accuracy: 0.9350 - val_loss: 1.9359 - val_accuracy: 0.4570\n",
            "Epoch 4651/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4718 - accuracy: 0.9350 - val_loss: 1.9364 - val_accuracy: 0.4565\n",
            "Epoch 4652/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4485 - accuracy: 0.9650 - val_loss: 1.9360 - val_accuracy: 0.4568\n",
            "Epoch 4653/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4973 - accuracy: 0.9400 - val_loss: 1.9360 - val_accuracy: 0.4567\n",
            "Epoch 4654/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5060 - accuracy: 0.9250 - val_loss: 1.9350 - val_accuracy: 0.4571\n",
            "Epoch 4655/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4705 - accuracy: 0.9300 - val_loss: 1.9350 - val_accuracy: 0.4571\n",
            "Epoch 4656/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4566 - accuracy: 0.9550 - val_loss: 1.9349 - val_accuracy: 0.4567\n",
            "Epoch 4657/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4964 - accuracy: 0.9350 - val_loss: 1.9344 - val_accuracy: 0.4571\n",
            "Epoch 4658/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5117 - accuracy: 0.9150 - val_loss: 1.9334 - val_accuracy: 0.4572\n",
            "Epoch 4659/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4798 - accuracy: 0.9400 - val_loss: 1.9329 - val_accuracy: 0.4576\n",
            "Epoch 4660/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4812 - accuracy: 0.9500 - val_loss: 1.9327 - val_accuracy: 0.4574\n",
            "Epoch 4661/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4361 - accuracy: 0.9800 - val_loss: 1.9324 - val_accuracy: 0.4573\n",
            "Epoch 4662/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4913 - accuracy: 0.9200 - val_loss: 1.9301 - val_accuracy: 0.4573\n",
            "Epoch 4663/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4785 - accuracy: 0.9500 - val_loss: 1.9297 - val_accuracy: 0.4573\n",
            "Epoch 4664/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4855 - accuracy: 0.9400 - val_loss: 1.9305 - val_accuracy: 0.4575\n",
            "Epoch 4665/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4645 - accuracy: 0.9450 - val_loss: 1.9303 - val_accuracy: 0.4571\n",
            "Epoch 4666/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4065 - accuracy: 0.9800 - val_loss: 1.9301 - val_accuracy: 0.4572\n",
            "Epoch 4667/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4857 - accuracy: 0.9250 - val_loss: 1.9296 - val_accuracy: 0.4574\n",
            "Epoch 4668/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4636 - accuracy: 0.9400 - val_loss: 1.9297 - val_accuracy: 0.4573\n",
            "Epoch 4669/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4405 - accuracy: 0.9450 - val_loss: 1.9303 - val_accuracy: 0.4573\n",
            "Epoch 4670/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4752 - accuracy: 0.9250 - val_loss: 1.9296 - val_accuracy: 0.4573\n",
            "Epoch 4671/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4291 - accuracy: 0.9550 - val_loss: 1.9288 - val_accuracy: 0.4576\n",
            "Epoch 4672/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4808 - accuracy: 0.9450 - val_loss: 1.9298 - val_accuracy: 0.4574\n",
            "Epoch 4673/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4609 - accuracy: 0.9350 - val_loss: 1.9296 - val_accuracy: 0.4579\n",
            "Epoch 4674/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4914 - accuracy: 0.9350 - val_loss: 1.9306 - val_accuracy: 0.4578\n",
            "Epoch 4675/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4766 - accuracy: 0.9500 - val_loss: 1.9301 - val_accuracy: 0.4578\n",
            "Epoch 4676/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4981 - accuracy: 0.9350 - val_loss: 1.9301 - val_accuracy: 0.4578\n",
            "Epoch 4677/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4626 - accuracy: 0.9500 - val_loss: 1.9305 - val_accuracy: 0.4577\n",
            "Epoch 4678/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4241 - accuracy: 0.9650 - val_loss: 1.9300 - val_accuracy: 0.4580\n",
            "Epoch 4679/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4750 - accuracy: 0.9350 - val_loss: 1.9301 - val_accuracy: 0.4578\n",
            "Epoch 4680/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4724 - accuracy: 0.9550 - val_loss: 1.9301 - val_accuracy: 0.4582\n",
            "Epoch 4681/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4488 - accuracy: 0.9450 - val_loss: 1.9312 - val_accuracy: 0.4580\n",
            "Epoch 4682/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4324 - accuracy: 0.9650 - val_loss: 1.9307 - val_accuracy: 0.4580\n",
            "Epoch 4683/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4851 - accuracy: 0.9400 - val_loss: 1.9303 - val_accuracy: 0.4581\n",
            "Epoch 4684/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4495 - accuracy: 0.9450 - val_loss: 1.9302 - val_accuracy: 0.4579\n",
            "Epoch 4685/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4491 - accuracy: 0.9650 - val_loss: 1.9312 - val_accuracy: 0.4579\n",
            "Epoch 4686/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4909 - accuracy: 0.9250 - val_loss: 1.9301 - val_accuracy: 0.4587\n",
            "Epoch 4687/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5126 - accuracy: 0.9050 - val_loss: 1.9295 - val_accuracy: 0.4587\n",
            "Epoch 4688/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4459 - accuracy: 0.9450 - val_loss: 1.9297 - val_accuracy: 0.4589\n",
            "Epoch 4689/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4698 - accuracy: 0.9400 - val_loss: 1.9300 - val_accuracy: 0.4584\n",
            "Epoch 4690/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4873 - accuracy: 0.9350 - val_loss: 1.9310 - val_accuracy: 0.4585\n",
            "Epoch 4691/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4862 - accuracy: 0.9250 - val_loss: 1.9312 - val_accuracy: 0.4584\n",
            "Epoch 4692/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4924 - accuracy: 0.9400 - val_loss: 1.9309 - val_accuracy: 0.4582\n",
            "Epoch 4693/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4324 - accuracy: 0.9500 - val_loss: 1.9308 - val_accuracy: 0.4580\n",
            "Epoch 4694/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4559 - accuracy: 0.9650 - val_loss: 1.9299 - val_accuracy: 0.4577\n",
            "Epoch 4695/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4842 - accuracy: 0.9350 - val_loss: 1.9304 - val_accuracy: 0.4577\n",
            "Epoch 4696/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4679 - accuracy: 0.9350 - val_loss: 1.9313 - val_accuracy: 0.4576\n",
            "Epoch 4697/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4569 - accuracy: 0.9500 - val_loss: 1.9303 - val_accuracy: 0.4581\n",
            "Epoch 4698/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4338 - accuracy: 0.9800 - val_loss: 1.9299 - val_accuracy: 0.4581\n",
            "Epoch 4699/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4324 - accuracy: 0.9650 - val_loss: 1.9295 - val_accuracy: 0.4581\n",
            "Epoch 4700/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4636 - accuracy: 0.9500 - val_loss: 1.9285 - val_accuracy: 0.4581\n",
            "Epoch 4701/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4984 - accuracy: 0.9450 - val_loss: 1.9272 - val_accuracy: 0.4589\n",
            "Epoch 4702/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4706 - accuracy: 0.9250 - val_loss: 1.9272 - val_accuracy: 0.4588\n",
            "Epoch 4703/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4634 - accuracy: 0.9550 - val_loss: 1.9272 - val_accuracy: 0.4587\n",
            "Epoch 4704/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4572 - accuracy: 0.9350 - val_loss: 1.9267 - val_accuracy: 0.4587\n",
            "Epoch 4705/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4582 - accuracy: 0.9500 - val_loss: 1.9266 - val_accuracy: 0.4590\n",
            "Epoch 4706/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4403 - accuracy: 0.9400 - val_loss: 1.9279 - val_accuracy: 0.4584\n",
            "Epoch 4707/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4571 - accuracy: 0.9450 - val_loss: 1.9284 - val_accuracy: 0.4584\n",
            "Epoch 4708/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4658 - accuracy: 0.9450 - val_loss: 1.9293 - val_accuracy: 0.4585\n",
            "Epoch 4709/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4662 - accuracy: 0.9450 - val_loss: 1.9297 - val_accuracy: 0.4587\n",
            "Epoch 4710/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4550 - accuracy: 0.9400 - val_loss: 1.9305 - val_accuracy: 0.4587\n",
            "Epoch 4711/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4487 - accuracy: 0.9550 - val_loss: 1.9307 - val_accuracy: 0.4588\n",
            "Epoch 4712/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4422 - accuracy: 0.9600 - val_loss: 1.9308 - val_accuracy: 0.4588\n",
            "Epoch 4713/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4419 - accuracy: 0.9650 - val_loss: 1.9316 - val_accuracy: 0.4585\n",
            "Epoch 4714/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4378 - accuracy: 0.9600 - val_loss: 1.9327 - val_accuracy: 0.4586\n",
            "Epoch 4715/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4548 - accuracy: 0.9350 - val_loss: 1.9343 - val_accuracy: 0.4585\n",
            "Epoch 4716/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4906 - accuracy: 0.9200 - val_loss: 1.9337 - val_accuracy: 0.4584\n",
            "Epoch 4717/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.5100 - accuracy: 0.9350 - val_loss: 1.9344 - val_accuracy: 0.4584\n",
            "Epoch 4718/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4257 - accuracy: 0.9700 - val_loss: 1.9348 - val_accuracy: 0.4583\n",
            "Epoch 4719/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4564 - accuracy: 0.9550 - val_loss: 1.9358 - val_accuracy: 0.4586\n",
            "Epoch 4720/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4434 - accuracy: 0.9400 - val_loss: 1.9363 - val_accuracy: 0.4586\n",
            "Epoch 4721/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4105 - accuracy: 0.9650 - val_loss: 1.9364 - val_accuracy: 0.4583\n",
            "Epoch 4722/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4149 - accuracy: 0.9750 - val_loss: 1.9364 - val_accuracy: 0.4584\n",
            "Epoch 4723/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4323 - accuracy: 0.9650 - val_loss: 1.9379 - val_accuracy: 0.4585\n",
            "Epoch 4724/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5005 - accuracy: 0.9150 - val_loss: 1.9380 - val_accuracy: 0.4587\n",
            "Epoch 4725/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4346 - accuracy: 0.9600 - val_loss: 1.9375 - val_accuracy: 0.4584\n",
            "Epoch 4726/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4802 - accuracy: 0.9450 - val_loss: 1.9381 - val_accuracy: 0.4582\n",
            "Epoch 4727/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4320 - accuracy: 0.9650 - val_loss: 1.9382 - val_accuracy: 0.4584\n",
            "Epoch 4728/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4717 - accuracy: 0.9450 - val_loss: 1.9383 - val_accuracy: 0.4580\n",
            "Epoch 4729/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4462 - accuracy: 0.9400 - val_loss: 1.9392 - val_accuracy: 0.4581\n",
            "Epoch 4730/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4689 - accuracy: 0.9500 - val_loss: 1.9396 - val_accuracy: 0.4581\n",
            "Epoch 4731/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4537 - accuracy: 0.9550 - val_loss: 1.9397 - val_accuracy: 0.4583\n",
            "Epoch 4732/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4475 - accuracy: 0.9450 - val_loss: 1.9407 - val_accuracy: 0.4578\n",
            "Epoch 4733/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4512 - accuracy: 0.9600 - val_loss: 1.9391 - val_accuracy: 0.4575\n",
            "Epoch 4734/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4227 - accuracy: 0.9700 - val_loss: 1.9387 - val_accuracy: 0.4575\n",
            "Epoch 4735/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4674 - accuracy: 0.9450 - val_loss: 1.9391 - val_accuracy: 0.4573\n",
            "Epoch 4736/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4706 - accuracy: 0.9450 - val_loss: 1.9392 - val_accuracy: 0.4572\n",
            "Epoch 4737/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3827 - accuracy: 0.9800 - val_loss: 1.9394 - val_accuracy: 0.4573\n",
            "Epoch 4738/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4435 - accuracy: 0.9450 - val_loss: 1.9395 - val_accuracy: 0.4570\n",
            "Epoch 4739/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4161 - accuracy: 0.9600 - val_loss: 1.9405 - val_accuracy: 0.4568\n",
            "Epoch 4740/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4333 - accuracy: 0.9500 - val_loss: 1.9408 - val_accuracy: 0.4572\n",
            "Epoch 4741/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4648 - accuracy: 0.9500 - val_loss: 1.9409 - val_accuracy: 0.4568\n",
            "Epoch 4742/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4875 - accuracy: 0.9450 - val_loss: 1.9406 - val_accuracy: 0.4574\n",
            "Epoch 4743/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4076 - accuracy: 0.9750 - val_loss: 1.9413 - val_accuracy: 0.4572\n",
            "Epoch 4744/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4688 - accuracy: 0.9700 - val_loss: 1.9419 - val_accuracy: 0.4570\n",
            "Epoch 4745/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4445 - accuracy: 0.9550 - val_loss: 1.9418 - val_accuracy: 0.4567\n",
            "Epoch 4746/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4694 - accuracy: 0.9300 - val_loss: 1.9427 - val_accuracy: 0.4567\n",
            "Epoch 4747/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4957 - accuracy: 0.9250 - val_loss: 1.9424 - val_accuracy: 0.4569\n",
            "Epoch 4748/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4956 - accuracy: 0.9400 - val_loss: 1.9430 - val_accuracy: 0.4568\n",
            "Epoch 4749/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4801 - accuracy: 0.9350 - val_loss: 1.9442 - val_accuracy: 0.4565\n",
            "Epoch 4750/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4615 - accuracy: 0.9500 - val_loss: 1.9441 - val_accuracy: 0.4565\n",
            "Epoch 4751/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4882 - accuracy: 0.9450 - val_loss: 1.9444 - val_accuracy: 0.4569\n",
            "Epoch 4752/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4788 - accuracy: 0.9350 - val_loss: 1.9430 - val_accuracy: 0.4572\n",
            "Epoch 4753/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4910 - accuracy: 0.9250 - val_loss: 1.9437 - val_accuracy: 0.4575\n",
            "Epoch 4754/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4665 - accuracy: 0.9450 - val_loss: 1.9438 - val_accuracy: 0.4572\n",
            "Epoch 4755/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4733 - accuracy: 0.9500 - val_loss: 1.9446 - val_accuracy: 0.4570\n",
            "Epoch 4756/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4650 - accuracy: 0.9350 - val_loss: 1.9456 - val_accuracy: 0.4568\n",
            "Epoch 4757/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4727 - accuracy: 0.9700 - val_loss: 1.9461 - val_accuracy: 0.4575\n",
            "Epoch 4758/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5149 - accuracy: 0.9200 - val_loss: 1.9481 - val_accuracy: 0.4579\n",
            "Epoch 4759/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4904 - accuracy: 0.9300 - val_loss: 1.9488 - val_accuracy: 0.4579\n",
            "Epoch 4760/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4760 - accuracy: 0.9400 - val_loss: 1.9486 - val_accuracy: 0.4580\n",
            "Epoch 4761/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4238 - accuracy: 0.9550 - val_loss: 1.9488 - val_accuracy: 0.4578\n",
            "Epoch 4762/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4415 - accuracy: 0.9650 - val_loss: 1.9492 - val_accuracy: 0.4579\n",
            "Epoch 4763/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4347 - accuracy: 0.9800 - val_loss: 1.9493 - val_accuracy: 0.4580\n",
            "Epoch 4764/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4266 - accuracy: 0.9650 - val_loss: 1.9496 - val_accuracy: 0.4579\n",
            "Epoch 4765/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5012 - accuracy: 0.9150 - val_loss: 1.9505 - val_accuracy: 0.4579\n",
            "Epoch 4766/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5161 - accuracy: 0.9250 - val_loss: 1.9518 - val_accuracy: 0.4578\n",
            "Epoch 4767/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4771 - accuracy: 0.9500 - val_loss: 1.9524 - val_accuracy: 0.4578\n",
            "Epoch 4768/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4994 - accuracy: 0.9550 - val_loss: 1.9525 - val_accuracy: 0.4575\n",
            "Epoch 4769/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4915 - accuracy: 0.9250 - val_loss: 1.9530 - val_accuracy: 0.4573\n",
            "Epoch 4770/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4539 - accuracy: 0.9550 - val_loss: 1.9531 - val_accuracy: 0.4571\n",
            "Epoch 4771/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4256 - accuracy: 0.9650 - val_loss: 1.9517 - val_accuracy: 0.4568\n",
            "Epoch 4772/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4650 - accuracy: 0.9500 - val_loss: 1.9519 - val_accuracy: 0.4569\n",
            "Epoch 4773/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4594 - accuracy: 0.9550 - val_loss: 1.9518 - val_accuracy: 0.4571\n",
            "Epoch 4774/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4220 - accuracy: 0.9550 - val_loss: 1.9524 - val_accuracy: 0.4574\n",
            "Epoch 4775/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4585 - accuracy: 0.9500 - val_loss: 1.9519 - val_accuracy: 0.4575\n",
            "Epoch 4776/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4817 - accuracy: 0.9350 - val_loss: 1.9509 - val_accuracy: 0.4572\n",
            "Epoch 4777/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4781 - accuracy: 0.9450 - val_loss: 1.9525 - val_accuracy: 0.4570\n",
            "Epoch 4778/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4415 - accuracy: 0.9500 - val_loss: 1.9522 - val_accuracy: 0.4572\n",
            "Epoch 4779/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4597 - accuracy: 0.9450 - val_loss: 1.9528 - val_accuracy: 0.4572\n",
            "Epoch 4780/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4745 - accuracy: 0.9400 - val_loss: 1.9533 - val_accuracy: 0.4576\n",
            "Epoch 4781/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4563 - accuracy: 0.9350 - val_loss: 1.9528 - val_accuracy: 0.4577\n",
            "Epoch 4782/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4807 - accuracy: 0.9350 - val_loss: 1.9532 - val_accuracy: 0.4576\n",
            "Epoch 4783/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4491 - accuracy: 0.9500 - val_loss: 1.9534 - val_accuracy: 0.4575\n",
            "Epoch 4784/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4340 - accuracy: 0.9600 - val_loss: 1.9525 - val_accuracy: 0.4574\n",
            "Epoch 4785/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4705 - accuracy: 0.9450 - val_loss: 1.9511 - val_accuracy: 0.4572\n",
            "Epoch 4786/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4083 - accuracy: 0.9600 - val_loss: 1.9490 - val_accuracy: 0.4570\n",
            "Epoch 4787/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4670 - accuracy: 0.9400 - val_loss: 1.9480 - val_accuracy: 0.4573\n",
            "Epoch 4788/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4593 - accuracy: 0.9450 - val_loss: 1.9472 - val_accuracy: 0.4575\n",
            "Epoch 4789/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4591 - accuracy: 0.9450 - val_loss: 1.9473 - val_accuracy: 0.4576\n",
            "Epoch 4790/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4308 - accuracy: 0.9750 - val_loss: 1.9465 - val_accuracy: 0.4578\n",
            "Epoch 4791/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4735 - accuracy: 0.9350 - val_loss: 1.9459 - val_accuracy: 0.4577\n",
            "Epoch 4792/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4659 - accuracy: 0.9400 - val_loss: 1.9459 - val_accuracy: 0.4577\n",
            "Epoch 4793/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4744 - accuracy: 0.9400 - val_loss: 1.9447 - val_accuracy: 0.4574\n",
            "Epoch 4794/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4616 - accuracy: 0.9650 - val_loss: 1.9441 - val_accuracy: 0.4575\n",
            "Epoch 4795/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4302 - accuracy: 0.9700 - val_loss: 1.9438 - val_accuracy: 0.4576\n",
            "Epoch 4796/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4556 - accuracy: 0.9350 - val_loss: 1.9437 - val_accuracy: 0.4577\n",
            "Epoch 4797/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4759 - accuracy: 0.9450 - val_loss: 1.9423 - val_accuracy: 0.4580\n",
            "Epoch 4798/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4390 - accuracy: 0.9750 - val_loss: 1.9410 - val_accuracy: 0.4589\n",
            "Epoch 4799/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4358 - accuracy: 0.9750 - val_loss: 1.9389 - val_accuracy: 0.4595\n",
            "Epoch 4800/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4543 - accuracy: 0.9400 - val_loss: 1.9380 - val_accuracy: 0.4597\n",
            "Epoch 4801/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4485 - accuracy: 0.9550 - val_loss: 1.9375 - val_accuracy: 0.4598\n",
            "Epoch 4802/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5110 - accuracy: 0.9050 - val_loss: 1.9381 - val_accuracy: 0.4601\n",
            "Epoch 4803/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5028 - accuracy: 0.9450 - val_loss: 1.9389 - val_accuracy: 0.4604\n",
            "Epoch 4804/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4714 - accuracy: 0.9250 - val_loss: 1.9380 - val_accuracy: 0.4603\n",
            "Epoch 4805/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4692 - accuracy: 0.9650 - val_loss: 1.9372 - val_accuracy: 0.4604\n",
            "Epoch 4806/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4399 - accuracy: 0.9400 - val_loss: 1.9373 - val_accuracy: 0.4601\n",
            "Epoch 4807/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4763 - accuracy: 0.9250 - val_loss: 1.9367 - val_accuracy: 0.4598\n",
            "Epoch 4808/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3992 - accuracy: 0.9750 - val_loss: 1.9355 - val_accuracy: 0.4601\n",
            "Epoch 4809/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4519 - accuracy: 0.9450 - val_loss: 1.9346 - val_accuracy: 0.4597\n",
            "Epoch 4810/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4580 - accuracy: 0.9700 - val_loss: 1.9346 - val_accuracy: 0.4598\n",
            "Epoch 4811/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4692 - accuracy: 0.9300 - val_loss: 1.9344 - val_accuracy: 0.4598\n",
            "Epoch 4812/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4180 - accuracy: 0.9650 - val_loss: 1.9342 - val_accuracy: 0.4601\n",
            "Epoch 4813/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4264 - accuracy: 0.9600 - val_loss: 1.9344 - val_accuracy: 0.4603\n",
            "Epoch 4814/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4414 - accuracy: 0.9550 - val_loss: 1.9352 - val_accuracy: 0.4596\n",
            "Epoch 4815/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4315 - accuracy: 0.9550 - val_loss: 1.9350 - val_accuracy: 0.4601\n",
            "Epoch 4816/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4424 - accuracy: 0.9450 - val_loss: 1.9349 - val_accuracy: 0.4604\n",
            "Epoch 4817/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4496 - accuracy: 0.9450 - val_loss: 1.9359 - val_accuracy: 0.4597\n",
            "Epoch 4818/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4362 - accuracy: 0.9800 - val_loss: 1.9365 - val_accuracy: 0.4601\n",
            "Epoch 4819/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4353 - accuracy: 0.9550 - val_loss: 1.9365 - val_accuracy: 0.4600\n",
            "Epoch 4820/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4848 - accuracy: 0.9400 - val_loss: 1.9373 - val_accuracy: 0.4594\n",
            "Epoch 4821/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4563 - accuracy: 0.9400 - val_loss: 1.9377 - val_accuracy: 0.4596\n",
            "Epoch 4822/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4241 - accuracy: 0.9800 - val_loss: 1.9375 - val_accuracy: 0.4596\n",
            "Epoch 4823/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4430 - accuracy: 0.9600 - val_loss: 1.9382 - val_accuracy: 0.4596\n",
            "Epoch 4824/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4379 - accuracy: 0.9450 - val_loss: 1.9384 - val_accuracy: 0.4595\n",
            "Epoch 4825/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4646 - accuracy: 0.9400 - val_loss: 1.9399 - val_accuracy: 0.4600\n",
            "Epoch 4826/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4681 - accuracy: 0.9350 - val_loss: 1.9404 - val_accuracy: 0.4599\n",
            "Epoch 4827/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4494 - accuracy: 0.9350 - val_loss: 1.9403 - val_accuracy: 0.4598\n",
            "Epoch 4828/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4482 - accuracy: 0.9500 - val_loss: 1.9405 - val_accuracy: 0.4594\n",
            "Epoch 4829/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4393 - accuracy: 0.9700 - val_loss: 1.9418 - val_accuracy: 0.4595\n",
            "Epoch 4830/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4555 - accuracy: 0.9550 - val_loss: 1.9424 - val_accuracy: 0.4596\n",
            "Epoch 4831/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4808 - accuracy: 0.9500 - val_loss: 1.9433 - val_accuracy: 0.4591\n",
            "Epoch 4832/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4339 - accuracy: 0.9650 - val_loss: 1.9441 - val_accuracy: 0.4585\n",
            "Epoch 4833/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4895 - accuracy: 0.9300 - val_loss: 1.9449 - val_accuracy: 0.4583\n",
            "Epoch 4834/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4588 - accuracy: 0.9400 - val_loss: 1.9449 - val_accuracy: 0.4585\n",
            "Epoch 4835/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4241 - accuracy: 0.9600 - val_loss: 1.9452 - val_accuracy: 0.4587\n",
            "Epoch 4836/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4179 - accuracy: 0.9600 - val_loss: 1.9454 - val_accuracy: 0.4583\n",
            "Epoch 4837/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4386 - accuracy: 0.9450 - val_loss: 1.9456 - val_accuracy: 0.4577\n",
            "Epoch 4838/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4268 - accuracy: 0.9500 - val_loss: 1.9452 - val_accuracy: 0.4578\n",
            "Epoch 4839/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4767 - accuracy: 0.9250 - val_loss: 1.9456 - val_accuracy: 0.4575\n",
            "Epoch 4840/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4528 - accuracy: 0.9500 - val_loss: 1.9463 - val_accuracy: 0.4574\n",
            "Epoch 4841/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4273 - accuracy: 0.9700 - val_loss: 1.9463 - val_accuracy: 0.4581\n",
            "Epoch 4842/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4456 - accuracy: 0.9500 - val_loss: 1.9456 - val_accuracy: 0.4578\n",
            "Epoch 4843/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4184 - accuracy: 0.9550 - val_loss: 1.9458 - val_accuracy: 0.4578\n",
            "Epoch 4844/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5089 - accuracy: 0.9300 - val_loss: 1.9452 - val_accuracy: 0.4584\n",
            "Epoch 4845/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4422 - accuracy: 0.9350 - val_loss: 1.9453 - val_accuracy: 0.4582\n",
            "Epoch 4846/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4305 - accuracy: 0.9700 - val_loss: 1.9451 - val_accuracy: 0.4581\n",
            "Epoch 4847/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4562 - accuracy: 0.9550 - val_loss: 1.9453 - val_accuracy: 0.4578\n",
            "Epoch 4848/6000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4464 - accuracy: 0.9500 - val_loss: 1.9447 - val_accuracy: 0.4585\n",
            "Epoch 4849/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4238 - accuracy: 0.9450 - val_loss: 1.9453 - val_accuracy: 0.4580\n",
            "Epoch 4850/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4343 - accuracy: 0.9700 - val_loss: 1.9452 - val_accuracy: 0.4584\n",
            "Epoch 4851/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4511 - accuracy: 0.9700 - val_loss: 1.9451 - val_accuracy: 0.4586\n",
            "Epoch 4852/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4763 - accuracy: 0.9350 - val_loss: 1.9444 - val_accuracy: 0.4586\n",
            "Epoch 4853/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4847 - accuracy: 0.9300 - val_loss: 1.9441 - val_accuracy: 0.4590\n",
            "Epoch 4854/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4325 - accuracy: 0.9550 - val_loss: 1.9444 - val_accuracy: 0.4585\n",
            "Epoch 4855/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4477 - accuracy: 0.9250 - val_loss: 1.9448 - val_accuracy: 0.4585\n",
            "Epoch 4856/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4201 - accuracy: 0.9500 - val_loss: 1.9460 - val_accuracy: 0.4584\n",
            "Epoch 4857/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3705 - accuracy: 0.9700 - val_loss: 1.9465 - val_accuracy: 0.4578\n",
            "Epoch 4858/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4301 - accuracy: 0.9550 - val_loss: 1.9471 - val_accuracy: 0.4579\n",
            "Epoch 4859/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4469 - accuracy: 0.9550 - val_loss: 1.9474 - val_accuracy: 0.4579\n",
            "Epoch 4860/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4506 - accuracy: 0.9300 - val_loss: 1.9465 - val_accuracy: 0.4581\n",
            "Epoch 4861/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4520 - accuracy: 0.9400 - val_loss: 1.9466 - val_accuracy: 0.4579\n",
            "Epoch 4862/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4258 - accuracy: 0.9700 - val_loss: 1.9471 - val_accuracy: 0.4579\n",
            "Epoch 4863/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4876 - accuracy: 0.9300 - val_loss: 1.9474 - val_accuracy: 0.4574\n",
            "Epoch 4864/6000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4542 - accuracy: 0.9350 - val_loss: 1.9485 - val_accuracy: 0.4573\n",
            "Epoch 4865/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4075 - accuracy: 0.9700 - val_loss: 1.9486 - val_accuracy: 0.4575\n",
            "Epoch 4866/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4244 - accuracy: 0.9650 - val_loss: 1.9483 - val_accuracy: 0.4579\n",
            "Epoch 4867/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4861 - accuracy: 0.9450 - val_loss: 1.9479 - val_accuracy: 0.4579\n",
            "Epoch 4868/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4155 - accuracy: 0.9700 - val_loss: 1.9477 - val_accuracy: 0.4581\n",
            "Epoch 4869/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4227 - accuracy: 0.9700 - val_loss: 1.9472 - val_accuracy: 0.4583\n",
            "Epoch 4870/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4793 - accuracy: 0.9150 - val_loss: 1.9480 - val_accuracy: 0.4583\n",
            "Epoch 4871/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4412 - accuracy: 0.9650 - val_loss: 1.9476 - val_accuracy: 0.4583\n",
            "Epoch 4872/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5040 - accuracy: 0.9500 - val_loss: 1.9462 - val_accuracy: 0.4589\n",
            "Epoch 4873/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4486 - accuracy: 0.9300 - val_loss: 1.9461 - val_accuracy: 0.4590\n",
            "Epoch 4874/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4378 - accuracy: 0.9650 - val_loss: 1.9469 - val_accuracy: 0.4590\n",
            "Epoch 4875/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4676 - accuracy: 0.9400 - val_loss: 1.9458 - val_accuracy: 0.4591\n",
            "Epoch 4876/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4290 - accuracy: 0.9500 - val_loss: 1.9463 - val_accuracy: 0.4589\n",
            "Epoch 4877/6000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4306 - accuracy: 0.9550 - val_loss: 1.9465 - val_accuracy: 0.4592\n",
            "Epoch 4878/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4601 - accuracy: 0.9450 - val_loss: 1.9470 - val_accuracy: 0.4591\n",
            "Epoch 4879/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4318 - accuracy: 0.9650 - val_loss: 1.9476 - val_accuracy: 0.4589\n",
            "Epoch 4880/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4365 - accuracy: 0.9400 - val_loss: 1.9464 - val_accuracy: 0.4589\n",
            "Epoch 4881/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4394 - accuracy: 0.9700 - val_loss: 1.9464 - val_accuracy: 0.4588\n",
            "Epoch 4882/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4412 - accuracy: 0.9550 - val_loss: 1.9462 - val_accuracy: 0.4590\n",
            "Epoch 4883/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4020 - accuracy: 0.9700 - val_loss: 1.9444 - val_accuracy: 0.4595\n",
            "Epoch 4884/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4232 - accuracy: 0.9600 - val_loss: 1.9445 - val_accuracy: 0.4599\n",
            "Epoch 4885/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4355 - accuracy: 0.9500 - val_loss: 1.9442 - val_accuracy: 0.4598\n",
            "Epoch 4886/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4197 - accuracy: 0.9700 - val_loss: 1.9439 - val_accuracy: 0.4602\n",
            "Epoch 4887/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5135 - accuracy: 0.9000 - val_loss: 1.9440 - val_accuracy: 0.4601\n",
            "Epoch 4888/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4228 - accuracy: 0.9550 - val_loss: 1.9442 - val_accuracy: 0.4599\n",
            "Epoch 4889/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4051 - accuracy: 0.9750 - val_loss: 1.9444 - val_accuracy: 0.4598\n",
            "Epoch 4890/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4282 - accuracy: 0.9700 - val_loss: 1.9456 - val_accuracy: 0.4601\n",
            "Epoch 4891/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4911 - accuracy: 0.9200 - val_loss: 1.9456 - val_accuracy: 0.4604\n",
            "Epoch 4892/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4111 - accuracy: 0.9550 - val_loss: 1.9466 - val_accuracy: 0.4602\n",
            "Epoch 4893/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4328 - accuracy: 0.9600 - val_loss: 1.9463 - val_accuracy: 0.4599\n",
            "Epoch 4894/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4332 - accuracy: 0.9450 - val_loss: 1.9467 - val_accuracy: 0.4597\n",
            "Epoch 4895/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4554 - accuracy: 0.9350 - val_loss: 1.9477 - val_accuracy: 0.4597\n",
            "Epoch 4896/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4968 - accuracy: 0.9300 - val_loss: 1.9486 - val_accuracy: 0.4597\n",
            "Epoch 4897/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4553 - accuracy: 0.9450 - val_loss: 1.9493 - val_accuracy: 0.4600\n",
            "Epoch 4898/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4486 - accuracy: 0.9600 - val_loss: 1.9494 - val_accuracy: 0.4603\n",
            "Epoch 4899/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4109 - accuracy: 0.9750 - val_loss: 1.9489 - val_accuracy: 0.4601\n",
            "Epoch 4900/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4701 - accuracy: 0.9450 - val_loss: 1.9493 - val_accuracy: 0.4598\n",
            "Epoch 4901/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4598 - accuracy: 0.9400 - val_loss: 1.9484 - val_accuracy: 0.4597\n",
            "Epoch 4902/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4276 - accuracy: 0.9600 - val_loss: 1.9496 - val_accuracy: 0.4599\n",
            "Epoch 4903/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4698 - accuracy: 0.9350 - val_loss: 1.9498 - val_accuracy: 0.4601\n",
            "Epoch 4904/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4231 - accuracy: 0.9700 - val_loss: 1.9503 - val_accuracy: 0.4601\n",
            "Epoch 4905/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4278 - accuracy: 0.9550 - val_loss: 1.9507 - val_accuracy: 0.4597\n",
            "Epoch 4906/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4305 - accuracy: 0.9550 - val_loss: 1.9500 - val_accuracy: 0.4596\n",
            "Epoch 4907/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4471 - accuracy: 0.9450 - val_loss: 1.9511 - val_accuracy: 0.4592\n",
            "Epoch 4908/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4704 - accuracy: 0.9350 - val_loss: 1.9507 - val_accuracy: 0.4592\n",
            "Epoch 4909/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4432 - accuracy: 0.9350 - val_loss: 1.9495 - val_accuracy: 0.4600\n",
            "Epoch 4910/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4361 - accuracy: 0.9500 - val_loss: 1.9498 - val_accuracy: 0.4600\n",
            "Epoch 4911/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4276 - accuracy: 0.9650 - val_loss: 1.9504 - val_accuracy: 0.4597\n",
            "Epoch 4912/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4613 - accuracy: 0.9550 - val_loss: 1.9514 - val_accuracy: 0.4592\n",
            "Epoch 4913/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4260 - accuracy: 0.9550 - val_loss: 1.9515 - val_accuracy: 0.4593\n",
            "Epoch 4914/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4171 - accuracy: 0.9750 - val_loss: 1.9518 - val_accuracy: 0.4593\n",
            "Epoch 4915/6000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4170 - accuracy: 0.9650 - val_loss: 1.9525 - val_accuracy: 0.4590\n",
            "Epoch 4916/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4613 - accuracy: 0.9650 - val_loss: 1.9534 - val_accuracy: 0.4596\n",
            "Epoch 4917/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4213 - accuracy: 0.9600 - val_loss: 1.9527 - val_accuracy: 0.4594\n",
            "Epoch 4918/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4186 - accuracy: 0.9400 - val_loss: 1.9535 - val_accuracy: 0.4594\n",
            "Epoch 4919/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4527 - accuracy: 0.9300 - val_loss: 1.9533 - val_accuracy: 0.4595\n",
            "Epoch 4920/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4213 - accuracy: 0.9600 - val_loss: 1.9529 - val_accuracy: 0.4595\n",
            "Epoch 4921/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4588 - accuracy: 0.9400 - val_loss: 1.9526 - val_accuracy: 0.4597\n",
            "Epoch 4922/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3987 - accuracy: 0.9700 - val_loss: 1.9506 - val_accuracy: 0.4600\n",
            "Epoch 4923/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4911 - accuracy: 0.9200 - val_loss: 1.9508 - val_accuracy: 0.4599\n",
            "Epoch 4924/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4241 - accuracy: 0.9600 - val_loss: 1.9506 - val_accuracy: 0.4598\n",
            "Epoch 4925/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4737 - accuracy: 0.9300 - val_loss: 1.9496 - val_accuracy: 0.4597\n",
            "Epoch 4926/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4144 - accuracy: 0.9650 - val_loss: 1.9489 - val_accuracy: 0.4599\n",
            "Epoch 4927/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4543 - accuracy: 0.9350 - val_loss: 1.9483 - val_accuracy: 0.4595\n",
            "Epoch 4928/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4064 - accuracy: 0.9600 - val_loss: 1.9481 - val_accuracy: 0.4600\n",
            "Epoch 4929/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4343 - accuracy: 0.9650 - val_loss: 1.9491 - val_accuracy: 0.4601\n",
            "Epoch 4930/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4328 - accuracy: 0.9600 - val_loss: 1.9491 - val_accuracy: 0.4603\n",
            "Epoch 4931/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4240 - accuracy: 0.9650 - val_loss: 1.9504 - val_accuracy: 0.4605\n",
            "Epoch 4932/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4251 - accuracy: 0.9450 - val_loss: 1.9520 - val_accuracy: 0.4596\n",
            "Epoch 4933/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4089 - accuracy: 0.9600 - val_loss: 1.9520 - val_accuracy: 0.4601\n",
            "Epoch 4934/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4317 - accuracy: 0.9500 - val_loss: 1.9516 - val_accuracy: 0.4603\n",
            "Epoch 4935/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4325 - accuracy: 0.9700 - val_loss: 1.9519 - val_accuracy: 0.4602\n",
            "Epoch 4936/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4387 - accuracy: 0.9500 - val_loss: 1.9520 - val_accuracy: 0.4603\n",
            "Epoch 4937/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4676 - accuracy: 0.9350 - val_loss: 1.9527 - val_accuracy: 0.4600\n",
            "Epoch 4938/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4383 - accuracy: 0.9500 - val_loss: 1.9529 - val_accuracy: 0.4601\n",
            "Epoch 4939/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4580 - accuracy: 0.9400 - val_loss: 1.9535 - val_accuracy: 0.4601\n",
            "Epoch 4940/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4190 - accuracy: 0.9550 - val_loss: 1.9527 - val_accuracy: 0.4606\n",
            "Epoch 4941/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4185 - accuracy: 0.9550 - val_loss: 1.9528 - val_accuracy: 0.4605\n",
            "Epoch 4942/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3959 - accuracy: 0.9700 - val_loss: 1.9534 - val_accuracy: 0.4603\n",
            "Epoch 4943/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4159 - accuracy: 0.9550 - val_loss: 1.9538 - val_accuracy: 0.4600\n",
            "Epoch 4944/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4395 - accuracy: 0.9450 - val_loss: 1.9539 - val_accuracy: 0.4604\n",
            "Epoch 4945/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4674 - accuracy: 0.9350 - val_loss: 1.9548 - val_accuracy: 0.4598\n",
            "Epoch 4946/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4606 - accuracy: 0.9350 - val_loss: 1.9536 - val_accuracy: 0.4603\n",
            "Epoch 4947/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4409 - accuracy: 0.9600 - val_loss: 1.9525 - val_accuracy: 0.4602\n",
            "Epoch 4948/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4119 - accuracy: 0.9600 - val_loss: 1.9530 - val_accuracy: 0.4603\n",
            "Epoch 4949/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4620 - accuracy: 0.9400 - val_loss: 1.9544 - val_accuracy: 0.4602\n",
            "Epoch 4950/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4575 - accuracy: 0.9450 - val_loss: 1.9542 - val_accuracy: 0.4600\n",
            "Epoch 4951/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4447 - accuracy: 0.9550 - val_loss: 1.9543 - val_accuracy: 0.4603\n",
            "Epoch 4952/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4504 - accuracy: 0.9450 - val_loss: 1.9549 - val_accuracy: 0.4609\n",
            "Epoch 4953/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4694 - accuracy: 0.9450 - val_loss: 1.9562 - val_accuracy: 0.4605\n",
            "Epoch 4954/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4205 - accuracy: 0.9500 - val_loss: 1.9577 - val_accuracy: 0.4605\n",
            "Epoch 4955/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4830 - accuracy: 0.9300 - val_loss: 1.9585 - val_accuracy: 0.4602\n",
            "Epoch 4956/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4829 - accuracy: 0.9350 - val_loss: 1.9584 - val_accuracy: 0.4603\n",
            "Epoch 4957/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4100 - accuracy: 0.9600 - val_loss: 1.9597 - val_accuracy: 0.4600\n",
            "Epoch 4958/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4320 - accuracy: 0.9750 - val_loss: 1.9610 - val_accuracy: 0.4601\n",
            "Epoch 4959/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3975 - accuracy: 0.9650 - val_loss: 1.9613 - val_accuracy: 0.4600\n",
            "Epoch 4960/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4193 - accuracy: 0.9450 - val_loss: 1.9618 - val_accuracy: 0.4597\n",
            "Epoch 4961/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4101 - accuracy: 0.9600 - val_loss: 1.9620 - val_accuracy: 0.4600\n",
            "Epoch 4962/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4147 - accuracy: 0.9550 - val_loss: 1.9614 - val_accuracy: 0.4599\n",
            "Epoch 4963/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3939 - accuracy: 0.9750 - val_loss: 1.9620 - val_accuracy: 0.4599\n",
            "Epoch 4964/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4140 - accuracy: 0.9650 - val_loss: 1.9634 - val_accuracy: 0.4600\n",
            "Epoch 4965/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4936 - accuracy: 0.9200 - val_loss: 1.9639 - val_accuracy: 0.4594\n",
            "Epoch 4966/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4155 - accuracy: 0.9650 - val_loss: 1.9642 - val_accuracy: 0.4592\n",
            "Epoch 4967/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4619 - accuracy: 0.9450 - val_loss: 1.9649 - val_accuracy: 0.4595\n",
            "Epoch 4968/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4058 - accuracy: 0.9700 - val_loss: 1.9651 - val_accuracy: 0.4592\n",
            "Epoch 4969/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4467 - accuracy: 0.9700 - val_loss: 1.9650 - val_accuracy: 0.4592\n",
            "Epoch 4970/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4224 - accuracy: 0.9550 - val_loss: 1.9652 - val_accuracy: 0.4591\n",
            "Epoch 4971/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4907 - accuracy: 0.9350 - val_loss: 1.9643 - val_accuracy: 0.4597\n",
            "Epoch 4972/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4531 - accuracy: 0.9450 - val_loss: 1.9646 - val_accuracy: 0.4594\n",
            "Epoch 4973/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4230 - accuracy: 0.9650 - val_loss: 1.9642 - val_accuracy: 0.4593\n",
            "Epoch 4974/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4056 - accuracy: 0.9650 - val_loss: 1.9640 - val_accuracy: 0.4594\n",
            "Epoch 4975/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3812 - accuracy: 0.9850 - val_loss: 1.9640 - val_accuracy: 0.4594\n",
            "Epoch 4976/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4977 - accuracy: 0.9100 - val_loss: 1.9617 - val_accuracy: 0.4589\n",
            "Epoch 4977/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4331 - accuracy: 0.9500 - val_loss: 1.9618 - val_accuracy: 0.4593\n",
            "Epoch 4978/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4319 - accuracy: 0.9750 - val_loss: 1.9610 - val_accuracy: 0.4586\n",
            "Epoch 4979/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4137 - accuracy: 0.9650 - val_loss: 1.9599 - val_accuracy: 0.4589\n",
            "Epoch 4980/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4300 - accuracy: 0.9600 - val_loss: 1.9603 - val_accuracy: 0.4591\n",
            "Epoch 4981/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4159 - accuracy: 0.9650 - val_loss: 1.9597 - val_accuracy: 0.4592\n",
            "Epoch 4982/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4197 - accuracy: 0.9550 - val_loss: 1.9596 - val_accuracy: 0.4583\n",
            "Epoch 4983/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4916 - accuracy: 0.9300 - val_loss: 1.9591 - val_accuracy: 0.4585\n",
            "Epoch 4984/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4598 - accuracy: 0.9400 - val_loss: 1.9580 - val_accuracy: 0.4593\n",
            "Epoch 4985/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4433 - accuracy: 0.9650 - val_loss: 1.9582 - val_accuracy: 0.4591\n",
            "Epoch 4986/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4683 - accuracy: 0.9500 - val_loss: 1.9580 - val_accuracy: 0.4586\n",
            "Epoch 4987/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4179 - accuracy: 0.9600 - val_loss: 1.9571 - val_accuracy: 0.4593\n",
            "Epoch 4988/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4182 - accuracy: 0.9650 - val_loss: 1.9564 - val_accuracy: 0.4594\n",
            "Epoch 4989/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4045 - accuracy: 0.9750 - val_loss: 1.9562 - val_accuracy: 0.4592\n",
            "Epoch 4990/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4288 - accuracy: 0.9500 - val_loss: 1.9555 - val_accuracy: 0.4592\n",
            "Epoch 4991/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4608 - accuracy: 0.9350 - val_loss: 1.9559 - val_accuracy: 0.4590\n",
            "Epoch 4992/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4855 - accuracy: 0.9250 - val_loss: 1.9550 - val_accuracy: 0.4590\n",
            "Epoch 4993/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4436 - accuracy: 0.9300 - val_loss: 1.9552 - val_accuracy: 0.4590\n",
            "Epoch 4994/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4196 - accuracy: 0.9650 - val_loss: 1.9542 - val_accuracy: 0.4593\n",
            "Epoch 4995/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4703 - accuracy: 0.9400 - val_loss: 1.9533 - val_accuracy: 0.4592\n",
            "Epoch 4996/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4276 - accuracy: 0.9650 - val_loss: 1.9517 - val_accuracy: 0.4601\n",
            "Epoch 4997/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4429 - accuracy: 0.9600 - val_loss: 1.9507 - val_accuracy: 0.4600\n",
            "Epoch 4998/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4355 - accuracy: 0.9350 - val_loss: 1.9507 - val_accuracy: 0.4598\n",
            "Epoch 4999/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4401 - accuracy: 0.9400 - val_loss: 1.9506 - val_accuracy: 0.4592\n",
            "Epoch 5000/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4439 - accuracy: 0.9600 - val_loss: 1.9507 - val_accuracy: 0.4590\n",
            "Epoch 5001/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4590 - accuracy: 0.9650 - val_loss: 1.9500 - val_accuracy: 0.4595\n",
            "Epoch 5002/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3992 - accuracy: 0.9650 - val_loss: 1.9506 - val_accuracy: 0.4593\n",
            "Epoch 5003/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4435 - accuracy: 0.9500 - val_loss: 1.9498 - val_accuracy: 0.4594\n",
            "Epoch 5004/6000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.4193 - accuracy: 0.9550 - val_loss: 1.9501 - val_accuracy: 0.4597\n",
            "Epoch 5005/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4144 - accuracy: 0.9650 - val_loss: 1.9495 - val_accuracy: 0.4595\n",
            "Epoch 5006/6000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4137 - accuracy: 0.9500 - val_loss: 1.9500 - val_accuracy: 0.4597\n",
            "Epoch 5007/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4290 - accuracy: 0.9550 - val_loss: 1.9516 - val_accuracy: 0.4597\n",
            "Epoch 5008/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4930 - accuracy: 0.9150 - val_loss: 1.9522 - val_accuracy: 0.4593\n",
            "Epoch 5009/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3974 - accuracy: 0.9800 - val_loss: 1.9522 - val_accuracy: 0.4595\n",
            "Epoch 5010/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4278 - accuracy: 0.9600 - val_loss: 1.9520 - val_accuracy: 0.4594\n",
            "Epoch 5011/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4741 - accuracy: 0.9300 - val_loss: 1.9521 - val_accuracy: 0.4592\n",
            "Epoch 5012/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4659 - accuracy: 0.9200 - val_loss: 1.9526 - val_accuracy: 0.4593\n",
            "Epoch 5013/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4150 - accuracy: 0.9500 - val_loss: 1.9532 - val_accuracy: 0.4594\n",
            "Epoch 5014/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4078 - accuracy: 0.9800 - val_loss: 1.9535 - val_accuracy: 0.4595\n",
            "Epoch 5015/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4257 - accuracy: 0.9600 - val_loss: 1.9543 - val_accuracy: 0.4595\n",
            "Epoch 5016/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4534 - accuracy: 0.9600 - val_loss: 1.9546 - val_accuracy: 0.4598\n",
            "Epoch 5017/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4055 - accuracy: 0.9650 - val_loss: 1.9553 - val_accuracy: 0.4598\n",
            "Epoch 5018/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4729 - accuracy: 0.9250 - val_loss: 1.9560 - val_accuracy: 0.4596\n",
            "Epoch 5019/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4251 - accuracy: 0.9350 - val_loss: 1.9564 - val_accuracy: 0.4593\n",
            "Epoch 5020/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4104 - accuracy: 0.9500 - val_loss: 1.9574 - val_accuracy: 0.4586\n",
            "Epoch 5021/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3972 - accuracy: 0.9800 - val_loss: 1.9582 - val_accuracy: 0.4581\n",
            "Epoch 5022/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4189 - accuracy: 0.9600 - val_loss: 1.9585 - val_accuracy: 0.4581\n",
            "Epoch 5023/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4434 - accuracy: 0.9550 - val_loss: 1.9594 - val_accuracy: 0.4581\n",
            "Epoch 5024/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4489 - accuracy: 0.9450 - val_loss: 1.9606 - val_accuracy: 0.4581\n",
            "Epoch 5025/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4855 - accuracy: 0.9300 - val_loss: 1.9623 - val_accuracy: 0.4584\n",
            "Epoch 5026/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3966 - accuracy: 0.9650 - val_loss: 1.9631 - val_accuracy: 0.4584\n",
            "Epoch 5027/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4350 - accuracy: 0.9500 - val_loss: 1.9646 - val_accuracy: 0.4587\n",
            "Epoch 5028/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4223 - accuracy: 0.9600 - val_loss: 1.9648 - val_accuracy: 0.4580\n",
            "Epoch 5029/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4659 - accuracy: 0.9400 - val_loss: 1.9656 - val_accuracy: 0.4580\n",
            "Epoch 5030/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4024 - accuracy: 0.9600 - val_loss: 1.9657 - val_accuracy: 0.4584\n",
            "Epoch 5031/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4176 - accuracy: 0.9550 - val_loss: 1.9665 - val_accuracy: 0.4582\n",
            "Epoch 5032/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4532 - accuracy: 0.9500 - val_loss: 1.9659 - val_accuracy: 0.4580\n",
            "Epoch 5033/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4112 - accuracy: 0.9650 - val_loss: 1.9668 - val_accuracy: 0.4581\n",
            "Epoch 5034/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4501 - accuracy: 0.9400 - val_loss: 1.9660 - val_accuracy: 0.4579\n",
            "Epoch 5035/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4505 - accuracy: 0.9600 - val_loss: 1.9676 - val_accuracy: 0.4574\n",
            "Epoch 5036/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4147 - accuracy: 0.9700 - val_loss: 1.9693 - val_accuracy: 0.4572\n",
            "Epoch 5037/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4338 - accuracy: 0.9500 - val_loss: 1.9699 - val_accuracy: 0.4574\n",
            "Epoch 5038/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4369 - accuracy: 0.9550 - val_loss: 1.9697 - val_accuracy: 0.4573\n",
            "Epoch 5039/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4221 - accuracy: 0.9750 - val_loss: 1.9703 - val_accuracy: 0.4570\n",
            "Epoch 5040/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4457 - accuracy: 0.9600 - val_loss: 1.9714 - val_accuracy: 0.4573\n",
            "Epoch 5041/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4179 - accuracy: 0.9600 - val_loss: 1.9720 - val_accuracy: 0.4574\n",
            "Epoch 5042/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4146 - accuracy: 0.9500 - val_loss: 1.9739 - val_accuracy: 0.4571\n",
            "Epoch 5043/6000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4516 - accuracy: 0.9400 - val_loss: 1.9758 - val_accuracy: 0.4570\n",
            "Epoch 5044/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4453 - accuracy: 0.9550 - val_loss: 1.9769 - val_accuracy: 0.4570\n",
            "Epoch 5045/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4510 - accuracy: 0.9400 - val_loss: 1.9787 - val_accuracy: 0.4563\n",
            "Epoch 5046/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4078 - accuracy: 0.9600 - val_loss: 1.9797 - val_accuracy: 0.4563\n",
            "Epoch 5047/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3948 - accuracy: 0.9750 - val_loss: 1.9806 - val_accuracy: 0.4562\n",
            "Epoch 5048/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4111 - accuracy: 0.9600 - val_loss: 1.9831 - val_accuracy: 0.4559\n",
            "Epoch 5049/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4265 - accuracy: 0.9600 - val_loss: 1.9840 - val_accuracy: 0.4556\n",
            "Epoch 5050/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4179 - accuracy: 0.9550 - val_loss: 1.9841 - val_accuracy: 0.4551\n",
            "Epoch 5051/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4432 - accuracy: 0.9500 - val_loss: 1.9847 - val_accuracy: 0.4552\n",
            "Epoch 5052/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4533 - accuracy: 0.9600 - val_loss: 1.9861 - val_accuracy: 0.4551\n",
            "Epoch 5053/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4272 - accuracy: 0.9450 - val_loss: 1.9859 - val_accuracy: 0.4549\n",
            "Epoch 5054/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4171 - accuracy: 0.9700 - val_loss: 1.9846 - val_accuracy: 0.4554\n",
            "Epoch 5055/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4476 - accuracy: 0.9400 - val_loss: 1.9847 - val_accuracy: 0.4552\n",
            "Epoch 5056/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4659 - accuracy: 0.9450 - val_loss: 1.9854 - val_accuracy: 0.4548\n",
            "Epoch 5057/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3912 - accuracy: 0.9600 - val_loss: 1.9845 - val_accuracy: 0.4553\n",
            "Epoch 5058/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4272 - accuracy: 0.9350 - val_loss: 1.9840 - val_accuracy: 0.4552\n",
            "Epoch 5059/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4244 - accuracy: 0.9450 - val_loss: 1.9824 - val_accuracy: 0.4559\n",
            "Epoch 5060/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4437 - accuracy: 0.9650 - val_loss: 1.9814 - val_accuracy: 0.4558\n",
            "Epoch 5061/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4406 - accuracy: 0.9400 - val_loss: 1.9802 - val_accuracy: 0.4566\n",
            "Epoch 5062/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4076 - accuracy: 0.9650 - val_loss: 1.9800 - val_accuracy: 0.4564\n",
            "Epoch 5063/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4315 - accuracy: 0.9650 - val_loss: 1.9788 - val_accuracy: 0.4562\n",
            "Epoch 5064/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4116 - accuracy: 0.9850 - val_loss: 1.9776 - val_accuracy: 0.4567\n",
            "Epoch 5065/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4590 - accuracy: 0.9300 - val_loss: 1.9779 - val_accuracy: 0.4563\n",
            "Epoch 5066/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4114 - accuracy: 0.9600 - val_loss: 1.9798 - val_accuracy: 0.4564\n",
            "Epoch 5067/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4535 - accuracy: 0.9450 - val_loss: 1.9800 - val_accuracy: 0.4565\n",
            "Epoch 5068/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3932 - accuracy: 0.9850 - val_loss: 1.9789 - val_accuracy: 0.4567\n",
            "Epoch 5069/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4394 - accuracy: 0.9600 - val_loss: 1.9792 - val_accuracy: 0.4567\n",
            "Epoch 5070/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4333 - accuracy: 0.9350 - val_loss: 1.9784 - val_accuracy: 0.4563\n",
            "Epoch 5071/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4054 - accuracy: 0.9550 - val_loss: 1.9780 - val_accuracy: 0.4565\n",
            "Epoch 5072/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4175 - accuracy: 0.9700 - val_loss: 1.9779 - val_accuracy: 0.4565\n",
            "Epoch 5073/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4407 - accuracy: 0.9400 - val_loss: 1.9782 - val_accuracy: 0.4565\n",
            "Epoch 5074/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4053 - accuracy: 0.9550 - val_loss: 1.9778 - val_accuracy: 0.4563\n",
            "Epoch 5075/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3861 - accuracy: 0.9700 - val_loss: 1.9775 - val_accuracy: 0.4565\n",
            "Epoch 5076/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4209 - accuracy: 0.9550 - val_loss: 1.9772 - val_accuracy: 0.4566\n",
            "Epoch 5077/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4243 - accuracy: 0.9600 - val_loss: 1.9776 - val_accuracy: 0.4570\n",
            "Epoch 5078/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4785 - accuracy: 0.9350 - val_loss: 1.9781 - val_accuracy: 0.4570\n",
            "Epoch 5079/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3699 - accuracy: 0.9800 - val_loss: 1.9787 - val_accuracy: 0.4573\n",
            "Epoch 5080/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4013 - accuracy: 0.9600 - val_loss: 1.9770 - val_accuracy: 0.4571\n",
            "Epoch 5081/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4419 - accuracy: 0.9400 - val_loss: 1.9772 - val_accuracy: 0.4571\n",
            "Epoch 5082/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3892 - accuracy: 0.9700 - val_loss: 1.9782 - val_accuracy: 0.4573\n",
            "Epoch 5083/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4135 - accuracy: 0.9550 - val_loss: 1.9773 - val_accuracy: 0.4575\n",
            "Epoch 5084/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4398 - accuracy: 0.9550 - val_loss: 1.9765 - val_accuracy: 0.4577\n",
            "Epoch 5085/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4036 - accuracy: 0.9650 - val_loss: 1.9759 - val_accuracy: 0.4572\n",
            "Epoch 5086/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4324 - accuracy: 0.9450 - val_loss: 1.9775 - val_accuracy: 0.4572\n",
            "Epoch 5087/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4261 - accuracy: 0.9600 - val_loss: 1.9778 - val_accuracy: 0.4571\n",
            "Epoch 5088/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4441 - accuracy: 0.9500 - val_loss: 1.9774 - val_accuracy: 0.4570\n",
            "Epoch 5089/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3982 - accuracy: 0.9650 - val_loss: 1.9758 - val_accuracy: 0.4575\n",
            "Epoch 5090/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4050 - accuracy: 0.9550 - val_loss: 1.9753 - val_accuracy: 0.4571\n",
            "Epoch 5091/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4214 - accuracy: 0.9650 - val_loss: 1.9741 - val_accuracy: 0.4577\n",
            "Epoch 5092/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4163 - accuracy: 0.9550 - val_loss: 1.9746 - val_accuracy: 0.4572\n",
            "Epoch 5093/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4231 - accuracy: 0.9600 - val_loss: 1.9753 - val_accuracy: 0.4574\n",
            "Epoch 5094/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4407 - accuracy: 0.9450 - val_loss: 1.9754 - val_accuracy: 0.4575\n",
            "Epoch 5095/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3928 - accuracy: 0.9850 - val_loss: 1.9750 - val_accuracy: 0.4575\n",
            "Epoch 5096/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4567 - accuracy: 0.9300 - val_loss: 1.9753 - val_accuracy: 0.4576\n",
            "Epoch 5097/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4207 - accuracy: 0.9600 - val_loss: 1.9742 - val_accuracy: 0.4578\n",
            "Epoch 5098/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4507 - accuracy: 0.9400 - val_loss: 1.9742 - val_accuracy: 0.4581\n",
            "Epoch 5099/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4032 - accuracy: 0.9700 - val_loss: 1.9740 - val_accuracy: 0.4580\n",
            "Epoch 5100/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4469 - accuracy: 0.9200 - val_loss: 1.9734 - val_accuracy: 0.4578\n",
            "Epoch 5101/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4212 - accuracy: 0.9600 - val_loss: 1.9722 - val_accuracy: 0.4577\n",
            "Epoch 5102/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4129 - accuracy: 0.9700 - val_loss: 1.9709 - val_accuracy: 0.4573\n",
            "Epoch 5103/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4638 - accuracy: 0.9400 - val_loss: 1.9699 - val_accuracy: 0.4576\n",
            "Epoch 5104/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4523 - accuracy: 0.9450 - val_loss: 1.9697 - val_accuracy: 0.4577\n",
            "Epoch 5105/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4450 - accuracy: 0.9550 - val_loss: 1.9697 - val_accuracy: 0.4581\n",
            "Epoch 5106/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4392 - accuracy: 0.9650 - val_loss: 1.9689 - val_accuracy: 0.4583\n",
            "Epoch 5107/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4006 - accuracy: 0.9750 - val_loss: 1.9685 - val_accuracy: 0.4581\n",
            "Epoch 5108/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4147 - accuracy: 0.9550 - val_loss: 1.9674 - val_accuracy: 0.4581\n",
            "Epoch 5109/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4061 - accuracy: 0.9650 - val_loss: 1.9676 - val_accuracy: 0.4582\n",
            "Epoch 5110/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3941 - accuracy: 0.9650 - val_loss: 1.9669 - val_accuracy: 0.4587\n",
            "Epoch 5111/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4422 - accuracy: 0.9500 - val_loss: 1.9668 - val_accuracy: 0.4584\n",
            "Epoch 5112/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3967 - accuracy: 0.9750 - val_loss: 1.9661 - val_accuracy: 0.4581\n",
            "Epoch 5113/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4030 - accuracy: 0.9700 - val_loss: 1.9655 - val_accuracy: 0.4585\n",
            "Epoch 5114/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4178 - accuracy: 0.9600 - val_loss: 1.9661 - val_accuracy: 0.4584\n",
            "Epoch 5115/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4081 - accuracy: 0.9800 - val_loss: 1.9664 - val_accuracy: 0.4583\n",
            "Epoch 5116/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4044 - accuracy: 0.9750 - val_loss: 1.9669 - val_accuracy: 0.4586\n",
            "Epoch 5117/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4293 - accuracy: 0.9650 - val_loss: 1.9684 - val_accuracy: 0.4589\n",
            "Epoch 5118/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4038 - accuracy: 0.9850 - val_loss: 1.9683 - val_accuracy: 0.4588\n",
            "Epoch 5119/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4450 - accuracy: 0.9450 - val_loss: 1.9691 - val_accuracy: 0.4586\n",
            "Epoch 5120/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3781 - accuracy: 0.9750 - val_loss: 1.9694 - val_accuracy: 0.4584\n",
            "Epoch 5121/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4321 - accuracy: 0.9500 - val_loss: 1.9703 - val_accuracy: 0.4578\n",
            "Epoch 5122/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4465 - accuracy: 0.9400 - val_loss: 1.9709 - val_accuracy: 0.4579\n",
            "Epoch 5123/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4292 - accuracy: 0.9400 - val_loss: 1.9710 - val_accuracy: 0.4581\n",
            "Epoch 5124/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4128 - accuracy: 0.9500 - val_loss: 1.9725 - val_accuracy: 0.4584\n",
            "Epoch 5125/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4568 - accuracy: 0.9300 - val_loss: 1.9718 - val_accuracy: 0.4580\n",
            "Epoch 5126/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3933 - accuracy: 0.9650 - val_loss: 1.9720 - val_accuracy: 0.4582\n",
            "Epoch 5127/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4080 - accuracy: 0.9700 - val_loss: 1.9724 - val_accuracy: 0.4580\n",
            "Epoch 5128/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4051 - accuracy: 0.9750 - val_loss: 1.9730 - val_accuracy: 0.4581\n",
            "Epoch 5129/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4436 - accuracy: 0.9500 - val_loss: 1.9735 - val_accuracy: 0.4576\n",
            "Epoch 5130/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4501 - accuracy: 0.9400 - val_loss: 1.9733 - val_accuracy: 0.4579\n",
            "Epoch 5131/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4367 - accuracy: 0.9450 - val_loss: 1.9724 - val_accuracy: 0.4579\n",
            "Epoch 5132/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4429 - accuracy: 0.9400 - val_loss: 1.9737 - val_accuracy: 0.4575\n",
            "Epoch 5133/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4043 - accuracy: 0.9800 - val_loss: 1.9733 - val_accuracy: 0.4578\n",
            "Epoch 5134/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4174 - accuracy: 0.9600 - val_loss: 1.9736 - val_accuracy: 0.4576\n",
            "Epoch 5135/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4368 - accuracy: 0.9450 - val_loss: 1.9749 - val_accuracy: 0.4571\n",
            "Epoch 5136/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4252 - accuracy: 0.9450 - val_loss: 1.9759 - val_accuracy: 0.4568\n",
            "Epoch 5137/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4181 - accuracy: 0.9550 - val_loss: 1.9782 - val_accuracy: 0.4564\n",
            "Epoch 5138/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3895 - accuracy: 0.9750 - val_loss: 1.9778 - val_accuracy: 0.4567\n",
            "Epoch 5139/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4214 - accuracy: 0.9600 - val_loss: 1.9788 - val_accuracy: 0.4564\n",
            "Epoch 5140/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4244 - accuracy: 0.9700 - val_loss: 1.9793 - val_accuracy: 0.4569\n",
            "Epoch 5141/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4166 - accuracy: 0.9650 - val_loss: 1.9798 - val_accuracy: 0.4565\n",
            "Epoch 5142/6000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4309 - accuracy: 0.9450 - val_loss: 1.9803 - val_accuracy: 0.4561\n",
            "Epoch 5143/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3890 - accuracy: 0.9700 - val_loss: 1.9815 - val_accuracy: 0.4560\n",
            "Epoch 5144/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4760 - accuracy: 0.9300 - val_loss: 1.9820 - val_accuracy: 0.4559\n",
            "Epoch 5145/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4298 - accuracy: 0.9550 - val_loss: 1.9830 - val_accuracy: 0.4561\n",
            "Epoch 5146/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4196 - accuracy: 0.9650 - val_loss: 1.9839 - val_accuracy: 0.4564\n",
            "Epoch 5147/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4468 - accuracy: 0.9450 - val_loss: 1.9855 - val_accuracy: 0.4560\n",
            "Epoch 5148/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3558 - accuracy: 0.9800 - val_loss: 1.9852 - val_accuracy: 0.4564\n",
            "Epoch 5149/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4049 - accuracy: 0.9500 - val_loss: 1.9861 - val_accuracy: 0.4565\n",
            "Epoch 5150/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4274 - accuracy: 0.9400 - val_loss: 1.9854 - val_accuracy: 0.4562\n",
            "Epoch 5151/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4044 - accuracy: 0.9650 - val_loss: 1.9876 - val_accuracy: 0.4559\n",
            "Epoch 5152/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3941 - accuracy: 0.9600 - val_loss: 1.9891 - val_accuracy: 0.4564\n",
            "Epoch 5153/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3939 - accuracy: 0.9800 - val_loss: 1.9907 - val_accuracy: 0.4564\n",
            "Epoch 5154/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4784 - accuracy: 0.9300 - val_loss: 1.9894 - val_accuracy: 0.4561\n",
            "Epoch 5155/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3994 - accuracy: 0.9850 - val_loss: 1.9879 - val_accuracy: 0.4563\n",
            "Epoch 5156/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4059 - accuracy: 0.9750 - val_loss: 1.9876 - val_accuracy: 0.4560\n",
            "Epoch 5157/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4361 - accuracy: 0.9500 - val_loss: 1.9861 - val_accuracy: 0.4564\n",
            "Epoch 5158/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4140 - accuracy: 0.9650 - val_loss: 1.9862 - val_accuracy: 0.4565\n",
            "Epoch 5159/6000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4234 - accuracy: 0.9450 - val_loss: 1.9838 - val_accuracy: 0.4568\n",
            "Epoch 5160/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.3812 - accuracy: 0.9650 - val_loss: 1.9836 - val_accuracy: 0.4567\n",
            "Epoch 5161/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4083 - accuracy: 0.9500 - val_loss: 1.9833 - val_accuracy: 0.4565\n",
            "Epoch 5162/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4387 - accuracy: 0.9400 - val_loss: 1.9825 - val_accuracy: 0.4565\n",
            "Epoch 5163/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4239 - accuracy: 0.9500 - val_loss: 1.9823 - val_accuracy: 0.4570\n",
            "Epoch 5164/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4047 - accuracy: 0.9750 - val_loss: 1.9819 - val_accuracy: 0.4569\n",
            "Epoch 5165/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3974 - accuracy: 0.9600 - val_loss: 1.9821 - val_accuracy: 0.4570\n",
            "Epoch 5166/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3971 - accuracy: 0.9750 - val_loss: 1.9814 - val_accuracy: 0.4573\n",
            "Epoch 5167/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4195 - accuracy: 0.9550 - val_loss: 1.9811 - val_accuracy: 0.4577\n",
            "Epoch 5168/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4017 - accuracy: 0.9600 - val_loss: 1.9814 - val_accuracy: 0.4580\n",
            "Epoch 5169/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3983 - accuracy: 0.9800 - val_loss: 1.9816 - val_accuracy: 0.4580\n",
            "Epoch 5170/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4125 - accuracy: 0.9600 - val_loss: 1.9829 - val_accuracy: 0.4581\n",
            "Epoch 5171/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4428 - accuracy: 0.9400 - val_loss: 1.9851 - val_accuracy: 0.4573\n",
            "Epoch 5172/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3786 - accuracy: 0.9700 - val_loss: 1.9850 - val_accuracy: 0.4573\n",
            "Epoch 5173/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3750 - accuracy: 0.9850 - val_loss: 1.9851 - val_accuracy: 0.4574\n",
            "Epoch 5174/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4368 - accuracy: 0.9550 - val_loss: 1.9852 - val_accuracy: 0.4575\n",
            "Epoch 5175/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3963 - accuracy: 0.9650 - val_loss: 1.9858 - val_accuracy: 0.4571\n",
            "Epoch 5176/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4071 - accuracy: 0.9550 - val_loss: 1.9857 - val_accuracy: 0.4573\n",
            "Epoch 5177/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4157 - accuracy: 0.9650 - val_loss: 1.9867 - val_accuracy: 0.4572\n",
            "Epoch 5178/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4248 - accuracy: 0.9550 - val_loss: 1.9860 - val_accuracy: 0.4572\n",
            "Epoch 5179/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4199 - accuracy: 0.9700 - val_loss: 1.9849 - val_accuracy: 0.4580\n",
            "Epoch 5180/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3872 - accuracy: 0.9800 - val_loss: 1.9829 - val_accuracy: 0.4584\n",
            "Epoch 5181/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4155 - accuracy: 0.9550 - val_loss: 1.9826 - val_accuracy: 0.4583\n",
            "Epoch 5182/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4125 - accuracy: 0.9450 - val_loss: 1.9826 - val_accuracy: 0.4587\n",
            "Epoch 5183/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4325 - accuracy: 0.9600 - val_loss: 1.9827 - val_accuracy: 0.4588\n",
            "Epoch 5184/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4285 - accuracy: 0.9550 - val_loss: 1.9818 - val_accuracy: 0.4586\n",
            "Epoch 5185/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3913 - accuracy: 0.9650 - val_loss: 1.9818 - val_accuracy: 0.4587\n",
            "Epoch 5186/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4357 - accuracy: 0.9450 - val_loss: 1.9819 - val_accuracy: 0.4583\n",
            "Epoch 5187/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3972 - accuracy: 0.9550 - val_loss: 1.9820 - val_accuracy: 0.4586\n",
            "Epoch 5188/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4051 - accuracy: 0.9600 - val_loss: 1.9823 - val_accuracy: 0.4586\n",
            "Epoch 5189/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4105 - accuracy: 0.9700 - val_loss: 1.9819 - val_accuracy: 0.4586\n",
            "Epoch 5190/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4324 - accuracy: 0.9450 - val_loss: 1.9823 - val_accuracy: 0.4588\n",
            "Epoch 5191/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3760 - accuracy: 0.9700 - val_loss: 1.9827 - val_accuracy: 0.4589\n",
            "Epoch 5192/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3858 - accuracy: 0.9800 - val_loss: 1.9831 - val_accuracy: 0.4586\n",
            "Epoch 5193/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4453 - accuracy: 0.9550 - val_loss: 1.9835 - val_accuracy: 0.4584\n",
            "Epoch 5194/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4182 - accuracy: 0.9650 - val_loss: 1.9824 - val_accuracy: 0.4587\n",
            "Epoch 5195/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3861 - accuracy: 0.9700 - val_loss: 1.9814 - val_accuracy: 0.4585\n",
            "Epoch 5196/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4393 - accuracy: 0.9400 - val_loss: 1.9804 - val_accuracy: 0.4581\n",
            "Epoch 5197/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3955 - accuracy: 0.9700 - val_loss: 1.9803 - val_accuracy: 0.4580\n",
            "Epoch 5198/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4073 - accuracy: 0.9750 - val_loss: 1.9807 - val_accuracy: 0.4582\n",
            "Epoch 5199/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4210 - accuracy: 0.9500 - val_loss: 1.9796 - val_accuracy: 0.4583\n",
            "Epoch 5200/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3813 - accuracy: 0.9700 - val_loss: 1.9794 - val_accuracy: 0.4581\n",
            "Epoch 5201/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4107 - accuracy: 0.9450 - val_loss: 1.9783 - val_accuracy: 0.4589\n",
            "Epoch 5202/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.3888 - accuracy: 0.9800 - val_loss: 1.9775 - val_accuracy: 0.4591\n",
            "Epoch 5203/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4040 - accuracy: 0.9400 - val_loss: 1.9769 - val_accuracy: 0.4592\n",
            "Epoch 5204/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4174 - accuracy: 0.9550 - val_loss: 1.9770 - val_accuracy: 0.4595\n",
            "Epoch 5205/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4508 - accuracy: 0.9550 - val_loss: 1.9763 - val_accuracy: 0.4591\n",
            "Epoch 5206/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4113 - accuracy: 0.9700 - val_loss: 1.9744 - val_accuracy: 0.4593\n",
            "Epoch 5207/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3722 - accuracy: 0.9750 - val_loss: 1.9734 - val_accuracy: 0.4592\n",
            "Epoch 5208/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3988 - accuracy: 0.9650 - val_loss: 1.9726 - val_accuracy: 0.4587\n",
            "Epoch 5209/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4076 - accuracy: 0.9550 - val_loss: 1.9731 - val_accuracy: 0.4590\n",
            "Epoch 5210/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3851 - accuracy: 0.9600 - val_loss: 1.9726 - val_accuracy: 0.4585\n",
            "Epoch 5211/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3939 - accuracy: 0.9700 - val_loss: 1.9735 - val_accuracy: 0.4587\n",
            "Epoch 5212/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4178 - accuracy: 0.9650 - val_loss: 1.9749 - val_accuracy: 0.4587\n",
            "Epoch 5213/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4459 - accuracy: 0.9450 - val_loss: 1.9759 - val_accuracy: 0.4586\n",
            "Epoch 5214/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4090 - accuracy: 0.9600 - val_loss: 1.9766 - val_accuracy: 0.4585\n",
            "Epoch 5215/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4360 - accuracy: 0.9550 - val_loss: 1.9775 - val_accuracy: 0.4580\n",
            "Epoch 5216/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4089 - accuracy: 0.9550 - val_loss: 1.9785 - val_accuracy: 0.4574\n",
            "Epoch 5217/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3993 - accuracy: 0.9750 - val_loss: 1.9790 - val_accuracy: 0.4573\n",
            "Epoch 5218/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4255 - accuracy: 0.9500 - val_loss: 1.9795 - val_accuracy: 0.4575\n",
            "Epoch 5219/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3891 - accuracy: 0.9800 - val_loss: 1.9799 - val_accuracy: 0.4572\n",
            "Epoch 5220/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4024 - accuracy: 0.9650 - val_loss: 1.9803 - val_accuracy: 0.4573\n",
            "Epoch 5221/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3849 - accuracy: 0.9750 - val_loss: 1.9805 - val_accuracy: 0.4573\n",
            "Epoch 5222/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4033 - accuracy: 0.9600 - val_loss: 1.9799 - val_accuracy: 0.4580\n",
            "Epoch 5223/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4034 - accuracy: 0.9500 - val_loss: 1.9792 - val_accuracy: 0.4581\n",
            "Epoch 5224/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3873 - accuracy: 0.9850 - val_loss: 1.9780 - val_accuracy: 0.4583\n",
            "Epoch 5225/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3757 - accuracy: 0.9700 - val_loss: 1.9778 - val_accuracy: 0.4579\n",
            "Epoch 5226/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4068 - accuracy: 0.9700 - val_loss: 1.9775 - val_accuracy: 0.4578\n",
            "Epoch 5227/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3959 - accuracy: 0.9750 - val_loss: 1.9762 - val_accuracy: 0.4585\n",
            "Epoch 5228/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4445 - accuracy: 0.9450 - val_loss: 1.9762 - val_accuracy: 0.4584\n",
            "Epoch 5229/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4390 - accuracy: 0.9650 - val_loss: 1.9767 - val_accuracy: 0.4584\n",
            "Epoch 5230/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4235 - accuracy: 0.9550 - val_loss: 1.9778 - val_accuracy: 0.4583\n",
            "Epoch 5231/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4127 - accuracy: 0.9600 - val_loss: 1.9784 - val_accuracy: 0.4583\n",
            "Epoch 5232/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4636 - accuracy: 0.9400 - val_loss: 1.9781 - val_accuracy: 0.4585\n",
            "Epoch 5233/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4161 - accuracy: 0.9650 - val_loss: 1.9784 - val_accuracy: 0.4589\n",
            "Epoch 5234/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4050 - accuracy: 0.9700 - val_loss: 1.9781 - val_accuracy: 0.4596\n",
            "Epoch 5235/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3830 - accuracy: 0.9650 - val_loss: 1.9784 - val_accuracy: 0.4594\n",
            "Epoch 5236/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4359 - accuracy: 0.9650 - val_loss: 1.9782 - val_accuracy: 0.4595\n",
            "Epoch 5237/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3976 - accuracy: 0.9750 - val_loss: 1.9780 - val_accuracy: 0.4591\n",
            "Epoch 5238/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3984 - accuracy: 0.9600 - val_loss: 1.9778 - val_accuracy: 0.4587\n",
            "Epoch 5239/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3774 - accuracy: 0.9700 - val_loss: 1.9771 - val_accuracy: 0.4586\n",
            "Epoch 5240/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4449 - accuracy: 0.9500 - val_loss: 1.9765 - val_accuracy: 0.4588\n",
            "Epoch 5241/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4884 - accuracy: 0.9350 - val_loss: 1.9753 - val_accuracy: 0.4584\n",
            "Epoch 5242/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4139 - accuracy: 0.9450 - val_loss: 1.9752 - val_accuracy: 0.4588\n",
            "Epoch 5243/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4155 - accuracy: 0.9650 - val_loss: 1.9756 - val_accuracy: 0.4585\n",
            "Epoch 5244/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4106 - accuracy: 0.9450 - val_loss: 1.9766 - val_accuracy: 0.4590\n",
            "Epoch 5245/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4096 - accuracy: 0.9700 - val_loss: 1.9766 - val_accuracy: 0.4589\n",
            "Epoch 5246/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3992 - accuracy: 0.9650 - val_loss: 1.9769 - val_accuracy: 0.4592\n",
            "Epoch 5247/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4469 - accuracy: 0.9600 - val_loss: 1.9763 - val_accuracy: 0.4594\n",
            "Epoch 5248/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3922 - accuracy: 0.9600 - val_loss: 1.9766 - val_accuracy: 0.4589\n",
            "Epoch 5249/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3710 - accuracy: 0.9750 - val_loss: 1.9757 - val_accuracy: 0.4591\n",
            "Epoch 5250/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4049 - accuracy: 0.9600 - val_loss: 1.9753 - val_accuracy: 0.4589\n",
            "Epoch 5251/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4225 - accuracy: 0.9500 - val_loss: 1.9757 - val_accuracy: 0.4591\n",
            "Epoch 5252/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4470 - accuracy: 0.9450 - val_loss: 1.9760 - val_accuracy: 0.4596\n",
            "Epoch 5253/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4326 - accuracy: 0.9500 - val_loss: 1.9757 - val_accuracy: 0.4597\n",
            "Epoch 5254/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3937 - accuracy: 0.9600 - val_loss: 1.9769 - val_accuracy: 0.4594\n",
            "Epoch 5255/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3855 - accuracy: 0.9750 - val_loss: 1.9775 - val_accuracy: 0.4597\n",
            "Epoch 5256/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4117 - accuracy: 0.9400 - val_loss: 1.9782 - val_accuracy: 0.4598\n",
            "Epoch 5257/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3878 - accuracy: 0.9650 - val_loss: 1.9784 - val_accuracy: 0.4600\n",
            "Epoch 5258/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3756 - accuracy: 0.9600 - val_loss: 1.9782 - val_accuracy: 0.4594\n",
            "Epoch 5259/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4134 - accuracy: 0.9700 - val_loss: 1.9783 - val_accuracy: 0.4597\n",
            "Epoch 5260/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4070 - accuracy: 0.9600 - val_loss: 1.9783 - val_accuracy: 0.4599\n",
            "Epoch 5261/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3927 - accuracy: 0.9700 - val_loss: 1.9803 - val_accuracy: 0.4596\n",
            "Epoch 5262/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3873 - accuracy: 0.9650 - val_loss: 1.9805 - val_accuracy: 0.4596\n",
            "Epoch 5263/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4024 - accuracy: 0.9700 - val_loss: 1.9798 - val_accuracy: 0.4596\n",
            "Epoch 5264/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4643 - accuracy: 0.9350 - val_loss: 1.9797 - val_accuracy: 0.4596\n",
            "Epoch 5265/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3986 - accuracy: 0.9750 - val_loss: 1.9812 - val_accuracy: 0.4591\n",
            "Epoch 5266/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4501 - accuracy: 0.9300 - val_loss: 1.9805 - val_accuracy: 0.4588\n",
            "Epoch 5267/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3997 - accuracy: 0.9550 - val_loss: 1.9799 - val_accuracy: 0.4592\n",
            "Epoch 5268/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4333 - accuracy: 0.9500 - val_loss: 1.9791 - val_accuracy: 0.4596\n",
            "Epoch 5269/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4375 - accuracy: 0.9350 - val_loss: 1.9790 - val_accuracy: 0.4594\n",
            "Epoch 5270/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4073 - accuracy: 0.9650 - val_loss: 1.9791 - val_accuracy: 0.4594\n",
            "Epoch 5271/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4606 - accuracy: 0.9300 - val_loss: 1.9789 - val_accuracy: 0.4593\n",
            "Epoch 5272/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3935 - accuracy: 0.9700 - val_loss: 1.9782 - val_accuracy: 0.4595\n",
            "Epoch 5273/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3906 - accuracy: 0.9700 - val_loss: 1.9775 - val_accuracy: 0.4595\n",
            "Epoch 5274/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4058 - accuracy: 0.9500 - val_loss: 1.9775 - val_accuracy: 0.4596\n",
            "Epoch 5275/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4498 - accuracy: 0.9500 - val_loss: 1.9768 - val_accuracy: 0.4596\n",
            "Epoch 5276/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4026 - accuracy: 0.9700 - val_loss: 1.9761 - val_accuracy: 0.4594\n",
            "Epoch 5277/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3762 - accuracy: 0.9750 - val_loss: 1.9747 - val_accuracy: 0.4594\n",
            "Epoch 5278/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3716 - accuracy: 0.9800 - val_loss: 1.9751 - val_accuracy: 0.4595\n",
            "Epoch 5279/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3988 - accuracy: 0.9650 - val_loss: 1.9755 - val_accuracy: 0.4595\n",
            "Epoch 5280/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4173 - accuracy: 0.9550 - val_loss: 1.9753 - val_accuracy: 0.4599\n",
            "Epoch 5281/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4812 - accuracy: 0.9400 - val_loss: 1.9744 - val_accuracy: 0.4607\n",
            "Epoch 5282/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4011 - accuracy: 0.9650 - val_loss: 1.9735 - val_accuracy: 0.4605\n",
            "Epoch 5283/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4135 - accuracy: 0.9700 - val_loss: 1.9738 - val_accuracy: 0.4604\n",
            "Epoch 5284/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3946 - accuracy: 0.9700 - val_loss: 1.9743 - val_accuracy: 0.4605\n",
            "Epoch 5285/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4160 - accuracy: 0.9450 - val_loss: 1.9754 - val_accuracy: 0.4606\n",
            "Epoch 5286/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3826 - accuracy: 0.9700 - val_loss: 1.9759 - val_accuracy: 0.4603\n",
            "Epoch 5287/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4218 - accuracy: 0.9500 - val_loss: 1.9755 - val_accuracy: 0.4605\n",
            "Epoch 5288/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4181 - accuracy: 0.9450 - val_loss: 1.9745 - val_accuracy: 0.4604\n",
            "Epoch 5289/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3674 - accuracy: 0.9650 - val_loss: 1.9737 - val_accuracy: 0.4604\n",
            "Epoch 5290/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4065 - accuracy: 0.9650 - val_loss: 1.9727 - val_accuracy: 0.4609\n",
            "Epoch 5291/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3843 - accuracy: 0.9700 - val_loss: 1.9718 - val_accuracy: 0.4603\n",
            "Epoch 5292/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4059 - accuracy: 0.9450 - val_loss: 1.9713 - val_accuracy: 0.4604\n",
            "Epoch 5293/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4167 - accuracy: 0.9550 - val_loss: 1.9708 - val_accuracy: 0.4607\n",
            "Epoch 5294/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4168 - accuracy: 0.9550 - val_loss: 1.9700 - val_accuracy: 0.4608\n",
            "Epoch 5295/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4233 - accuracy: 0.9450 - val_loss: 1.9700 - val_accuracy: 0.4601\n",
            "Epoch 5296/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3837 - accuracy: 0.9700 - val_loss: 1.9685 - val_accuracy: 0.4607\n",
            "Epoch 5297/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4119 - accuracy: 0.9650 - val_loss: 1.9684 - val_accuracy: 0.4606\n",
            "Epoch 5298/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3679 - accuracy: 0.9800 - val_loss: 1.9688 - val_accuracy: 0.4605\n",
            "Epoch 5299/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4351 - accuracy: 0.9650 - val_loss: 1.9693 - val_accuracy: 0.4607\n",
            "Epoch 5300/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3768 - accuracy: 0.9600 - val_loss: 1.9701 - val_accuracy: 0.4605\n",
            "Epoch 5301/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4006 - accuracy: 0.9600 - val_loss: 1.9710 - val_accuracy: 0.4603\n",
            "Epoch 5302/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3965 - accuracy: 0.9700 - val_loss: 1.9708 - val_accuracy: 0.4602\n",
            "Epoch 5303/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4161 - accuracy: 0.9550 - val_loss: 1.9708 - val_accuracy: 0.4606\n",
            "Epoch 5304/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4074 - accuracy: 0.9550 - val_loss: 1.9715 - val_accuracy: 0.4600\n",
            "Epoch 5305/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4026 - accuracy: 0.9600 - val_loss: 1.9715 - val_accuracy: 0.4603\n",
            "Epoch 5306/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3832 - accuracy: 0.9700 - val_loss: 1.9718 - val_accuracy: 0.4598\n",
            "Epoch 5307/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3900 - accuracy: 0.9750 - val_loss: 1.9717 - val_accuracy: 0.4602\n",
            "Epoch 5308/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4420 - accuracy: 0.9400 - val_loss: 1.9736 - val_accuracy: 0.4594\n",
            "Epoch 5309/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4016 - accuracy: 0.9650 - val_loss: 1.9746 - val_accuracy: 0.4594\n",
            "Epoch 5310/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4168 - accuracy: 0.9400 - val_loss: 1.9754 - val_accuracy: 0.4598\n",
            "Epoch 5311/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4105 - accuracy: 0.9400 - val_loss: 1.9758 - val_accuracy: 0.4600\n",
            "Epoch 5312/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4294 - accuracy: 0.9450 - val_loss: 1.9767 - val_accuracy: 0.4595\n",
            "Epoch 5313/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3919 - accuracy: 0.9750 - val_loss: 1.9768 - val_accuracy: 0.4597\n",
            "Epoch 5314/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3723 - accuracy: 0.9900 - val_loss: 1.9775 - val_accuracy: 0.4595\n",
            "Epoch 5315/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4165 - accuracy: 0.9600 - val_loss: 1.9773 - val_accuracy: 0.4598\n",
            "Epoch 5316/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4473 - accuracy: 0.9550 - val_loss: 1.9798 - val_accuracy: 0.4586\n",
            "Epoch 5317/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4215 - accuracy: 0.9650 - val_loss: 1.9798 - val_accuracy: 0.4585\n",
            "Epoch 5318/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3755 - accuracy: 0.9900 - val_loss: 1.9799 - val_accuracy: 0.4586\n",
            "Epoch 5319/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4136 - accuracy: 0.9550 - val_loss: 1.9798 - val_accuracy: 0.4585\n",
            "Epoch 5320/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3628 - accuracy: 0.9750 - val_loss: 1.9795 - val_accuracy: 0.4586\n",
            "Epoch 5321/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3844 - accuracy: 0.9750 - val_loss: 1.9800 - val_accuracy: 0.4589\n",
            "Epoch 5322/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4351 - accuracy: 0.9450 - val_loss: 1.9807 - val_accuracy: 0.4587\n",
            "Epoch 5323/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4132 - accuracy: 0.9500 - val_loss: 1.9802 - val_accuracy: 0.4588\n",
            "Epoch 5324/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4291 - accuracy: 0.9500 - val_loss: 1.9805 - val_accuracy: 0.4593\n",
            "Epoch 5325/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4138 - accuracy: 0.9600 - val_loss: 1.9800 - val_accuracy: 0.4593\n",
            "Epoch 5326/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4018 - accuracy: 0.9600 - val_loss: 1.9804 - val_accuracy: 0.4594\n",
            "Epoch 5327/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4067 - accuracy: 0.9600 - val_loss: 1.9799 - val_accuracy: 0.4593\n",
            "Epoch 5328/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4274 - accuracy: 0.9600 - val_loss: 1.9800 - val_accuracy: 0.4596\n",
            "Epoch 5329/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3848 - accuracy: 0.9800 - val_loss: 1.9803 - val_accuracy: 0.4599\n",
            "Epoch 5330/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3919 - accuracy: 0.9550 - val_loss: 1.9809 - val_accuracy: 0.4597\n",
            "Epoch 5331/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3901 - accuracy: 0.9600 - val_loss: 1.9820 - val_accuracy: 0.4594\n",
            "Epoch 5332/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3992 - accuracy: 0.9500 - val_loss: 1.9832 - val_accuracy: 0.4588\n",
            "Epoch 5333/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4085 - accuracy: 0.9400 - val_loss: 1.9837 - val_accuracy: 0.4587\n",
            "Epoch 5334/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4145 - accuracy: 0.9600 - val_loss: 1.9851 - val_accuracy: 0.4586\n",
            "Epoch 5335/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3922 - accuracy: 0.9550 - val_loss: 1.9855 - val_accuracy: 0.4586\n",
            "Epoch 5336/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3963 - accuracy: 0.9550 - val_loss: 1.9863 - val_accuracy: 0.4586\n",
            "Epoch 5337/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4027 - accuracy: 0.9450 - val_loss: 1.9869 - val_accuracy: 0.4586\n",
            "Epoch 5338/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4006 - accuracy: 0.9650 - val_loss: 1.9873 - val_accuracy: 0.4583\n",
            "Epoch 5339/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3807 - accuracy: 0.9850 - val_loss: 1.9867 - val_accuracy: 0.4587\n",
            "Epoch 5340/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3596 - accuracy: 0.9750 - val_loss: 1.9865 - val_accuracy: 0.4589\n",
            "Epoch 5341/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3789 - accuracy: 0.9750 - val_loss: 1.9863 - val_accuracy: 0.4588\n",
            "Epoch 5342/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3819 - accuracy: 0.9650 - val_loss: 1.9862 - val_accuracy: 0.4584\n",
            "Epoch 5343/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4004 - accuracy: 0.9600 - val_loss: 1.9866 - val_accuracy: 0.4583\n",
            "Epoch 5344/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4115 - accuracy: 0.9400 - val_loss: 1.9865 - val_accuracy: 0.4585\n",
            "Epoch 5345/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3978 - accuracy: 0.9700 - val_loss: 1.9856 - val_accuracy: 0.4585\n",
            "Epoch 5346/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4559 - accuracy: 0.9350 - val_loss: 1.9867 - val_accuracy: 0.4584\n",
            "Epoch 5347/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4204 - accuracy: 0.9550 - val_loss: 1.9875 - val_accuracy: 0.4584\n",
            "Epoch 5348/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3734 - accuracy: 0.9550 - val_loss: 1.9868 - val_accuracy: 0.4585\n",
            "Epoch 5349/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4019 - accuracy: 0.9700 - val_loss: 1.9872 - val_accuracy: 0.4583\n",
            "Epoch 5350/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4199 - accuracy: 0.9550 - val_loss: 1.9879 - val_accuracy: 0.4584\n",
            "Epoch 5351/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4268 - accuracy: 0.9550 - val_loss: 1.9888 - val_accuracy: 0.4577\n",
            "Epoch 5352/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4055 - accuracy: 0.9600 - val_loss: 1.9864 - val_accuracy: 0.4585\n",
            "Epoch 5353/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4246 - accuracy: 0.9400 - val_loss: 1.9872 - val_accuracy: 0.4584\n",
            "Epoch 5354/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3872 - accuracy: 0.9700 - val_loss: 1.9869 - val_accuracy: 0.4583\n",
            "Epoch 5355/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3740 - accuracy: 0.9750 - val_loss: 1.9862 - val_accuracy: 0.4589\n",
            "Epoch 5356/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3896 - accuracy: 0.9900 - val_loss: 1.9857 - val_accuracy: 0.4587\n",
            "Epoch 5357/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3698 - accuracy: 0.9850 - val_loss: 1.9848 - val_accuracy: 0.4588\n",
            "Epoch 5358/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3609 - accuracy: 0.9800 - val_loss: 1.9852 - val_accuracy: 0.4586\n",
            "Epoch 5359/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4317 - accuracy: 0.9500 - val_loss: 1.9855 - val_accuracy: 0.4589\n",
            "Epoch 5360/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3640 - accuracy: 0.9850 - val_loss: 1.9863 - val_accuracy: 0.4589\n",
            "Epoch 5361/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4091 - accuracy: 0.9650 - val_loss: 1.9870 - val_accuracy: 0.4583\n",
            "Epoch 5362/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4017 - accuracy: 0.9450 - val_loss: 1.9877 - val_accuracy: 0.4590\n",
            "Epoch 5363/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3994 - accuracy: 0.9600 - val_loss: 1.9887 - val_accuracy: 0.4587\n",
            "Epoch 5364/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3959 - accuracy: 0.9750 - val_loss: 1.9885 - val_accuracy: 0.4581\n",
            "Epoch 5365/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4052 - accuracy: 0.9650 - val_loss: 1.9881 - val_accuracy: 0.4584\n",
            "Epoch 5366/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3757 - accuracy: 0.9850 - val_loss: 1.9883 - val_accuracy: 0.4582\n",
            "Epoch 5367/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3748 - accuracy: 0.9850 - val_loss: 1.9885 - val_accuracy: 0.4584\n",
            "Epoch 5368/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3667 - accuracy: 0.9700 - val_loss: 1.9889 - val_accuracy: 0.4584\n",
            "Epoch 5369/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3760 - accuracy: 0.9700 - val_loss: 1.9886 - val_accuracy: 0.4583\n",
            "Epoch 5370/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3965 - accuracy: 0.9650 - val_loss: 1.9886 - val_accuracy: 0.4590\n",
            "Epoch 5371/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4029 - accuracy: 0.9600 - val_loss: 1.9892 - val_accuracy: 0.4585\n",
            "Epoch 5372/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3997 - accuracy: 0.9700 - val_loss: 1.9894 - val_accuracy: 0.4587\n",
            "Epoch 5373/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3980 - accuracy: 0.9700 - val_loss: 1.9895 - val_accuracy: 0.4578\n",
            "Epoch 5374/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4051 - accuracy: 0.9650 - val_loss: 1.9889 - val_accuracy: 0.4581\n",
            "Epoch 5375/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3492 - accuracy: 0.9850 - val_loss: 1.9875 - val_accuracy: 0.4586\n",
            "Epoch 5376/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4191 - accuracy: 0.9600 - val_loss: 1.9886 - val_accuracy: 0.4583\n",
            "Epoch 5377/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4102 - accuracy: 0.9450 - val_loss: 1.9885 - val_accuracy: 0.4581\n",
            "Epoch 5378/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4012 - accuracy: 0.9600 - val_loss: 1.9880 - val_accuracy: 0.4587\n",
            "Epoch 5379/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3857 - accuracy: 0.9550 - val_loss: 1.9879 - val_accuracy: 0.4584\n",
            "Epoch 5380/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3689 - accuracy: 0.9850 - val_loss: 1.9866 - val_accuracy: 0.4591\n",
            "Epoch 5381/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3890 - accuracy: 0.9600 - val_loss: 1.9874 - val_accuracy: 0.4587\n",
            "Epoch 5382/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4626 - accuracy: 0.9400 - val_loss: 1.9875 - val_accuracy: 0.4588\n",
            "Epoch 5383/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3961 - accuracy: 0.9700 - val_loss: 1.9889 - val_accuracy: 0.4579\n",
            "Epoch 5384/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3800 - accuracy: 0.9750 - val_loss: 1.9885 - val_accuracy: 0.4585\n",
            "Epoch 5385/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4356 - accuracy: 0.9500 - val_loss: 1.9885 - val_accuracy: 0.4582\n",
            "Epoch 5386/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3921 - accuracy: 0.9750 - val_loss: 1.9891 - val_accuracy: 0.4583\n",
            "Epoch 5387/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4160 - accuracy: 0.9550 - val_loss: 1.9888 - val_accuracy: 0.4589\n",
            "Epoch 5388/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3714 - accuracy: 0.9800 - val_loss: 1.9891 - val_accuracy: 0.4588\n",
            "Epoch 5389/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4072 - accuracy: 0.9700 - val_loss: 1.9901 - val_accuracy: 0.4592\n",
            "Epoch 5390/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4177 - accuracy: 0.9550 - val_loss: 1.9899 - val_accuracy: 0.4594\n",
            "Epoch 5391/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3744 - accuracy: 0.9600 - val_loss: 1.9898 - val_accuracy: 0.4595\n",
            "Epoch 5392/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4180 - accuracy: 0.9550 - val_loss: 1.9904 - val_accuracy: 0.4591\n",
            "Epoch 5393/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4137 - accuracy: 0.9450 - val_loss: 1.9901 - val_accuracy: 0.4593\n",
            "Epoch 5394/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3927 - accuracy: 0.9750 - val_loss: 1.9907 - val_accuracy: 0.4593\n",
            "Epoch 5395/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3812 - accuracy: 0.9800 - val_loss: 1.9906 - val_accuracy: 0.4593\n",
            "Epoch 5396/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3832 - accuracy: 0.9650 - val_loss: 1.9922 - val_accuracy: 0.4590\n",
            "Epoch 5397/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4076 - accuracy: 0.9500 - val_loss: 1.9924 - val_accuracy: 0.4592\n",
            "Epoch 5398/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4292 - accuracy: 0.9550 - val_loss: 1.9934 - val_accuracy: 0.4590\n",
            "Epoch 5399/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3955 - accuracy: 0.9650 - val_loss: 1.9944 - val_accuracy: 0.4586\n",
            "Epoch 5400/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3910 - accuracy: 0.9500 - val_loss: 1.9955 - val_accuracy: 0.4584\n",
            "Epoch 5401/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4142 - accuracy: 0.9600 - val_loss: 1.9962 - val_accuracy: 0.4579\n",
            "Epoch 5402/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3759 - accuracy: 0.9700 - val_loss: 1.9969 - val_accuracy: 0.4580\n",
            "Epoch 5403/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3690 - accuracy: 0.9750 - val_loss: 1.9971 - val_accuracy: 0.4578\n",
            "Epoch 5404/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.3997 - accuracy: 0.9550 - val_loss: 1.9981 - val_accuracy: 0.4580\n",
            "Epoch 5405/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4216 - accuracy: 0.9500 - val_loss: 1.9993 - val_accuracy: 0.4575\n",
            "Epoch 5406/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4296 - accuracy: 0.9700 - val_loss: 1.9996 - val_accuracy: 0.4577\n",
            "Epoch 5407/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4040 - accuracy: 0.9800 - val_loss: 2.0004 - val_accuracy: 0.4581\n",
            "Epoch 5408/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.3672 - accuracy: 0.9600 - val_loss: 1.9999 - val_accuracy: 0.4585\n",
            "Epoch 5409/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4016 - accuracy: 0.9500 - val_loss: 1.9996 - val_accuracy: 0.4582\n",
            "Epoch 5410/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4312 - accuracy: 0.9350 - val_loss: 1.9995 - val_accuracy: 0.4579\n",
            "Epoch 5411/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3991 - accuracy: 0.9600 - val_loss: 2.0002 - val_accuracy: 0.4580\n",
            "Epoch 5412/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3709 - accuracy: 0.9800 - val_loss: 2.0010 - val_accuracy: 0.4579\n",
            "Epoch 5413/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4085 - accuracy: 0.9700 - val_loss: 2.0008 - val_accuracy: 0.4580\n",
            "Epoch 5414/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3855 - accuracy: 0.9700 - val_loss: 2.0000 - val_accuracy: 0.4579\n",
            "Epoch 5415/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3633 - accuracy: 0.9800 - val_loss: 1.9994 - val_accuracy: 0.4579\n",
            "Epoch 5416/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4031 - accuracy: 0.9450 - val_loss: 1.9998 - val_accuracy: 0.4581\n",
            "Epoch 5417/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4167 - accuracy: 0.9500 - val_loss: 1.9998 - val_accuracy: 0.4580\n",
            "Epoch 5418/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3369 - accuracy: 0.9900 - val_loss: 1.9994 - val_accuracy: 0.4578\n",
            "Epoch 5419/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3917 - accuracy: 0.9700 - val_loss: 1.9994 - val_accuracy: 0.4578\n",
            "Epoch 5420/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3940 - accuracy: 0.9650 - val_loss: 1.9981 - val_accuracy: 0.4583\n",
            "Epoch 5421/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3850 - accuracy: 0.9750 - val_loss: 1.9990 - val_accuracy: 0.4581\n",
            "Epoch 5422/6000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.3843 - accuracy: 0.9750 - val_loss: 1.9993 - val_accuracy: 0.4581\n",
            "Epoch 5423/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4057 - accuracy: 0.9700 - val_loss: 1.9993 - val_accuracy: 0.4582\n",
            "Epoch 5424/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3936 - accuracy: 0.9650 - val_loss: 1.9995 - val_accuracy: 0.4583\n",
            "Epoch 5425/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3402 - accuracy: 0.9850 - val_loss: 1.9991 - val_accuracy: 0.4584\n",
            "Epoch 5426/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4137 - accuracy: 0.9600 - val_loss: 1.9998 - val_accuracy: 0.4582\n",
            "Epoch 5427/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4064 - accuracy: 0.9700 - val_loss: 1.9997 - val_accuracy: 0.4583\n",
            "Epoch 5428/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4014 - accuracy: 0.9650 - val_loss: 2.0017 - val_accuracy: 0.4580\n",
            "Epoch 5429/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3575 - accuracy: 0.9800 - val_loss: 2.0025 - val_accuracy: 0.4581\n",
            "Epoch 5430/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3873 - accuracy: 0.9700 - val_loss: 2.0027 - val_accuracy: 0.4582\n",
            "Epoch 5431/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4081 - accuracy: 0.9600 - val_loss: 2.0028 - val_accuracy: 0.4583\n",
            "Epoch 5432/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4171 - accuracy: 0.9650 - val_loss: 2.0006 - val_accuracy: 0.4583\n",
            "Epoch 5433/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3968 - accuracy: 0.9650 - val_loss: 2.0001 - val_accuracy: 0.4583\n",
            "Epoch 5434/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3755 - accuracy: 0.9750 - val_loss: 2.0006 - val_accuracy: 0.4584\n",
            "Epoch 5435/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4327 - accuracy: 0.9500 - val_loss: 1.9989 - val_accuracy: 0.4585\n",
            "Epoch 5436/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3789 - accuracy: 0.9800 - val_loss: 1.9988 - val_accuracy: 0.4585\n",
            "Epoch 5437/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3866 - accuracy: 0.9600 - val_loss: 1.9978 - val_accuracy: 0.4583\n",
            "Epoch 5438/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3836 - accuracy: 0.9800 - val_loss: 1.9965 - val_accuracy: 0.4583\n",
            "Epoch 5439/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4025 - accuracy: 0.9600 - val_loss: 1.9970 - val_accuracy: 0.4582\n",
            "Epoch 5440/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3725 - accuracy: 0.9750 - val_loss: 1.9970 - val_accuracy: 0.4582\n",
            "Epoch 5441/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3891 - accuracy: 0.9650 - val_loss: 1.9961 - val_accuracy: 0.4587\n",
            "Epoch 5442/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3911 - accuracy: 0.9750 - val_loss: 1.9949 - val_accuracy: 0.4589\n",
            "Epoch 5443/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3744 - accuracy: 0.9600 - val_loss: 1.9944 - val_accuracy: 0.4588\n",
            "Epoch 5444/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3766 - accuracy: 0.9750 - val_loss: 1.9942 - val_accuracy: 0.4587\n",
            "Epoch 5445/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4404 - accuracy: 0.9500 - val_loss: 1.9930 - val_accuracy: 0.4588\n",
            "Epoch 5446/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4267 - accuracy: 0.9650 - val_loss: 1.9917 - val_accuracy: 0.4592\n",
            "Epoch 5447/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4112 - accuracy: 0.9500 - val_loss: 1.9914 - val_accuracy: 0.4589\n",
            "Epoch 5448/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3759 - accuracy: 0.9800 - val_loss: 1.9906 - val_accuracy: 0.4593\n",
            "Epoch 5449/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4234 - accuracy: 0.9550 - val_loss: 1.9894 - val_accuracy: 0.4593\n",
            "Epoch 5450/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4065 - accuracy: 0.9600 - val_loss: 1.9895 - val_accuracy: 0.4597\n",
            "Epoch 5451/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4055 - accuracy: 0.9600 - val_loss: 1.9895 - val_accuracy: 0.4597\n",
            "Epoch 5452/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3679 - accuracy: 0.9700 - val_loss: 1.9882 - val_accuracy: 0.4593\n",
            "Epoch 5453/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3731 - accuracy: 0.9650 - val_loss: 1.9882 - val_accuracy: 0.4594\n",
            "Epoch 5454/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3891 - accuracy: 0.9600 - val_loss: 1.9878 - val_accuracy: 0.4593\n",
            "Epoch 5455/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3826 - accuracy: 0.9800 - val_loss: 1.9880 - val_accuracy: 0.4595\n",
            "Epoch 5456/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4520 - accuracy: 0.9300 - val_loss: 1.9875 - val_accuracy: 0.4592\n",
            "Epoch 5457/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4002 - accuracy: 0.9600 - val_loss: 1.9865 - val_accuracy: 0.4594\n",
            "Epoch 5458/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4291 - accuracy: 0.9450 - val_loss: 1.9883 - val_accuracy: 0.4594\n",
            "Epoch 5459/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3847 - accuracy: 0.9750 - val_loss: 1.9881 - val_accuracy: 0.4595\n",
            "Epoch 5460/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3846 - accuracy: 0.9600 - val_loss: 1.9877 - val_accuracy: 0.4592\n",
            "Epoch 5461/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3782 - accuracy: 0.9700 - val_loss: 1.9888 - val_accuracy: 0.4591\n",
            "Epoch 5462/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3775 - accuracy: 0.9750 - val_loss: 1.9885 - val_accuracy: 0.4596\n",
            "Epoch 5463/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3928 - accuracy: 0.9600 - val_loss: 1.9885 - val_accuracy: 0.4593\n",
            "Epoch 5464/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3917 - accuracy: 0.9650 - val_loss: 1.9893 - val_accuracy: 0.4596\n",
            "Epoch 5465/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4057 - accuracy: 0.9600 - val_loss: 1.9900 - val_accuracy: 0.4596\n",
            "Epoch 5466/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3958 - accuracy: 0.9600 - val_loss: 1.9908 - val_accuracy: 0.4590\n",
            "Epoch 5467/6000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4439 - accuracy: 0.9500 - val_loss: 1.9903 - val_accuracy: 0.4591\n",
            "Epoch 5468/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3656 - accuracy: 0.9850 - val_loss: 1.9903 - val_accuracy: 0.4595\n",
            "Epoch 5469/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.3838 - accuracy: 0.9650 - val_loss: 1.9915 - val_accuracy: 0.4588\n",
            "Epoch 5470/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3758 - accuracy: 0.9800 - val_loss: 1.9923 - val_accuracy: 0.4586\n",
            "Epoch 5471/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3923 - accuracy: 0.9600 - val_loss: 1.9928 - val_accuracy: 0.4586\n",
            "Epoch 5472/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3939 - accuracy: 0.9650 - val_loss: 1.9930 - val_accuracy: 0.4584\n",
            "Epoch 5473/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3619 - accuracy: 0.9650 - val_loss: 1.9942 - val_accuracy: 0.4591\n",
            "Epoch 5474/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3683 - accuracy: 0.9650 - val_loss: 1.9945 - val_accuracy: 0.4588\n",
            "Epoch 5475/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3954 - accuracy: 0.9800 - val_loss: 1.9959 - val_accuracy: 0.4588\n",
            "Epoch 5476/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3997 - accuracy: 0.9700 - val_loss: 1.9971 - val_accuracy: 0.4581\n",
            "Epoch 5477/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3587 - accuracy: 0.9800 - val_loss: 1.9972 - val_accuracy: 0.4582\n",
            "Epoch 5478/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4182 - accuracy: 0.9400 - val_loss: 1.9984 - val_accuracy: 0.4583\n",
            "Epoch 5479/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3799 - accuracy: 0.9750 - val_loss: 1.9991 - val_accuracy: 0.4584\n",
            "Epoch 5480/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3891 - accuracy: 0.9600 - val_loss: 2.0005 - val_accuracy: 0.4585\n",
            "Epoch 5481/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3927 - accuracy: 0.9650 - val_loss: 2.0013 - val_accuracy: 0.4586\n",
            "Epoch 5482/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3990 - accuracy: 0.9600 - val_loss: 2.0019 - val_accuracy: 0.4584\n",
            "Epoch 5483/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3749 - accuracy: 0.9950 - val_loss: 2.0043 - val_accuracy: 0.4582\n",
            "Epoch 5484/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3657 - accuracy: 0.9800 - val_loss: 2.0060 - val_accuracy: 0.4581\n",
            "Epoch 5485/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3890 - accuracy: 0.9750 - val_loss: 2.0066 - val_accuracy: 0.4580\n",
            "Epoch 5486/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3810 - accuracy: 0.9750 - val_loss: 2.0074 - val_accuracy: 0.4574\n",
            "Epoch 5487/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3553 - accuracy: 0.9850 - val_loss: 2.0082 - val_accuracy: 0.4571\n",
            "Epoch 5488/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3967 - accuracy: 0.9650 - val_loss: 2.0083 - val_accuracy: 0.4572\n",
            "Epoch 5489/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3857 - accuracy: 0.9500 - val_loss: 2.0109 - val_accuracy: 0.4569\n",
            "Epoch 5490/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3601 - accuracy: 0.9800 - val_loss: 2.0114 - val_accuracy: 0.4567\n",
            "Epoch 5491/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3683 - accuracy: 0.9850 - val_loss: 2.0122 - val_accuracy: 0.4570\n",
            "Epoch 5492/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3511 - accuracy: 0.9850 - val_loss: 2.0133 - val_accuracy: 0.4562\n",
            "Epoch 5493/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3690 - accuracy: 0.9600 - val_loss: 2.0135 - val_accuracy: 0.4564\n",
            "Epoch 5494/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4132 - accuracy: 0.9500 - val_loss: 2.0133 - val_accuracy: 0.4563\n",
            "Epoch 5495/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4253 - accuracy: 0.9300 - val_loss: 2.0112 - val_accuracy: 0.4569\n",
            "Epoch 5496/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3880 - accuracy: 0.9650 - val_loss: 2.0115 - val_accuracy: 0.4569\n",
            "Epoch 5497/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4049 - accuracy: 0.9550 - val_loss: 2.0113 - val_accuracy: 0.4565\n",
            "Epoch 5498/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3751 - accuracy: 0.9700 - val_loss: 2.0106 - val_accuracy: 0.4562\n",
            "Epoch 5499/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3615 - accuracy: 0.9700 - val_loss: 2.0092 - val_accuracy: 0.4566\n",
            "Epoch 5500/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4021 - accuracy: 0.9600 - val_loss: 2.0091 - val_accuracy: 0.4565\n",
            "Epoch 5501/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3825 - accuracy: 0.9650 - val_loss: 2.0073 - val_accuracy: 0.4572\n",
            "Epoch 5502/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3524 - accuracy: 0.9800 - val_loss: 2.0081 - val_accuracy: 0.4572\n",
            "Epoch 5503/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4272 - accuracy: 0.9400 - val_loss: 2.0084 - val_accuracy: 0.4566\n",
            "Epoch 5504/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3635 - accuracy: 0.9750 - val_loss: 2.0076 - val_accuracy: 0.4564\n",
            "Epoch 5505/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3473 - accuracy: 0.9800 - val_loss: 2.0077 - val_accuracy: 0.4567\n",
            "Epoch 5506/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3674 - accuracy: 0.9850 - val_loss: 2.0082 - val_accuracy: 0.4566\n",
            "Epoch 5507/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3767 - accuracy: 0.9700 - val_loss: 2.0091 - val_accuracy: 0.4566\n",
            "Epoch 5508/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3548 - accuracy: 0.9850 - val_loss: 2.0090 - val_accuracy: 0.4566\n",
            "Epoch 5509/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3843 - accuracy: 0.9650 - val_loss: 2.0083 - val_accuracy: 0.4566\n",
            "Epoch 5510/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4219 - accuracy: 0.9500 - val_loss: 2.0085 - val_accuracy: 0.4562\n",
            "Epoch 5511/6000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4185 - accuracy: 0.9350 - val_loss: 2.0087 - val_accuracy: 0.4562\n",
            "Epoch 5512/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3788 - accuracy: 0.9700 - val_loss: 2.0070 - val_accuracy: 0.4576\n",
            "Epoch 5513/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3833 - accuracy: 0.9600 - val_loss: 2.0070 - val_accuracy: 0.4580\n",
            "Epoch 5514/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4476 - accuracy: 0.9550 - val_loss: 2.0065 - val_accuracy: 0.4581\n",
            "Epoch 5515/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4148 - accuracy: 0.9650 - val_loss: 2.0047 - val_accuracy: 0.4584\n",
            "Epoch 5516/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3440 - accuracy: 0.9900 - val_loss: 2.0036 - val_accuracy: 0.4589\n",
            "Epoch 5517/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3766 - accuracy: 0.9750 - val_loss: 2.0026 - val_accuracy: 0.4591\n",
            "Epoch 5518/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3751 - accuracy: 0.9750 - val_loss: 2.0035 - val_accuracy: 0.4591\n",
            "Epoch 5519/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3795 - accuracy: 0.9650 - val_loss: 2.0027 - val_accuracy: 0.4591\n",
            "Epoch 5520/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4319 - accuracy: 0.9550 - val_loss: 2.0029 - val_accuracy: 0.4591\n",
            "Epoch 5521/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3643 - accuracy: 0.9750 - val_loss: 2.0025 - val_accuracy: 0.4591\n",
            "Epoch 5522/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4098 - accuracy: 0.9500 - val_loss: 2.0014 - val_accuracy: 0.4588\n",
            "Epoch 5523/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3930 - accuracy: 0.9600 - val_loss: 1.9993 - val_accuracy: 0.4589\n",
            "Epoch 5524/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3683 - accuracy: 0.9700 - val_loss: 1.9994 - val_accuracy: 0.4593\n",
            "Epoch 5525/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3652 - accuracy: 0.9800 - val_loss: 1.9989 - val_accuracy: 0.4590\n",
            "Epoch 5526/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4124 - accuracy: 0.9500 - val_loss: 1.9987 - val_accuracy: 0.4590\n",
            "Epoch 5527/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3909 - accuracy: 0.9800 - val_loss: 1.9994 - val_accuracy: 0.4593\n",
            "Epoch 5528/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3670 - accuracy: 0.9700 - val_loss: 1.9981 - val_accuracy: 0.4597\n",
            "Epoch 5529/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.3844 - accuracy: 0.9700 - val_loss: 1.9977 - val_accuracy: 0.4599\n",
            "Epoch 5530/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3801 - accuracy: 0.9800 - val_loss: 1.9966 - val_accuracy: 0.4606\n",
            "Epoch 5531/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4130 - accuracy: 0.9450 - val_loss: 1.9982 - val_accuracy: 0.4599\n",
            "Epoch 5532/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4015 - accuracy: 0.9600 - val_loss: 1.9981 - val_accuracy: 0.4598\n",
            "Epoch 5533/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3769 - accuracy: 0.9650 - val_loss: 1.9990 - val_accuracy: 0.4603\n",
            "Epoch 5534/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3908 - accuracy: 0.9750 - val_loss: 1.9987 - val_accuracy: 0.4606\n",
            "Epoch 5535/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4090 - accuracy: 0.9400 - val_loss: 1.9999 - val_accuracy: 0.4610\n",
            "Epoch 5536/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4218 - accuracy: 0.9550 - val_loss: 2.0004 - val_accuracy: 0.4607\n",
            "Epoch 5537/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4079 - accuracy: 0.9550 - val_loss: 1.9999 - val_accuracy: 0.4606\n",
            "Epoch 5538/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3655 - accuracy: 0.9750 - val_loss: 2.0006 - val_accuracy: 0.4608\n",
            "Epoch 5539/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4055 - accuracy: 0.9600 - val_loss: 2.0003 - val_accuracy: 0.4610\n",
            "Epoch 5540/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3895 - accuracy: 0.9600 - val_loss: 1.9994 - val_accuracy: 0.4607\n",
            "Epoch 5541/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4321 - accuracy: 0.9400 - val_loss: 1.9983 - val_accuracy: 0.4610\n",
            "Epoch 5542/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3851 - accuracy: 0.9750 - val_loss: 1.9976 - val_accuracy: 0.4611\n",
            "Epoch 5543/6000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.3641 - accuracy: 0.9700 - val_loss: 1.9984 - val_accuracy: 0.4611\n",
            "Epoch 5544/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3788 - accuracy: 0.9650 - val_loss: 1.9986 - val_accuracy: 0.4608\n",
            "Epoch 5545/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3874 - accuracy: 0.9700 - val_loss: 2.0004 - val_accuracy: 0.4605\n",
            "Epoch 5546/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3593 - accuracy: 0.9800 - val_loss: 2.0006 - val_accuracy: 0.4606\n",
            "Epoch 5547/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3835 - accuracy: 0.9750 - val_loss: 2.0009 - val_accuracy: 0.4607\n",
            "Epoch 5548/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4241 - accuracy: 0.9500 - val_loss: 2.0001 - val_accuracy: 0.4606\n",
            "Epoch 5549/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3676 - accuracy: 0.9700 - val_loss: 1.9993 - val_accuracy: 0.4607\n",
            "Epoch 5550/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3864 - accuracy: 0.9550 - val_loss: 1.9993 - val_accuracy: 0.4610\n",
            "Epoch 5551/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3893 - accuracy: 0.9500 - val_loss: 1.9995 - val_accuracy: 0.4605\n",
            "Epoch 5552/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4018 - accuracy: 0.9450 - val_loss: 2.0001 - val_accuracy: 0.4604\n",
            "Epoch 5553/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3420 - accuracy: 0.9950 - val_loss: 1.9994 - val_accuracy: 0.4605\n",
            "Epoch 5554/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4176 - accuracy: 0.9650 - val_loss: 1.9994 - val_accuracy: 0.4606\n",
            "Epoch 5555/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3717 - accuracy: 0.9700 - val_loss: 1.9986 - val_accuracy: 0.4604\n",
            "Epoch 5556/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3487 - accuracy: 0.9800 - val_loss: 1.9991 - val_accuracy: 0.4599\n",
            "Epoch 5557/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3932 - accuracy: 0.9600 - val_loss: 1.9990 - val_accuracy: 0.4602\n",
            "Epoch 5558/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4397 - accuracy: 0.9350 - val_loss: 1.9991 - val_accuracy: 0.4601\n",
            "Epoch 5559/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3693 - accuracy: 0.9750 - val_loss: 2.0000 - val_accuracy: 0.4596\n",
            "Epoch 5560/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3780 - accuracy: 0.9800 - val_loss: 2.0000 - val_accuracy: 0.4597\n",
            "Epoch 5561/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4284 - accuracy: 0.9750 - val_loss: 2.0008 - val_accuracy: 0.4596\n",
            "Epoch 5562/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4241 - accuracy: 0.9600 - val_loss: 2.0020 - val_accuracy: 0.4601\n",
            "Epoch 5563/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3917 - accuracy: 0.9750 - val_loss: 2.0025 - val_accuracy: 0.4603\n",
            "Epoch 5564/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3660 - accuracy: 0.9800 - val_loss: 2.0024 - val_accuracy: 0.4603\n",
            "Epoch 5565/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4183 - accuracy: 0.9450 - val_loss: 2.0022 - val_accuracy: 0.4600\n",
            "Epoch 5566/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3875 - accuracy: 0.9600 - val_loss: 2.0024 - val_accuracy: 0.4601\n",
            "Epoch 5567/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4077 - accuracy: 0.9600 - val_loss: 2.0018 - val_accuracy: 0.4605\n",
            "Epoch 5568/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3540 - accuracy: 0.9800 - val_loss: 2.0005 - val_accuracy: 0.4609\n",
            "Epoch 5569/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4013 - accuracy: 0.9700 - val_loss: 2.0010 - val_accuracy: 0.4609\n",
            "Epoch 5570/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4173 - accuracy: 0.9550 - val_loss: 2.0016 - val_accuracy: 0.4605\n",
            "Epoch 5571/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3684 - accuracy: 0.9850 - val_loss: 2.0016 - val_accuracy: 0.4603\n",
            "Epoch 5572/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4034 - accuracy: 0.9600 - val_loss: 2.0008 - val_accuracy: 0.4608\n",
            "Epoch 5573/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3909 - accuracy: 0.9700 - val_loss: 1.9996 - val_accuracy: 0.4608\n",
            "Epoch 5574/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3848 - accuracy: 0.9650 - val_loss: 1.9996 - val_accuracy: 0.4610\n",
            "Epoch 5575/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3895 - accuracy: 0.9700 - val_loss: 1.9994 - val_accuracy: 0.4607\n",
            "Epoch 5576/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3878 - accuracy: 0.9600 - val_loss: 1.9978 - val_accuracy: 0.4606\n",
            "Epoch 5577/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4194 - accuracy: 0.9600 - val_loss: 1.9978 - val_accuracy: 0.4606\n",
            "Epoch 5578/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3908 - accuracy: 0.9500 - val_loss: 1.9977 - val_accuracy: 0.4609\n",
            "Epoch 5579/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3981 - accuracy: 0.9600 - val_loss: 1.9989 - val_accuracy: 0.4609\n",
            "Epoch 5580/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3695 - accuracy: 0.9750 - val_loss: 1.9992 - val_accuracy: 0.4607\n",
            "Epoch 5581/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3474 - accuracy: 0.9950 - val_loss: 1.9991 - val_accuracy: 0.4608\n",
            "Epoch 5582/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3935 - accuracy: 0.9600 - val_loss: 1.9995 - val_accuracy: 0.4605\n",
            "Epoch 5583/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4211 - accuracy: 0.9400 - val_loss: 1.9994 - val_accuracy: 0.4606\n",
            "Epoch 5584/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3649 - accuracy: 0.9700 - val_loss: 1.9983 - val_accuracy: 0.4610\n",
            "Epoch 5585/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3966 - accuracy: 0.9700 - val_loss: 1.9986 - val_accuracy: 0.4609\n",
            "Epoch 5586/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3524 - accuracy: 0.9800 - val_loss: 1.9984 - val_accuracy: 0.4610\n",
            "Epoch 5587/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3522 - accuracy: 0.9950 - val_loss: 1.9988 - val_accuracy: 0.4608\n",
            "Epoch 5588/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4468 - accuracy: 0.9200 - val_loss: 1.9987 - val_accuracy: 0.4605\n",
            "Epoch 5589/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3803 - accuracy: 0.9750 - val_loss: 1.9980 - val_accuracy: 0.4610\n",
            "Epoch 5590/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3478 - accuracy: 0.9850 - val_loss: 1.9986 - val_accuracy: 0.4610\n",
            "Epoch 5591/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3696 - accuracy: 0.9750 - val_loss: 1.9986 - val_accuracy: 0.4612\n",
            "Epoch 5592/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3655 - accuracy: 0.9700 - val_loss: 1.9981 - val_accuracy: 0.4613\n",
            "Epoch 5593/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4111 - accuracy: 0.9550 - val_loss: 1.9985 - val_accuracy: 0.4613\n",
            "Epoch 5594/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3726 - accuracy: 0.9650 - val_loss: 1.9983 - val_accuracy: 0.4615\n",
            "Epoch 5595/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4261 - accuracy: 0.9450 - val_loss: 1.9992 - val_accuracy: 0.4611\n",
            "Epoch 5596/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3703 - accuracy: 0.9750 - val_loss: 1.9994 - val_accuracy: 0.4610\n",
            "Epoch 5597/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3559 - accuracy: 0.9750 - val_loss: 1.9991 - val_accuracy: 0.4608\n",
            "Epoch 5598/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3860 - accuracy: 0.9700 - val_loss: 1.9990 - val_accuracy: 0.4609\n",
            "Epoch 5599/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4455 - accuracy: 0.9400 - val_loss: 2.0007 - val_accuracy: 0.4606\n",
            "Epoch 5600/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3854 - accuracy: 0.9550 - val_loss: 2.0015 - val_accuracy: 0.4602\n",
            "Epoch 5601/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3694 - accuracy: 0.9650 - val_loss: 2.0029 - val_accuracy: 0.4599\n",
            "Epoch 5602/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3941 - accuracy: 0.9550 - val_loss: 2.0030 - val_accuracy: 0.4600\n",
            "Epoch 5603/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3741 - accuracy: 0.9650 - val_loss: 2.0050 - val_accuracy: 0.4600\n",
            "Epoch 5604/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3663 - accuracy: 0.9700 - val_loss: 2.0057 - val_accuracy: 0.4600\n",
            "Epoch 5605/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3789 - accuracy: 0.9800 - val_loss: 2.0071 - val_accuracy: 0.4598\n",
            "Epoch 5606/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3507 - accuracy: 0.9750 - val_loss: 2.0074 - val_accuracy: 0.4596\n",
            "Epoch 5607/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3461 - accuracy: 0.9900 - val_loss: 2.0074 - val_accuracy: 0.4596\n",
            "Epoch 5608/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3888 - accuracy: 0.9650 - val_loss: 2.0075 - val_accuracy: 0.4598\n",
            "Epoch 5609/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3763 - accuracy: 0.9600 - val_loss: 2.0081 - val_accuracy: 0.4600\n",
            "Epoch 5610/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3437 - accuracy: 0.9900 - val_loss: 2.0086 - val_accuracy: 0.4598\n",
            "Epoch 5611/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3485 - accuracy: 0.9800 - val_loss: 2.0085 - val_accuracy: 0.4596\n",
            "Epoch 5612/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3999 - accuracy: 0.9700 - val_loss: 2.0100 - val_accuracy: 0.4598\n",
            "Epoch 5613/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4262 - accuracy: 0.9550 - val_loss: 2.0106 - val_accuracy: 0.4599\n",
            "Epoch 5614/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3676 - accuracy: 0.9950 - val_loss: 2.0109 - val_accuracy: 0.4601\n",
            "Epoch 5615/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.3570 - accuracy: 0.9750 - val_loss: 2.0114 - val_accuracy: 0.4597\n",
            "Epoch 5616/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3843 - accuracy: 0.9800 - val_loss: 2.0113 - val_accuracy: 0.4598\n",
            "Epoch 5617/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3459 - accuracy: 0.9900 - val_loss: 2.0122 - val_accuracy: 0.4592\n",
            "Epoch 5618/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3723 - accuracy: 0.9750 - val_loss: 2.0137 - val_accuracy: 0.4591\n",
            "Epoch 5619/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3712 - accuracy: 0.9800 - val_loss: 2.0137 - val_accuracy: 0.4592\n",
            "Epoch 5620/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3510 - accuracy: 0.9750 - val_loss: 2.0142 - val_accuracy: 0.4594\n",
            "Epoch 5621/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3801 - accuracy: 0.9600 - val_loss: 2.0142 - val_accuracy: 0.4594\n",
            "Epoch 5622/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3849 - accuracy: 0.9600 - val_loss: 2.0151 - val_accuracy: 0.4592\n",
            "Epoch 5623/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3565 - accuracy: 0.9750 - val_loss: 2.0147 - val_accuracy: 0.4594\n",
            "Epoch 5624/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3677 - accuracy: 0.9650 - val_loss: 2.0152 - val_accuracy: 0.4592\n",
            "Epoch 5625/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3911 - accuracy: 0.9650 - val_loss: 2.0159 - val_accuracy: 0.4591\n",
            "Epoch 5626/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3418 - accuracy: 0.9950 - val_loss: 2.0159 - val_accuracy: 0.4586\n",
            "Epoch 5627/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3609 - accuracy: 0.9850 - val_loss: 2.0156 - val_accuracy: 0.4584\n",
            "Epoch 5628/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4003 - accuracy: 0.9650 - val_loss: 2.0174 - val_accuracy: 0.4583\n",
            "Epoch 5629/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3670 - accuracy: 0.9700 - val_loss: 2.0164 - val_accuracy: 0.4585\n",
            "Epoch 5630/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3606 - accuracy: 0.9700 - val_loss: 2.0166 - val_accuracy: 0.4585\n",
            "Epoch 5631/6000\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.3640 - accuracy: 0.9750 - val_loss: 2.0164 - val_accuracy: 0.4585\n",
            "Epoch 5632/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3991 - accuracy: 0.9700 - val_loss: 2.0152 - val_accuracy: 0.4591\n",
            "Epoch 5633/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3884 - accuracy: 0.9700 - val_loss: 2.0152 - val_accuracy: 0.4595\n",
            "Epoch 5634/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3473 - accuracy: 0.9850 - val_loss: 2.0153 - val_accuracy: 0.4594\n",
            "Epoch 5635/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3829 - accuracy: 0.9750 - val_loss: 2.0153 - val_accuracy: 0.4594\n",
            "Epoch 5636/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3837 - accuracy: 0.9650 - val_loss: 2.0147 - val_accuracy: 0.4590\n",
            "Epoch 5637/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4022 - accuracy: 0.9450 - val_loss: 2.0149 - val_accuracy: 0.4587\n",
            "Epoch 5638/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3595 - accuracy: 0.9750 - val_loss: 2.0145 - val_accuracy: 0.4587\n",
            "Epoch 5639/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3618 - accuracy: 0.9900 - val_loss: 2.0150 - val_accuracy: 0.4588\n",
            "Epoch 5640/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4083 - accuracy: 0.9600 - val_loss: 2.0164 - val_accuracy: 0.4592\n",
            "Epoch 5641/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3597 - accuracy: 0.9900 - val_loss: 2.0172 - val_accuracy: 0.4587\n",
            "Epoch 5642/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3979 - accuracy: 0.9600 - val_loss: 2.0177 - val_accuracy: 0.4585\n",
            "Epoch 5643/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3711 - accuracy: 0.9750 - val_loss: 2.0172 - val_accuracy: 0.4589\n",
            "Epoch 5644/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3756 - accuracy: 0.9750 - val_loss: 2.0170 - val_accuracy: 0.4588\n",
            "Epoch 5645/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3539 - accuracy: 0.9800 - val_loss: 2.0172 - val_accuracy: 0.4591\n",
            "Epoch 5646/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3437 - accuracy: 1.0000 - val_loss: 2.0170 - val_accuracy: 0.4591\n",
            "Epoch 5647/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3691 - accuracy: 0.9700 - val_loss: 2.0168 - val_accuracy: 0.4593\n",
            "Epoch 5648/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3592 - accuracy: 0.9700 - val_loss: 2.0170 - val_accuracy: 0.4589\n",
            "Epoch 5649/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4000 - accuracy: 0.9650 - val_loss: 2.0153 - val_accuracy: 0.4591\n",
            "Epoch 5650/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3671 - accuracy: 0.9700 - val_loss: 2.0157 - val_accuracy: 0.4593\n",
            "Epoch 5651/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3900 - accuracy: 0.9700 - val_loss: 2.0155 - val_accuracy: 0.4598\n",
            "Epoch 5652/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3801 - accuracy: 0.9650 - val_loss: 2.0160 - val_accuracy: 0.4592\n",
            "Epoch 5653/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3553 - accuracy: 0.9850 - val_loss: 2.0143 - val_accuracy: 0.4599\n",
            "Epoch 5654/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3565 - accuracy: 0.9900 - val_loss: 2.0149 - val_accuracy: 0.4596\n",
            "Epoch 5655/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4299 - accuracy: 0.9400 - val_loss: 2.0139 - val_accuracy: 0.4597\n",
            "Epoch 5656/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4345 - accuracy: 0.9500 - val_loss: 2.0146 - val_accuracy: 0.4597\n",
            "Epoch 5657/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3760 - accuracy: 0.9650 - val_loss: 2.0137 - val_accuracy: 0.4596\n",
            "Epoch 5658/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4623 - accuracy: 0.9250 - val_loss: 2.0146 - val_accuracy: 0.4595\n",
            "Epoch 5659/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4079 - accuracy: 0.9450 - val_loss: 2.0144 - val_accuracy: 0.4595\n",
            "Epoch 5660/6000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.3664 - accuracy: 0.9900 - val_loss: 2.0144 - val_accuracy: 0.4593\n",
            "Epoch 5661/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3971 - accuracy: 0.9600 - val_loss: 2.0129 - val_accuracy: 0.4590\n",
            "Epoch 5662/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3791 - accuracy: 0.9600 - val_loss: 2.0121 - val_accuracy: 0.4589\n",
            "Epoch 5663/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3877 - accuracy: 0.9450 - val_loss: 2.0116 - val_accuracy: 0.4592\n",
            "Epoch 5664/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3849 - accuracy: 0.9750 - val_loss: 2.0117 - val_accuracy: 0.4593\n",
            "Epoch 5665/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3635 - accuracy: 0.9800 - val_loss: 2.0108 - val_accuracy: 0.4595\n",
            "Epoch 5666/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3775 - accuracy: 0.9700 - val_loss: 2.0110 - val_accuracy: 0.4597\n",
            "Epoch 5667/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3678 - accuracy: 0.9800 - val_loss: 2.0102 - val_accuracy: 0.4595\n",
            "Epoch 5668/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3872 - accuracy: 0.9650 - val_loss: 2.0096 - val_accuracy: 0.4595\n",
            "Epoch 5669/6000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.3801 - accuracy: 0.9750 - val_loss: 2.0091 - val_accuracy: 0.4601\n",
            "Epoch 5670/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3765 - accuracy: 0.9700 - val_loss: 2.0090 - val_accuracy: 0.4606\n",
            "Epoch 5671/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3408 - accuracy: 0.9900 - val_loss: 2.0093 - val_accuracy: 0.4609\n",
            "Epoch 5672/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4160 - accuracy: 0.9600 - val_loss: 2.0096 - val_accuracy: 0.4605\n",
            "Epoch 5673/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3643 - accuracy: 0.9850 - val_loss: 2.0087 - val_accuracy: 0.4611\n",
            "Epoch 5674/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4340 - accuracy: 0.9400 - val_loss: 2.0084 - val_accuracy: 0.4607\n",
            "Epoch 5675/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3870 - accuracy: 0.9600 - val_loss: 2.0070 - val_accuracy: 0.4606\n",
            "Epoch 5676/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3554 - accuracy: 0.9700 - val_loss: 2.0071 - val_accuracy: 0.4612\n",
            "Epoch 5677/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3572 - accuracy: 0.9850 - val_loss: 2.0067 - val_accuracy: 0.4610\n",
            "Epoch 5678/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3782 - accuracy: 0.9650 - val_loss: 2.0072 - val_accuracy: 0.4611\n",
            "Epoch 5679/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3713 - accuracy: 0.9750 - val_loss: 2.0072 - val_accuracy: 0.4609\n",
            "Epoch 5680/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3522 - accuracy: 0.9800 - val_loss: 2.0063 - val_accuracy: 0.4611\n",
            "Epoch 5681/6000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.3842 - accuracy: 0.9700 - val_loss: 2.0062 - val_accuracy: 0.4615\n",
            "Epoch 5682/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3732 - accuracy: 0.9600 - val_loss: 2.0058 - val_accuracy: 0.4609\n",
            "Epoch 5683/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3603 - accuracy: 0.9800 - val_loss: 2.0049 - val_accuracy: 0.4611\n",
            "Epoch 5684/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3770 - accuracy: 0.9700 - val_loss: 2.0043 - val_accuracy: 0.4611\n",
            "Epoch 5685/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3670 - accuracy: 0.9800 - val_loss: 2.0043 - val_accuracy: 0.4610\n",
            "Epoch 5686/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3620 - accuracy: 0.9800 - val_loss: 2.0040 - val_accuracy: 0.4611\n",
            "Epoch 5687/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3989 - accuracy: 0.9700 - val_loss: 2.0051 - val_accuracy: 0.4612\n",
            "Epoch 5688/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4325 - accuracy: 0.9450 - val_loss: 2.0044 - val_accuracy: 0.4610\n",
            "Epoch 5689/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4284 - accuracy: 0.9500 - val_loss: 2.0041 - val_accuracy: 0.4611\n",
            "Epoch 5690/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3721 - accuracy: 0.9700 - val_loss: 2.0051 - val_accuracy: 0.4610\n",
            "Epoch 5691/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3440 - accuracy: 0.9850 - val_loss: 2.0050 - val_accuracy: 0.4609\n",
            "Epoch 5692/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3541 - accuracy: 0.9800 - val_loss: 2.0059 - val_accuracy: 0.4610\n",
            "Epoch 5693/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3486 - accuracy: 0.9800 - val_loss: 2.0060 - val_accuracy: 0.4613\n",
            "Epoch 5694/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3892 - accuracy: 0.9550 - val_loss: 2.0052 - val_accuracy: 0.4609\n",
            "Epoch 5695/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3624 - accuracy: 0.9850 - val_loss: 2.0052 - val_accuracy: 0.4610\n",
            "Epoch 5696/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3787 - accuracy: 0.9650 - val_loss: 2.0044 - val_accuracy: 0.4611\n",
            "Epoch 5697/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3830 - accuracy: 0.9700 - val_loss: 2.0047 - val_accuracy: 0.4613\n",
            "Epoch 5698/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3488 - accuracy: 0.9850 - val_loss: 2.0057 - val_accuracy: 0.4609\n",
            "Epoch 5699/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3782 - accuracy: 0.9750 - val_loss: 2.0062 - val_accuracy: 0.4612\n",
            "Epoch 5700/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3592 - accuracy: 0.9750 - val_loss: 2.0066 - val_accuracy: 0.4608\n",
            "Epoch 5701/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3667 - accuracy: 0.9600 - val_loss: 2.0073 - val_accuracy: 0.4606\n",
            "Epoch 5702/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3594 - accuracy: 0.9750 - val_loss: 2.0073 - val_accuracy: 0.4610\n",
            "Epoch 5703/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3606 - accuracy: 0.9750 - val_loss: 2.0079 - val_accuracy: 0.4606\n",
            "Epoch 5704/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3778 - accuracy: 0.9750 - val_loss: 2.0088 - val_accuracy: 0.4605\n",
            "Epoch 5705/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3701 - accuracy: 0.9750 - val_loss: 2.0085 - val_accuracy: 0.4607\n",
            "Epoch 5706/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3872 - accuracy: 0.9650 - val_loss: 2.0088 - val_accuracy: 0.4610\n",
            "Epoch 5707/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4018 - accuracy: 0.9600 - val_loss: 2.0092 - val_accuracy: 0.4608\n",
            "Epoch 5708/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3328 - accuracy: 0.9850 - val_loss: 2.0098 - val_accuracy: 0.4606\n",
            "Epoch 5709/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3811 - accuracy: 0.9750 - val_loss: 2.0097 - val_accuracy: 0.4610\n",
            "Epoch 5710/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3581 - accuracy: 0.9650 - val_loss: 2.0097 - val_accuracy: 0.4610\n",
            "Epoch 5711/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3672 - accuracy: 0.9650 - val_loss: 2.0094 - val_accuracy: 0.4606\n",
            "Epoch 5712/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3666 - accuracy: 0.9800 - val_loss: 2.0091 - val_accuracy: 0.4610\n",
            "Epoch 5713/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3831 - accuracy: 0.9650 - val_loss: 2.0096 - val_accuracy: 0.4609\n",
            "Epoch 5714/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3801 - accuracy: 0.9700 - val_loss: 2.0106 - val_accuracy: 0.4612\n",
            "Epoch 5715/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3770 - accuracy: 0.9750 - val_loss: 2.0097 - val_accuracy: 0.4614\n",
            "Epoch 5716/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3692 - accuracy: 0.9900 - val_loss: 2.0094 - val_accuracy: 0.4616\n",
            "Epoch 5717/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3666 - accuracy: 0.9550 - val_loss: 2.0095 - val_accuracy: 0.4611\n",
            "Epoch 5718/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3722 - accuracy: 0.9750 - val_loss: 2.0087 - val_accuracy: 0.4616\n",
            "Epoch 5719/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3601 - accuracy: 0.9650 - val_loss: 2.0077 - val_accuracy: 0.4618\n",
            "Epoch 5720/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3906 - accuracy: 0.9750 - val_loss: 2.0070 - val_accuracy: 0.4617\n",
            "Epoch 5721/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3602 - accuracy: 0.9550 - val_loss: 2.0067 - val_accuracy: 0.4618\n",
            "Epoch 5722/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3651 - accuracy: 0.9750 - val_loss: 2.0063 - val_accuracy: 0.4616\n",
            "Epoch 5723/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3809 - accuracy: 0.9800 - val_loss: 2.0075 - val_accuracy: 0.4613\n",
            "Epoch 5724/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4061 - accuracy: 0.9600 - val_loss: 2.0070 - val_accuracy: 0.4612\n",
            "Epoch 5725/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3994 - accuracy: 0.9550 - val_loss: 2.0070 - val_accuracy: 0.4614\n",
            "Epoch 5726/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3707 - accuracy: 0.9650 - val_loss: 2.0063 - val_accuracy: 0.4615\n",
            "Epoch 5727/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3760 - accuracy: 0.9800 - val_loss: 2.0062 - val_accuracy: 0.4618\n",
            "Epoch 5728/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3856 - accuracy: 0.9750 - val_loss: 2.0047 - val_accuracy: 0.4610\n",
            "Epoch 5729/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3650 - accuracy: 0.9650 - val_loss: 2.0036 - val_accuracy: 0.4607\n",
            "Epoch 5730/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3700 - accuracy: 0.9650 - val_loss: 2.0025 - val_accuracy: 0.4612\n",
            "Epoch 5731/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3894 - accuracy: 0.9550 - val_loss: 2.0019 - val_accuracy: 0.4609\n",
            "Epoch 5732/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4027 - accuracy: 0.9600 - val_loss: 2.0014 - val_accuracy: 0.4613\n",
            "Epoch 5733/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3694 - accuracy: 0.9800 - val_loss: 2.0010 - val_accuracy: 0.4616\n",
            "Epoch 5734/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3641 - accuracy: 0.9800 - val_loss: 2.0004 - val_accuracy: 0.4614\n",
            "Epoch 5735/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3902 - accuracy: 0.9650 - val_loss: 1.9995 - val_accuracy: 0.4618\n",
            "Epoch 5736/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3691 - accuracy: 0.9700 - val_loss: 1.9988 - val_accuracy: 0.4618\n",
            "Epoch 5737/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3782 - accuracy: 0.9700 - val_loss: 1.9978 - val_accuracy: 0.4623\n",
            "Epoch 5738/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3580 - accuracy: 0.9700 - val_loss: 1.9985 - val_accuracy: 0.4621\n",
            "Epoch 5739/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3503 - accuracy: 0.9800 - val_loss: 1.9982 - val_accuracy: 0.4619\n",
            "Epoch 5740/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3668 - accuracy: 0.9850 - val_loss: 1.9980 - val_accuracy: 0.4614\n",
            "Epoch 5741/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3935 - accuracy: 0.9650 - val_loss: 1.9987 - val_accuracy: 0.4612\n",
            "Epoch 5742/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.3144 - accuracy: 0.9900 - val_loss: 1.9987 - val_accuracy: 0.4612\n",
            "Epoch 5743/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4089 - accuracy: 0.9550 - val_loss: 1.9985 - val_accuracy: 0.4615\n",
            "Epoch 5744/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3636 - accuracy: 0.9800 - val_loss: 1.9995 - val_accuracy: 0.4611\n",
            "Epoch 5745/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3516 - accuracy: 0.9800 - val_loss: 2.0000 - val_accuracy: 0.4611\n",
            "Epoch 5746/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3749 - accuracy: 0.9750 - val_loss: 1.9986 - val_accuracy: 0.4614\n",
            "Epoch 5747/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3718 - accuracy: 0.9800 - val_loss: 1.9992 - val_accuracy: 0.4613\n",
            "Epoch 5748/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3588 - accuracy: 0.9700 - val_loss: 1.9993 - val_accuracy: 0.4616\n",
            "Epoch 5749/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3630 - accuracy: 0.9650 - val_loss: 2.0012 - val_accuracy: 0.4617\n",
            "Epoch 5750/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3548 - accuracy: 0.9900 - val_loss: 2.0024 - val_accuracy: 0.4616\n",
            "Epoch 5751/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3658 - accuracy: 0.9850 - val_loss: 2.0025 - val_accuracy: 0.4617\n",
            "Epoch 5752/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4004 - accuracy: 0.9650 - val_loss: 2.0036 - val_accuracy: 0.4615\n",
            "Epoch 5753/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3521 - accuracy: 0.9850 - val_loss: 2.0039 - val_accuracy: 0.4613\n",
            "Epoch 5754/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3933 - accuracy: 0.9700 - val_loss: 2.0046 - val_accuracy: 0.4608\n",
            "Epoch 5755/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3768 - accuracy: 0.9650 - val_loss: 2.0060 - val_accuracy: 0.4605\n",
            "Epoch 5756/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3701 - accuracy: 0.9550 - val_loss: 2.0071 - val_accuracy: 0.4605\n",
            "Epoch 5757/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3652 - accuracy: 0.9750 - val_loss: 2.0062 - val_accuracy: 0.4603\n",
            "Epoch 5758/6000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4111 - accuracy: 0.9700 - val_loss: 2.0053 - val_accuracy: 0.4606\n",
            "Epoch 5759/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3798 - accuracy: 0.9800 - val_loss: 2.0048 - val_accuracy: 0.4607\n",
            "Epoch 5760/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4049 - accuracy: 0.9400 - val_loss: 2.0048 - val_accuracy: 0.4604\n",
            "Epoch 5761/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3887 - accuracy: 0.9650 - val_loss: 2.0050 - val_accuracy: 0.4607\n",
            "Epoch 5762/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3513 - accuracy: 0.9800 - val_loss: 2.0043 - val_accuracy: 0.4605\n",
            "Epoch 5763/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4290 - accuracy: 0.9500 - val_loss: 2.0053 - val_accuracy: 0.4602\n",
            "Epoch 5764/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3849 - accuracy: 0.9600 - val_loss: 2.0054 - val_accuracy: 0.4608\n",
            "Epoch 5765/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3787 - accuracy: 0.9700 - val_loss: 2.0043 - val_accuracy: 0.4608\n",
            "Epoch 5766/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3849 - accuracy: 0.9750 - val_loss: 2.0037 - val_accuracy: 0.4607\n",
            "Epoch 5767/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3586 - accuracy: 0.9800 - val_loss: 2.0038 - val_accuracy: 0.4610\n",
            "Epoch 5768/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.3660 - accuracy: 0.9700 - val_loss: 2.0028 - val_accuracy: 0.4610\n",
            "Epoch 5769/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4053 - accuracy: 0.9550 - val_loss: 2.0021 - val_accuracy: 0.4613\n",
            "Epoch 5770/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3539 - accuracy: 0.9800 - val_loss: 2.0016 - val_accuracy: 0.4614\n",
            "Epoch 5771/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4459 - accuracy: 0.9350 - val_loss: 2.0029 - val_accuracy: 0.4611\n",
            "Epoch 5772/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3508 - accuracy: 0.9600 - val_loss: 2.0025 - val_accuracy: 0.4612\n",
            "Epoch 5773/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4044 - accuracy: 0.9550 - val_loss: 2.0025 - val_accuracy: 0.4616\n",
            "Epoch 5774/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3697 - accuracy: 0.9750 - val_loss: 2.0023 - val_accuracy: 0.4615\n",
            "Epoch 5775/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3629 - accuracy: 0.9850 - val_loss: 2.0019 - val_accuracy: 0.4621\n",
            "Epoch 5776/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3765 - accuracy: 0.9650 - val_loss: 2.0015 - val_accuracy: 0.4623\n",
            "Epoch 5777/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3734 - accuracy: 0.9700 - val_loss: 2.0026 - val_accuracy: 0.4619\n",
            "Epoch 5778/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3599 - accuracy: 0.9600 - val_loss: 2.0031 - val_accuracy: 0.4620\n",
            "Epoch 5779/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3452 - accuracy: 0.9850 - val_loss: 2.0029 - val_accuracy: 0.4620\n",
            "Epoch 5780/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3419 - accuracy: 0.9900 - val_loss: 2.0030 - val_accuracy: 0.4621\n",
            "Epoch 5781/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3487 - accuracy: 0.9700 - val_loss: 2.0021 - val_accuracy: 0.4622\n",
            "Epoch 5782/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3795 - accuracy: 0.9600 - val_loss: 2.0013 - val_accuracy: 0.4625\n",
            "Epoch 5783/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3916 - accuracy: 0.9750 - val_loss: 2.0001 - val_accuracy: 0.4629\n",
            "Epoch 5784/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3699 - accuracy: 0.9550 - val_loss: 2.0003 - val_accuracy: 0.4631\n",
            "Epoch 5785/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3582 - accuracy: 0.9800 - val_loss: 1.9993 - val_accuracy: 0.4632\n",
            "Epoch 5786/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3429 - accuracy: 0.9900 - val_loss: 1.9987 - val_accuracy: 0.4630\n",
            "Epoch 5787/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3715 - accuracy: 0.9750 - val_loss: 1.9995 - val_accuracy: 0.4629\n",
            "Epoch 5788/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4123 - accuracy: 0.9600 - val_loss: 1.9991 - val_accuracy: 0.4636\n",
            "Epoch 5789/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3791 - accuracy: 0.9800 - val_loss: 1.9989 - val_accuracy: 0.4643\n",
            "Epoch 5790/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3307 - accuracy: 0.9950 - val_loss: 1.9993 - val_accuracy: 0.4644\n",
            "Epoch 5791/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3397 - accuracy: 0.9800 - val_loss: 2.0003 - val_accuracy: 0.4641\n",
            "Epoch 5792/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3596 - accuracy: 0.9750 - val_loss: 1.9995 - val_accuracy: 0.4640\n",
            "Epoch 5793/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3730 - accuracy: 0.9650 - val_loss: 1.9996 - val_accuracy: 0.4640\n",
            "Epoch 5794/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3878 - accuracy: 0.9500 - val_loss: 1.9994 - val_accuracy: 0.4637\n",
            "Epoch 5795/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3775 - accuracy: 0.9750 - val_loss: 2.0000 - val_accuracy: 0.4638\n",
            "Epoch 5796/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3904 - accuracy: 0.9600 - val_loss: 2.0003 - val_accuracy: 0.4638\n",
            "Epoch 5797/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3705 - accuracy: 0.9650 - val_loss: 2.0011 - val_accuracy: 0.4631\n",
            "Epoch 5798/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3910 - accuracy: 0.9650 - val_loss: 2.0011 - val_accuracy: 0.4631\n",
            "Epoch 5799/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3582 - accuracy: 0.9700 - val_loss: 2.0005 - val_accuracy: 0.4626\n",
            "Epoch 5800/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3681 - accuracy: 0.9650 - val_loss: 1.9997 - val_accuracy: 0.4632\n",
            "Epoch 5801/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3831 - accuracy: 0.9800 - val_loss: 1.9991 - val_accuracy: 0.4632\n",
            "Epoch 5802/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3840 - accuracy: 0.9800 - val_loss: 1.9983 - val_accuracy: 0.4642\n",
            "Epoch 5803/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3805 - accuracy: 0.9700 - val_loss: 1.9985 - val_accuracy: 0.4637\n",
            "Epoch 5804/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3714 - accuracy: 0.9550 - val_loss: 1.9993 - val_accuracy: 0.4637\n",
            "Epoch 5805/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3489 - accuracy: 0.9700 - val_loss: 1.9998 - val_accuracy: 0.4634\n",
            "Epoch 5806/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3648 - accuracy: 0.9750 - val_loss: 1.9998 - val_accuracy: 0.4635\n",
            "Epoch 5807/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3440 - accuracy: 0.9800 - val_loss: 1.9999 - val_accuracy: 0.4636\n",
            "Epoch 5808/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3798 - accuracy: 0.9650 - val_loss: 2.0001 - val_accuracy: 0.4633\n",
            "Epoch 5809/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3599 - accuracy: 0.9750 - val_loss: 2.0001 - val_accuracy: 0.4633\n",
            "Epoch 5810/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3445 - accuracy: 0.9800 - val_loss: 2.0004 - val_accuracy: 0.4634\n",
            "Epoch 5811/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3906 - accuracy: 0.9550 - val_loss: 2.0019 - val_accuracy: 0.4633\n",
            "Epoch 5812/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3958 - accuracy: 0.9750 - val_loss: 2.0014 - val_accuracy: 0.4635\n",
            "Epoch 5813/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3806 - accuracy: 0.9750 - val_loss: 2.0016 - val_accuracy: 0.4634\n",
            "Epoch 5814/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3273 - accuracy: 0.9950 - val_loss: 2.0015 - val_accuracy: 0.4632\n",
            "Epoch 5815/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.3308 - accuracy: 0.9950 - val_loss: 2.0021 - val_accuracy: 0.4630\n",
            "Epoch 5816/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3574 - accuracy: 0.9800 - val_loss: 2.0019 - val_accuracy: 0.4634\n",
            "Epoch 5817/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4055 - accuracy: 0.9550 - val_loss: 2.0023 - val_accuracy: 0.4634\n",
            "Epoch 5818/6000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4425 - accuracy: 0.9350 - val_loss: 2.0036 - val_accuracy: 0.4632\n",
            "Epoch 5819/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3646 - accuracy: 0.9750 - val_loss: 2.0053 - val_accuracy: 0.4631\n",
            "Epoch 5820/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3554 - accuracy: 0.9800 - val_loss: 2.0056 - val_accuracy: 0.4629\n",
            "Epoch 5821/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3910 - accuracy: 0.9650 - val_loss: 2.0052 - val_accuracy: 0.4631\n",
            "Epoch 5822/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3705 - accuracy: 0.9700 - val_loss: 2.0053 - val_accuracy: 0.4629\n",
            "Epoch 5823/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3679 - accuracy: 0.9700 - val_loss: 2.0061 - val_accuracy: 0.4627\n",
            "Epoch 5824/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3908 - accuracy: 0.9850 - val_loss: 2.0056 - val_accuracy: 0.4630\n",
            "Epoch 5825/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3551 - accuracy: 0.9800 - val_loss: 2.0066 - val_accuracy: 0.4632\n",
            "Epoch 5826/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3694 - accuracy: 0.9700 - val_loss: 2.0067 - val_accuracy: 0.4630\n",
            "Epoch 5827/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3967 - accuracy: 0.9500 - val_loss: 2.0067 - val_accuracy: 0.4634\n",
            "Epoch 5828/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3640 - accuracy: 0.9600 - val_loss: 2.0067 - val_accuracy: 0.4636\n",
            "Epoch 5829/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3831 - accuracy: 0.9650 - val_loss: 2.0072 - val_accuracy: 0.4633\n",
            "Epoch 5830/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3612 - accuracy: 0.9750 - val_loss: 2.0071 - val_accuracy: 0.4633\n",
            "Epoch 5831/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3746 - accuracy: 0.9500 - val_loss: 2.0071 - val_accuracy: 0.4633\n",
            "Epoch 5832/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3925 - accuracy: 0.9550 - val_loss: 2.0074 - val_accuracy: 0.4632\n",
            "Epoch 5833/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3717 - accuracy: 0.9500 - val_loss: 2.0072 - val_accuracy: 0.4632\n",
            "Epoch 5834/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3336 - accuracy: 0.9800 - val_loss: 2.0084 - val_accuracy: 0.4633\n",
            "Epoch 5835/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3700 - accuracy: 0.9650 - val_loss: 2.0091 - val_accuracy: 0.4627\n",
            "Epoch 5836/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3722 - accuracy: 0.9700 - val_loss: 2.0089 - val_accuracy: 0.4630\n",
            "Epoch 5837/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3629 - accuracy: 0.9750 - val_loss: 2.0090 - val_accuracy: 0.4630\n",
            "Epoch 5838/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3735 - accuracy: 0.9750 - val_loss: 2.0084 - val_accuracy: 0.4636\n",
            "Epoch 5839/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3899 - accuracy: 0.9550 - val_loss: 2.0084 - val_accuracy: 0.4633\n",
            "Epoch 5840/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3866 - accuracy: 0.9600 - val_loss: 2.0090 - val_accuracy: 0.4633\n",
            "Epoch 5841/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4134 - accuracy: 0.9500 - val_loss: 2.0103 - val_accuracy: 0.4623\n",
            "Epoch 5842/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3863 - accuracy: 0.9650 - val_loss: 2.0102 - val_accuracy: 0.4626\n",
            "Epoch 5843/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3808 - accuracy: 0.9500 - val_loss: 2.0103 - val_accuracy: 0.4624\n",
            "Epoch 5844/6000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.3736 - accuracy: 0.9700 - val_loss: 2.0108 - val_accuracy: 0.4624\n",
            "Epoch 5845/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3490 - accuracy: 0.9650 - val_loss: 2.0122 - val_accuracy: 0.4619\n",
            "Epoch 5846/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3922 - accuracy: 0.9650 - val_loss: 2.0136 - val_accuracy: 0.4616\n",
            "Epoch 5847/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3490 - accuracy: 0.9700 - val_loss: 2.0145 - val_accuracy: 0.4617\n",
            "Epoch 5848/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4134 - accuracy: 0.9350 - val_loss: 2.0147 - val_accuracy: 0.4615\n",
            "Epoch 5849/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.3761 - accuracy: 0.9700 - val_loss: 2.0165 - val_accuracy: 0.4615\n",
            "Epoch 5850/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4022 - accuracy: 0.9450 - val_loss: 2.0172 - val_accuracy: 0.4614\n",
            "Epoch 5851/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3951 - accuracy: 0.9450 - val_loss: 2.0172 - val_accuracy: 0.4618\n",
            "Epoch 5852/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3896 - accuracy: 0.9700 - val_loss: 2.0176 - val_accuracy: 0.4616\n",
            "Epoch 5853/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4182 - accuracy: 0.9600 - val_loss: 2.0179 - val_accuracy: 0.4615\n",
            "Epoch 5854/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3533 - accuracy: 0.9800 - val_loss: 2.0175 - val_accuracy: 0.4616\n",
            "Epoch 5855/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3635 - accuracy: 0.9700 - val_loss: 2.0167 - val_accuracy: 0.4613\n",
            "Epoch 5856/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3274 - accuracy: 0.9950 - val_loss: 2.0159 - val_accuracy: 0.4618\n",
            "Epoch 5857/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3638 - accuracy: 0.9700 - val_loss: 2.0155 - val_accuracy: 0.4616\n",
            "Epoch 5858/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3909 - accuracy: 0.9750 - val_loss: 2.0149 - val_accuracy: 0.4619\n",
            "Epoch 5859/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3937 - accuracy: 0.9700 - val_loss: 2.0152 - val_accuracy: 0.4619\n",
            "Epoch 5860/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3448 - accuracy: 0.9900 - val_loss: 2.0160 - val_accuracy: 0.4617\n",
            "Epoch 5861/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3745 - accuracy: 0.9700 - val_loss: 2.0161 - val_accuracy: 0.4617\n",
            "Epoch 5862/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3973 - accuracy: 0.9650 - val_loss: 2.0168 - val_accuracy: 0.4614\n",
            "Epoch 5863/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3708 - accuracy: 0.9800 - val_loss: 2.0162 - val_accuracy: 0.4613\n",
            "Epoch 5864/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3871 - accuracy: 0.9450 - val_loss: 2.0150 - val_accuracy: 0.4618\n",
            "Epoch 5865/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3713 - accuracy: 0.9750 - val_loss: 2.0143 - val_accuracy: 0.4617\n",
            "Epoch 5866/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3788 - accuracy: 0.9650 - val_loss: 2.0150 - val_accuracy: 0.4617\n",
            "Epoch 5867/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3650 - accuracy: 0.9650 - val_loss: 2.0146 - val_accuracy: 0.4617\n",
            "Epoch 5868/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3734 - accuracy: 0.9700 - val_loss: 2.0151 - val_accuracy: 0.4619\n",
            "Epoch 5869/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3615 - accuracy: 0.9700 - val_loss: 2.0152 - val_accuracy: 0.4621\n",
            "Epoch 5870/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3946 - accuracy: 0.9600 - val_loss: 2.0154 - val_accuracy: 0.4618\n",
            "Epoch 5871/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3773 - accuracy: 0.9850 - val_loss: 2.0153 - val_accuracy: 0.4619\n",
            "Epoch 5872/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3736 - accuracy: 0.9750 - val_loss: 2.0141 - val_accuracy: 0.4621\n",
            "Epoch 5873/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3403 - accuracy: 0.9800 - val_loss: 2.0139 - val_accuracy: 0.4625\n",
            "Epoch 5874/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3353 - accuracy: 0.9800 - val_loss: 2.0137 - val_accuracy: 0.4627\n",
            "Epoch 5875/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3592 - accuracy: 0.9800 - val_loss: 2.0138 - val_accuracy: 0.4627\n",
            "Epoch 5876/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3634 - accuracy: 0.9700 - val_loss: 2.0136 - val_accuracy: 0.4627\n",
            "Epoch 5877/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3827 - accuracy: 0.9650 - val_loss: 2.0137 - val_accuracy: 0.4623\n",
            "Epoch 5878/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3723 - accuracy: 0.9600 - val_loss: 2.0143 - val_accuracy: 0.4623\n",
            "Epoch 5879/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4008 - accuracy: 0.9650 - val_loss: 2.0153 - val_accuracy: 0.4619\n",
            "Epoch 5880/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3846 - accuracy: 0.9550 - val_loss: 2.0148 - val_accuracy: 0.4624\n",
            "Epoch 5881/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3657 - accuracy: 0.9600 - val_loss: 2.0138 - val_accuracy: 0.4624\n",
            "Epoch 5882/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3607 - accuracy: 0.9600 - val_loss: 2.0131 - val_accuracy: 0.4626\n",
            "Epoch 5883/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3469 - accuracy: 0.9700 - val_loss: 2.0130 - val_accuracy: 0.4633\n",
            "Epoch 5884/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3819 - accuracy: 0.9550 - val_loss: 2.0126 - val_accuracy: 0.4636\n",
            "Epoch 5885/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4183 - accuracy: 0.9600 - val_loss: 2.0142 - val_accuracy: 0.4628\n",
            "Epoch 5886/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3439 - accuracy: 0.9850 - val_loss: 2.0142 - val_accuracy: 0.4630\n",
            "Epoch 5887/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3228 - accuracy: 0.9950 - val_loss: 2.0131 - val_accuracy: 0.4640\n",
            "Epoch 5888/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3955 - accuracy: 0.9550 - val_loss: 2.0140 - val_accuracy: 0.4637\n",
            "Epoch 5889/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3565 - accuracy: 0.9800 - val_loss: 2.0130 - val_accuracy: 0.4639\n",
            "Epoch 5890/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3418 - accuracy: 0.9700 - val_loss: 2.0128 - val_accuracy: 0.4640\n",
            "Epoch 5891/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4046 - accuracy: 0.9550 - val_loss: 2.0126 - val_accuracy: 0.4643\n",
            "Epoch 5892/6000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3483 - accuracy: 0.9700 - val_loss: 2.0129 - val_accuracy: 0.4641\n",
            "Epoch 5893/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3549 - accuracy: 0.9800 - val_loss: 2.0137 - val_accuracy: 0.4638\n",
            "Epoch 5894/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3604 - accuracy: 0.9800 - val_loss: 2.0146 - val_accuracy: 0.4631\n",
            "Epoch 5895/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3657 - accuracy: 0.9750 - val_loss: 2.0142 - val_accuracy: 0.4638\n",
            "Epoch 5896/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3844 - accuracy: 0.9600 - val_loss: 2.0145 - val_accuracy: 0.4636\n",
            "Epoch 5897/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3766 - accuracy: 0.9650 - val_loss: 2.0149 - val_accuracy: 0.4637\n",
            "Epoch 5898/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3667 - accuracy: 0.9850 - val_loss: 2.0153 - val_accuracy: 0.4638\n",
            "Epoch 5899/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3688 - accuracy: 0.9750 - val_loss: 2.0162 - val_accuracy: 0.4638\n",
            "Epoch 5900/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4041 - accuracy: 0.9550 - val_loss: 2.0158 - val_accuracy: 0.4640\n",
            "Epoch 5901/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3408 - accuracy: 0.9750 - val_loss: 2.0154 - val_accuracy: 0.4638\n",
            "Epoch 5902/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3643 - accuracy: 0.9750 - val_loss: 2.0165 - val_accuracy: 0.4634\n",
            "Epoch 5903/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3501 - accuracy: 0.9800 - val_loss: 2.0169 - val_accuracy: 0.4632\n",
            "Epoch 5904/6000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.3615 - accuracy: 0.9600 - val_loss: 2.0173 - val_accuracy: 0.4629\n",
            "Epoch 5905/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3991 - accuracy: 0.9600 - val_loss: 2.0180 - val_accuracy: 0.4632\n",
            "Epoch 5906/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3703 - accuracy: 0.9650 - val_loss: 2.0187 - val_accuracy: 0.4626\n",
            "Epoch 5907/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3598 - accuracy: 0.9750 - val_loss: 2.0195 - val_accuracy: 0.4625\n",
            "Epoch 5908/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3649 - accuracy: 0.9800 - val_loss: 2.0208 - val_accuracy: 0.4621\n",
            "Epoch 5909/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3751 - accuracy: 0.9650 - val_loss: 2.0221 - val_accuracy: 0.4618\n",
            "Epoch 5910/6000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.3849 - accuracy: 0.9750 - val_loss: 2.0207 - val_accuracy: 0.4620\n",
            "Epoch 5911/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3728 - accuracy: 0.9650 - val_loss: 2.0218 - val_accuracy: 0.4617\n",
            "Epoch 5912/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3879 - accuracy: 0.9700 - val_loss: 2.0223 - val_accuracy: 0.4618\n",
            "Epoch 5913/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3698 - accuracy: 0.9750 - val_loss: 2.0220 - val_accuracy: 0.4622\n",
            "Epoch 5914/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3635 - accuracy: 0.9750 - val_loss: 2.0230 - val_accuracy: 0.4619\n",
            "Epoch 5915/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3211 - accuracy: 0.9900 - val_loss: 2.0227 - val_accuracy: 0.4621\n",
            "Epoch 5916/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3803 - accuracy: 0.9750 - val_loss: 2.0234 - val_accuracy: 0.4622\n",
            "Epoch 5917/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3380 - accuracy: 0.9850 - val_loss: 2.0234 - val_accuracy: 0.4619\n",
            "Epoch 5918/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3858 - accuracy: 0.9600 - val_loss: 2.0226 - val_accuracy: 0.4618\n",
            "Epoch 5919/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3675 - accuracy: 0.9750 - val_loss: 2.0235 - val_accuracy: 0.4619\n",
            "Epoch 5920/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3732 - accuracy: 0.9800 - val_loss: 2.0230 - val_accuracy: 0.4619\n",
            "Epoch 5921/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3645 - accuracy: 0.9650 - val_loss: 2.0222 - val_accuracy: 0.4620\n",
            "Epoch 5922/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3532 - accuracy: 0.9750 - val_loss: 2.0217 - val_accuracy: 0.4621\n",
            "Epoch 5923/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.3652 - accuracy: 0.9650 - val_loss: 2.0205 - val_accuracy: 0.4625\n",
            "Epoch 5924/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3649 - accuracy: 0.9750 - val_loss: 2.0206 - val_accuracy: 0.4625\n",
            "Epoch 5925/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3669 - accuracy: 0.9700 - val_loss: 2.0202 - val_accuracy: 0.4624\n",
            "Epoch 5926/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3462 - accuracy: 0.9700 - val_loss: 2.0202 - val_accuracy: 0.4622\n",
            "Epoch 5927/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3236 - accuracy: 0.9950 - val_loss: 2.0196 - val_accuracy: 0.4627\n",
            "Epoch 5928/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3453 - accuracy: 0.9850 - val_loss: 2.0193 - val_accuracy: 0.4626\n",
            "Epoch 5929/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4001 - accuracy: 0.9500 - val_loss: 2.0201 - val_accuracy: 0.4623\n",
            "Epoch 5930/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3445 - accuracy: 0.9850 - val_loss: 2.0194 - val_accuracy: 0.4633\n",
            "Epoch 5931/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3264 - accuracy: 0.9950 - val_loss: 2.0189 - val_accuracy: 0.4638\n",
            "Epoch 5932/6000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3655 - accuracy: 0.9750 - val_loss: 2.0176 - val_accuracy: 0.4635\n",
            "Epoch 5933/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3813 - accuracy: 0.9500 - val_loss: 2.0162 - val_accuracy: 0.4637\n",
            "Epoch 5934/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3734 - accuracy: 0.9750 - val_loss: 2.0150 - val_accuracy: 0.4641\n",
            "Epoch 5935/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3420 - accuracy: 0.9850 - val_loss: 2.0150 - val_accuracy: 0.4642\n",
            "Epoch 5936/6000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3490 - accuracy: 0.9900 - val_loss: 2.0151 - val_accuracy: 0.4644\n",
            "Epoch 5937/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3150 - accuracy: 0.9950 - val_loss: 2.0139 - val_accuracy: 0.4645\n",
            "Epoch 5938/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3518 - accuracy: 0.9700 - val_loss: 2.0127 - val_accuracy: 0.4644\n",
            "Epoch 5939/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3450 - accuracy: 0.9750 - val_loss: 2.0110 - val_accuracy: 0.4644\n",
            "Epoch 5940/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3314 - accuracy: 0.9950 - val_loss: 2.0102 - val_accuracy: 0.4643\n",
            "Epoch 5941/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3389 - accuracy: 0.9800 - val_loss: 2.0107 - val_accuracy: 0.4640\n",
            "Epoch 5942/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3691 - accuracy: 0.9700 - val_loss: 2.0102 - val_accuracy: 0.4639\n",
            "Epoch 5943/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3602 - accuracy: 0.9800 - val_loss: 2.0110 - val_accuracy: 0.4637\n",
            "Epoch 5944/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3284 - accuracy: 0.9850 - val_loss: 2.0101 - val_accuracy: 0.4641\n",
            "Epoch 5945/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3608 - accuracy: 0.9800 - val_loss: 2.0093 - val_accuracy: 0.4642\n",
            "Epoch 5946/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3553 - accuracy: 0.9850 - val_loss: 2.0091 - val_accuracy: 0.4642\n",
            "Epoch 5947/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3847 - accuracy: 0.9700 - val_loss: 2.0098 - val_accuracy: 0.4648\n",
            "Epoch 5948/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3349 - accuracy: 0.9750 - val_loss: 2.0097 - val_accuracy: 0.4643\n",
            "Epoch 5949/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3287 - accuracy: 0.9850 - val_loss: 2.0105 - val_accuracy: 0.4639\n",
            "Epoch 5950/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3879 - accuracy: 0.9650 - val_loss: 2.0107 - val_accuracy: 0.4645\n",
            "Epoch 5951/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3125 - accuracy: 0.9950 - val_loss: 2.0112 - val_accuracy: 0.4647\n",
            "Epoch 5952/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3557 - accuracy: 0.9500 - val_loss: 2.0117 - val_accuracy: 0.4645\n",
            "Epoch 5953/6000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.3339 - accuracy: 0.9850 - val_loss: 2.0116 - val_accuracy: 0.4646\n",
            "Epoch 5954/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3651 - accuracy: 0.9600 - val_loss: 2.0127 - val_accuracy: 0.4644\n",
            "Epoch 5955/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3309 - accuracy: 0.9950 - val_loss: 2.0131 - val_accuracy: 0.4645\n",
            "Epoch 5956/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3833 - accuracy: 0.9700 - val_loss: 2.0140 - val_accuracy: 0.4637\n",
            "Epoch 5957/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3402 - accuracy: 0.9850 - val_loss: 2.0140 - val_accuracy: 0.4636\n",
            "Epoch 5958/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3829 - accuracy: 0.9700 - val_loss: 2.0127 - val_accuracy: 0.4643\n",
            "Epoch 5959/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3615 - accuracy: 0.9750 - val_loss: 2.0122 - val_accuracy: 0.4644\n",
            "Epoch 5960/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3692 - accuracy: 0.9800 - val_loss: 2.0129 - val_accuracy: 0.4643\n",
            "Epoch 5961/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4027 - accuracy: 0.9550 - val_loss: 2.0131 - val_accuracy: 0.4645\n",
            "Epoch 5962/6000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3485 - accuracy: 0.9750 - val_loss: 2.0131 - val_accuracy: 0.4645\n",
            "Epoch 5963/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3775 - accuracy: 0.9700 - val_loss: 2.0142 - val_accuracy: 0.4639\n",
            "Epoch 5964/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3484 - accuracy: 0.9800 - val_loss: 2.0133 - val_accuracy: 0.4637\n",
            "Epoch 5965/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3757 - accuracy: 0.9700 - val_loss: 2.0134 - val_accuracy: 0.4634\n",
            "Epoch 5966/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3839 - accuracy: 0.9700 - val_loss: 2.0135 - val_accuracy: 0.4635\n",
            "Epoch 5967/6000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3513 - accuracy: 0.9700 - val_loss: 2.0129 - val_accuracy: 0.4635\n",
            "Epoch 5968/6000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.3748 - accuracy: 0.9600 - val_loss: 2.0135 - val_accuracy: 0.4631\n",
            "Epoch 5969/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3798 - accuracy: 0.9800 - val_loss: 2.0137 - val_accuracy: 0.4623\n",
            "Epoch 5970/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3206 - accuracy: 0.9750 - val_loss: 2.0137 - val_accuracy: 0.4624\n",
            "Epoch 5971/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3688 - accuracy: 0.9550 - val_loss: 2.0134 - val_accuracy: 0.4629\n",
            "Epoch 5972/6000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.3860 - accuracy: 0.9650 - val_loss: 2.0134 - val_accuracy: 0.4631\n",
            "Epoch 5973/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3715 - accuracy: 0.9700 - val_loss: 2.0120 - val_accuracy: 0.4629\n",
            "Epoch 5974/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3583 - accuracy: 0.9650 - val_loss: 2.0128 - val_accuracy: 0.4631\n",
            "Epoch 5975/6000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3660 - accuracy: 0.9700 - val_loss: 2.0126 - val_accuracy: 0.4633\n",
            "Epoch 5976/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3743 - accuracy: 0.9700 - val_loss: 2.0138 - val_accuracy: 0.4632\n",
            "Epoch 5977/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3508 - accuracy: 0.9700 - val_loss: 2.0137 - val_accuracy: 0.4632\n",
            "Epoch 5978/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3950 - accuracy: 0.9550 - val_loss: 2.0132 - val_accuracy: 0.4630\n",
            "Epoch 5979/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3375 - accuracy: 0.9750 - val_loss: 2.0132 - val_accuracy: 0.4634\n",
            "Epoch 5980/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3691 - accuracy: 0.9650 - val_loss: 2.0126 - val_accuracy: 0.4632\n",
            "Epoch 5981/6000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.3848 - accuracy: 0.9600 - val_loss: 2.0125 - val_accuracy: 0.4631\n",
            "Epoch 5982/6000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.3994 - accuracy: 0.9550 - val_loss: 2.0120 - val_accuracy: 0.4632\n",
            "Epoch 5983/6000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.3588 - accuracy: 0.9800 - val_loss: 2.0120 - val_accuracy: 0.4629\n",
            "Epoch 5984/6000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.3650 - accuracy: 0.9750 - val_loss: 2.0118 - val_accuracy: 0.4630\n",
            "Epoch 5985/6000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3669 - accuracy: 0.9600 - val_loss: 2.0112 - val_accuracy: 0.4629\n",
            "Epoch 5986/6000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3589 - accuracy: 0.9850 - val_loss: 2.0114 - val_accuracy: 0.4630\n",
            "Epoch 5987/6000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3774 - accuracy: 0.9700 - val_loss: 2.0118 - val_accuracy: 0.4631\n",
            "Epoch 5988/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3560 - accuracy: 0.9750 - val_loss: 2.0124 - val_accuracy: 0.4626\n",
            "Epoch 5989/6000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3608 - accuracy: 0.9800 - val_loss: 2.0129 - val_accuracy: 0.4625\n",
            "Epoch 5990/6000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3262 - accuracy: 0.9750 - val_loss: 2.0136 - val_accuracy: 0.4624\n",
            "Epoch 5991/6000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.3358 - accuracy: 0.9900 - val_loss: 2.0127 - val_accuracy: 0.4626\n",
            "Epoch 5992/6000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3510 - accuracy: 0.9800 - val_loss: 2.0138 - val_accuracy: 0.4621\n",
            "Epoch 5993/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3676 - accuracy: 0.9750 - val_loss: 2.0148 - val_accuracy: 0.4620\n",
            "Epoch 5994/6000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3611 - accuracy: 0.9750 - val_loss: 2.0147 - val_accuracy: 0.4619\n",
            "Epoch 5995/6000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3599 - accuracy: 0.9750 - val_loss: 2.0151 - val_accuracy: 0.4622\n",
            "Epoch 5996/6000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3173 - accuracy: 0.9950 - val_loss: 2.0155 - val_accuracy: 0.4620\n",
            "Epoch 5997/6000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.3330 - accuracy: 0.9850 - val_loss: 2.0159 - val_accuracy: 0.4617\n",
            "Epoch 5998/6000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3693 - accuracy: 0.9750 - val_loss: 2.0165 - val_accuracy: 0.4616\n",
            "Epoch 5999/6000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3781 - accuracy: 0.9750 - val_loss: 2.0181 - val_accuracy: 0.4610\n",
            "Epoch 6000/6000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.3404 - accuracy: 0.9950 - val_loss: 2.0192 - val_accuracy: 0.4613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "moBdHLG4_Av-",
        "outputId": "45837f65-1002-4f7f-fbd0-ff17b0a13b7c"
      },
      "source": [
        "# show result\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range((len(acc)))\n",
        "\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}